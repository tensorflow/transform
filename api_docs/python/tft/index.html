
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../../../tft_bestpractices/">
      
      
        <link rel="next" href="../tft-coders/">
      
      
      <link rel="icon" href="../../../images/tf_full_color_primary_icon.svg">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.16">
    
    
      
        <title>tft - TensorFlow Data Transform</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.7e37652d.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="custom">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#tensorflow-transform-tft-module" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="TensorFlow Data Transform" class="md-header__button md-logo" aria-label="TensorFlow Data Transform" data-md-component="logo">
      
  <img src="../../../images/tf_full_color_primary_icon.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            TensorFlow Data Transform
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              tft
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="custom"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="custom"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="custom" data-md-color-accent="custom"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/tensorflow/transform" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    transform
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="TensorFlow Data Transform" class="md-nav__button md-logo" aria-label="TensorFlow Data Transform" data-md-component="logo">
      
  <img src="../../../images/tf_full_color_primary_icon.svg" alt="logo">

    </a>
    TensorFlow Data Transform
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/tensorflow/transform" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    transform
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Preprocess and transform data
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Guide
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Guide
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../install/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Install
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../get_started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Get Started
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tf2_support/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Using tf.Transform with TensorFlow 2.x
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../common_transformations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Common Transformations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tft_bestpractices/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Data preprocessing best practices
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    API
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    tft
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    tft
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#tensorflow_transform" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;tensorflow_transform
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â tensorflow_transform">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform-attributes" class="md-nav__link">
    <span class="md-ellipsis">
      Attributes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Attributes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.Callable" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;Callable
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.Iterable" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;Iterable
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.List" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;List
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.Mapping" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;Mapping
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.Tuple" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;Tuple
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.__version__" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;__version__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform-classes" class="md-nav__link">
    <span class="md-ellipsis">
      Classes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Classes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.DatasetMetadata" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;DatasetMetadata
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â DatasetMetadata">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.DatasetMetadata-attributes" class="md-nav__link">
    <span class="md-ellipsis">
      Attributes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Attributes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.DatasetMetadata.schema" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;schema
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.DatasetMetadata-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Functions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.DatasetMetadata.from_feature_spec" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;from_feature_spec
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TFTransformOutput
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â TFTransformOutput">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput-attributes" class="md-nav__link">
    <span class="md-ellipsis">
      Attributes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Attributes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.ASSET_MAP" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;ASSET_MAP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.POST_TRANSFORM_FEATURE_STATS_PATH" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;POST_TRANSFORM_FEATURE_STATS_PATH
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.PRE_TRANSFORM_FEATURE_STATS_PATH" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;PRE_TRANSFORM_FEATURE_STATS_PATH
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.RAW_METADATA_DIR" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;RAW_METADATA_DIR
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.TRANSFORMED_METADATA_DIR" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;TRANSFORMED_METADATA_DIR
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.TRANSFORM_FN_DIR" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;TRANSFORM_FN_DIR
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.post_transform_statistics_path" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;post_transform_statistics_path
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.pre_transform_statistics_path" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;pre_transform_statistics_path
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.raw_metadata" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;raw_metadata
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.raw_metadata--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.transform_savedmodel_dir" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;transform_savedmodel_dir
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.transformed_metadata" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;transformed_metadata
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Functions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.load_transform_graph" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;load_transform_graph
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.num_buckets_for_transformed_feature" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;num_buckets_for_transformed_feature
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.raw_domains" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;raw_domains
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.raw_domains--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.raw_feature_spec" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;raw_feature_spec
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.raw_feature_spec--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.transform_features_layer" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;transform_features_layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.transform_features_layer--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.transform_raw_features" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;transform_raw_features
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.transformed_domains" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;transformed_domains
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.transformed_domains--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.transformed_feature_spec" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;transformed_feature_spec
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.transformed_feature_spec--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.vocabulary_by_name" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;vocabulary_by_name
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.vocabulary_file_by_name" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;vocabulary_file_by_name
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.vocabulary_size_by_name" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;vocabulary_size_by_name
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TransformFeaturesLayer" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TransformFeaturesLayer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â TransformFeaturesLayer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TransformFeaturesLayer-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Functions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TransformFeaturesLayer.call" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;call
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Functions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.Any" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;Any
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.Optional" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;Optional
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.Union" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;Union
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.annotate_asset" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;annotate_asset
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.apply_buckets" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;apply_buckets
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â apply_buckets">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.apply_buckets--example" class="md-nav__link">
    <span class="md-ellipsis">
      Example:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.apply_buckets_with_interpolation" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;apply_buckets_with_interpolation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.apply_pyfunc" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;apply_pyfunc
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.apply_vocabulary" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;apply_vocabulary
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.bag_of_words" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;bag_of_words
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.bucketize" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;bucketize
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.bucketize_per_key" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;bucketize_per_key
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.compute_and_apply_vocabulary" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;compute_and_apply_vocabulary
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.count_per_key" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;count_per_key
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.covariance" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;covariance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.deduplicate_tensor_per_row" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;deduplicate_tensor_per_row
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.estimated_probability_density" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;estimated_probability_density
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.get_analyze_input_columns" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_analyze_input_columns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.get_num_buckets_for_transformed_feature" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_num_buckets_for_transformed_feature
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â get_num_buckets_for_transformed_feature">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.get_num_buckets_for_transformed_feature--example" class="md-nav__link">
    <span class="md-ellipsis">
      Example:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.get_transform_input_columns" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_transform_input_columns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.hash_strings" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;hash_strings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.histogram" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;histogram
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.make_and_track_object" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;make_and_track_object
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â make_and_track_object">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.make_and_track_object--example" class="md-nav__link">
    <span class="md-ellipsis">
      Example:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.max" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;max
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.mean" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;mean
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.min" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;min
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.ngrams" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;ngrams
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â ngrams">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.ngrams--example" class="md-nav__link">
    <span class="md-ellipsis">
      Example:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.pca" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;pca
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.quantiles" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;quantiles
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.scale_by_min_max" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;scale_by_min_max
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.scale_by_min_max_per_key" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;scale_by_min_max_per_key
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â scale_by_min_max_per_key">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.scale_by_min_max_per_key--example" class="md-nav__link">
    <span class="md-ellipsis">
      Example:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.scale_to_0_1" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;scale_to_0_1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.scale_to_0_1_per_key" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;scale_to_0_1_per_key
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â scale_to_0_1_per_key">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.scale_to_0_1_per_key--example" class="md-nav__link">
    <span class="md-ellipsis">
      Example:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.scale_to_gaussian" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;scale_to_gaussian
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.scale_to_z_score" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;scale_to_z_score
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.scale_to_z_score_per_key" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;scale_to_z_score_per_key
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.segment_indices" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;segment_indices
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â segment_indices">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.segment_indices--example" class="md-nav__link">
    <span class="md-ellipsis">
      Example:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.size" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;size
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.sparse_tensor_left_align" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;sparse_tensor_left_align
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.sparse_tensor_to_dense_with_shape" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;sparse_tensor_to_dense_with_shape
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.sum" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;sum
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.tfidf" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;tfidf
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.tukey_h_params" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;tukey_h_params
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.tukey_location" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;tukey_location
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.tukey_scale" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;tukey_scale
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.var" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;var
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.vocabulary" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;vocabulary
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.word_count" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;word_count
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â word_count">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.word_count--example" class="md-nav__link">
    <span class="md-ellipsis">
      Example:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tft-coders/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    tft.coders
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tft-experimental/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    tft.experimental ðŸ§ª
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tft-beam/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    tft.beam
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tft-beam-analyzer-cache/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    tft.beam.analyzer_cache
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tft-beam-experimental/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    tft.beam.experimental ðŸ§ª
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#tensorflow_transform" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;tensorflow_transform
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â tensorflow_transform">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform-attributes" class="md-nav__link">
    <span class="md-ellipsis">
      Attributes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Attributes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.Callable" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;Callable
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.Iterable" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;Iterable
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.List" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;List
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.Mapping" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;Mapping
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.Tuple" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;Tuple
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.__version__" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;__version__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform-classes" class="md-nav__link">
    <span class="md-ellipsis">
      Classes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Classes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.DatasetMetadata" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;DatasetMetadata
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â DatasetMetadata">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.DatasetMetadata-attributes" class="md-nav__link">
    <span class="md-ellipsis">
      Attributes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Attributes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.DatasetMetadata.schema" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;schema
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.DatasetMetadata-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Functions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.DatasetMetadata.from_feature_spec" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;from_feature_spec
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TFTransformOutput
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â TFTransformOutput">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput-attributes" class="md-nav__link">
    <span class="md-ellipsis">
      Attributes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Attributes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.ASSET_MAP" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;ASSET_MAP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.POST_TRANSFORM_FEATURE_STATS_PATH" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;POST_TRANSFORM_FEATURE_STATS_PATH
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.PRE_TRANSFORM_FEATURE_STATS_PATH" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;PRE_TRANSFORM_FEATURE_STATS_PATH
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.RAW_METADATA_DIR" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;RAW_METADATA_DIR
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.TRANSFORMED_METADATA_DIR" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;TRANSFORMED_METADATA_DIR
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.TRANSFORM_FN_DIR" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;TRANSFORM_FN_DIR
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.post_transform_statistics_path" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;post_transform_statistics_path
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.pre_transform_statistics_path" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;pre_transform_statistics_path
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.raw_metadata" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;raw_metadata
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.raw_metadata--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.transform_savedmodel_dir" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;transform_savedmodel_dir
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.transformed_metadata" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;transformed_metadata
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Functions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.load_transform_graph" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;load_transform_graph
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.num_buckets_for_transformed_feature" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;num_buckets_for_transformed_feature
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.raw_domains" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;raw_domains
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.raw_domains--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.raw_feature_spec" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;raw_feature_spec
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.raw_feature_spec--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.transform_features_layer" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;transform_features_layer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.transform_features_layer--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.transform_raw_features" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;transform_raw_features
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.transformed_domains" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;transformed_domains
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.transformed_domains--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.transformed_feature_spec" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;transformed_feature_spec
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.transformed_feature_spec--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.vocabulary_by_name" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;vocabulary_by_name
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.vocabulary_file_by_name" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;vocabulary_file_by_name
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TFTransformOutput.vocabulary_size_by_name" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;vocabulary_size_by_name
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TransformFeaturesLayer" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TransformFeaturesLayer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â TransformFeaturesLayer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TransformFeaturesLayer-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Functions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.TransformFeaturesLayer.call" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;call
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Functions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.Any" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;Any
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.Optional" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;Optional
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.Union" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;Union
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.annotate_asset" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;annotate_asset
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.apply_buckets" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;apply_buckets
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â apply_buckets">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.apply_buckets--example" class="md-nav__link">
    <span class="md-ellipsis">
      Example:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.apply_buckets_with_interpolation" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;apply_buckets_with_interpolation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.apply_pyfunc" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;apply_pyfunc
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.apply_vocabulary" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;apply_vocabulary
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.bag_of_words" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;bag_of_words
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.bucketize" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;bucketize
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.bucketize_per_key" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;bucketize_per_key
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.compute_and_apply_vocabulary" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;compute_and_apply_vocabulary
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.count_per_key" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;count_per_key
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.covariance" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;covariance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.deduplicate_tensor_per_row" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;deduplicate_tensor_per_row
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.estimated_probability_density" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;estimated_probability_density
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.get_analyze_input_columns" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_analyze_input_columns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.get_num_buckets_for_transformed_feature" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_num_buckets_for_transformed_feature
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â get_num_buckets_for_transformed_feature">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.get_num_buckets_for_transformed_feature--example" class="md-nav__link">
    <span class="md-ellipsis">
      Example:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.get_transform_input_columns" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_transform_input_columns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.hash_strings" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;hash_strings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.histogram" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;histogram
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.make_and_track_object" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;make_and_track_object
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â make_and_track_object">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.make_and_track_object--example" class="md-nav__link">
    <span class="md-ellipsis">
      Example:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.max" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;max
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.mean" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;mean
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.min" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;min
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.ngrams" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;ngrams
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â ngrams">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.ngrams--example" class="md-nav__link">
    <span class="md-ellipsis">
      Example:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.pca" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;pca
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.quantiles" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;quantiles
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.scale_by_min_max" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;scale_by_min_max
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.scale_by_min_max_per_key" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;scale_by_min_max_per_key
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â scale_by_min_max_per_key">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.scale_by_min_max_per_key--example" class="md-nav__link">
    <span class="md-ellipsis">
      Example:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.scale_to_0_1" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;scale_to_0_1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.scale_to_0_1_per_key" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;scale_to_0_1_per_key
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â scale_to_0_1_per_key">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.scale_to_0_1_per_key--example" class="md-nav__link">
    <span class="md-ellipsis">
      Example:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.scale_to_gaussian" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;scale_to_gaussian
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.scale_to_z_score" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;scale_to_z_score
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.scale_to_z_score_per_key" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;scale_to_z_score_per_key
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.segment_indices" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;segment_indices
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â segment_indices">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.segment_indices--example" class="md-nav__link">
    <span class="md-ellipsis">
      Example:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.size" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;size
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.sparse_tensor_left_align" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;sparse_tensor_left_align
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.sparse_tensor_to_dense_with_shape" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;sparse_tensor_to_dense_with_shape
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.sum" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;sum
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.tfidf" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;tfidf
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.tukey_h_params" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;tukey_h_params
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.tukey_location" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;tukey_location
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.tukey_scale" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;tukey_scale
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.var" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;var
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.vocabulary" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;vocabulary
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.word_count" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;word_count
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â word_count">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflow_transform.word_count--example" class="md-nav__link">
    <span class="md-ellipsis">
      Example:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/tensorflow/transform/edit/master/docs/api_docs/python/tft.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  


<h1 id="tensorflow-transform-tft-module">TensorFlow Transform <code>tft</code> Module<a class="headerlink" href="#tensorflow-transform-tft-module" title="Permanent link">Â¶</a></h1>


<div class="doc doc-object doc-module">



<h2 id="tensorflow_transform" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">tensorflow_transform</span>


<a href="#tensorflow_transform" class="headerlink" title="Permanent link">Â¶</a></h2>

    <div class="doc doc-contents first">

        <p>Init module for TF.Transform.</p>









  <div class="doc doc-children">





<h3 id="tensorflow_transform-attributes">Attributes<a href="#tensorflow_transform-attributes" class="headerlink" title="Permanent link">Â¶</a></h3>

<div class="doc doc-object doc-attribute">



<h4 id="tensorflow_transform.Callable" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">Callable</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-module-attribute"><code>module-attribute</code></small>
  </span>

<a href="#tensorflow_transform.Callable" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">Callable</span> <span class="o">=</span> <span class="n"><span title="typing._CallableType">_CallableType</span></span><span class="p">(</span><span class="n"><a class="autorefs autorefs-external" title="collections.abc.Callable" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Callable">Callable</a></span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="tensorflow_transform.Iterable" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">Iterable</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-module-attribute"><code>module-attribute</code></small>
  </span>

<a href="#tensorflow_transform.Iterable" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">Iterable</span> <span class="o">=</span> <span class="n"><span title="typing._alias">_alias</span></span><span class="p">(</span><span class="n"><a class="autorefs autorefs-external" title="collections.abc.Iterable" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable">Iterable</a></span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="tensorflow_transform.List" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">List</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-module-attribute"><code>module-attribute</code></small>
  </span>

<a href="#tensorflow_transform.List" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">List</span> <span class="o">=</span> <span class="n"><span title="typing._alias">_alias</span></span><span class="p">(</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#list">list</a></span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n"><span title="typing._alias(inst)">inst</span></span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n"><span title="typing._alias(name)">name</span></span><span class="o">=</span><span class="s1">'List'</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="tensorflow_transform.Mapping" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">Mapping</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-module-attribute"><code>module-attribute</code></small>
  </span>

<a href="#tensorflow_transform.Mapping" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">Mapping</span> <span class="o">=</span> <span class="n"><span title="typing._alias">_alias</span></span><span class="p">(</span><span class="n"><a class="autorefs autorefs-external" title="collections.abc.Mapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Mapping">Mapping</a></span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="tensorflow_transform.Tuple" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">Tuple</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-module-attribute"><code>module-attribute</code></small>
  </span>

<a href="#tensorflow_transform.Tuple" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">Tuple</span> <span class="o">=</span> <span class="n"><span title="typing._TupleType">_TupleType</span></span><span class="p">(</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n"><span title="typing._TupleType(inst)">inst</span></span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n"><span title="typing._TupleType(name)">name</span></span><span class="o">=</span><span class="s1">'Tuple'</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="tensorflow_transform.__version__" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">__version__</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-module-attribute"><code>module-attribute</code></small>
  </span>

<a href="#tensorflow_transform.__version__" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">__version__</span> <span class="o">=</span> <span class="s1">'1.18.0.dev'</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>
<h3 id="tensorflow_transform-classes">Classes<a href="#tensorflow_transform-classes" class="headerlink" title="Permanent link">Â¶</a></h3>

<div class="doc doc-object doc-class">



<h4 id="tensorflow_transform.DatasetMetadata" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">DatasetMetadata</span>


<a href="#tensorflow_transform.DatasetMetadata" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">DatasetMetadata</span><span class="p">(</span><span class="n">schema</span><span class="p">:</span> <span class="n"><span title="tensorflow_metadata.proto.v0.schema_pb2.Schema">Schema</span></span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


        <p>Metadata about a dataset used for the "instance dict" format.</p>
<p>Caution: The "instance dict" format used with <code>DatasetMetadata</code> is much less
efficient than TFXIO. For any serious workloads you should use TFXIO with a
<code>tfxio.TensorAdapterConfig</code> instance as the metadata. Refer to
<a href="https://www.tensorflow.org/tfx/transform/get_started#data_formats_and_schema">Get started with TF-Transform</a>
for more details.</p>
<p>This is an in-memory representation that may be serialized and deserialized to
and from a variety of disk representations.</p>







                  <details class="quote">
                    <summary>Source code in <code>tensorflow_transform/tf_metadata/dataset_metadata.py</code></summary>
                    <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-39"><a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">schema</span><span class="p">:</span> <span class="n">schema_pb2</span><span class="o">.</span><span class="n">Schema</span><span class="p">):</span>
</span><span id="__span-0-40"><a id="__codelineno-0-40" name="__codelineno-0-40"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_schema</span> <span class="o">=</span> <span class="n">schema</span>
</span><span id="__span-0-41"><a id="__codelineno-0-41" name="__codelineno-0-41"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_output_record_batches</span> <span class="o">=</span> <span class="kc">True</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



  <div class="doc doc-children">





<h5 id="tensorflow_transform.DatasetMetadata-attributes">Attributes<a href="#tensorflow_transform.DatasetMetadata-attributes" class="headerlink" title="Permanent link">Â¶</a></h5>

<div class="doc doc-object doc-attribute">



<h6 id="tensorflow_transform.DatasetMetadata.schema" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">schema</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#tensorflow_transform.DatasetMetadata.schema" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">schema</span><span class="p">:</span> <span class="n"><span title="tensorflow_metadata.proto.v0.schema_pb2.Schema">Schema</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<h5 id="tensorflow_transform.DatasetMetadata-functions">Functions<a href="#tensorflow_transform.DatasetMetadata-functions" class="headerlink" title="Permanent link">Â¶</a></h5>

<div class="doc doc-object doc-function">


<h6 id="tensorflow_transform.DatasetMetadata.from_feature_spec" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">from_feature_spec</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

<a href="#tensorflow_transform.DatasetMetadata.from_feature_spec" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">from_feature_spec</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">feature_spec</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Mapping


  
      module-attribute
   (typing.Mapping)" href="#tensorflow_transform.Mapping">Mapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="tensorflow_transform.common_types.FeatureSpecType">FeatureSpecType</span></span><span class="p">],</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">domains</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="            Mapping


  
      module-attribute
   (typing.Mapping)" href="#tensorflow_transform.Mapping">Mapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="tensorflow_transform.common_types.DomainType">DomainType</span></span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow_transform.tf_metadata.dataset_metadata._DatasetMetadataType">_DatasetMetadataType</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Creates a DatasetMetadata from a TF feature spec dict.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/tf_metadata/dataset_metadata.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-43"><a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="nd">@classmethod</span>
</span><span id="__span-0-44"><a id="__codelineno-0-44" name="__codelineno-0-44"></a><span class="k">def</span><span class="w"> </span><span class="nf">from_feature_spec</span><span class="p">(</span>
</span><span id="__span-0-45"><a id="__codelineno-0-45" name="__codelineno-0-45"></a>    <span class="bp">cls</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">_DatasetMetadataType</span><span class="p">],</span>
</span><span id="__span-0-46"><a id="__codelineno-0-46" name="__codelineno-0-46"></a>    <span class="n">feature_spec</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">common_types</span><span class="o">.</span><span class="n">FeatureSpecType</span><span class="p">],</span>
</span><span id="__span-0-47"><a id="__codelineno-0-47" name="__codelineno-0-47"></a>    <span class="n">domains</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">common_types</span><span class="o">.</span><span class="n">DomainType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-48"><a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_DatasetMetadataType</span><span class="p">:</span>
</span><span id="__span-0-49"><a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="w">    </span><span class="sd">"""Creates a DatasetMetadata from a TF feature spec dict."""</span>
</span><span id="__span-0-50"><a id="__codelineno-0-50" name="__codelineno-0-50"></a>    <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">schema_utils</span><span class="o">.</span><span class="n">schema_from_feature_spec</span><span class="p">(</span><span class="n">feature_spec</span><span class="p">,</span> <span class="n">domains</span><span class="p">))</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="tensorflow_transform.TFTransformOutput" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">TFTransformOutput</span>


<a href="#tensorflow_transform.TFTransformOutput" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">TFTransformOutput</span><span class="p">(</span><span class="n">transform_output_dir</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


        <p>A wrapper around the output of the tf.Transform.</p>

        <p>Init method for TFTransformOutput.</p>
        <hr>
<p>transform_output_dir: The directory containig tf.Transform output.</p>







                  <details class="quote">
                    <summary>Source code in <code>tensorflow_transform/output_wrapper.py</code></summary>
                    <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span>
<span class="normal"><a href="#__codelineno-0-75">75</a></span>
<span class="normal"><a href="#__codelineno-0-76">76</a></span>
<span class="normal"><a href="#__codelineno-0-77">77</a></span>
<span class="normal"><a href="#__codelineno-0-78">78</a></span>
<span class="normal"><a href="#__codelineno-0-79">79</a></span>
<span class="normal"><a href="#__codelineno-0-80">80</a></span>
<span class="normal"><a href="#__codelineno-0-81">81</a></span>
<span class="normal"><a href="#__codelineno-0-82">82</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-68"><a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transform_output_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="__span-0-69"><a id="__codelineno-0-69" name="__codelineno-0-69"></a><span class="w">    </span><span class="sd">"""Init method for TFTransformOutput.</span>
</span><span id="__span-0-70"><a id="__codelineno-0-70" name="__codelineno-0-70"></a>
</span><span id="__span-0-71"><a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="sd">    Args:</span>
</span><span id="__span-0-72"><a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="sd">    ----</span>
</span><span id="__span-0-73"><a id="__codelineno-0-73" name="__codelineno-0-73"></a><span class="sd">      transform_output_dir: The directory containig tf.Transform output.</span>
</span><span id="__span-0-74"><a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="sd">    """</span>
</span><span id="__span-0-75"><a id="__codelineno-0-75" name="__codelineno-0-75"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_transform_output_dir</span> <span class="o">=</span> <span class="n">transform_output_dir</span>
</span><span id="__span-0-76"><a id="__codelineno-0-76" name="__codelineno-0-76"></a>
</span><span id="__span-0-77"><a id="__codelineno-0-77" name="__codelineno-0-77"></a>    <span class="c1"># Lazily constructed properties.</span>
</span><span id="__span-0-78"><a id="__codelineno-0-78" name="__codelineno-0-78"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_transformed_metadata</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-79"><a id="__codelineno-0-79" name="__codelineno-0-79"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_raw_metadata</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-80"><a id="__codelineno-0-80" name="__codelineno-0-80"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_transform_features_layer</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-81"><a id="__codelineno-0-81" name="__codelineno-0-81"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_exported_as_v1_value</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-82"><a id="__codelineno-0-82" name="__codelineno-0-82"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_transformed_domains</span> <span class="o">=</span> <span class="kc">None</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



  <div class="doc doc-children">





<h5 id="tensorflow_transform.TFTransformOutput-attributes">Attributes<a href="#tensorflow_transform.TFTransformOutput-attributes" class="headerlink" title="Permanent link">Â¶</a></h5>

<div class="doc doc-object doc-attribute">



<h6 id="tensorflow_transform.TFTransformOutput.ASSET_MAP" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">ASSET_MAP</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#tensorflow_transform.TFTransformOutput.ASSET_MAP" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">ASSET_MAP</span> <span class="o">=</span> <span class="s1">'asset_map'</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h6 id="tensorflow_transform.TFTransformOutput.POST_TRANSFORM_FEATURE_STATS_PATH" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">POST_TRANSFORM_FEATURE_STATS_PATH</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#tensorflow_transform.TFTransformOutput.POST_TRANSFORM_FEATURE_STATS_PATH" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">POST_TRANSFORM_FEATURE_STATS_PATH</span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-external" title="os.path.join" href="https://docs.python.org/3/library/os.path.html#os.path.join">join</a></span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="s2">"post_transform_feature_stats"</span><span class="p">,</span> <span class="n"><span title="tensorflow_transform.output_wrapper.TFTransformOutput._FEATURE_STATS_PB">_FEATURE_STATS_PB</span></span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h6 id="tensorflow_transform.TFTransformOutput.PRE_TRANSFORM_FEATURE_STATS_PATH" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">PRE_TRANSFORM_FEATURE_STATS_PATH</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#tensorflow_transform.TFTransformOutput.PRE_TRANSFORM_FEATURE_STATS_PATH" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">PRE_TRANSFORM_FEATURE_STATS_PATH</span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-external" title="os.path.join" href="https://docs.python.org/3/library/os.path.html#os.path.join">join</a></span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="s2">"pre_transform_feature_stats"</span><span class="p">,</span> <span class="n"><span title="tensorflow_transform.output_wrapper.TFTransformOutput._FEATURE_STATS_PB">_FEATURE_STATS_PB</span></span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h6 id="tensorflow_transform.TFTransformOutput.RAW_METADATA_DIR" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">RAW_METADATA_DIR</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#tensorflow_transform.TFTransformOutput.RAW_METADATA_DIR" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">RAW_METADATA_DIR</span> <span class="o">=</span> <span class="s1">'metadata'</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h6 id="tensorflow_transform.TFTransformOutput.TRANSFORMED_METADATA_DIR" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">TRANSFORMED_METADATA_DIR</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#tensorflow_transform.TFTransformOutput.TRANSFORMED_METADATA_DIR" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">TRANSFORMED_METADATA_DIR</span> <span class="o">=</span> <span class="s1">'transformed_metadata'</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h6 id="tensorflow_transform.TFTransformOutput.TRANSFORM_FN_DIR" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">TRANSFORM_FN_DIR</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#tensorflow_transform.TFTransformOutput.TRANSFORM_FN_DIR" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">TRANSFORM_FN_DIR</span> <span class="o">=</span> <span class="s1">'transform_fn'</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h6 id="tensorflow_transform.TFTransformOutput.post_transform_statistics_path" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">post_transform_statistics_path</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#tensorflow_transform.TFTransformOutput.post_transform_statistics_path" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">post_transform_statistics_path</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Returns the path to the post-transform datum statistics.</p>
<p>Note: post_transform_statistics is not guaranteed to exist in the output of
tf.transform and hence using this could fail, if post_transform statistics
is not present in TFTransformOutput.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h6 id="tensorflow_transform.TFTransformOutput.pre_transform_statistics_path" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">pre_transform_statistics_path</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#tensorflow_transform.TFTransformOutput.pre_transform_statistics_path" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">pre_transform_statistics_path</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Returns the path to the pre-transform datum statistics.</p>
<p>Note: pre_transform_statistics is not guaranteed to exist in the output of
tf.transform and hence using this could fail, if pre_transform statistics is
not present in TFTransformOutput.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h6 id="tensorflow_transform.TFTransformOutput.raw_metadata" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">raw_metadata</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#tensorflow_transform.TFTransformOutput.raw_metadata" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">raw_metadata</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            DatasetMetadata (tensorflow_transform.tf_metadata.dataset_metadata.DatasetMetadata)" href="#tensorflow_transform.DatasetMetadata">DatasetMetadata</a></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>A DatasetMetadata.</p>
<p>Note: raw_metadata is not guaranteed to exist in the output of tf.transform
and hence using this could fail, if raw_metadata is not present in
TFTransformOutput.</p>
<h6 id="tensorflow_transform.TFTransformOutput.raw_metadata--returns">Returns<a class="headerlink" href="#tensorflow_transform.TFTransformOutput.raw_metadata--returns" title="Permanent link">Â¶</a></h6>
<p>A DatasetMetadata</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h6 id="tensorflow_transform.TFTransformOutput.transform_savedmodel_dir" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">transform_savedmodel_dir</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#tensorflow_transform.TFTransformOutput.transform_savedmodel_dir" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">transform_savedmodel_dir</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>A python str.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h6 id="tensorflow_transform.TFTransformOutput.transformed_metadata" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">transformed_metadata</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#tensorflow_transform.TFTransformOutput.transformed_metadata" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">transformed_metadata</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            DatasetMetadata (tensorflow_transform.tf_metadata.dataset_metadata.DatasetMetadata)" href="#tensorflow_transform.DatasetMetadata">DatasetMetadata</a></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>A DatasetMetadata.</p>

    </div>

</div>

<h5 id="tensorflow_transform.TFTransformOutput-functions">Functions<a href="#tensorflow_transform.TFTransformOutput-functions" class="headerlink" title="Permanent link">Â¶</a></h5>

<div class="doc doc-object doc-function">


<h6 id="tensorflow_transform.TFTransformOutput.load_transform_graph" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">load_transform_graph</span>


<a href="#tensorflow_transform.TFTransformOutput.load_transform_graph" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">load_transform_graph</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Load the transform graph without replacing any placeholders.</p>
<p>This is necessary to ensure that variables in the transform graph are
included in the training checkpoint when using tf.Estimator.  This should
be called in the training input_fn.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/output_wrapper.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-378">378</a></span>
<span class="normal"><a href="#__codelineno-0-379">379</a></span>
<span class="normal"><a href="#__codelineno-0-380">380</a></span>
<span class="normal"><a href="#__codelineno-0-381">381</a></span>
<span class="normal"><a href="#__codelineno-0-382">382</a></span>
<span class="normal"><a href="#__codelineno-0-383">383</a></span>
<span class="normal"><a href="#__codelineno-0-384">384</a></span>
<span class="normal"><a href="#__codelineno-0-385">385</a></span>
<span class="normal"><a href="#__codelineno-0-386">386</a></span>
<span class="normal"><a href="#__codelineno-0-387">387</a></span>
<span class="normal"><a href="#__codelineno-0-388">388</a></span>
<span class="normal"><a href="#__codelineno-0-389">389</a></span>
<span class="normal"><a href="#__codelineno-0-390">390</a></span>
<span class="normal"><a href="#__codelineno-0-391">391</a></span>
<span class="normal"><a href="#__codelineno-0-392">392</a></span>
<span class="normal"><a href="#__codelineno-0-393">393</a></span>
<span class="normal"><a href="#__codelineno-0-394">394</a></span>
<span class="normal"><a href="#__codelineno-0-395">395</a></span>
<span class="normal"><a href="#__codelineno-0-396">396</a></span>
<span class="normal"><a href="#__codelineno-0-397">397</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-378"><a id="__codelineno-0-378" name="__codelineno-0-378"></a><span class="k">def</span><span class="w"> </span><span class="nf">load_transform_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="__span-0-379"><a id="__codelineno-0-379" name="__codelineno-0-379"></a><span class="w">    </span><span class="sd">"""Load the transform graph without replacing any placeholders.</span>
</span><span id="__span-0-380"><a id="__codelineno-0-380" name="__codelineno-0-380"></a>
</span><span id="__span-0-381"><a id="__codelineno-0-381" name="__codelineno-0-381"></a><span class="sd">    This is necessary to ensure that variables in the transform graph are</span>
</span><span id="__span-0-382"><a id="__codelineno-0-382" name="__codelineno-0-382"></a><span class="sd">    included in the training checkpoint when using tf.Estimator.  This should</span>
</span><span id="__span-0-383"><a id="__codelineno-0-383" name="__codelineno-0-383"></a><span class="sd">    be called in the training input_fn.</span>
</span><span id="__span-0-384"><a id="__codelineno-0-384" name="__codelineno-0-384"></a><span class="sd">    """</span>
</span><span id="__span-0-385"><a id="__codelineno-0-385" name="__codelineno-0-385"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exported_as_v1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-386"><a id="__codelineno-0-386" name="__codelineno-0-386"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_exported_as_v1</span> <span class="o">=</span> <span class="n">saved_transform_io</span><span class="o">.</span><span class="n">exported_as_v1</span><span class="p">(</span>
</span><span id="__span-0-387"><a id="__codelineno-0-387" name="__codelineno-0-387"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">transform_savedmodel_dir</span>
</span><span id="__span-0-388"><a id="__codelineno-0-388" name="__codelineno-0-388"></a>        <span class="p">)</span>
</span><span id="__span-0-389"><a id="__codelineno-0-389" name="__codelineno-0-389"></a>
</span><span id="__span-0-390"><a id="__codelineno-0-390" name="__codelineno-0-390"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exported_as_v1</span><span class="p">:</span>
</span><span id="__span-0-391"><a id="__codelineno-0-391" name="__codelineno-0-391"></a>        <span class="n">saved_transform_io</span><span class="o">.</span><span class="n">partially_apply_saved_transform_internal</span><span class="p">(</span>
</span><span id="__span-0-392"><a id="__codelineno-0-392" name="__codelineno-0-392"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">transform_savedmodel_dir</span><span class="p">,</span> <span class="p">{}</span>
</span><span id="__span-0-393"><a id="__codelineno-0-393" name="__codelineno-0-393"></a>        <span class="p">)</span>
</span><span id="__span-0-394"><a id="__codelineno-0-394" name="__codelineno-0-394"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-395"><a id="__codelineno-0-395" name="__codelineno-0-395"></a>        <span class="c1"># Note: This should use the same mechanism as `transform_raw_features` to</span>
</span><span id="__span-0-396"><a id="__codelineno-0-396" name="__codelineno-0-396"></a>        <span class="c1"># load the SavedModel into the current graph context.</span>
</span><span id="__span-0-397"><a id="__codelineno-0-397" name="__codelineno-0-397"></a>        <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_features_layer</span><span class="p">()({})</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h6 id="tensorflow_transform.TFTransformOutput.num_buckets_for_transformed_feature" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">num_buckets_for_transformed_feature</span>


<a href="#tensorflow_transform.TFTransformOutput.num_buckets_for_transformed_feature" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">num_buckets_for_transformed_feature</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Returns the number of buckets for an integerized transformed feature.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/output_wrapper.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span>
<span class="normal"><a href="#__codelineno-0-274">274</a></span>
<span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-265"><a id="__codelineno-0-265" name="__codelineno-0-265"></a><span class="k">def</span><span class="w"> </span><span class="nf">num_buckets_for_transformed_feature</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-266"><a id="__codelineno-0-266" name="__codelineno-0-266"></a><span class="w">    </span><span class="sd">"""Returns the number of buckets for an integerized transformed feature."""</span>
</span><span id="__span-0-267"><a id="__codelineno-0-267" name="__codelineno-0-267"></a>    <span class="c1"># Do checks that this tensor can be wrapped in</span>
</span><span id="__span-0-268"><a id="__codelineno-0-268" name="__codelineno-0-268"></a>    <span class="c1"># sparse_column_with_integerized_feature</span>
</span><span id="__span-0-269"><a id="__codelineno-0-269" name="__codelineno-0-269"></a>    <span class="k">try</span><span class="p">:</span>
</span><span id="__span-0-270"><a id="__codelineno-0-270" name="__codelineno-0-270"></a>        <span class="n">domain</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformed_domains</span><span class="p">()[</span><span class="n">name</span><span class="p">]</span>
</span><span id="__span-0-271"><a id="__codelineno-0-271" name="__codelineno-0-271"></a>    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
</span><span id="__span-0-272"><a id="__codelineno-0-272" name="__codelineno-0-272"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Column </span><span class="si">{}</span><span class="s2"> did not have a domain provided."</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
</span><span id="__span-0-273"><a id="__codelineno-0-273" name="__codelineno-0-273"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">domain</span><span class="p">,</span> <span class="n">schema_pb2</span><span class="o">.</span><span class="n">IntDomain</span><span class="p">):</span>
</span><span id="__span-0-274"><a id="__codelineno-0-274" name="__codelineno-0-274"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="__span-0-275"><a id="__codelineno-0-275" name="__codelineno-0-275"></a>            <span class="s2">"Column </span><span class="si">{}</span><span class="s2"> has domain </span><span class="si">{}</span><span class="s2">, expected an IntDomain"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">domain</span><span class="p">)</span>
</span><span id="__span-0-276"><a id="__codelineno-0-276" name="__codelineno-0-276"></a>        <span class="p">)</span>
</span><span id="__span-0-277"><a id="__codelineno-0-277" name="__codelineno-0-277"></a>    <span class="k">if</span> <span class="n">domain</span><span class="o">.</span><span class="n">min</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="__span-0-278"><a id="__codelineno-0-278" name="__codelineno-0-278"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="__span-0-279"><a id="__codelineno-0-279" name="__codelineno-0-279"></a>            <span class="s2">"Column </span><span class="si">{}</span><span class="s2"> has min value </span><span class="si">{}</span><span class="s2">, should be 0"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">domain</span><span class="o">.</span><span class="n">min</span><span class="p">)</span>
</span><span id="__span-0-280"><a id="__codelineno-0-280" name="__codelineno-0-280"></a>        <span class="p">)</span>
</span><span id="__span-0-281"><a id="__codelineno-0-281" name="__codelineno-0-281"></a>    <span class="k">return</span> <span class="n">domain</span><span class="o">.</span><span class="n">max</span> <span class="o">+</span> <span class="mi">1</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h6 id="tensorflow_transform.TFTransformOutput.raw_domains" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">raw_domains</span>


<a href="#tensorflow_transform.TFTransformOutput.raw_domains" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">raw_domains</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Dict" href="https://docs.python.org/3/library/typing.html#typing.Dict">Dict</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="tensorflow_transform.common_types.DomainType">DomainType</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Returns domains for the raw features.</p>
<h6 id="tensorflow_transform.TFTransformOutput.raw_domains--returns">Returns<a class="headerlink" href="#tensorflow_transform.TFTransformOutput.raw_domains--returns" title="Permanent link">Â¶</a></h6>
<p>A dict from feature names to one of schema_pb2.IntDomain,
  schema_pb2.StringDomain or schema_pb2.FloatDomain.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/output_wrapper.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-437">437</a></span>
<span class="normal"><a href="#__codelineno-0-438">438</a></span>
<span class="normal"><a href="#__codelineno-0-439">439</a></span>
<span class="normal"><a href="#__codelineno-0-440">440</a></span>
<span class="normal"><a href="#__codelineno-0-441">441</a></span>
<span class="normal"><a href="#__codelineno-0-442">442</a></span>
<span class="normal"><a href="#__codelineno-0-443">443</a></span>
<span class="normal"><a href="#__codelineno-0-444">444</a></span>
<span class="normal"><a href="#__codelineno-0-445">445</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-437"><a id="__codelineno-0-437" name="__codelineno-0-437"></a><span class="k">def</span><span class="w"> </span><span class="nf">raw_domains</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">common_types</span><span class="o">.</span><span class="n">DomainType</span><span class="p">]:</span>
</span><span id="__span-0-438"><a id="__codelineno-0-438" name="__codelineno-0-438"></a><span class="w">    </span><span class="sd">"""Returns domains for the raw features.</span>
</span><span id="__span-0-439"><a id="__codelineno-0-439" name="__codelineno-0-439"></a>
</span><span id="__span-0-440"><a id="__codelineno-0-440" name="__codelineno-0-440"></a><span class="sd">    Returns</span>
</span><span id="__span-0-441"><a id="__codelineno-0-441" name="__codelineno-0-441"></a><span class="sd">    -------</span>
</span><span id="__span-0-442"><a id="__codelineno-0-442" name="__codelineno-0-442"></a><span class="sd">      A dict from feature names to one of schema_pb2.IntDomain,</span>
</span><span id="__span-0-443"><a id="__codelineno-0-443" name="__codelineno-0-443"></a><span class="sd">      schema_pb2.StringDomain or schema_pb2.FloatDomain.</span>
</span><span id="__span-0-444"><a id="__codelineno-0-444" name="__codelineno-0-444"></a><span class="sd">    """</span>
</span><span id="__span-0-445"><a id="__codelineno-0-445" name="__codelineno-0-445"></a>    <span class="k">return</span> <span class="n">schema_utils</span><span class="o">.</span><span class="n">schema_as_feature_spec</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_metadata</span><span class="o">.</span><span class="n">schema</span><span class="p">)</span><span class="o">.</span><span class="n">domains</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h6 id="tensorflow_transform.TFTransformOutput.raw_feature_spec" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">raw_feature_spec</span>


<a href="#tensorflow_transform.TFTransformOutput.raw_feature_spec" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">raw_feature_spec</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Dict" href="https://docs.python.org/3/library/typing.html#typing.Dict">Dict</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="tensorflow_transform.common_types.FeatureSpecType">FeatureSpecType</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Returns a feature_spec for the raw features.</p>
<h6 id="tensorflow_transform.TFTransformOutput.raw_feature_spec--returns">Returns<a class="headerlink" href="#tensorflow_transform.TFTransformOutput.raw_feature_spec--returns" title="Permanent link">Â¶</a></h6>
<p>A dict from feature names to FixedLenFeature/SparseFeature/VarLenFeature.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/output_wrapper.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-426">426</a></span>
<span class="normal"><a href="#__codelineno-0-427">427</a></span>
<span class="normal"><a href="#__codelineno-0-428">428</a></span>
<span class="normal"><a href="#__codelineno-0-429">429</a></span>
<span class="normal"><a href="#__codelineno-0-430">430</a></span>
<span class="normal"><a href="#__codelineno-0-431">431</a></span>
<span class="normal"><a href="#__codelineno-0-432">432</a></span>
<span class="normal"><a href="#__codelineno-0-433">433</a></span>
<span class="normal"><a href="#__codelineno-0-434">434</a></span>
<span class="normal"><a href="#__codelineno-0-435">435</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-426"><a id="__codelineno-0-426" name="__codelineno-0-426"></a><span class="k">def</span><span class="w"> </span><span class="nf">raw_feature_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">common_types</span><span class="o">.</span><span class="n">FeatureSpecType</span><span class="p">]:</span>
</span><span id="__span-0-427"><a id="__codelineno-0-427" name="__codelineno-0-427"></a><span class="w">    </span><span class="sd">"""Returns a feature_spec for the raw features.</span>
</span><span id="__span-0-428"><a id="__codelineno-0-428" name="__codelineno-0-428"></a>
</span><span id="__span-0-429"><a id="__codelineno-0-429" name="__codelineno-0-429"></a><span class="sd">    Returns</span>
</span><span id="__span-0-430"><a id="__codelineno-0-430" name="__codelineno-0-430"></a><span class="sd">    -------</span>
</span><span id="__span-0-431"><a id="__codelineno-0-431" name="__codelineno-0-431"></a><span class="sd">      A dict from feature names to FixedLenFeature/SparseFeature/VarLenFeature.</span>
</span><span id="__span-0-432"><a id="__codelineno-0-432" name="__codelineno-0-432"></a><span class="sd">    """</span>
</span><span id="__span-0-433"><a id="__codelineno-0-433" name="__codelineno-0-433"></a>    <span class="k">return</span> <span class="n">schema_utils</span><span class="o">.</span><span class="n">schema_as_feature_spec</span><span class="p">(</span>
</span><span id="__span-0-434"><a id="__codelineno-0-434" name="__codelineno-0-434"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">raw_metadata</span><span class="o">.</span><span class="n">schema</span>
</span><span id="__span-0-435"><a id="__codelineno-0-435" name="__codelineno-0-435"></a>    <span class="p">)</span><span class="o">.</span><span class="n">feature_spec</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h6 id="tensorflow_transform.TFTransformOutput.transform_features_layer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">transform_features_layer</span>


<a href="#tensorflow_transform.TFTransformOutput.transform_features_layer" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">transform_features_layer</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow_transform.keras_lib.tf_keras.Model">Model</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Creates a <code>TransformFeaturesLayer</code> from this transform output.</p>
<p>If a <code>TransformFeaturesLayer</code> has already been created for self, the same
one will be returned.</p>
<h6 id="tensorflow_transform.TFTransformOutput.transform_features_layer--returns">Returns<a class="headerlink" href="#tensorflow_transform.TFTransformOutput.transform_features_layer--returns" title="Permanent link">Â¶</a></h6>
<p>A <code>TransformFeaturesLayer</code> instance.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/output_wrapper.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span>
<span class="normal"><a href="#__codelineno-0-285">285</a></span>
<span class="normal"><a href="#__codelineno-0-286">286</a></span>
<span class="normal"><a href="#__codelineno-0-287">287</a></span>
<span class="normal"><a href="#__codelineno-0-288">288</a></span>
<span class="normal"><a href="#__codelineno-0-289">289</a></span>
<span class="normal"><a href="#__codelineno-0-290">290</a></span>
<span class="normal"><a href="#__codelineno-0-291">291</a></span>
<span class="normal"><a href="#__codelineno-0-292">292</a></span>
<span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-283"><a id="__codelineno-0-283" name="__codelineno-0-283"></a><span class="k">def</span><span class="w"> </span><span class="nf">transform_features_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf_keras</span><span class="o">.</span><span class="n">Model</span><span class="p">:</span>
</span><span id="__span-0-284"><a id="__codelineno-0-284" name="__codelineno-0-284"></a><span class="w">    </span><span class="sd">"""Creates a `TransformFeaturesLayer` from this transform output.</span>
</span><span id="__span-0-285"><a id="__codelineno-0-285" name="__codelineno-0-285"></a>
</span><span id="__span-0-286"><a id="__codelineno-0-286" name="__codelineno-0-286"></a><span class="sd">    If a `TransformFeaturesLayer` has already been created for self, the same</span>
</span><span id="__span-0-287"><a id="__codelineno-0-287" name="__codelineno-0-287"></a><span class="sd">    one will be returned.</span>
</span><span id="__span-0-288"><a id="__codelineno-0-288" name="__codelineno-0-288"></a>
</span><span id="__span-0-289"><a id="__codelineno-0-289" name="__codelineno-0-289"></a><span class="sd">    Returns</span>
</span><span id="__span-0-290"><a id="__codelineno-0-290" name="__codelineno-0-290"></a><span class="sd">    -------</span>
</span><span id="__span-0-291"><a id="__codelineno-0-291" name="__codelineno-0-291"></a><span class="sd">      A `TransformFeaturesLayer` instance.</span>
</span><span id="__span-0-292"><a id="__codelineno-0-292" name="__codelineno-0-292"></a><span class="sd">    """</span>
</span><span id="__span-0-293"><a id="__codelineno-0-293" name="__codelineno-0-293"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_features_layer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-294"><a id="__codelineno-0-294" name="__codelineno-0-294"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_transform_features_layer</span> <span class="o">=</span> <span class="n">TransformFeaturesLayer</span><span class="p">(</span>
</span><span id="__span-0-295"><a id="__codelineno-0-295" name="__codelineno-0-295"></a>            <span class="bp">self</span><span class="p">,</span> <span class="n">exported_as_v1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_exported_as_v1</span>
</span><span id="__span-0-296"><a id="__codelineno-0-296" name="__codelineno-0-296"></a>        <span class="p">)</span>
</span><span id="__span-0-297"><a id="__codelineno-0-297" name="__codelineno-0-297"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_features_layer</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h6 id="tensorflow_transform.TFTransformOutput.transform_raw_features" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">transform_raw_features</span>


<a href="#tensorflow_transform.TFTransformOutput.transform_raw_features" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">transform_raw_features</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">raw_features</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Mapping


  
      module-attribute
   (typing.Mapping)" href="#tensorflow_transform.Mapping">Mapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">],</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">drop_unused_features</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Dict" href="https://docs.python.org/3/library/typing.html#typing.Dict">Dict</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Takes a dict of tensors representing raw features and transforms them.</p>
<p>Takes a dictionary of <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>s that
represent the raw features, and applies the transformation defined by
tf.Transform.</p>
<p>If False it returns all transformed features defined by tf.Transform. To
only return features transformed from the given 'raw_features', set
<code>drop_unused_features</code> to True.</p>
<p>Note: If eager execution is enabled and this API is invoked inside a
tf.function or an API that uses tf.function such as dataset.map, please use
<code>transform_features_layer</code> instead. It separates out loading of the
transform graph and hence resources will not be initialized on each
invocation. This can have significant performance improvement if the
transform graph was exported as a TF1 SavedModel and guarantees correctness
if it was exported as a TF2 SavedModel.</p>
        <hr>
<p>raw_features: A dict whose keys are feature names and values are
  <code>Tensor</code>s, <code>SparseTensor</code>s, or <code>RaggedTensor</code>s.
  drop_unused_features: If True, the result will be filtered. Only the
    features that are transformed from 'raw_features' will be included in
    the returned result. If a feature is transformed from multiple raw
    features (e.g, feature cross), it will only be included if all its base
    raw features are present in <code>raw_features</code>.</p>
        <hr>
<p>A dict whose keys are feature names and values are <code>Tensor</code>s,
  <code>SparseTensor</code>s, or <code>RaggedTensor</code>s representing transformed features.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/output_wrapper.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-299">299</a></span>
<span class="normal"><a href="#__codelineno-0-300">300</a></span>
<span class="normal"><a href="#__codelineno-0-301">301</a></span>
<span class="normal"><a href="#__codelineno-0-302">302</a></span>
<span class="normal"><a href="#__codelineno-0-303">303</a></span>
<span class="normal"><a href="#__codelineno-0-304">304</a></span>
<span class="normal"><a href="#__codelineno-0-305">305</a></span>
<span class="normal"><a href="#__codelineno-0-306">306</a></span>
<span class="normal"><a href="#__codelineno-0-307">307</a></span>
<span class="normal"><a href="#__codelineno-0-308">308</a></span>
<span class="normal"><a href="#__codelineno-0-309">309</a></span>
<span class="normal"><a href="#__codelineno-0-310">310</a></span>
<span class="normal"><a href="#__codelineno-0-311">311</a></span>
<span class="normal"><a href="#__codelineno-0-312">312</a></span>
<span class="normal"><a href="#__codelineno-0-313">313</a></span>
<span class="normal"><a href="#__codelineno-0-314">314</a></span>
<span class="normal"><a href="#__codelineno-0-315">315</a></span>
<span class="normal"><a href="#__codelineno-0-316">316</a></span>
<span class="normal"><a href="#__codelineno-0-317">317</a></span>
<span class="normal"><a href="#__codelineno-0-318">318</a></span>
<span class="normal"><a href="#__codelineno-0-319">319</a></span>
<span class="normal"><a href="#__codelineno-0-320">320</a></span>
<span class="normal"><a href="#__codelineno-0-321">321</a></span>
<span class="normal"><a href="#__codelineno-0-322">322</a></span>
<span class="normal"><a href="#__codelineno-0-323">323</a></span>
<span class="normal"><a href="#__codelineno-0-324">324</a></span>
<span class="normal"><a href="#__codelineno-0-325">325</a></span>
<span class="normal"><a href="#__codelineno-0-326">326</a></span>
<span class="normal"><a href="#__codelineno-0-327">327</a></span>
<span class="normal"><a href="#__codelineno-0-328">328</a></span>
<span class="normal"><a href="#__codelineno-0-329">329</a></span>
<span class="normal"><a href="#__codelineno-0-330">330</a></span>
<span class="normal"><a href="#__codelineno-0-331">331</a></span>
<span class="normal"><a href="#__codelineno-0-332">332</a></span>
<span class="normal"><a href="#__codelineno-0-333">333</a></span>
<span class="normal"><a href="#__codelineno-0-334">334</a></span>
<span class="normal"><a href="#__codelineno-0-335">335</a></span>
<span class="normal"><a href="#__codelineno-0-336">336</a></span>
<span class="normal"><a href="#__codelineno-0-337">337</a></span>
<span class="normal"><a href="#__codelineno-0-338">338</a></span>
<span class="normal"><a href="#__codelineno-0-339">339</a></span>
<span class="normal"><a href="#__codelineno-0-340">340</a></span>
<span class="normal"><a href="#__codelineno-0-341">341</a></span>
<span class="normal"><a href="#__codelineno-0-342">342</a></span>
<span class="normal"><a href="#__codelineno-0-343">343</a></span>
<span class="normal"><a href="#__codelineno-0-344">344</a></span>
<span class="normal"><a href="#__codelineno-0-345">345</a></span>
<span class="normal"><a href="#__codelineno-0-346">346</a></span>
<span class="normal"><a href="#__codelineno-0-347">347</a></span>
<span class="normal"><a href="#__codelineno-0-348">348</a></span>
<span class="normal"><a href="#__codelineno-0-349">349</a></span>
<span class="normal"><a href="#__codelineno-0-350">350</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-299"><a id="__codelineno-0-299" name="__codelineno-0-299"></a><span class="k">def</span><span class="w"> </span><span class="nf">transform_raw_features</span><span class="p">(</span>
</span><span id="__span-0-300"><a id="__codelineno-0-300" name="__codelineno-0-300"></a>    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-301"><a id="__codelineno-0-301" name="__codelineno-0-301"></a>    <span class="n">raw_features</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">],</span>
</span><span id="__span-0-302"><a id="__codelineno-0-302" name="__codelineno-0-302"></a>    <span class="n">drop_unused_features</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>  <span class="c1"># LEGACY_VALUE=False</span>
</span><span id="__span-0-303"><a id="__codelineno-0-303" name="__codelineno-0-303"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">]:</span>
</span><span id="__span-0-304"><a id="__codelineno-0-304" name="__codelineno-0-304"></a><span class="w">    </span><span class="sd">"""Takes a dict of tensors representing raw features and transforms them.</span>
</span><span id="__span-0-305"><a id="__codelineno-0-305" name="__codelineno-0-305"></a>
</span><span id="__span-0-306"><a id="__codelineno-0-306" name="__codelineno-0-306"></a><span class="sd">    Takes a dictionary of `Tensor`, `SparseTensor`, or `RaggedTensor`s that</span>
</span><span id="__span-0-307"><a id="__codelineno-0-307" name="__codelineno-0-307"></a><span class="sd">    represent the raw features, and applies the transformation defined by</span>
</span><span id="__span-0-308"><a id="__codelineno-0-308" name="__codelineno-0-308"></a><span class="sd">    tf.Transform.</span>
</span><span id="__span-0-309"><a id="__codelineno-0-309" name="__codelineno-0-309"></a>
</span><span id="__span-0-310"><a id="__codelineno-0-310" name="__codelineno-0-310"></a><span class="sd">    If False it returns all transformed features defined by tf.Transform. To</span>
</span><span id="__span-0-311"><a id="__codelineno-0-311" name="__codelineno-0-311"></a><span class="sd">    only return features transformed from the given 'raw_features', set</span>
</span><span id="__span-0-312"><a id="__codelineno-0-312" name="__codelineno-0-312"></a><span class="sd">    `drop_unused_features` to True.</span>
</span><span id="__span-0-313"><a id="__codelineno-0-313" name="__codelineno-0-313"></a>
</span><span id="__span-0-314"><a id="__codelineno-0-314" name="__codelineno-0-314"></a><span class="sd">    Note: If eager execution is enabled and this API is invoked inside a</span>
</span><span id="__span-0-315"><a id="__codelineno-0-315" name="__codelineno-0-315"></a><span class="sd">    tf.function or an API that uses tf.function such as dataset.map, please use</span>
</span><span id="__span-0-316"><a id="__codelineno-0-316" name="__codelineno-0-316"></a><span class="sd">    `transform_features_layer` instead. It separates out loading of the</span>
</span><span id="__span-0-317"><a id="__codelineno-0-317" name="__codelineno-0-317"></a><span class="sd">    transform graph and hence resources will not be initialized on each</span>
</span><span id="__span-0-318"><a id="__codelineno-0-318" name="__codelineno-0-318"></a><span class="sd">    invocation. This can have significant performance improvement if the</span>
</span><span id="__span-0-319"><a id="__codelineno-0-319" name="__codelineno-0-319"></a><span class="sd">    transform graph was exported as a TF1 SavedModel and guarantees correctness</span>
</span><span id="__span-0-320"><a id="__codelineno-0-320" name="__codelineno-0-320"></a><span class="sd">    if it was exported as a TF2 SavedModel.</span>
</span><span id="__span-0-321"><a id="__codelineno-0-321" name="__codelineno-0-321"></a>
</span><span id="__span-0-322"><a id="__codelineno-0-322" name="__codelineno-0-322"></a><span class="sd">    Args:</span>
</span><span id="__span-0-323"><a id="__codelineno-0-323" name="__codelineno-0-323"></a><span class="sd">    ----</span>
</span><span id="__span-0-324"><a id="__codelineno-0-324" name="__codelineno-0-324"></a><span class="sd">      raw_features: A dict whose keys are feature names and values are</span>
</span><span id="__span-0-325"><a id="__codelineno-0-325" name="__codelineno-0-325"></a><span class="sd">      `Tensor`s, `SparseTensor`s, or `RaggedTensor`s.</span>
</span><span id="__span-0-326"><a id="__codelineno-0-326" name="__codelineno-0-326"></a><span class="sd">      drop_unused_features: If True, the result will be filtered. Only the</span>
</span><span id="__span-0-327"><a id="__codelineno-0-327" name="__codelineno-0-327"></a><span class="sd">        features that are transformed from 'raw_features' will be included in</span>
</span><span id="__span-0-328"><a id="__codelineno-0-328" name="__codelineno-0-328"></a><span class="sd">        the returned result. If a feature is transformed from multiple raw</span>
</span><span id="__span-0-329"><a id="__codelineno-0-329" name="__codelineno-0-329"></a><span class="sd">        features (e.g, feature cross), it will only be included if all its base</span>
</span><span id="__span-0-330"><a id="__codelineno-0-330" name="__codelineno-0-330"></a><span class="sd">        raw features are present in `raw_features`.</span>
</span><span id="__span-0-331"><a id="__codelineno-0-331" name="__codelineno-0-331"></a>
</span><span id="__span-0-332"><a id="__codelineno-0-332" name="__codelineno-0-332"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-333"><a id="__codelineno-0-333" name="__codelineno-0-333"></a><span class="sd">    -------</span>
</span><span id="__span-0-334"><a id="__codelineno-0-334" name="__codelineno-0-334"></a><span class="sd">      A dict whose keys are feature names and values are `Tensor`s,</span>
</span><span id="__span-0-335"><a id="__codelineno-0-335" name="__codelineno-0-335"></a><span class="sd">      `SparseTensor`s, or `RaggedTensor`s representing transformed features.</span>
</span><span id="__span-0-336"><a id="__codelineno-0-336" name="__codelineno-0-336"></a><span class="sd">    """</span>
</span><span id="__span-0-337"><a id="__codelineno-0-337" name="__codelineno-0-337"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exported_as_v1</span><span class="p">:</span>
</span><span id="__span-0-338"><a id="__codelineno-0-338" name="__codelineno-0-338"></a>        <span class="n">transformed_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_raw_features_compat_v1</span><span class="p">(</span>
</span><span id="__span-0-339"><a id="__codelineno-0-339" name="__codelineno-0-339"></a>            <span class="n">raw_features</span><span class="p">,</span> <span class="n">drop_unused_features</span>
</span><span id="__span-0-340"><a id="__codelineno-0-340" name="__codelineno-0-340"></a>        <span class="p">)</span>
</span><span id="__span-0-341"><a id="__codelineno-0-341" name="__codelineno-0-341"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-342"><a id="__codelineno-0-342" name="__codelineno-0-342"></a>        <span class="n">tft_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_features_layer</span><span class="p">()</span>
</span><span id="__span-0-343"><a id="__codelineno-0-343" name="__codelineno-0-343"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">drop_unused_features</span><span class="p">:</span>
</span><span id="__span-0-344"><a id="__codelineno-0-344" name="__codelineno-0-344"></a>            <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
</span><span id="__span-0-345"><a id="__codelineno-0-345" name="__codelineno-0-345"></a>                <span class="s2">"Unused features are always dropped in the TF 2.x "</span>
</span><span id="__span-0-346"><a id="__codelineno-0-346" name="__codelineno-0-346"></a>                <span class="s2">"implementation. Ignoring value of drop_unused_features."</span>
</span><span id="__span-0-347"><a id="__codelineno-0-347" name="__codelineno-0-347"></a>            <span class="p">)</span>
</span><span id="__span-0-348"><a id="__codelineno-0-348" name="__codelineno-0-348"></a>
</span><span id="__span-0-349"><a id="__codelineno-0-349" name="__codelineno-0-349"></a>        <span class="n">transformed_features</span> <span class="o">=</span> <span class="n">tft_layer</span><span class="p">(</span><span class="n">raw_features</span><span class="p">)</span>
</span><span id="__span-0-350"><a id="__codelineno-0-350" name="__codelineno-0-350"></a>    <span class="k">return</span> <span class="n">_TransformedFeaturesDict</span><span class="p">(</span><span class="n">transformed_features</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h6 id="tensorflow_transform.TFTransformOutput.transformed_domains" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">transformed_domains</span>


<a href="#tensorflow_transform.TFTransformOutput.transformed_domains" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">transformed_domains</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Dict" href="https://docs.python.org/3/library/typing.html#typing.Dict">Dict</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="tensorflow_transform.common_types.DomainType">DomainType</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Returns domains for the transformed features.</p>
<h6 id="tensorflow_transform.TFTransformOutput.transformed_domains--returns">Returns<a class="headerlink" href="#tensorflow_transform.TFTransformOutput.transformed_domains--returns" title="Permanent link">Â¶</a></h6>
<p>A dict from feature names to one of schema_pb2.IntDomain,
  schema_pb2.StringDomain or schema_pb2.FloatDomain.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/output_wrapper.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-125"><a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="k">def</span><span class="w"> </span><span class="nf">transformed_domains</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">common_types</span><span class="o">.</span><span class="n">DomainType</span><span class="p">]:</span>
</span><span id="__span-0-126"><a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="w">    </span><span class="sd">"""Returns domains for the transformed features.</span>
</span><span id="__span-0-127"><a id="__codelineno-0-127" name="__codelineno-0-127"></a>
</span><span id="__span-0-128"><a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="sd">    Returns</span>
</span><span id="__span-0-129"><a id="__codelineno-0-129" name="__codelineno-0-129"></a><span class="sd">    -------</span>
</span><span id="__span-0-130"><a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">      A dict from feature names to one of schema_pb2.IntDomain,</span>
</span><span id="__span-0-131"><a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">      schema_pb2.StringDomain or schema_pb2.FloatDomain.</span>
</span><span id="__span-0-132"><a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="sd">    """</span>
</span><span id="__span-0-133"><a id="__codelineno-0-133" name="__codelineno-0-133"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transformed_domains</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-134"><a id="__codelineno-0-134" name="__codelineno-0-134"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_transformed_domains</span> <span class="o">=</span> <span class="n">schema_utils</span><span class="o">.</span><span class="n">schema_as_feature_spec</span><span class="p">(</span>
</span><span id="__span-0-135"><a id="__codelineno-0-135" name="__codelineno-0-135"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">transformed_metadata</span><span class="o">.</span><span class="n">schema</span>
</span><span id="__span-0-136"><a id="__codelineno-0-136" name="__codelineno-0-136"></a>        <span class="p">)</span><span class="o">.</span><span class="n">domains</span>
</span><span id="__span-0-137"><a id="__codelineno-0-137" name="__codelineno-0-137"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transformed_domains</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h6 id="tensorflow_transform.TFTransformOutput.transformed_feature_spec" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">transformed_feature_spec</span>


<a href="#tensorflow_transform.TFTransformOutput.transformed_feature_spec" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">transformed_feature_spec</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Dict" href="https://docs.python.org/3/library/typing.html#typing.Dict">Dict</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="tensorflow_transform.common_types.FeatureSpecType">FeatureSpecType</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Returns a feature_spec for the transformed features.</p>
<h6 id="tensorflow_transform.TFTransformOutput.transformed_feature_spec--returns">Returns<a class="headerlink" href="#tensorflow_transform.TFTransformOutput.transformed_feature_spec--returns" title="Permanent link">Â¶</a></h6>
<p>A dict from feature names to FixedLenFeature/SparseFeature/VarLenFeature.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/output_wrapper.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-114"><a id="__codelineno-0-114" name="__codelineno-0-114"></a><span class="k">def</span><span class="w"> </span><span class="nf">transformed_feature_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">common_types</span><span class="o">.</span><span class="n">FeatureSpecType</span><span class="p">]:</span>
</span><span id="__span-0-115"><a id="__codelineno-0-115" name="__codelineno-0-115"></a><span class="w">    </span><span class="sd">"""Returns a feature_spec for the transformed features.</span>
</span><span id="__span-0-116"><a id="__codelineno-0-116" name="__codelineno-0-116"></a>
</span><span id="__span-0-117"><a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="sd">    Returns</span>
</span><span id="__span-0-118"><a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="sd">    -------</span>
</span><span id="__span-0-119"><a id="__codelineno-0-119" name="__codelineno-0-119"></a><span class="sd">      A dict from feature names to FixedLenFeature/SparseFeature/VarLenFeature.</span>
</span><span id="__span-0-120"><a id="__codelineno-0-120" name="__codelineno-0-120"></a><span class="sd">    """</span>
</span><span id="__span-0-121"><a id="__codelineno-0-121" name="__codelineno-0-121"></a>    <span class="k">return</span> <span class="n">schema_utils</span><span class="o">.</span><span class="n">schema_as_feature_spec</span><span class="p">(</span>
</span><span id="__span-0-122"><a id="__codelineno-0-122" name="__codelineno-0-122"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">transformed_metadata</span><span class="o">.</span><span class="n">schema</span>
</span><span id="__span-0-123"><a id="__codelineno-0-123" name="__codelineno-0-123"></a>    <span class="p">)</span><span class="o">.</span><span class="n">feature_spec</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h6 id="tensorflow_transform.TFTransformOutput.vocabulary_by_name" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">vocabulary_by_name</span>


<a href="#tensorflow_transform.TFTransformOutput.vocabulary_by_name" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">vocabulary_by_name</span><span class="p">(</span><span class="n">vocab_filename</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="            List


  
      module-attribute
   (typing.List)" href="#tensorflow_transform.List">List</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#bytes">bytes</a></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Like vocabulary_file_by_name but returns a list.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/output_wrapper.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-245"><a id="__codelineno-0-245" name="__codelineno-0-245"></a><span class="k">def</span><span class="w"> </span><span class="nf">vocabulary_by_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">bytes</span><span class="p">]:</span>
</span><span id="__span-0-246"><a id="__codelineno-0-246" name="__codelineno-0-246"></a><span class="w">    </span><span class="sd">"""Like vocabulary_file_by_name but returns a list."""</span>
</span><span id="__span-0-247"><a id="__codelineno-0-247" name="__codelineno-0-247"></a>    <span class="n">vocab_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocabulary_file_by_name</span><span class="p">(</span><span class="n">vocab_filename</span><span class="p">)</span>
</span><span id="__span-0-248"><a id="__codelineno-0-248" name="__codelineno-0-248"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">vocab_path</span><span class="p">:</span>
</span><span id="__span-0-249"><a id="__codelineno-0-249" name="__codelineno-0-249"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="__span-0-250"><a id="__codelineno-0-250" name="__codelineno-0-250"></a>            <span class="s2">"Could not read vocabulary: </span><span class="si">{}</span><span class="s2">, does not exist"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">vocab_filename</span><span class="p">)</span>
</span><span id="__span-0-251"><a id="__codelineno-0-251" name="__codelineno-0-251"></a>        <span class="p">)</span>
</span><span id="__span-0-252"><a id="__codelineno-0-252" name="__codelineno-0-252"></a>    <span class="k">elif</span> <span class="n">vocab_path</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">"tfrecord.gz"</span><span class="p">):</span>
</span><span id="__span-0-253"><a id="__codelineno-0-253" name="__codelineno-0-253"></a>        <span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TFRecordDataset</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">,</span> <span class="n">compression_type</span><span class="o">=</span><span class="s2">"GZIP"</span><span class="p">)</span>
</span><span id="__span-0-254"><a id="__codelineno-0-254" name="__codelineno-0-254"></a>        <span class="n">vocab_tensor</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="o">.</span><span class="n">max</span><span class="p">)</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span>
</span><span id="__span-0-255"><a id="__codelineno-0-255" name="__codelineno-0-255"></a>            <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">),</span>
</span><span id="__span-0-256"><a id="__codelineno-0-256" name="__codelineno-0-256"></a>            <span class="k">lambda</span> <span class="n">state</span><span class="p">,</span> <span class="n">elem</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">elem</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
</span><span id="__span-0-257"><a id="__codelineno-0-257" name="__codelineno-0-257"></a>        <span class="p">)</span>
</span><span id="__span-0-258"><a id="__codelineno-0-258" name="__codelineno-0-258"></a>        <span class="c1"># Using as_numpy_iterator only works when executing eagerly.</span>
</span><span id="__span-0-259"><a id="__codelineno-0-259" name="__codelineno-0-259"></a>        <span class="k">return</span> <span class="n">_get_tensor_value</span><span class="p">(</span><span class="n">vocab_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span><span id="__span-0-260"><a id="__codelineno-0-260" name="__codelineno-0-260"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-261"><a id="__codelineno-0-261" name="__codelineno-0-261"></a>        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">GFile</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">,</span> <span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="__span-0-262"><a id="__codelineno-0-262" name="__codelineno-0-262"></a>            <span class="k">return</span> <span class="p">[</span><span class="n">l</span><span class="o">.</span><span class="n">rstrip</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">linesep</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">"utf-8"</span><span class="p">))</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">f</span><span class="p">]</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h6 id="tensorflow_transform.TFTransformOutput.vocabulary_file_by_name" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">vocabulary_file_by_name</span>


<a href="#tensorflow_transform.TFTransformOutput.vocabulary_file_by_name" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">vocabulary_file_by_name</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">vocab_filename</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Returns the vocabulary file path created in the preprocessing function.</p>
<p><code>vocab_filename</code> must either be (i) the name used as the vocab_filename
argument to tft.compute_and_apply_vocabulary / tft.vocabulary or (ii) the
key used in tft.annotate_asset.</p>
<p>When a mapping has been specified by calls to tft.annotate_asset, it will be
checked first for the provided filename. If present, this filename will be
used directly to construct a path.</p>
<p>If the mapping does not exist or <code>vocab_filename</code> is not present within it,
we will default to sanitizing <code>vocab_filename</code> and searching for files
matching it within the assets directory.</p>
<p>In either case, if the constructed path does not point to an existing file
within the assets subdirectory, we will return a None.</p>
        <hr>
<p>vocab_filename: The vocabulary name to lookup.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/output_wrapper.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-139"><a id="__codelineno-0-139" name="__codelineno-0-139"></a><span class="k">def</span><span class="w"> </span><span class="nf">vocabulary_file_by_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
</span><span id="__span-0-140"><a id="__codelineno-0-140" name="__codelineno-0-140"></a><span class="w">    </span><span class="sd">"""Returns the vocabulary file path created in the preprocessing function.</span>
</span><span id="__span-0-141"><a id="__codelineno-0-141" name="__codelineno-0-141"></a>
</span><span id="__span-0-142"><a id="__codelineno-0-142" name="__codelineno-0-142"></a><span class="sd">    `vocab_filename` must either be (i) the name used as the vocab_filename</span>
</span><span id="__span-0-143"><a id="__codelineno-0-143" name="__codelineno-0-143"></a><span class="sd">    argument to tft.compute_and_apply_vocabulary / tft.vocabulary or (ii) the</span>
</span><span id="__span-0-144"><a id="__codelineno-0-144" name="__codelineno-0-144"></a><span class="sd">    key used in tft.annotate_asset.</span>
</span><span id="__span-0-145"><a id="__codelineno-0-145" name="__codelineno-0-145"></a>
</span><span id="__span-0-146"><a id="__codelineno-0-146" name="__codelineno-0-146"></a><span class="sd">    When a mapping has been specified by calls to tft.annotate_asset, it will be</span>
</span><span id="__span-0-147"><a id="__codelineno-0-147" name="__codelineno-0-147"></a><span class="sd">    checked first for the provided filename. If present, this filename will be</span>
</span><span id="__span-0-148"><a id="__codelineno-0-148" name="__codelineno-0-148"></a><span class="sd">    used directly to construct a path.</span>
</span><span id="__span-0-149"><a id="__codelineno-0-149" name="__codelineno-0-149"></a>
</span><span id="__span-0-150"><a id="__codelineno-0-150" name="__codelineno-0-150"></a><span class="sd">    If the mapping does not exist or `vocab_filename` is not present within it,</span>
</span><span id="__span-0-151"><a id="__codelineno-0-151" name="__codelineno-0-151"></a><span class="sd">    we will default to sanitizing `vocab_filename` and searching for files</span>
</span><span id="__span-0-152"><a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="sd">    matching it within the assets directory.</span>
</span><span id="__span-0-153"><a id="__codelineno-0-153" name="__codelineno-0-153"></a>
</span><span id="__span-0-154"><a id="__codelineno-0-154" name="__codelineno-0-154"></a><span class="sd">    In either case, if the constructed path does not point to an existing file</span>
</span><span id="__span-0-155"><a id="__codelineno-0-155" name="__codelineno-0-155"></a><span class="sd">    within the assets subdirectory, we will return a None.</span>
</span><span id="__span-0-156"><a id="__codelineno-0-156" name="__codelineno-0-156"></a>
</span><span id="__span-0-157"><a id="__codelineno-0-157" name="__codelineno-0-157"></a><span class="sd">    Args:</span>
</span><span id="__span-0-158"><a id="__codelineno-0-158" name="__codelineno-0-158"></a><span class="sd">    ----</span>
</span><span id="__span-0-159"><a id="__codelineno-0-159" name="__codelineno-0-159"></a><span class="sd">      vocab_filename: The vocabulary name to lookup.</span>
</span><span id="__span-0-160"><a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="sd">    """</span>
</span><span id="__span-0-161"><a id="__codelineno-0-161" name="__codelineno-0-161"></a>    <span class="n">mapping_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_transformed_metadata_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ASSET_MAP</span><span class="p">)</span>
</span><span id="__span-0-162"><a id="__codelineno-0-162" name="__codelineno-0-162"></a>
</span><span id="__span-0-163"><a id="__codelineno-0-163" name="__codelineno-0-163"></a>    <span class="n">mapping</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="__span-0-164"><a id="__codelineno-0-164" name="__codelineno-0-164"></a>    <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">mapping_path</span><span class="p">):</span>
</span><span id="__span-0-165"><a id="__codelineno-0-165" name="__codelineno-0-165"></a>        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">GFile</span><span class="p">(</span><span class="n">mapping_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="__span-0-166"><a id="__codelineno-0-166" name="__codelineno-0-166"></a>            <span class="n">mapping</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</span><span id="__span-0-167"><a id="__codelineno-0-167" name="__codelineno-0-167"></a>            <span class="k">if</span> <span class="n">vocab_filename</span> <span class="ow">in</span> <span class="n">mapping</span><span class="p">:</span>
</span><span id="__span-0-168"><a id="__codelineno-0-168" name="__codelineno-0-168"></a>                <span class="n">vocab_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
</span><span id="__span-0-169"><a id="__codelineno-0-169" name="__codelineno-0-169"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">transform_savedmodel_dir</span><span class="p">,</span>
</span><span id="__span-0-170"><a id="__codelineno-0-170" name="__codelineno-0-170"></a>                    <span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">ASSETS_DIRECTORY</span><span class="p">,</span>
</span><span id="__span-0-171"><a id="__codelineno-0-171" name="__codelineno-0-171"></a>                    <span class="n">mapping</span><span class="p">[</span><span class="n">vocab_filename</span><span class="p">],</span>
</span><span id="__span-0-172"><a id="__codelineno-0-172" name="__codelineno-0-172"></a>                <span class="p">)</span>
</span><span id="__span-0-173"><a id="__codelineno-0-173" name="__codelineno-0-173"></a>                <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">):</span>
</span><span id="__span-0-174"><a id="__codelineno-0-174" name="__codelineno-0-174"></a>                    <span class="k">return</span> <span class="n">vocab_path</span>
</span><span id="__span-0-175"><a id="__codelineno-0-175" name="__codelineno-0-175"></a>
</span><span id="__span-0-176"><a id="__codelineno-0-176" name="__codelineno-0-176"></a>    <span class="n">prefix</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
</span><span id="__span-0-177"><a id="__codelineno-0-177" name="__codelineno-0-177"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">transform_savedmodel_dir</span><span class="p">,</span>
</span><span id="__span-0-178"><a id="__codelineno-0-178" name="__codelineno-0-178"></a>        <span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">ASSETS_DIRECTORY</span><span class="p">,</span>
</span><span id="__span-0-179"><a id="__codelineno-0-179" name="__codelineno-0-179"></a>        <span class="n">sanitized_vocab_filename</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="n">vocab_filename</span><span class="p">),</span>
</span><span id="__span-0-180"><a id="__codelineno-0-180" name="__codelineno-0-180"></a>    <span class="p">)</span>
</span><span id="__span-0-181"><a id="__codelineno-0-181" name="__codelineno-0-181"></a>    <span class="n">files</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span>
</span><span id="__span-0-182"><a id="__codelineno-0-182" name="__codelineno-0-182"></a>        <span class="s2">"</span><span class="si">{}</span><span class="s2">.tfrecord.gz"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span>
</span><span id="__span-0-183"><a id="__codelineno-0-183" name="__codelineno-0-183"></a>    <span class="p">)</span>
</span><span id="__span-0-184"><a id="__codelineno-0-184" name="__codelineno-0-184"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">files</span><span class="p">:</span>
</span><span id="__span-0-185"><a id="__codelineno-0-185" name="__codelineno-0-185"></a>        <span class="k">return</span> <span class="kc">None</span>
</span><span id="__span-0-186"><a id="__codelineno-0-186" name="__codelineno-0-186"></a>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">files</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="__span-0-187"><a id="__codelineno-0-187" name="__codelineno-0-187"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Found too many vocabulary files: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">files</span><span class="p">))</span>
</span><span id="__span-0-188"><a id="__codelineno-0-188" name="__codelineno-0-188"></a>    <span class="k">return</span> <span class="n">files</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h6 id="tensorflow_transform.TFTransformOutput.vocabulary_size_by_name" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">vocabulary_size_by_name</span>


<a href="#tensorflow_transform.TFTransformOutput.vocabulary_size_by_name" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">vocabulary_size_by_name</span><span class="p">(</span><span class="n">vocab_filename</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Like vocabulary_file_by_name, but returns the size of vocabulary.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/output_wrapper.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-217"><a id="__codelineno-0-217" name="__codelineno-0-217"></a><span class="k">def</span><span class="w"> </span><span class="nf">vocabulary_size_by_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-218"><a id="__codelineno-0-218" name="__codelineno-0-218"></a><span class="w">    </span><span class="sd">"""Like vocabulary_file_by_name, but returns the size of vocabulary."""</span>
</span><span id="__span-0-219"><a id="__codelineno-0-219" name="__codelineno-0-219"></a>    <span class="n">vocab_size_from_annotations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary_size_from_annotations</span><span class="p">(</span>
</span><span id="__span-0-220"><a id="__codelineno-0-220" name="__codelineno-0-220"></a>        <span class="n">vocab_filename</span>
</span><span id="__span-0-221"><a id="__codelineno-0-221" name="__codelineno-0-221"></a>    <span class="p">)</span>
</span><span id="__span-0-222"><a id="__codelineno-0-222" name="__codelineno-0-222"></a>    <span class="k">if</span> <span class="n">vocab_size_from_annotations</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-223"><a id="__codelineno-0-223" name="__codelineno-0-223"></a>        <span class="k">return</span> <span class="n">vocab_size_from_annotations</span>
</span><span id="__span-0-224"><a id="__codelineno-0-224" name="__codelineno-0-224"></a>
</span><span id="__span-0-225"><a id="__codelineno-0-225" name="__codelineno-0-225"></a>    <span class="n">vocab_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocabulary_file_by_name</span><span class="p">(</span><span class="n">vocab_filename</span><span class="p">)</span>
</span><span id="__span-0-226"><a id="__codelineno-0-226" name="__codelineno-0-226"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">vocab_path</span><span class="p">:</span>
</span><span id="__span-0-227"><a id="__codelineno-0-227" name="__codelineno-0-227"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="__span-0-228"><a id="__codelineno-0-228" name="__codelineno-0-228"></a>            <span class="s2">"Could not compute vocabulary size for </span><span class="si">{}</span><span class="s2">, does not exist"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
</span><span id="__span-0-229"><a id="__codelineno-0-229" name="__codelineno-0-229"></a>                <span class="n">vocab_filename</span>
</span><span id="__span-0-230"><a id="__codelineno-0-230" name="__codelineno-0-230"></a>            <span class="p">)</span>
</span><span id="__span-0-231"><a id="__codelineno-0-231" name="__codelineno-0-231"></a>        <span class="p">)</span>
</span><span id="__span-0-232"><a id="__codelineno-0-232" name="__codelineno-0-232"></a>    <span class="k">elif</span> <span class="n">vocab_path</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">"tfrecord.gz"</span><span class="p">):</span>
</span><span id="__span-0-233"><a id="__codelineno-0-233" name="__codelineno-0-233"></a>        <span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TFRecordDataset</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">,</span> <span class="n">compression_type</span><span class="o">=</span><span class="s2">"GZIP"</span><span class="p">)</span>
</span><span id="__span-0-234"><a id="__codelineno-0-234" name="__codelineno-0-234"></a>
</span><span id="__span-0-235"><a id="__codelineno-0-235" name="__codelineno-0-235"></a>        <span class="k">def</span><span class="w"> </span><span class="nf">reduce_fn</span><span class="p">(</span><span class="n">accum</span><span class="p">,</span> <span class="n">elem</span><span class="p">):</span>
</span><span id="__span-0-236"><a id="__codelineno-0-236" name="__codelineno-0-236"></a>            <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"vocabulary_size"</span><span class="p">)</span> <span class="o">+</span> <span class="n">accum</span>
</span><span id="__span-0-237"><a id="__codelineno-0-237" name="__codelineno-0-237"></a>
</span><span id="__span-0-238"><a id="__codelineno-0-238" name="__codelineno-0-238"></a>        <span class="k">return</span> <span class="n">_get_tensor_value</span><span class="p">(</span>
</span><span id="__span-0-239"><a id="__codelineno-0-239" name="__codelineno-0-239"></a>            <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="o">.</span><span class="n">max</span><span class="p">)</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">reduce_fn</span><span class="p">)</span>
</span><span id="__span-0-240"><a id="__codelineno-0-240" name="__codelineno-0-240"></a>        <span class="p">)</span>
</span><span id="__span-0-241"><a id="__codelineno-0-241" name="__codelineno-0-241"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-242"><a id="__codelineno-0-242" name="__codelineno-0-242"></a>        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">GFile</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">,</span> <span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="__span-0-243"><a id="__codelineno-0-243" name="__codelineno-0-243"></a>            <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">f</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h4 id="tensorflow_transform.TransformFeaturesLayer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">TransformFeaturesLayer</span>


<a href="#tensorflow_transform.TransformFeaturesLayer" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">TransformFeaturesLayer</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">tft_output</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            TFTransformOutput (tensorflow_transform.output_wrapper.TFTransformOutput)" href="#tensorflow_transform.TFTransformOutput">TFTransformOutput</a></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">exported_as_v1</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="tensorflow_transform.keras_lib.tf_keras.Model">Model</span></code></p>


        <p>A Keras layer for applying a tf.Transform output to input layers.</p>







                  <details class="quote">
                    <summary>Source code in <code>tensorflow_transform/output_wrapper.py</code></summary>
                    <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-477">477</a></span>
<span class="normal"><a href="#__codelineno-0-478">478</a></span>
<span class="normal"><a href="#__codelineno-0-479">479</a></span>
<span class="normal"><a href="#__codelineno-0-480">480</a></span>
<span class="normal"><a href="#__codelineno-0-481">481</a></span>
<span class="normal"><a href="#__codelineno-0-482">482</a></span>
<span class="normal"><a href="#__codelineno-0-483">483</a></span>
<span class="normal"><a href="#__codelineno-0-484">484</a></span>
<span class="normal"><a href="#__codelineno-0-485">485</a></span>
<span class="normal"><a href="#__codelineno-0-486">486</a></span>
<span class="normal"><a href="#__codelineno-0-487">487</a></span>
<span class="normal"><a href="#__codelineno-0-488">488</a></span>
<span class="normal"><a href="#__codelineno-0-489">489</a></span>
<span class="normal"><a href="#__codelineno-0-490">490</a></span>
<span class="normal"><a href="#__codelineno-0-491">491</a></span>
<span class="normal"><a href="#__codelineno-0-492">492</a></span>
<span class="normal"><a href="#__codelineno-0-493">493</a></span>
<span class="normal"><a href="#__codelineno-0-494">494</a></span>
<span class="normal"><a href="#__codelineno-0-495">495</a></span>
<span class="normal"><a href="#__codelineno-0-496">496</a></span>
<span class="normal"><a href="#__codelineno-0-497">497</a></span>
<span class="normal"><a href="#__codelineno-0-498">498</a></span>
<span class="normal"><a href="#__codelineno-0-499">499</a></span>
<span class="normal"><a href="#__codelineno-0-500">500</a></span>
<span class="normal"><a href="#__codelineno-0-501">501</a></span>
<span class="normal"><a href="#__codelineno-0-502">502</a></span>
<span class="normal"><a href="#__codelineno-0-503">503</a></span>
<span class="normal"><a href="#__codelineno-0-504">504</a></span>
<span class="normal"><a href="#__codelineno-0-505">505</a></span>
<span class="normal"><a href="#__codelineno-0-506">506</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-477"><a id="__codelineno-0-477" name="__codelineno-0-477"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-478"><a id="__codelineno-0-478" name="__codelineno-0-478"></a>    <span class="bp">self</span><span class="p">,</span> <span class="n">tft_output</span><span class="p">:</span> <span class="n">TFTransformOutput</span><span class="p">,</span> <span class="n">exported_as_v1</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-479"><a id="__codelineno-0-479" name="__codelineno-0-479"></a><span class="p">):</span>
</span><span id="__span-0-480"><a id="__codelineno-0-480" name="__codelineno-0-480"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="__span-0-481"><a id="__codelineno-0-481" name="__codelineno-0-481"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_tft_output</span> <span class="o">=</span> <span class="n">tft_output</span>
</span><span id="__span-0-482"><a id="__codelineno-0-482" name="__codelineno-0-482"></a>    <span class="k">if</span> <span class="n">exported_as_v1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-483"><a id="__codelineno-0-483" name="__codelineno-0-483"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_exported_as_v1</span> <span class="o">=</span> <span class="n">saved_transform_io</span><span class="o">.</span><span class="n">exported_as_v1</span><span class="p">(</span>
</span><span id="__span-0-484"><a id="__codelineno-0-484" name="__codelineno-0-484"></a>            <span class="n">tft_output</span><span class="o">.</span><span class="n">transform_savedmodel_dir</span>
</span><span id="__span-0-485"><a id="__codelineno-0-485" name="__codelineno-0-485"></a>        <span class="p">)</span>
</span><span id="__span-0-486"><a id="__codelineno-0-486" name="__codelineno-0-486"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-487"><a id="__codelineno-0-487" name="__codelineno-0-487"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_exported_as_v1</span> <span class="o">=</span> <span class="n">exported_as_v1</span>
</span><span id="__span-0-488"><a id="__codelineno-0-488" name="__codelineno-0-488"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_saved_model_loader_value</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-489"><a id="__codelineno-0-489" name="__codelineno-0-489"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_loaded_saved_model_graph</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-490"><a id="__codelineno-0-490" name="__codelineno-0-490"></a>    <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">executing_eagerly_outside_functions</span><span class="p">():</span>
</span><span id="__span-0-491"><a id="__codelineno-0-491" name="__codelineno-0-491"></a>        <span class="c1"># The model must be tracked by assigning to an attribute of the Keras</span>
</span><span id="__span-0-492"><a id="__codelineno-0-492" name="__codelineno-0-492"></a>        <span class="c1"># layer. Hence, we track the attributes of _saved_model_loader here as</span>
</span><span id="__span-0-493"><a id="__codelineno-0-493" name="__codelineno-0-493"></a>        <span class="c1"># well.</span>
</span><span id="__span-0-494"><a id="__codelineno-0-494" name="__codelineno-0-494"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_saved_model_loader_tracked_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_saved_model_loader</span><span class="o">.</span><span class="vm">__dict__</span>
</span><span id="__span-0-495"><a id="__codelineno-0-495" name="__codelineno-0-495"></a>
</span><span id="__span-0-496"><a id="__codelineno-0-496" name="__codelineno-0-496"></a>    <span class="c1"># TODO(b/162055065): This is needed because otherwise we'd get an error in</span>
</span><span id="__span-0-497"><a id="__codelineno-0-497" name="__codelineno-0-497"></a>    <span class="c1"># some cases:</span>
</span><span id="__span-0-498"><a id="__codelineno-0-498" name="__codelineno-0-498"></a>    <span class="c1"># ValueError: Your Layer or Model is in an invalid state. This can happen</span>
</span><span id="__span-0-499"><a id="__codelineno-0-499" name="__codelineno-0-499"></a>    <span class="c1"># if you are interleaving estimator/non-estimator models or interleaving</span>
</span><span id="__span-0-500"><a id="__codelineno-0-500" name="__codelineno-0-500"></a>    <span class="c1"># models/layers made in tf.compat.v1.Graph.as_default() with models/layers</span>
</span><span id="__span-0-501"><a id="__codelineno-0-501" name="__codelineno-0-501"></a>    <span class="c1"># created outside of it. Converting a model to an estimator (via</span>
</span><span id="__span-0-502"><a id="__codelineno-0-502" name="__codelineno-0-502"></a>    <span class="c1"># model_to_estimator) invalidates all models/layers made before the</span>
</span><span id="__span-0-503"><a id="__codelineno-0-503" name="__codelineno-0-503"></a>    <span class="c1"># conversion (even if they were not the model converted to an estimator).</span>
</span><span id="__span-0-504"><a id="__codelineno-0-504" name="__codelineno-0-504"></a>    <span class="c1"># Similarly, making a layer or a model inside a a tf.compat.v1.Graph</span>
</span><span id="__span-0-505"><a id="__codelineno-0-505" name="__codelineno-0-505"></a>    <span class="c1"># invalidates all layers/models you previously made outside of the graph.</span>
</span><span id="__span-0-506"><a id="__codelineno-0-506" name="__codelineno-0-506"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_originally_built_as_v1</span> <span class="o">=</span> <span class="kc">True</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



  <div class="doc doc-children">







<h5 id="tensorflow_transform.TransformFeaturesLayer-functions">Functions<a href="#tensorflow_transform.TransformFeaturesLayer-functions" class="headerlink" title="Permanent link">Â¶</a></h5>

<div class="doc doc-object doc-function">


<h6 id="tensorflow_transform.TransformFeaturesLayer.call" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">call</span>


<a href="#tensorflow_transform.TransformFeaturesLayer.call" class="headerlink" title="Permanent link">Â¶</a></h6>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">call</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">inputs</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Mapping


  
      module-attribute
   (typing.Mapping)" href="#tensorflow_transform.Mapping">Mapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">],</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Dict" href="https://docs.python.org/3/library/typing.html#typing.Dict">Dict</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/output_wrapper.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-547">547</a></span>
<span class="normal"><a href="#__codelineno-0-548">548</a></span>
<span class="normal"><a href="#__codelineno-0-549">549</a></span>
<span class="normal"><a href="#__codelineno-0-550">550</a></span>
<span class="normal"><a href="#__codelineno-0-551">551</a></span>
<span class="normal"><a href="#__codelineno-0-552">552</a></span>
<span class="normal"><a href="#__codelineno-0-553">553</a></span>
<span class="normal"><a href="#__codelineno-0-554">554</a></span>
<span class="normal"><a href="#__codelineno-0-555">555</a></span>
<span class="normal"><a href="#__codelineno-0-556">556</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-547"><a id="__codelineno-0-547" name="__codelineno-0-547"></a><span class="k">def</span><span class="w"> </span><span class="nf">call</span><span class="p">(</span>  <span class="c1"># pytype: disable=signature-mismatch  # overriding-parameter-count-checks</span>
</span><span id="__span-0-548"><a id="__codelineno-0-548" name="__codelineno-0-548"></a>    <span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">]</span>
</span><span id="__span-0-549"><a id="__codelineno-0-549" name="__codelineno-0-549"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">]:</span>
</span><span id="__span-0-550"><a id="__codelineno-0-550" name="__codelineno-0-550"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exported_as_v1</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">ops</span><span class="o">.</span><span class="n">executing_eagerly_outside_functions</span><span class="p">():</span>
</span><span id="__span-0-551"><a id="__codelineno-0-551" name="__codelineno-0-551"></a>        <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"Falling back to transform_raw_features..."</span><span class="p">)</span>
</span><span id="__span-0-552"><a id="__codelineno-0-552" name="__codelineno-0-552"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tft_output</span><span class="o">.</span><span class="n">_transform_raw_features_compat_v1</span><span class="p">(</span>  <span class="c1"># pylint: disable=protected-access</span>
</span><span id="__span-0-553"><a id="__codelineno-0-553" name="__codelineno-0-553"></a>            <span class="n">inputs</span><span class="p">,</span> <span class="n">drop_unused_features</span><span class="o">=</span><span class="kc">True</span>
</span><span id="__span-0-554"><a id="__codelineno-0-554" name="__codelineno-0-554"></a>        <span class="p">)</span>
</span><span id="__span-0-555"><a id="__codelineno-0-555" name="__codelineno-0-555"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-556"><a id="__codelineno-0-556" name="__codelineno-0-556"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_saved_model_loader</span><span class="o">.</span><span class="n">apply_transform_model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>
<h3 id="tensorflow_transform-functions">Functions<a href="#tensorflow_transform-functions" class="headerlink" title="Permanent link">Â¶</a></h3>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.Any" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">Any</span>


<a href="#tensorflow_transform.Any" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">Any</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Special type indicating an unconstrained type.</p>
<ul>
<li>Any is compatible with every type.</li>
<li>Any assumed to have all methods.</li>
<li>All values assumed to be instances of Any.</li>
</ul>
<p>Note that all the above statements are true from the point of view of
static type checkers. At runtime, Any should not be used with instance
or class checks.</p>


            <details class="quote">
              <summary>Source code in <code>python3.9/typing.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-364">364</a></span>
<span class="normal"><a href="#__codelineno-0-365">365</a></span>
<span class="normal"><a href="#__codelineno-0-366">366</a></span>
<span class="normal"><a href="#__codelineno-0-367">367</a></span>
<span class="normal"><a href="#__codelineno-0-368">368</a></span>
<span class="normal"><a href="#__codelineno-0-369">369</a></span>
<span class="normal"><a href="#__codelineno-0-370">370</a></span>
<span class="normal"><a href="#__codelineno-0-371">371</a></span>
<span class="normal"><a href="#__codelineno-0-372">372</a></span>
<span class="normal"><a href="#__codelineno-0-373">373</a></span>
<span class="normal"><a href="#__codelineno-0-374">374</a></span>
<span class="normal"><a href="#__codelineno-0-375">375</a></span>
<span class="normal"><a href="#__codelineno-0-376">376</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-364"><a id="__codelineno-0-364" name="__codelineno-0-364"></a><span class="nd">@_SpecialForm</span>
</span><span id="__span-0-365"><a id="__codelineno-0-365" name="__codelineno-0-365"></a><span class="k">def</span><span class="w"> </span><span class="nf">Any</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">):</span>
</span><span id="__span-0-366"><a id="__codelineno-0-366" name="__codelineno-0-366"></a><span class="w">    </span><span class="sd">"""Special type indicating an unconstrained type.</span>
</span><span id="__span-0-367"><a id="__codelineno-0-367" name="__codelineno-0-367"></a>
</span><span id="__span-0-368"><a id="__codelineno-0-368" name="__codelineno-0-368"></a><span class="sd">    - Any is compatible with every type.</span>
</span><span id="__span-0-369"><a id="__codelineno-0-369" name="__codelineno-0-369"></a><span class="sd">    - Any assumed to have all methods.</span>
</span><span id="__span-0-370"><a id="__codelineno-0-370" name="__codelineno-0-370"></a><span class="sd">    - All values assumed to be instances of Any.</span>
</span><span id="__span-0-371"><a id="__codelineno-0-371" name="__codelineno-0-371"></a>
</span><span id="__span-0-372"><a id="__codelineno-0-372" name="__codelineno-0-372"></a><span class="sd">    Note that all the above statements are true from the point of view of</span>
</span><span id="__span-0-373"><a id="__codelineno-0-373" name="__codelineno-0-373"></a><span class="sd">    static type checkers. At runtime, Any should not be used with instance</span>
</span><span id="__span-0-374"><a id="__codelineno-0-374" name="__codelineno-0-374"></a><span class="sd">    or class checks.</span>
</span><span id="__span-0-375"><a id="__codelineno-0-375" name="__codelineno-0-375"></a><span class="sd">    """</span>
</span><span id="__span-0-376"><a id="__codelineno-0-376" name="__codelineno-0-376"></a>    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="bp">self</span><span class="si">}</span><span class="s2"> is not subscriptable"</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.Optional" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">Optional</span>


<a href="#tensorflow_transform.Optional" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">Optional</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Optional type.</p>
<p>Optional[X] is equivalent to Union[X, None].</p>


            <details class="quote">
              <summary>Source code in <code>python3.9/typing.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-472">472</a></span>
<span class="normal"><a href="#__codelineno-0-473">473</a></span>
<span class="normal"><a href="#__codelineno-0-474">474</a></span>
<span class="normal"><a href="#__codelineno-0-475">475</a></span>
<span class="normal"><a href="#__codelineno-0-476">476</a></span>
<span class="normal"><a href="#__codelineno-0-477">477</a></span>
<span class="normal"><a href="#__codelineno-0-478">478</a></span>
<span class="normal"><a href="#__codelineno-0-479">479</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-472"><a id="__codelineno-0-472" name="__codelineno-0-472"></a><span class="nd">@_SpecialForm</span>
</span><span id="__span-0-473"><a id="__codelineno-0-473" name="__codelineno-0-473"></a><span class="k">def</span><span class="w"> </span><span class="nf">Optional</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">):</span>
</span><span id="__span-0-474"><a id="__codelineno-0-474" name="__codelineno-0-474"></a><span class="w">    </span><span class="sd">"""Optional type.</span>
</span><span id="__span-0-475"><a id="__codelineno-0-475" name="__codelineno-0-475"></a>
</span><span id="__span-0-476"><a id="__codelineno-0-476" name="__codelineno-0-476"></a><span class="sd">    Optional[X] is equivalent to Union[X, None].</span>
</span><span id="__span-0-477"><a id="__codelineno-0-477" name="__codelineno-0-477"></a><span class="sd">    """</span>
</span><span id="__span-0-478"><a id="__codelineno-0-478" name="__codelineno-0-478"></a>    <span class="n">arg</span> <span class="o">=</span> <span class="n">_type_check</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="bp">self</span><span class="si">}</span><span class="s2"> requires a single type."</span><span class="p">)</span>
</span><span id="__span-0-479"><a id="__codelineno-0-479" name="__codelineno-0-479"></a>    <span class="k">return</span> <span class="n">Union</span><span class="p">[</span><span class="n">arg</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">)]</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.Union" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">Union</span>


<a href="#tensorflow_transform.Union" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">Union</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Union type; Union[X, Y] means either X or Y.</p>
<p>To define a union, use e.g. Union[int, str].  Details:
- The arguments must be types and there must be at least one.
- None as an argument is a special case and is replaced by
  type(None).
- Unions of unions are flattened, e.g.::</p>
<div class="language-text highlight"><pre><span></span><code>Union[Union[int, str], float] == Union[int, str, float]
</code></pre></div>
<ul>
<li>
<p>Unions of a single argument vanish, e.g.::</p>
<p>Union[int] == int  # The constructor actually returns int</p>
</li>
<li>
<p>Redundant arguments are skipped, e.g.::</p>
<p>Union[int, str, int] == Union[int, str]</p>
</li>
<li>
<p>When comparing unions, the argument order is ignored, e.g.::</p>
<p>Union[int, str] == Union[str, int]</p>
</li>
<li>
<p>You cannot subclass or instantiate a union.</p>
</li>
<li>You can use Optional[X] as a shorthand for Union[X, None].</li>
</ul>


            <details class="quote">
              <summary>Source code in <code>python3.9/typing.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-434">434</a></span>
<span class="normal"><a href="#__codelineno-0-435">435</a></span>
<span class="normal"><a href="#__codelineno-0-436">436</a></span>
<span class="normal"><a href="#__codelineno-0-437">437</a></span>
<span class="normal"><a href="#__codelineno-0-438">438</a></span>
<span class="normal"><a href="#__codelineno-0-439">439</a></span>
<span class="normal"><a href="#__codelineno-0-440">440</a></span>
<span class="normal"><a href="#__codelineno-0-441">441</a></span>
<span class="normal"><a href="#__codelineno-0-442">442</a></span>
<span class="normal"><a href="#__codelineno-0-443">443</a></span>
<span class="normal"><a href="#__codelineno-0-444">444</a></span>
<span class="normal"><a href="#__codelineno-0-445">445</a></span>
<span class="normal"><a href="#__codelineno-0-446">446</a></span>
<span class="normal"><a href="#__codelineno-0-447">447</a></span>
<span class="normal"><a href="#__codelineno-0-448">448</a></span>
<span class="normal"><a href="#__codelineno-0-449">449</a></span>
<span class="normal"><a href="#__codelineno-0-450">450</a></span>
<span class="normal"><a href="#__codelineno-0-451">451</a></span>
<span class="normal"><a href="#__codelineno-0-452">452</a></span>
<span class="normal"><a href="#__codelineno-0-453">453</a></span>
<span class="normal"><a href="#__codelineno-0-454">454</a></span>
<span class="normal"><a href="#__codelineno-0-455">455</a></span>
<span class="normal"><a href="#__codelineno-0-456">456</a></span>
<span class="normal"><a href="#__codelineno-0-457">457</a></span>
<span class="normal"><a href="#__codelineno-0-458">458</a></span>
<span class="normal"><a href="#__codelineno-0-459">459</a></span>
<span class="normal"><a href="#__codelineno-0-460">460</a></span>
<span class="normal"><a href="#__codelineno-0-461">461</a></span>
<span class="normal"><a href="#__codelineno-0-462">462</a></span>
<span class="normal"><a href="#__codelineno-0-463">463</a></span>
<span class="normal"><a href="#__codelineno-0-464">464</a></span>
<span class="normal"><a href="#__codelineno-0-465">465</a></span>
<span class="normal"><a href="#__codelineno-0-466">466</a></span>
<span class="normal"><a href="#__codelineno-0-467">467</a></span>
<span class="normal"><a href="#__codelineno-0-468">468</a></span>
<span class="normal"><a href="#__codelineno-0-469">469</a></span>
<span class="normal"><a href="#__codelineno-0-470">470</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-434"><a id="__codelineno-0-434" name="__codelineno-0-434"></a><span class="nd">@_SpecialForm</span>
</span><span id="__span-0-435"><a id="__codelineno-0-435" name="__codelineno-0-435"></a><span class="k">def</span><span class="w"> </span><span class="nf">Union</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">):</span>
</span><span id="__span-0-436"><a id="__codelineno-0-436" name="__codelineno-0-436"></a><span class="w">    </span><span class="sd">"""Union type; Union[X, Y] means either X or Y.</span>
</span><span id="__span-0-437"><a id="__codelineno-0-437" name="__codelineno-0-437"></a>
</span><span id="__span-0-438"><a id="__codelineno-0-438" name="__codelineno-0-438"></a><span class="sd">    To define a union, use e.g. Union[int, str].  Details:</span>
</span><span id="__span-0-439"><a id="__codelineno-0-439" name="__codelineno-0-439"></a><span class="sd">    - The arguments must be types and there must be at least one.</span>
</span><span id="__span-0-440"><a id="__codelineno-0-440" name="__codelineno-0-440"></a><span class="sd">    - None as an argument is a special case and is replaced by</span>
</span><span id="__span-0-441"><a id="__codelineno-0-441" name="__codelineno-0-441"></a><span class="sd">      type(None).</span>
</span><span id="__span-0-442"><a id="__codelineno-0-442" name="__codelineno-0-442"></a><span class="sd">    - Unions of unions are flattened, e.g.::</span>
</span><span id="__span-0-443"><a id="__codelineno-0-443" name="__codelineno-0-443"></a>
</span><span id="__span-0-444"><a id="__codelineno-0-444" name="__codelineno-0-444"></a><span class="sd">        Union[Union[int, str], float] == Union[int, str, float]</span>
</span><span id="__span-0-445"><a id="__codelineno-0-445" name="__codelineno-0-445"></a>
</span><span id="__span-0-446"><a id="__codelineno-0-446" name="__codelineno-0-446"></a><span class="sd">    - Unions of a single argument vanish, e.g.::</span>
</span><span id="__span-0-447"><a id="__codelineno-0-447" name="__codelineno-0-447"></a>
</span><span id="__span-0-448"><a id="__codelineno-0-448" name="__codelineno-0-448"></a><span class="sd">        Union[int] == int  # The constructor actually returns int</span>
</span><span id="__span-0-449"><a id="__codelineno-0-449" name="__codelineno-0-449"></a>
</span><span id="__span-0-450"><a id="__codelineno-0-450" name="__codelineno-0-450"></a><span class="sd">    - Redundant arguments are skipped, e.g.::</span>
</span><span id="__span-0-451"><a id="__codelineno-0-451" name="__codelineno-0-451"></a>
</span><span id="__span-0-452"><a id="__codelineno-0-452" name="__codelineno-0-452"></a><span class="sd">        Union[int, str, int] == Union[int, str]</span>
</span><span id="__span-0-453"><a id="__codelineno-0-453" name="__codelineno-0-453"></a>
</span><span id="__span-0-454"><a id="__codelineno-0-454" name="__codelineno-0-454"></a><span class="sd">    - When comparing unions, the argument order is ignored, e.g.::</span>
</span><span id="__span-0-455"><a id="__codelineno-0-455" name="__codelineno-0-455"></a>
</span><span id="__span-0-456"><a id="__codelineno-0-456" name="__codelineno-0-456"></a><span class="sd">        Union[int, str] == Union[str, int]</span>
</span><span id="__span-0-457"><a id="__codelineno-0-457" name="__codelineno-0-457"></a>
</span><span id="__span-0-458"><a id="__codelineno-0-458" name="__codelineno-0-458"></a><span class="sd">    - You cannot subclass or instantiate a union.</span>
</span><span id="__span-0-459"><a id="__codelineno-0-459" name="__codelineno-0-459"></a><span class="sd">    - You can use Optional[X] as a shorthand for Union[X, None].</span>
</span><span id="__span-0-460"><a id="__codelineno-0-460" name="__codelineno-0-460"></a><span class="sd">    """</span>
</span><span id="__span-0-461"><a id="__codelineno-0-461" name="__codelineno-0-461"></a>    <span class="k">if</span> <span class="n">parameters</span> <span class="o">==</span> <span class="p">():</span>
</span><span id="__span-0-462"><a id="__codelineno-0-462" name="__codelineno-0-462"></a>        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">"Cannot take a Union of no types."</span><span class="p">)</span>
</span><span id="__span-0-463"><a id="__codelineno-0-463" name="__codelineno-0-463"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
</span><span id="__span-0-464"><a id="__codelineno-0-464" name="__codelineno-0-464"></a>        <span class="n">parameters</span> <span class="o">=</span> <span class="p">(</span><span class="n">parameters</span><span class="p">,)</span>
</span><span id="__span-0-465"><a id="__codelineno-0-465" name="__codelineno-0-465"></a>    <span class="n">msg</span> <span class="o">=</span> <span class="s2">"Union[arg, ...]: each arg must be a type."</span>
</span><span id="__span-0-466"><a id="__codelineno-0-466" name="__codelineno-0-466"></a>    <span class="n">parameters</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">_type_check</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">msg</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">)</span>
</span><span id="__span-0-467"><a id="__codelineno-0-467" name="__codelineno-0-467"></a>    <span class="n">parameters</span> <span class="o">=</span> <span class="n">_remove_dups_flatten</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>
</span><span id="__span-0-468"><a id="__codelineno-0-468" name="__codelineno-0-468"></a>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="__span-0-469"><a id="__codelineno-0-469" name="__codelineno-0-469"></a>        <span class="k">return</span> <span class="n">parameters</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="__span-0-470"><a id="__codelineno-0-470" name="__codelineno-0-470"></a>    <span class="k">return</span> <span class="n">_UnionGenericAlias</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.annotate_asset" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">annotate_asset</span>


<a href="#tensorflow_transform.annotate_asset" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">annotate_asset</span><span class="p">(</span><span class="n">asset_key</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n">asset_filename</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Creates mapping between user-defined keys and SavedModel assets.</p>
<p>This mapping is made available in <code>BeamDatasetMetadata</code> and is also used to
resolve vocabularies in <code>tft.TFTransformOutput</code>.</p>
<p>Note: multiple mappings for the same key will overwrite the previous one.</p>
        <hr>
<p>asset_key: The key to associate with the asset.
  asset_filename: The filename as it appears within the assets/ subdirectory.
    Must be sanitized and complete (e.g. include the tfrecord.gz for suffix
    appropriate files).</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/annotators.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-230"><a id="__codelineno-0-230" name="__codelineno-0-230"></a><span class="k">def</span><span class="w"> </span><span class="nf">annotate_asset</span><span class="p">(</span><span class="n">asset_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">asset_filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="__span-0-231"><a id="__codelineno-0-231" name="__codelineno-0-231"></a><span class="w">    </span><span class="sd">"""Creates mapping between user-defined keys and SavedModel assets.</span>
</span><span id="__span-0-232"><a id="__codelineno-0-232" name="__codelineno-0-232"></a>
</span><span id="__span-0-233"><a id="__codelineno-0-233" name="__codelineno-0-233"></a><span class="sd">    This mapping is made available in `BeamDatasetMetadata` and is also used to</span>
</span><span id="__span-0-234"><a id="__codelineno-0-234" name="__codelineno-0-234"></a><span class="sd">    resolve vocabularies in `tft.TFTransformOutput`.</span>
</span><span id="__span-0-235"><a id="__codelineno-0-235" name="__codelineno-0-235"></a>
</span><span id="__span-0-236"><a id="__codelineno-0-236" name="__codelineno-0-236"></a><span class="sd">    Note: multiple mappings for the same key will overwrite the previous one.</span>
</span><span id="__span-0-237"><a id="__codelineno-0-237" name="__codelineno-0-237"></a>
</span><span id="__span-0-238"><a id="__codelineno-0-238" name="__codelineno-0-238"></a><span class="sd">    Args:</span>
</span><span id="__span-0-239"><a id="__codelineno-0-239" name="__codelineno-0-239"></a><span class="sd">    ----</span>
</span><span id="__span-0-240"><a id="__codelineno-0-240" name="__codelineno-0-240"></a><span class="sd">      asset_key: The key to associate with the asset.</span>
</span><span id="__span-0-241"><a id="__codelineno-0-241" name="__codelineno-0-241"></a><span class="sd">      asset_filename: The filename as it appears within the assets/ subdirectory.</span>
</span><span id="__span-0-242"><a id="__codelineno-0-242" name="__codelineno-0-242"></a><span class="sd">        Must be sanitized and complete (e.g. include the tfrecord.gz for suffix</span>
</span><span id="__span-0-243"><a id="__codelineno-0-243" name="__codelineno-0-243"></a><span class="sd">        appropriate files).</span>
</span><span id="__span-0-244"><a id="__codelineno-0-244" name="__codelineno-0-244"></a><span class="sd">    """</span>
</span><span id="__span-0-245"><a id="__codelineno-0-245" name="__codelineno-0-245"></a>    <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">add_to_collection</span><span class="p">(</span><span class="n">_ASSET_KEY_COLLECTION</span><span class="p">,</span> <span class="n">asset_key</span><span class="p">)</span>
</span><span id="__span-0-246"><a id="__codelineno-0-246" name="__codelineno-0-246"></a>    <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">add_to_collection</span><span class="p">(</span><span class="n">_ASSET_FILENAME_COLLECTION</span><span class="p">,</span> <span class="n">asset_filename</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.apply_buckets" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">apply_buckets</span>


<a href="#tensorflow_transform.apply_buckets" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">apply_buckets</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">bucket_boundaries</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.BucketBoundariesType">BucketBoundariesType</span></span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Returns a bucketized column, with a bucket index assigned to each input.</p>
<p>Each element <code>e</code> in <code>x</code> is mapped to a positive index <code>i</code> for which
<code>bucket_boundaries[i-1] &lt;= e &lt; bucket_boundaries[i]</code>, if it exists.
If <code>e &lt; bucket_boundaries[0]</code>, then <code>e</code> is mapped to <code>0</code>. If
<code>e &gt;= bucket_boundaries[-1]</code>, then <code>e</code> is mapped to <code>len(bucket_boundaries)</code>.
NaNs are mapped to <code>len(bucket_boundaries)</code>.</p>
<h6 id="tensorflow_transform.apply_buckets--example">Example:<a class="headerlink" href="#tensorflow_transform.apply_buckets--example" title="Permanent link">Â¶</a></h6>
<blockquote>
<blockquote>
<blockquote>
<p>x = tf.constant([[4.0, float('nan'), 1.0], [float('-inf'), 7.5, 10.0]])
bucket_boundaries = tf.constant([[2.0, 5.0, 10.0]])
tft.apply_buckets(x, bucket_boundaries)
<tf.tensor: shape="(2," 3), dtype="int64," numpy="array([[1," 3, 0], [0, 2, 3]])></tf.tensor:></p>
</blockquote>
</blockquote>
</blockquote>
        <hr>
<p>x: A numeric input <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> whose values
    should be mapped to buckets.  For <code>CompositeTensor</code>s, the non-missing
    values will be mapped to buckets and missing value left missing.
  bucket_boundaries: A rank 2 <code>Tensor</code> or list representing the bucket
    boundaries sorted in ascending order.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of the same shape as <code>x</code>, with
  each element in the returned tensor representing the bucketized value.
  Bucketized value is in the range [0, len(bucket_boundaries)].</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-2299">2299</a></span>
<span class="normal"><a href="#__codelineno-0-2300">2300</a></span>
<span class="normal"><a href="#__codelineno-0-2301">2301</a></span>
<span class="normal"><a href="#__codelineno-0-2302">2302</a></span>
<span class="normal"><a href="#__codelineno-0-2303">2303</a></span>
<span class="normal"><a href="#__codelineno-0-2304">2304</a></span>
<span class="normal"><a href="#__codelineno-0-2305">2305</a></span>
<span class="normal"><a href="#__codelineno-0-2306">2306</a></span>
<span class="normal"><a href="#__codelineno-0-2307">2307</a></span>
<span class="normal"><a href="#__codelineno-0-2308">2308</a></span>
<span class="normal"><a href="#__codelineno-0-2309">2309</a></span>
<span class="normal"><a href="#__codelineno-0-2310">2310</a></span>
<span class="normal"><a href="#__codelineno-0-2311">2311</a></span>
<span class="normal"><a href="#__codelineno-0-2312">2312</a></span>
<span class="normal"><a href="#__codelineno-0-2313">2313</a></span>
<span class="normal"><a href="#__codelineno-0-2314">2314</a></span>
<span class="normal"><a href="#__codelineno-0-2315">2315</a></span>
<span class="normal"><a href="#__codelineno-0-2316">2316</a></span>
<span class="normal"><a href="#__codelineno-0-2317">2317</a></span>
<span class="normal"><a href="#__codelineno-0-2318">2318</a></span>
<span class="normal"><a href="#__codelineno-0-2319">2319</a></span>
<span class="normal"><a href="#__codelineno-0-2320">2320</a></span>
<span class="normal"><a href="#__codelineno-0-2321">2321</a></span>
<span class="normal"><a href="#__codelineno-0-2322">2322</a></span>
<span class="normal"><a href="#__codelineno-0-2323">2323</a></span>
<span class="normal"><a href="#__codelineno-0-2324">2324</a></span>
<span class="normal"><a href="#__codelineno-0-2325">2325</a></span>
<span class="normal"><a href="#__codelineno-0-2326">2326</a></span>
<span class="normal"><a href="#__codelineno-0-2327">2327</a></span>
<span class="normal"><a href="#__codelineno-0-2328">2328</a></span>
<span class="normal"><a href="#__codelineno-0-2329">2329</a></span>
<span class="normal"><a href="#__codelineno-0-2330">2330</a></span>
<span class="normal"><a href="#__codelineno-0-2331">2331</a></span>
<span class="normal"><a href="#__codelineno-0-2332">2332</a></span>
<span class="normal"><a href="#__codelineno-0-2333">2333</a></span>
<span class="normal"><a href="#__codelineno-0-2334">2334</a></span>
<span class="normal"><a href="#__codelineno-0-2335">2335</a></span>
<span class="normal"><a href="#__codelineno-0-2336">2336</a></span>
<span class="normal"><a href="#__codelineno-0-2337">2337</a></span>
<span class="normal"><a href="#__codelineno-0-2338">2338</a></span>
<span class="normal"><a href="#__codelineno-0-2339">2339</a></span>
<span class="normal"><a href="#__codelineno-0-2340">2340</a></span>
<span class="normal"><a href="#__codelineno-0-2341">2341</a></span>
<span class="normal"><a href="#__codelineno-0-2342">2342</a></span>
<span class="normal"><a href="#__codelineno-0-2343">2343</a></span>
<span class="normal"><a href="#__codelineno-0-2344">2344</a></span>
<span class="normal"><a href="#__codelineno-0-2345">2345</a></span>
<span class="normal"><a href="#__codelineno-0-2346">2346</a></span>
<span class="normal"><a href="#__codelineno-0-2347">2347</a></span>
<span class="normal"><a href="#__codelineno-0-2348">2348</a></span>
<span class="normal"><a href="#__codelineno-0-2349">2349</a></span>
<span class="normal"><a href="#__codelineno-0-2350">2350</a></span>
<span class="normal"><a href="#__codelineno-0-2351">2351</a></span>
<span class="normal"><a href="#__codelineno-0-2352">2352</a></span>
<span class="normal"><a href="#__codelineno-0-2353">2353</a></span>
<span class="normal"><a href="#__codelineno-0-2354">2354</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-2299"><a id="__codelineno-0-2299" name="__codelineno-0-2299"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-2300"><a id="__codelineno-0-2300" name="__codelineno-0-2300"></a><span class="k">def</span><span class="w"> </span><span class="nf">apply_buckets</span><span class="p">(</span>
</span><span id="__span-0-2301"><a id="__codelineno-0-2301" name="__codelineno-0-2301"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">,</span>
</span><span id="__span-0-2302"><a id="__codelineno-0-2302" name="__codelineno-0-2302"></a>    <span class="n">bucket_boundaries</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">BucketBoundariesType</span><span class="p">,</span>
</span><span id="__span-0-2303"><a id="__codelineno-0-2303" name="__codelineno-0-2303"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-2304"><a id="__codelineno-0-2304" name="__codelineno-0-2304"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">:</span>
</span><span id="__span-0-2305"><a id="__codelineno-0-2305" name="__codelineno-0-2305"></a><span class="w">    </span><span class="sd">"""Returns a bucketized column, with a bucket index assigned to each input.</span>
</span><span id="__span-0-2306"><a id="__codelineno-0-2306" name="__codelineno-0-2306"></a>
</span><span id="__span-0-2307"><a id="__codelineno-0-2307" name="__codelineno-0-2307"></a><span class="sd">    Each element `e` in `x` is mapped to a positive index `i` for which</span>
</span><span id="__span-0-2308"><a id="__codelineno-0-2308" name="__codelineno-0-2308"></a><span class="sd">    `bucket_boundaries[i-1] &lt;= e &lt; bucket_boundaries[i]`, if it exists.</span>
</span><span id="__span-0-2309"><a id="__codelineno-0-2309" name="__codelineno-0-2309"></a><span class="sd">    If `e &lt; bucket_boundaries[0]`, then `e` is mapped to `0`. If</span>
</span><span id="__span-0-2310"><a id="__codelineno-0-2310" name="__codelineno-0-2310"></a><span class="sd">    `e &gt;= bucket_boundaries[-1]`, then `e` is mapped to `len(bucket_boundaries)`.</span>
</span><span id="__span-0-2311"><a id="__codelineno-0-2311" name="__codelineno-0-2311"></a><span class="sd">    NaNs are mapped to `len(bucket_boundaries)`.</span>
</span><span id="__span-0-2312"><a id="__codelineno-0-2312" name="__codelineno-0-2312"></a>
</span><span id="__span-0-2313"><a id="__codelineno-0-2313" name="__codelineno-0-2313"></a><span class="sd">    Example:</span>
</span><span id="__span-0-2314"><a id="__codelineno-0-2314" name="__codelineno-0-2314"></a><span class="sd">    -------</span>
</span><span id="__span-0-2315"><a id="__codelineno-0-2315" name="__codelineno-0-2315"></a><span class="sd">    &gt;&gt;&gt; x = tf.constant([[4.0, float('nan'), 1.0], [float('-inf'), 7.5, 10.0]])</span>
</span><span id="__span-0-2316"><a id="__codelineno-0-2316" name="__codelineno-0-2316"></a><span class="sd">    &gt;&gt;&gt; bucket_boundaries = tf.constant([[2.0, 5.0, 10.0]])</span>
</span><span id="__span-0-2317"><a id="__codelineno-0-2317" name="__codelineno-0-2317"></a><span class="sd">    &gt;&gt;&gt; tft.apply_buckets(x, bucket_boundaries)</span>
</span><span id="__span-0-2318"><a id="__codelineno-0-2318" name="__codelineno-0-2318"></a><span class="sd">    &lt;tf.Tensor: shape=(2, 3), dtype=int64, numpy=</span>
</span><span id="__span-0-2319"><a id="__codelineno-0-2319" name="__codelineno-0-2319"></a><span class="sd">    array([[1, 3, 0],</span>
</span><span id="__span-0-2320"><a id="__codelineno-0-2320" name="__codelineno-0-2320"></a><span class="sd">           [0, 2, 3]])&gt;</span>
</span><span id="__span-0-2321"><a id="__codelineno-0-2321" name="__codelineno-0-2321"></a>
</span><span id="__span-0-2322"><a id="__codelineno-0-2322" name="__codelineno-0-2322"></a><span class="sd">    Args:</span>
</span><span id="__span-0-2323"><a id="__codelineno-0-2323" name="__codelineno-0-2323"></a><span class="sd">    ----</span>
</span><span id="__span-0-2324"><a id="__codelineno-0-2324" name="__codelineno-0-2324"></a><span class="sd">      x: A numeric input `Tensor`, `SparseTensor`, or `RaggedTensor` whose values</span>
</span><span id="__span-0-2325"><a id="__codelineno-0-2325" name="__codelineno-0-2325"></a><span class="sd">        should be mapped to buckets.  For `CompositeTensor`s, the non-missing</span>
</span><span id="__span-0-2326"><a id="__codelineno-0-2326" name="__codelineno-0-2326"></a><span class="sd">        values will be mapped to buckets and missing value left missing.</span>
</span><span id="__span-0-2327"><a id="__codelineno-0-2327" name="__codelineno-0-2327"></a><span class="sd">      bucket_boundaries: A rank 2 `Tensor` or list representing the bucket</span>
</span><span id="__span-0-2328"><a id="__codelineno-0-2328" name="__codelineno-0-2328"></a><span class="sd">        boundaries sorted in ascending order.</span>
</span><span id="__span-0-2329"><a id="__codelineno-0-2329" name="__codelineno-0-2329"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-2330"><a id="__codelineno-0-2330" name="__codelineno-0-2330"></a>
</span><span id="__span-0-2331"><a id="__codelineno-0-2331" name="__codelineno-0-2331"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-2332"><a id="__codelineno-0-2332" name="__codelineno-0-2332"></a><span class="sd">    -------</span>
</span><span id="__span-0-2333"><a id="__codelineno-0-2333" name="__codelineno-0-2333"></a><span class="sd">      A `Tensor`, `SparseTensor`, or `RaggedTensor` of the same shape as `x`, with</span>
</span><span id="__span-0-2334"><a id="__codelineno-0-2334" name="__codelineno-0-2334"></a><span class="sd">      each element in the returned tensor representing the bucketized value.</span>
</span><span id="__span-0-2335"><a id="__codelineno-0-2335" name="__codelineno-0-2335"></a><span class="sd">      Bucketized value is in the range [0, len(bucket_boundaries)].</span>
</span><span id="__span-0-2336"><a id="__codelineno-0-2336" name="__codelineno-0-2336"></a><span class="sd">    """</span>
</span><span id="__span-0-2337"><a id="__codelineno-0-2337" name="__codelineno-0-2337"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"apply_buckets"</span><span class="p">):</span>
</span><span id="__span-0-2338"><a id="__codelineno-0-2338" name="__codelineno-0-2338"></a>        <span class="n">bucket_boundaries</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">bucket_boundaries</span><span class="p">)</span>
</span><span id="__span-0-2339"><a id="__codelineno-0-2339" name="__codelineno-0-2339"></a>        <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">assert_rank</span><span class="p">(</span><span class="n">bucket_boundaries</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="__span-0-2340"><a id="__codelineno-0-2340" name="__codelineno-0-2340"></a>
</span><span id="__span-0-2341"><a id="__codelineno-0-2341" name="__codelineno-0-2341"></a>        <span class="n">bucketized_values</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">assign_buckets</span><span class="p">(</span>
</span><span id="__span-0-2342"><a id="__codelineno-0-2342" name="__codelineno-0-2342"></a>            <span class="n">tf_utils</span><span class="o">.</span><span class="n">get_values</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">bucket_boundaries</span><span class="p">,</span> <span class="n">side</span><span class="o">=</span><span class="n">tf_utils</span><span class="o">.</span><span class="n">Side</span><span class="o">.</span><span class="n">RIGHT</span>
</span><span id="__span-0-2343"><a id="__codelineno-0-2343" name="__codelineno-0-2343"></a>        <span class="p">)</span>
</span><span id="__span-0-2344"><a id="__codelineno-0-2344" name="__codelineno-0-2344"></a>
</span><span id="__span-0-2345"><a id="__codelineno-0-2345" name="__codelineno-0-2345"></a>        <span class="c1"># Attach the relevant metadata to result, so that the corresponding</span>
</span><span id="__span-0-2346"><a id="__codelineno-0-2346" name="__codelineno-0-2346"></a>        <span class="c1"># output feature will have this metadata set.</span>
</span><span id="__span-0-2347"><a id="__codelineno-0-2347" name="__codelineno-0-2347"></a>        <span class="n">min_value</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span><span id="__span-0-2348"><a id="__codelineno-0-2348" name="__codelineno-0-2348"></a>        <span class="n">max_value</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">bucket_boundaries</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="__span-0-2349"><a id="__codelineno-0-2349" name="__codelineno-0-2349"></a>        <span class="n">schema_inference</span><span class="o">.</span><span class="n">set_tensor_schema_override</span><span class="p">(</span>
</span><span id="__span-0-2350"><a id="__codelineno-0-2350" name="__codelineno-0-2350"></a>            <span class="n">bucketized_values</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span>
</span><span id="__span-0-2351"><a id="__codelineno-0-2351" name="__codelineno-0-2351"></a>        <span class="p">)</span>
</span><span id="__span-0-2352"><a id="__codelineno-0-2352" name="__codelineno-0-2352"></a>        <span class="n">_annotate_buckets</span><span class="p">(</span><span class="n">bucketized_values</span><span class="p">,</span> <span class="n">bucket_boundaries</span><span class="p">)</span>
</span><span id="__span-0-2353"><a id="__codelineno-0-2353" name="__codelineno-0-2353"></a>        <span class="n">compose_result_fn</span> <span class="o">=</span> <span class="n">_make_composite_tensor_wrapper_if_composite</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-0-2354"><a id="__codelineno-0-2354" name="__codelineno-0-2354"></a>        <span class="k">return</span> <span class="n">compose_result_fn</span><span class="p">(</span><span class="n">bucketized_values</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.apply_buckets_with_interpolation" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">apply_buckets_with_interpolation</span>


<a href="#tensorflow_transform.apply_buckets_with_interpolation" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">apply_buckets_with_interpolation</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">bucket_boundaries</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.BucketBoundariesType">BucketBoundariesType</span></span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Interpolates within the provided buckets and then normalizes to 0 to 1.</p>
<p>A method for normalizing continuous numeric data to the range [0, 1].
Numeric values are first bucketized according to the provided boundaries, then
linearly interpolated within their respective bucket ranges. Finally, the
interpolated values are normalized to the range [0, 1]. Values that are
less than or equal to the lowest boundary, or greater than or equal to the
highest boundary, will be mapped to 0 and 1 respectively. NaN values will be
mapped to the middle of the range (.5).</p>
<p>This is a non-linear approach to normalization that is less sensitive to
outliers than min-max or z-score scaling. When outliers are present, standard
forms of normalization can leave the majority of the data compressed into a
very small segment of the output range, whereas this approach tends to spread
out the more frequent values (if quantile buckets are used). Note that
distance relationships in the raw data are not necessarily preserved (data
points that close to each other in the raw feature space may not be equally
close in the transformed feature space). This means that unlike linear
normalization methods, correlations between features may be distorted by the
transformation. This scaling method may help with stability and minimize
exploding gradients in neural networks.</p>
        <hr>
<p>x: A numeric input <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>
    (tf.float[32|64], tf.int[32|64]).
  bucket_boundaries: Sorted bucket boundaries as a rank-2 <code>Tensor</code> or list.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of the same shape as <code>x</code>,
  normalized to the range [0, 1]. If the input x is tf.float64, the returned
  values will be tf.float64. Otherwise, returned values are tf.float32.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-2155">2155</a></span>
<span class="normal"><a href="#__codelineno-0-2156">2156</a></span>
<span class="normal"><a href="#__codelineno-0-2157">2157</a></span>
<span class="normal"><a href="#__codelineno-0-2158">2158</a></span>
<span class="normal"><a href="#__codelineno-0-2159">2159</a></span>
<span class="normal"><a href="#__codelineno-0-2160">2160</a></span>
<span class="normal"><a href="#__codelineno-0-2161">2161</a></span>
<span class="normal"><a href="#__codelineno-0-2162">2162</a></span>
<span class="normal"><a href="#__codelineno-0-2163">2163</a></span>
<span class="normal"><a href="#__codelineno-0-2164">2164</a></span>
<span class="normal"><a href="#__codelineno-0-2165">2165</a></span>
<span class="normal"><a href="#__codelineno-0-2166">2166</a></span>
<span class="normal"><a href="#__codelineno-0-2167">2167</a></span>
<span class="normal"><a href="#__codelineno-0-2168">2168</a></span>
<span class="normal"><a href="#__codelineno-0-2169">2169</a></span>
<span class="normal"><a href="#__codelineno-0-2170">2170</a></span>
<span class="normal"><a href="#__codelineno-0-2171">2171</a></span>
<span class="normal"><a href="#__codelineno-0-2172">2172</a></span>
<span class="normal"><a href="#__codelineno-0-2173">2173</a></span>
<span class="normal"><a href="#__codelineno-0-2174">2174</a></span>
<span class="normal"><a href="#__codelineno-0-2175">2175</a></span>
<span class="normal"><a href="#__codelineno-0-2176">2176</a></span>
<span class="normal"><a href="#__codelineno-0-2177">2177</a></span>
<span class="normal"><a href="#__codelineno-0-2178">2178</a></span>
<span class="normal"><a href="#__codelineno-0-2179">2179</a></span>
<span class="normal"><a href="#__codelineno-0-2180">2180</a></span>
<span class="normal"><a href="#__codelineno-0-2181">2181</a></span>
<span class="normal"><a href="#__codelineno-0-2182">2182</a></span>
<span class="normal"><a href="#__codelineno-0-2183">2183</a></span>
<span class="normal"><a href="#__codelineno-0-2184">2184</a></span>
<span class="normal"><a href="#__codelineno-0-2185">2185</a></span>
<span class="normal"><a href="#__codelineno-0-2186">2186</a></span>
<span class="normal"><a href="#__codelineno-0-2187">2187</a></span>
<span class="normal"><a href="#__codelineno-0-2188">2188</a></span>
<span class="normal"><a href="#__codelineno-0-2189">2189</a></span>
<span class="normal"><a href="#__codelineno-0-2190">2190</a></span>
<span class="normal"><a href="#__codelineno-0-2191">2191</a></span>
<span class="normal"><a href="#__codelineno-0-2192">2192</a></span>
<span class="normal"><a href="#__codelineno-0-2193">2193</a></span>
<span class="normal"><a href="#__codelineno-0-2194">2194</a></span>
<span class="normal"><a href="#__codelineno-0-2195">2195</a></span>
<span class="normal"><a href="#__codelineno-0-2196">2196</a></span>
<span class="normal"><a href="#__codelineno-0-2197">2197</a></span>
<span class="normal"><a href="#__codelineno-0-2198">2198</a></span>
<span class="normal"><a href="#__codelineno-0-2199">2199</a></span>
<span class="normal"><a href="#__codelineno-0-2200">2200</a></span>
<span class="normal"><a href="#__codelineno-0-2201">2201</a></span>
<span class="normal"><a href="#__codelineno-0-2202">2202</a></span>
<span class="normal"><a href="#__codelineno-0-2203">2203</a></span>
<span class="normal"><a href="#__codelineno-0-2204">2204</a></span>
<span class="normal"><a href="#__codelineno-0-2205">2205</a></span>
<span class="normal"><a href="#__codelineno-0-2206">2206</a></span>
<span class="normal"><a href="#__codelineno-0-2207">2207</a></span>
<span class="normal"><a href="#__codelineno-0-2208">2208</a></span>
<span class="normal"><a href="#__codelineno-0-2209">2209</a></span>
<span class="normal"><a href="#__codelineno-0-2210">2210</a></span>
<span class="normal"><a href="#__codelineno-0-2211">2211</a></span>
<span class="normal"><a href="#__codelineno-0-2212">2212</a></span>
<span class="normal"><a href="#__codelineno-0-2213">2213</a></span>
<span class="normal"><a href="#__codelineno-0-2214">2214</a></span>
<span class="normal"><a href="#__codelineno-0-2215">2215</a></span>
<span class="normal"><a href="#__codelineno-0-2216">2216</a></span>
<span class="normal"><a href="#__codelineno-0-2217">2217</a></span>
<span class="normal"><a href="#__codelineno-0-2218">2218</a></span>
<span class="normal"><a href="#__codelineno-0-2219">2219</a></span>
<span class="normal"><a href="#__codelineno-0-2220">2220</a></span>
<span class="normal"><a href="#__codelineno-0-2221">2221</a></span>
<span class="normal"><a href="#__codelineno-0-2222">2222</a></span>
<span class="normal"><a href="#__codelineno-0-2223">2223</a></span>
<span class="normal"><a href="#__codelineno-0-2224">2224</a></span>
<span class="normal"><a href="#__codelineno-0-2225">2225</a></span>
<span class="normal"><a href="#__codelineno-0-2226">2226</a></span>
<span class="normal"><a href="#__codelineno-0-2227">2227</a></span>
<span class="normal"><a href="#__codelineno-0-2228">2228</a></span>
<span class="normal"><a href="#__codelineno-0-2229">2229</a></span>
<span class="normal"><a href="#__codelineno-0-2230">2230</a></span>
<span class="normal"><a href="#__codelineno-0-2231">2231</a></span>
<span class="normal"><a href="#__codelineno-0-2232">2232</a></span>
<span class="normal"><a href="#__codelineno-0-2233">2233</a></span>
<span class="normal"><a href="#__codelineno-0-2234">2234</a></span>
<span class="normal"><a href="#__codelineno-0-2235">2235</a></span>
<span class="normal"><a href="#__codelineno-0-2236">2236</a></span>
<span class="normal"><a href="#__codelineno-0-2237">2237</a></span>
<span class="normal"><a href="#__codelineno-0-2238">2238</a></span>
<span class="normal"><a href="#__codelineno-0-2239">2239</a></span>
<span class="normal"><a href="#__codelineno-0-2240">2240</a></span>
<span class="normal"><a href="#__codelineno-0-2241">2241</a></span>
<span class="normal"><a href="#__codelineno-0-2242">2242</a></span>
<span class="normal"><a href="#__codelineno-0-2243">2243</a></span>
<span class="normal"><a href="#__codelineno-0-2244">2244</a></span>
<span class="normal"><a href="#__codelineno-0-2245">2245</a></span>
<span class="normal"><a href="#__codelineno-0-2246">2246</a></span>
<span class="normal"><a href="#__codelineno-0-2247">2247</a></span>
<span class="normal"><a href="#__codelineno-0-2248">2248</a></span>
<span class="normal"><a href="#__codelineno-0-2249">2249</a></span>
<span class="normal"><a href="#__codelineno-0-2250">2250</a></span>
<span class="normal"><a href="#__codelineno-0-2251">2251</a></span>
<span class="normal"><a href="#__codelineno-0-2252">2252</a></span>
<span class="normal"><a href="#__codelineno-0-2253">2253</a></span>
<span class="normal"><a href="#__codelineno-0-2254">2254</a></span>
<span class="normal"><a href="#__codelineno-0-2255">2255</a></span>
<span class="normal"><a href="#__codelineno-0-2256">2256</a></span>
<span class="normal"><a href="#__codelineno-0-2257">2257</a></span>
<span class="normal"><a href="#__codelineno-0-2258">2258</a></span>
<span class="normal"><a href="#__codelineno-0-2259">2259</a></span>
<span class="normal"><a href="#__codelineno-0-2260">2260</a></span>
<span class="normal"><a href="#__codelineno-0-2261">2261</a></span>
<span class="normal"><a href="#__codelineno-0-2262">2262</a></span>
<span class="normal"><a href="#__codelineno-0-2263">2263</a></span>
<span class="normal"><a href="#__codelineno-0-2264">2264</a></span>
<span class="normal"><a href="#__codelineno-0-2265">2265</a></span>
<span class="normal"><a href="#__codelineno-0-2266">2266</a></span>
<span class="normal"><a href="#__codelineno-0-2267">2267</a></span>
<span class="normal"><a href="#__codelineno-0-2268">2268</a></span>
<span class="normal"><a href="#__codelineno-0-2269">2269</a></span>
<span class="normal"><a href="#__codelineno-0-2270">2270</a></span>
<span class="normal"><a href="#__codelineno-0-2271">2271</a></span>
<span class="normal"><a href="#__codelineno-0-2272">2272</a></span>
<span class="normal"><a href="#__codelineno-0-2273">2273</a></span>
<span class="normal"><a href="#__codelineno-0-2274">2274</a></span>
<span class="normal"><a href="#__codelineno-0-2275">2275</a></span>
<span class="normal"><a href="#__codelineno-0-2276">2276</a></span>
<span class="normal"><a href="#__codelineno-0-2277">2277</a></span>
<span class="normal"><a href="#__codelineno-0-2278">2278</a></span>
<span class="normal"><a href="#__codelineno-0-2279">2279</a></span>
<span class="normal"><a href="#__codelineno-0-2280">2280</a></span>
<span class="normal"><a href="#__codelineno-0-2281">2281</a></span>
<span class="normal"><a href="#__codelineno-0-2282">2282</a></span>
<span class="normal"><a href="#__codelineno-0-2283">2283</a></span>
<span class="normal"><a href="#__codelineno-0-2284">2284</a></span>
<span class="normal"><a href="#__codelineno-0-2285">2285</a></span>
<span class="normal"><a href="#__codelineno-0-2286">2286</a></span>
<span class="normal"><a href="#__codelineno-0-2287">2287</a></span>
<span class="normal"><a href="#__codelineno-0-2288">2288</a></span>
<span class="normal"><a href="#__codelineno-0-2289">2289</a></span>
<span class="normal"><a href="#__codelineno-0-2290">2290</a></span>
<span class="normal"><a href="#__codelineno-0-2291">2291</a></span>
<span class="normal"><a href="#__codelineno-0-2292">2292</a></span>
<span class="normal"><a href="#__codelineno-0-2293">2293</a></span>
<span class="normal"><a href="#__codelineno-0-2294">2294</a></span>
<span class="normal"><a href="#__codelineno-0-2295">2295</a></span>
<span class="normal"><a href="#__codelineno-0-2296">2296</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-2155"><a id="__codelineno-0-2155" name="__codelineno-0-2155"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-2156"><a id="__codelineno-0-2156" name="__codelineno-0-2156"></a><span class="k">def</span><span class="w"> </span><span class="nf">apply_buckets_with_interpolation</span><span class="p">(</span>
</span><span id="__span-0-2157"><a id="__codelineno-0-2157" name="__codelineno-0-2157"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">,</span>
</span><span id="__span-0-2158"><a id="__codelineno-0-2158" name="__codelineno-0-2158"></a>    <span class="n">bucket_boundaries</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">BucketBoundariesType</span><span class="p">,</span>
</span><span id="__span-0-2159"><a id="__codelineno-0-2159" name="__codelineno-0-2159"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-2160"><a id="__codelineno-0-2160" name="__codelineno-0-2160"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">:</span>
</span><span id="__span-0-2161"><a id="__codelineno-0-2161" name="__codelineno-0-2161"></a><span class="w">    </span><span class="sd">"""Interpolates within the provided buckets and then normalizes to 0 to 1.</span>
</span><span id="__span-0-2162"><a id="__codelineno-0-2162" name="__codelineno-0-2162"></a>
</span><span id="__span-0-2163"><a id="__codelineno-0-2163" name="__codelineno-0-2163"></a><span class="sd">    A method for normalizing continuous numeric data to the range [0, 1].</span>
</span><span id="__span-0-2164"><a id="__codelineno-0-2164" name="__codelineno-0-2164"></a><span class="sd">    Numeric values are first bucketized according to the provided boundaries, then</span>
</span><span id="__span-0-2165"><a id="__codelineno-0-2165" name="__codelineno-0-2165"></a><span class="sd">    linearly interpolated within their respective bucket ranges. Finally, the</span>
</span><span id="__span-0-2166"><a id="__codelineno-0-2166" name="__codelineno-0-2166"></a><span class="sd">    interpolated values are normalized to the range [0, 1]. Values that are</span>
</span><span id="__span-0-2167"><a id="__codelineno-0-2167" name="__codelineno-0-2167"></a><span class="sd">    less than or equal to the lowest boundary, or greater than or equal to the</span>
</span><span id="__span-0-2168"><a id="__codelineno-0-2168" name="__codelineno-0-2168"></a><span class="sd">    highest boundary, will be mapped to 0 and 1 respectively. NaN values will be</span>
</span><span id="__span-0-2169"><a id="__codelineno-0-2169" name="__codelineno-0-2169"></a><span class="sd">    mapped to the middle of the range (.5).</span>
</span><span id="__span-0-2170"><a id="__codelineno-0-2170" name="__codelineno-0-2170"></a>
</span><span id="__span-0-2171"><a id="__codelineno-0-2171" name="__codelineno-0-2171"></a><span class="sd">    This is a non-linear approach to normalization that is less sensitive to</span>
</span><span id="__span-0-2172"><a id="__codelineno-0-2172" name="__codelineno-0-2172"></a><span class="sd">    outliers than min-max or z-score scaling. When outliers are present, standard</span>
</span><span id="__span-0-2173"><a id="__codelineno-0-2173" name="__codelineno-0-2173"></a><span class="sd">    forms of normalization can leave the majority of the data compressed into a</span>
</span><span id="__span-0-2174"><a id="__codelineno-0-2174" name="__codelineno-0-2174"></a><span class="sd">    very small segment of the output range, whereas this approach tends to spread</span>
</span><span id="__span-0-2175"><a id="__codelineno-0-2175" name="__codelineno-0-2175"></a><span class="sd">    out the more frequent values (if quantile buckets are used). Note that</span>
</span><span id="__span-0-2176"><a id="__codelineno-0-2176" name="__codelineno-0-2176"></a><span class="sd">    distance relationships in the raw data are not necessarily preserved (data</span>
</span><span id="__span-0-2177"><a id="__codelineno-0-2177" name="__codelineno-0-2177"></a><span class="sd">    points that close to each other in the raw feature space may not be equally</span>
</span><span id="__span-0-2178"><a id="__codelineno-0-2178" name="__codelineno-0-2178"></a><span class="sd">    close in the transformed feature space). This means that unlike linear</span>
</span><span id="__span-0-2179"><a id="__codelineno-0-2179" name="__codelineno-0-2179"></a><span class="sd">    normalization methods, correlations between features may be distorted by the</span>
</span><span id="__span-0-2180"><a id="__codelineno-0-2180" name="__codelineno-0-2180"></a><span class="sd">    transformation. This scaling method may help with stability and minimize</span>
</span><span id="__span-0-2181"><a id="__codelineno-0-2181" name="__codelineno-0-2181"></a><span class="sd">    exploding gradients in neural networks.</span>
</span><span id="__span-0-2182"><a id="__codelineno-0-2182" name="__codelineno-0-2182"></a>
</span><span id="__span-0-2183"><a id="__codelineno-0-2183" name="__codelineno-0-2183"></a><span class="sd">    Args:</span>
</span><span id="__span-0-2184"><a id="__codelineno-0-2184" name="__codelineno-0-2184"></a><span class="sd">    ----</span>
</span><span id="__span-0-2185"><a id="__codelineno-0-2185" name="__codelineno-0-2185"></a><span class="sd">      x: A numeric input `Tensor`, `SparseTensor`, or `RaggedTensor`</span>
</span><span id="__span-0-2186"><a id="__codelineno-0-2186" name="__codelineno-0-2186"></a><span class="sd">        (tf.float[32|64], tf.int[32|64]).</span>
</span><span id="__span-0-2187"><a id="__codelineno-0-2187" name="__codelineno-0-2187"></a><span class="sd">      bucket_boundaries: Sorted bucket boundaries as a rank-2 `Tensor` or list.</span>
</span><span id="__span-0-2188"><a id="__codelineno-0-2188" name="__codelineno-0-2188"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-2189"><a id="__codelineno-0-2189" name="__codelineno-0-2189"></a>
</span><span id="__span-0-2190"><a id="__codelineno-0-2190" name="__codelineno-0-2190"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-2191"><a id="__codelineno-0-2191" name="__codelineno-0-2191"></a><span class="sd">    -------</span>
</span><span id="__span-0-2192"><a id="__codelineno-0-2192" name="__codelineno-0-2192"></a><span class="sd">      A `Tensor`, `SparseTensor`, or `RaggedTensor` of the same shape as `x`,</span>
</span><span id="__span-0-2193"><a id="__codelineno-0-2193" name="__codelineno-0-2193"></a><span class="sd">      normalized to the range [0, 1]. If the input x is tf.float64, the returned</span>
</span><span id="__span-0-2194"><a id="__codelineno-0-2194" name="__codelineno-0-2194"></a><span class="sd">      values will be tf.float64. Otherwise, returned values are tf.float32.</span>
</span><span id="__span-0-2195"><a id="__codelineno-0-2195" name="__codelineno-0-2195"></a><span class="sd">    """</span>
</span><span id="__span-0-2196"><a id="__codelineno-0-2196" name="__codelineno-0-2196"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"buckets_with_interpolation"</span><span class="p">):</span>
</span><span id="__span-0-2197"><a id="__codelineno-0-2197" name="__codelineno-0-2197"></a>        <span class="n">bucket_boundaries</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">bucket_boundaries</span><span class="p">)</span>
</span><span id="__span-0-2198"><a id="__codelineno-0-2198" name="__codelineno-0-2198"></a>        <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">assert_rank</span><span class="p">(</span><span class="n">bucket_boundaries</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="__span-0-2199"><a id="__codelineno-0-2199" name="__codelineno-0-2199"></a>        <span class="n">x_values</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">get_values</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-0-2200"><a id="__codelineno-0-2200" name="__codelineno-0-2200"></a>        <span class="n">compose_result_fn</span> <span class="o">=</span> <span class="n">_make_composite_tensor_wrapper_if_composite</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-0-2201"><a id="__codelineno-0-2201" name="__codelineno-0-2201"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">x_values</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating</span> <span class="ow">or</span> <span class="n">x_values</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_integer</span><span class="p">):</span>
</span><span id="__span-0-2202"><a id="__codelineno-0-2202" name="__codelineno-0-2202"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="__span-0-2203"><a id="__codelineno-0-2203" name="__codelineno-0-2203"></a>                <span class="s2">"Input tensor to be normalized must be numeric, got </span><span class="si">{}</span><span class="s2">."</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
</span><span id="__span-0-2204"><a id="__codelineno-0-2204" name="__codelineno-0-2204"></a>                    <span class="n">x_values</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-2205"><a id="__codelineno-0-2205" name="__codelineno-0-2205"></a>                <span class="p">)</span>
</span><span id="__span-0-2206"><a id="__codelineno-0-2206" name="__codelineno-0-2206"></a>            <span class="p">)</span>
</span><span id="__span-0-2207"><a id="__codelineno-0-2207" name="__codelineno-0-2207"></a>        <span class="c1"># Remove any non-finite boundaries.</span>
</span><span id="__span-0-2208"><a id="__codelineno-0-2208" name="__codelineno-0-2208"></a>        <span class="k">if</span> <span class="n">bucket_boundaries</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">in</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
</span><span id="__span-0-2209"><a id="__codelineno-0-2209" name="__codelineno-0-2209"></a>            <span class="n">bucket_boundaries</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
</span><span id="__span-0-2210"><a id="__codelineno-0-2210" name="__codelineno-0-2210"></a>                <span class="n">tf</span><span class="o">.</span><span class="n">gather_nd</span><span class="p">(</span>
</span><span id="__span-0-2211"><a id="__codelineno-0-2211" name="__codelineno-0-2211"></a>                    <span class="n">bucket_boundaries</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">is_finite</span><span class="p">(</span><span class="n">bucket_boundaries</span><span class="p">))</span>
</span><span id="__span-0-2212"><a id="__codelineno-0-2212" name="__codelineno-0-2212"></a>                <span class="p">),</span>
</span><span id="__span-0-2213"><a id="__codelineno-0-2213" name="__codelineno-0-2213"></a>                <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-2214"><a id="__codelineno-0-2214" name="__codelineno-0-2214"></a>            <span class="p">)</span>
</span><span id="__span-0-2215"><a id="__codelineno-0-2215" name="__codelineno-0-2215"></a>        <span class="n">return_type</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float64</span> <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">float64</span> <span class="k">else</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
</span><span id="__span-0-2216"><a id="__codelineno-0-2216" name="__codelineno-0-2216"></a>        <span class="n">num_boundaries</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
</span><span id="__span-0-2217"><a id="__codelineno-0-2217" name="__codelineno-0-2217"></a>            <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">bucket_boundaries</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"num_boundaries"</span>
</span><span id="__span-0-2218"><a id="__codelineno-0-2218" name="__codelineno-0-2218"></a>        <span class="p">)</span>
</span><span id="__span-0-2219"><a id="__codelineno-0-2219" name="__codelineno-0-2219"></a>        <span class="n">assert_some_finite_boundaries</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">assert_greater</span><span class="p">(</span>
</span><span id="__span-0-2220"><a id="__codelineno-0-2220" name="__codelineno-0-2220"></a>            <span class="n">num_boundaries</span><span class="p">,</span>
</span><span id="__span-0-2221"><a id="__codelineno-0-2221" name="__codelineno-0-2221"></a>            <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
</span><span id="__span-0-2222"><a id="__codelineno-0-2222" name="__codelineno-0-2222"></a>            <span class="n">name</span><span class="o">=</span><span class="s2">"assert_1_or_more_finite_boundaries"</span><span class="p">,</span>
</span><span id="__span-0-2223"><a id="__codelineno-0-2223" name="__codelineno-0-2223"></a>        <span class="p">)</span>
</span><span id="__span-0-2224"><a id="__codelineno-0-2224" name="__codelineno-0-2224"></a>        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">assert_some_finite_boundaries</span><span class="p">]):</span>
</span><span id="__span-0-2225"><a id="__codelineno-0-2225" name="__codelineno-0-2225"></a>            <span class="n">bucket_indices</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">assign_buckets</span><span class="p">(</span>
</span><span id="__span-0-2226"><a id="__codelineno-0-2226" name="__codelineno-0-2226"></a>                <span class="n">x_values</span><span class="p">,</span> <span class="n">bucket_boundaries</span><span class="p">,</span> <span class="n">side</span><span class="o">=</span><span class="n">tf_utils</span><span class="o">.</span><span class="n">Side</span><span class="o">.</span><span class="n">RIGHT</span>
</span><span id="__span-0-2227"><a id="__codelineno-0-2227" name="__codelineno-0-2227"></a>            <span class="p">)</span>
</span><span id="__span-0-2228"><a id="__codelineno-0-2228" name="__codelineno-0-2228"></a>            <span class="c1"># Get max, min, and width of the corresponding bucket for each element.</span>
</span><span id="__span-0-2229"><a id="__codelineno-0-2229" name="__codelineno-0-2229"></a>            <span class="n">bucket_max</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
</span><span id="__span-0-2230"><a id="__codelineno-0-2230" name="__codelineno-0-2230"></a>                <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span>
</span><span id="__span-0-2231"><a id="__codelineno-0-2231" name="__codelineno-0-2231"></a>                    <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">bucket_boundaries</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bucket_boundaries</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
</span><span id="__span-0-2232"><a id="__codelineno-0-2232" name="__codelineno-0-2232"></a>                    <span class="n">bucket_indices</span><span class="p">,</span>
</span><span id="__span-0-2233"><a id="__codelineno-0-2233" name="__codelineno-0-2233"></a>                <span class="p">),</span>
</span><span id="__span-0-2234"><a id="__codelineno-0-2234" name="__codelineno-0-2234"></a>                <span class="n">return_type</span><span class="p">,</span>
</span><span id="__span-0-2235"><a id="__codelineno-0-2235" name="__codelineno-0-2235"></a>            <span class="p">)</span>
</span><span id="__span-0-2236"><a id="__codelineno-0-2236" name="__codelineno-0-2236"></a>            <span class="n">bucket_min</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
</span><span id="__span-0-2237"><a id="__codelineno-0-2237" name="__codelineno-0-2237"></a>                <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span>
</span><span id="__span-0-2238"><a id="__codelineno-0-2238" name="__codelineno-0-2238"></a>                    <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">bucket_boundaries</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">bucket_boundaries</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
</span><span id="__span-0-2239"><a id="__codelineno-0-2239" name="__codelineno-0-2239"></a>                    <span class="n">bucket_indices</span><span class="p">,</span>
</span><span id="__span-0-2240"><a id="__codelineno-0-2240" name="__codelineno-0-2240"></a>                <span class="p">),</span>
</span><span id="__span-0-2241"><a id="__codelineno-0-2241" name="__codelineno-0-2241"></a>                <span class="n">return_type</span><span class="p">,</span>
</span><span id="__span-0-2242"><a id="__codelineno-0-2242" name="__codelineno-0-2242"></a>            <span class="p">)</span>
</span><span id="__span-0-2243"><a id="__codelineno-0-2243" name="__codelineno-0-2243"></a>        <span class="n">bucket_width</span> <span class="o">=</span> <span class="n">bucket_max</span> <span class="o">-</span> <span class="n">bucket_min</span>
</span><span id="__span-0-2244"><a id="__codelineno-0-2244" name="__codelineno-0-2244"></a>        <span class="n">zeros</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">return_type</span><span class="p">)</span>
</span><span id="__span-0-2245"><a id="__codelineno-0-2245" name="__codelineno-0-2245"></a>        <span class="n">ones</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">return_type</span><span class="p">)</span>
</span><span id="__span-0-2246"><a id="__codelineno-0-2246" name="__codelineno-0-2246"></a>
</span><span id="__span-0-2247"><a id="__codelineno-0-2247" name="__codelineno-0-2247"></a>        <span class="c1"># Linearly interpolate each value within its respective bucket range.</span>
</span><span id="__span-0-2248"><a id="__codelineno-0-2248" name="__codelineno-0-2248"></a>        <span class="n">interpolation_value</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-2249"><a id="__codelineno-0-2249" name="__codelineno-0-2249"></a>            <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">return_type</span><span class="p">)</span> <span class="o">-</span> <span class="n">bucket_min</span>
</span><span id="__span-0-2250"><a id="__codelineno-0-2250" name="__codelineno-0-2250"></a>        <span class="p">)</span> <span class="o">/</span> <span class="n">bucket_width</span>
</span><span id="__span-0-2251"><a id="__codelineno-0-2251" name="__codelineno-0-2251"></a>        <span class="n">bucket_interpolation</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">verify_tensor_all_finite</span><span class="p">(</span>
</span><span id="__span-0-2252"><a id="__codelineno-0-2252" name="__codelineno-0-2252"></a>            <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
</span><span id="__span-0-2253"><a id="__codelineno-0-2253" name="__codelineno-0-2253"></a>                <span class="c1"># If bucket index is first or last, which represents "less than</span>
</span><span id="__span-0-2254"><a id="__codelineno-0-2254" name="__codelineno-0-2254"></a>                <span class="c1"># min" and "greater than max" respectively, the bucket logically</span>
</span><span id="__span-0-2255"><a id="__codelineno-0-2255" name="__codelineno-0-2255"></a>                <span class="c1"># has an infinite width and we can't meaningfully interpolate.</span>
</span><span id="__span-0-2256"><a id="__codelineno-0-2256" name="__codelineno-0-2256"></a>                <span class="n">tf</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span>
</span><span id="__span-0-2257"><a id="__codelineno-0-2257" name="__codelineno-0-2257"></a>                    <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">bucket_indices</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
</span><span id="__span-0-2258"><a id="__codelineno-0-2258" name="__codelineno-0-2258"></a>                    <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">bucket_indices</span><span class="p">,</span> <span class="n">num_boundaries</span><span class="p">),</span>
</span><span id="__span-0-2259"><a id="__codelineno-0-2259" name="__codelineno-0-2259"></a>                <span class="p">),</span>
</span><span id="__span-0-2260"><a id="__codelineno-0-2260" name="__codelineno-0-2260"></a>                <span class="n">zeros</span><span class="p">,</span>
</span><span id="__span-0-2261"><a id="__codelineno-0-2261" name="__codelineno-0-2261"></a>                <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
</span><span id="__span-0-2262"><a id="__codelineno-0-2262" name="__codelineno-0-2262"></a>                    <span class="c1"># If the bucket width is zero due to numerical imprecision,</span>
</span><span id="__span-0-2263"><a id="__codelineno-0-2263" name="__codelineno-0-2263"></a>                    <span class="c1"># there is no point in interpolating</span>
</span><span id="__span-0-2264"><a id="__codelineno-0-2264" name="__codelineno-0-2264"></a>                    <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">bucket_width</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span>
</span><span id="__span-0-2265"><a id="__codelineno-0-2265" name="__codelineno-0-2265"></a>                    <span class="n">ones</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">,</span>
</span><span id="__span-0-2266"><a id="__codelineno-0-2266" name="__codelineno-0-2266"></a>                    <span class="c1"># Finally, for a bucket with a valid width, we can interpolate.</span>
</span><span id="__span-0-2267"><a id="__codelineno-0-2267" name="__codelineno-0-2267"></a>                    <span class="n">interpolation_value</span><span class="p">,</span>
</span><span id="__span-0-2268"><a id="__codelineno-0-2268" name="__codelineno-0-2268"></a>                <span class="p">),</span>
</span><span id="__span-0-2269"><a id="__codelineno-0-2269" name="__codelineno-0-2269"></a>            <span class="p">),</span>
</span><span id="__span-0-2270"><a id="__codelineno-0-2270" name="__codelineno-0-2270"></a>            <span class="s2">"bucket_interpolation"</span><span class="p">,</span>
</span><span id="__span-0-2271"><a id="__codelineno-0-2271" name="__codelineno-0-2271"></a>        <span class="p">)</span>
</span><span id="__span-0-2272"><a id="__codelineno-0-2272" name="__codelineno-0-2272"></a>        <span class="n">bucket_indices_with_interpolation</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-2273"><a id="__codelineno-0-2273" name="__codelineno-0-2273"></a>            <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">bucket_indices</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">return_type</span><span class="p">)</span>
</span><span id="__span-0-2274"><a id="__codelineno-0-2274" name="__codelineno-0-2274"></a>            <span class="o">+</span> <span class="n">bucket_interpolation</span>
</span><span id="__span-0-2275"><a id="__codelineno-0-2275" name="__codelineno-0-2275"></a>        <span class="p">)</span>
</span><span id="__span-0-2276"><a id="__codelineno-0-2276" name="__codelineno-0-2276"></a>
</span><span id="__span-0-2277"><a id="__codelineno-0-2277" name="__codelineno-0-2277"></a>        <span class="c1"># Normalize the interpolated values to the range [0, 1].</span>
</span><span id="__span-0-2278"><a id="__codelineno-0-2278" name="__codelineno-0-2278"></a>        <span class="n">denominator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">num_boundaries</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">return_type</span><span class="p">)</span>
</span><span id="__span-0-2279"><a id="__codelineno-0-2279" name="__codelineno-0-2279"></a>        <span class="n">normalized_values</span> <span class="o">=</span> <span class="n">bucket_indices_with_interpolation</span> <span class="o">/</span> <span class="n">denominator</span>
</span><span id="__span-0-2280"><a id="__codelineno-0-2280" name="__codelineno-0-2280"></a>        <span class="k">if</span> <span class="n">x_values</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating</span><span class="p">:</span>
</span><span id="__span-0-2281"><a id="__codelineno-0-2281" name="__codelineno-0-2281"></a>            <span class="c1"># Impute NaNs with .5, the middle value of the normalized output range.</span>
</span><span id="__span-0-2282"><a id="__codelineno-0-2282" name="__codelineno-0-2282"></a>            <span class="n">imputed_values</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">return_type</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span>
</span><span id="__span-0-2283"><a id="__codelineno-0-2283" name="__codelineno-0-2283"></a>            <span class="n">normalized_values</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
</span><span id="__span-0-2284"><a id="__codelineno-0-2284" name="__codelineno-0-2284"></a>                <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">is_nan</span><span class="p">(</span><span class="n">x_values</span><span class="p">),</span> <span class="n">imputed_values</span><span class="p">,</span> <span class="n">normalized_values</span>
</span><span id="__span-0-2285"><a id="__codelineno-0-2285" name="__codelineno-0-2285"></a>            <span class="p">)</span>
</span><span id="__span-0-2286"><a id="__codelineno-0-2286" name="__codelineno-0-2286"></a>        <span class="c1"># If there is only one boundary, all values &lt; the boundary are 0, all values</span>
</span><span id="__span-0-2287"><a id="__codelineno-0-2287" name="__codelineno-0-2287"></a>        <span class="c1"># &gt;= the boundary are 1.</span>
</span><span id="__span-0-2288"><a id="__codelineno-0-2288" name="__codelineno-0-2288"></a>        <span class="n">single_boundary_values</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>  <span class="c1"># pylint: disable=g-long-lambda</span>
</span><span id="__span-0-2289"><a id="__codelineno-0-2289" name="__codelineno-0-2289"></a>            <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">bucket_indices</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">zeros</span><span class="p">,</span> <span class="n">ones</span>
</span><span id="__span-0-2290"><a id="__codelineno-0-2290" name="__codelineno-0-2290"></a>        <span class="p">)</span>
</span><span id="__span-0-2291"><a id="__codelineno-0-2291" name="__codelineno-0-2291"></a>        <span class="n">normalized_result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
</span><span id="__span-0-2292"><a id="__codelineno-0-2292" name="__codelineno-0-2292"></a>            <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">num_boundaries</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span><span id="__span-0-2293"><a id="__codelineno-0-2293" name="__codelineno-0-2293"></a>            <span class="n">single_boundary_values</span><span class="p">,</span>
</span><span id="__span-0-2294"><a id="__codelineno-0-2294" name="__codelineno-0-2294"></a>            <span class="k">lambda</span><span class="p">:</span> <span class="n">normalized_values</span><span class="p">,</span>
</span><span id="__span-0-2295"><a id="__codelineno-0-2295" name="__codelineno-0-2295"></a>        <span class="p">)</span>
</span><span id="__span-0-2296"><a id="__codelineno-0-2296" name="__codelineno-0-2296"></a>        <span class="k">return</span> <span class="n">compose_result_fn</span><span class="p">(</span><span class="n">normalized_result</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.apply_pyfunc" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">apply_pyfunc</span>


<a href="#tensorflow_transform.apply_pyfunc" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">apply_pyfunc</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">Tout</span><span class="p">,</span> <span class="n">stateful</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Applies a python function to some <code>Tensor</code>s.</p>
<p>Applies a python function to some <code>Tensor</code>s given by the argument list. The
number of arguments should match the number of inputs to the function.</p>
<p>This function is for using inside a preprocessing_fn.  It is a wrapper around
<code>tf.py_func</code>.  A function added this way can run in Transform, and during
training when the graph is imported using the <code>transform_raw_features</code> method
of the <code>TFTransformOutput</code> class.  However if the resulting training graph is
serialized and deserialized, then the <code>tf.py_func</code> op will not work and will
cause an error.  This means that TensorFlow Serving will not be able to serve
this graph.</p>
<p>The underlying reason for this limited support is that <code>tf.py_func</code> ops were
not designed to be serialized since they contain a reference to arbitrary
Python functions. This function pickles those functions and including them in
the graph, and <code>transform_raw_features</code> similarly unpickles the functions.
But unpickling requires a Python environment, so there it's not possible to
provide support in non-Python languages for loading such ops.  Therefore
loading these ops in libraries such as TensorFlow Serving is not supported.</p>
<p>Note: This API can only be used when TF2 is disabled or
<code>tft_beam.Context.force_tf_compat_v1=True</code>.</p>
        <hr>
<p>func: A Python function, which accepts a list of NumPy <code>ndarray</code> objects
    having element types that match the corresponding <code>tf.Tensor</code> objects
    in <code>*args</code>, and returns a list of <code>ndarray</code> objects (or a single
    <code>ndarray</code>) having element types that match the corresponding values
    in <code>Tout</code>.
  Tout: A list or tuple of tensorflow data types or a single tensorflow data
    type if there is only one, indicating what <code>func</code> returns.
  stateful: (Boolean.) If True, the function should be considered stateful.
    If a function is stateless, when given the same input it will return the
    same output and have no observable side effects. Optimizations such as
    common subexpression elimination are only performed on stateless
    operations.
  name: A name for the operation (optional).
  *args: The list of <code>Tensor</code>s to apply the arguments to.</p>
        <hr>
<p>A <code>Tensor</code> representing the application of the function.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/py_func/api.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-20">20</a></span>
<span class="normal"><a href="#__codelineno-0-21">21</a></span>
<span class="normal"><a href="#__codelineno-0-22">22</a></span>
<span class="normal"><a href="#__codelineno-0-23">23</a></span>
<span class="normal"><a href="#__codelineno-0-24">24</a></span>
<span class="normal"><a href="#__codelineno-0-25">25</a></span>
<span class="normal"><a href="#__codelineno-0-26">26</a></span>
<span class="normal"><a href="#__codelineno-0-27">27</a></span>
<span class="normal"><a href="#__codelineno-0-28">28</a></span>
<span class="normal"><a href="#__codelineno-0-29">29</a></span>
<span class="normal"><a href="#__codelineno-0-30">30</a></span>
<span class="normal"><a href="#__codelineno-0-31">31</a></span>
<span class="normal"><a href="#__codelineno-0-32">32</a></span>
<span class="normal"><a href="#__codelineno-0-33">33</a></span>
<span class="normal"><a href="#__codelineno-0-34">34</a></span>
<span class="normal"><a href="#__codelineno-0-35">35</a></span>
<span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-20"><a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="k">def</span><span class="w"> </span><span class="nf">apply_pyfunc</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">Tout</span><span class="p">,</span> <span class="n">stateful</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>  <span class="c1"># pylint: disable=invalid-name</span>
</span><span id="__span-0-21"><a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="w">    </span><span class="sd">"""Applies a python function to some `Tensor`s.</span>
</span><span id="__span-0-22"><a id="__codelineno-0-22" name="__codelineno-0-22"></a>
</span><span id="__span-0-23"><a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">    Applies a python function to some `Tensor`s given by the argument list. The</span>
</span><span id="__span-0-24"><a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">    number of arguments should match the number of inputs to the function.</span>
</span><span id="__span-0-25"><a id="__codelineno-0-25" name="__codelineno-0-25"></a>
</span><span id="__span-0-26"><a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">    This function is for using inside a preprocessing_fn.  It is a wrapper around</span>
</span><span id="__span-0-27"><a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">    `tf.py_func`.  A function added this way can run in Transform, and during</span>
</span><span id="__span-0-28"><a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">    training when the graph is imported using the `transform_raw_features` method</span>
</span><span id="__span-0-29"><a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">    of the `TFTransformOutput` class.  However if the resulting training graph is</span>
</span><span id="__span-0-30"><a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">    serialized and deserialized, then the `tf.py_func` op will not work and will</span>
</span><span id="__span-0-31"><a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">    cause an error.  This means that TensorFlow Serving will not be able to serve</span>
</span><span id="__span-0-32"><a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">    this graph.</span>
</span><span id="__span-0-33"><a id="__codelineno-0-33" name="__codelineno-0-33"></a>
</span><span id="__span-0-34"><a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">    The underlying reason for this limited support is that `tf.py_func` ops were</span>
</span><span id="__span-0-35"><a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">    not designed to be serialized since they contain a reference to arbitrary</span>
</span><span id="__span-0-36"><a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">    Python functions. This function pickles those functions and including them in</span>
</span><span id="__span-0-37"><a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">    the graph, and `transform_raw_features` similarly unpickles the functions.</span>
</span><span id="__span-0-38"><a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">    But unpickling requires a Python environment, so there it's not possible to</span>
</span><span id="__span-0-39"><a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="sd">    provide support in non-Python languages for loading such ops.  Therefore</span>
</span><span id="__span-0-40"><a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">    loading these ops in libraries such as TensorFlow Serving is not supported.</span>
</span><span id="__span-0-41"><a id="__codelineno-0-41" name="__codelineno-0-41"></a>
</span><span id="__span-0-42"><a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">    Note: This API can only be used when TF2 is disabled or</span>
</span><span id="__span-0-43"><a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">    `tft_beam.Context.force_tf_compat_v1=True`.</span>
</span><span id="__span-0-44"><a id="__codelineno-0-44" name="__codelineno-0-44"></a>
</span><span id="__span-0-45"><a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">    Args:</span>
</span><span id="__span-0-46"><a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">    ----</span>
</span><span id="__span-0-47"><a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="sd">      func: A Python function, which accepts a list of NumPy `ndarray` objects</span>
</span><span id="__span-0-48"><a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">        having element types that match the corresponding `tf.Tensor` objects</span>
</span><span id="__span-0-49"><a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">        in `*args`, and returns a list of `ndarray` objects (or a single</span>
</span><span id="__span-0-50"><a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">        `ndarray`) having element types that match the corresponding values</span>
</span><span id="__span-0-51"><a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">        in `Tout`.</span>
</span><span id="__span-0-52"><a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">      Tout: A list or tuple of tensorflow data types or a single tensorflow data</span>
</span><span id="__span-0-53"><a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">        type if there is only one, indicating what `func` returns.</span>
</span><span id="__span-0-54"><a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">      stateful: (Boolean.) If True, the function should be considered stateful.</span>
</span><span id="__span-0-55"><a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">        If a function is stateless, when given the same input it will return the</span>
</span><span id="__span-0-56"><a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">        same output and have no observable side effects. Optimizations such as</span>
</span><span id="__span-0-57"><a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">        common subexpression elimination are only performed on stateless</span>
</span><span id="__span-0-58"><a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">        operations.</span>
</span><span id="__span-0-59"><a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">      name: A name for the operation (optional).</span>
</span><span id="__span-0-60"><a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">      *args: The list of `Tensor`s to apply the arguments to.</span>
</span><span id="__span-0-61"><a id="__codelineno-0-61" name="__codelineno-0-61"></a>
</span><span id="__span-0-62"><a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-63"><a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">    -------</span>
</span><span id="__span-0-64"><a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">      A `Tensor` representing the application of the function.</span>
</span><span id="__span-0-65"><a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">    """</span>
</span><span id="__span-0-66"><a id="__codelineno-0-66" name="__codelineno-0-66"></a>    <span class="k">return</span> <span class="n">pyfunc_helper</span><span class="o">.</span><span class="n">insert_pyfunc</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">Tout</span><span class="p">,</span> <span class="n">stateful</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.apply_vocabulary" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">apply_vocabulary</span>


<a href="#tensorflow_transform.apply_vocabulary" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">apply_vocabulary</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">deferred_vocab_filename_tensor</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.TemporaryAnalyzerOutputType">TemporaryAnalyzerOutputType</span></span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">default_value</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Any (typing.Any)" href="#tensorflow_transform.Any">Any</a></span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">num_oov_buckets</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">lookup_fn</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>        <span class="n"><a class="autorefs autorefs-internal" title="            Callable


  
      module-attribute
   (typing.Callable)" href="#tensorflow_transform.Callable">Callable</a></span><span class="p">[</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>            <span class="p">[</span><span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">,</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-internal" title="            Tuple


  
      module-attribute
   (typing.Tuple)" href="#tensorflow_transform.Tuple">Tuple</a></span><span class="p">[</span><span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">]</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>        <span class="p">]</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="n">file_format</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.VocabularyFileFormatType">VocabularyFileFormatType</span></span> <span class="o">=</span> <span class="n"><span title="tensorflow_transform.analyzers.DEFAULT_VOCABULARY_FILE_FORMAT">DEFAULT_VOCABULARY_FILE_FORMAT</span></span><span class="p">,</span>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Maps <code>x</code> to a vocabulary specified by the deferred tensor.</p>
<p>This function also writes domain statistics about the vocabulary min and max
values. Note that the min and max are inclusive, and depend on the vocab size,
num_oov_buckets and default_value.</p>
        <hr>
<p>x: A categorical <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of type
    tf.string or tf.int[8|16|32|64] to which the vocabulary transformation
    should be applied. The column names are those intended for the transformed
    tensors.
  deferred_vocab_filename_tensor: The deferred vocab filename tensor as
    returned by <code>tft.vocabulary</code>, as long as the frequencies were not stored.
  default_value: The value to use for out-of-vocabulary values, unless
    'num_oov_buckets' is greater than zero.
  num_oov_buckets:  Any lookup of an out-of-vocabulary token will return a
    bucket ID based on its hash if <code>num_oov_buckets</code> is greater than zero.
    Otherwise it is assigned the <code>default_value</code>.
  lookup_fn: Optional lookup function, if specified it should take a tensor
    and a deferred vocab filename as an input and return a lookup <code>op</code> along
    with the table size, by default <code>apply_vocabulary</code> constructs a
    StaticHashTable for the table lookup.
  file_format: (Optional) A str. The format of the given vocabulary. Accepted
    formats are: 'tfrecord_gzip', 'text'. The default value is 'text'.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> where each string value is
  mapped to an integer. Each unique string value that appears in the
  vocabulary is mapped to a different integer and integers are consecutive
  starting from zero, and string value not in the vocabulary is
  assigned default_value.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1151">1151</a></span>
<span class="normal"><a href="#__codelineno-0-1152">1152</a></span>
<span class="normal"><a href="#__codelineno-0-1153">1153</a></span>
<span class="normal"><a href="#__codelineno-0-1154">1154</a></span>
<span class="normal"><a href="#__codelineno-0-1155">1155</a></span>
<span class="normal"><a href="#__codelineno-0-1156">1156</a></span>
<span class="normal"><a href="#__codelineno-0-1157">1157</a></span>
<span class="normal"><a href="#__codelineno-0-1158">1158</a></span>
<span class="normal"><a href="#__codelineno-0-1159">1159</a></span>
<span class="normal"><a href="#__codelineno-0-1160">1160</a></span>
<span class="normal"><a href="#__codelineno-0-1161">1161</a></span>
<span class="normal"><a href="#__codelineno-0-1162">1162</a></span>
<span class="normal"><a href="#__codelineno-0-1163">1163</a></span>
<span class="normal"><a href="#__codelineno-0-1164">1164</a></span>
<span class="normal"><a href="#__codelineno-0-1165">1165</a></span>
<span class="normal"><a href="#__codelineno-0-1166">1166</a></span>
<span class="normal"><a href="#__codelineno-0-1167">1167</a></span>
<span class="normal"><a href="#__codelineno-0-1168">1168</a></span>
<span class="normal"><a href="#__codelineno-0-1169">1169</a></span>
<span class="normal"><a href="#__codelineno-0-1170">1170</a></span>
<span class="normal"><a href="#__codelineno-0-1171">1171</a></span>
<span class="normal"><a href="#__codelineno-0-1172">1172</a></span>
<span class="normal"><a href="#__codelineno-0-1173">1173</a></span>
<span class="normal"><a href="#__codelineno-0-1174">1174</a></span>
<span class="normal"><a href="#__codelineno-0-1175">1175</a></span>
<span class="normal"><a href="#__codelineno-0-1176">1176</a></span>
<span class="normal"><a href="#__codelineno-0-1177">1177</a></span>
<span class="normal"><a href="#__codelineno-0-1178">1178</a></span>
<span class="normal"><a href="#__codelineno-0-1179">1179</a></span>
<span class="normal"><a href="#__codelineno-0-1180">1180</a></span>
<span class="normal"><a href="#__codelineno-0-1181">1181</a></span>
<span class="normal"><a href="#__codelineno-0-1182">1182</a></span>
<span class="normal"><a href="#__codelineno-0-1183">1183</a></span>
<span class="normal"><a href="#__codelineno-0-1184">1184</a></span>
<span class="normal"><a href="#__codelineno-0-1185">1185</a></span>
<span class="normal"><a href="#__codelineno-0-1186">1186</a></span>
<span class="normal"><a href="#__codelineno-0-1187">1187</a></span>
<span class="normal"><a href="#__codelineno-0-1188">1188</a></span>
<span class="normal"><a href="#__codelineno-0-1189">1189</a></span>
<span class="normal"><a href="#__codelineno-0-1190">1190</a></span>
<span class="normal"><a href="#__codelineno-0-1191">1191</a></span>
<span class="normal"><a href="#__codelineno-0-1192">1192</a></span>
<span class="normal"><a href="#__codelineno-0-1193">1193</a></span>
<span class="normal"><a href="#__codelineno-0-1194">1194</a></span>
<span class="normal"><a href="#__codelineno-0-1195">1195</a></span>
<span class="normal"><a href="#__codelineno-0-1196">1196</a></span>
<span class="normal"><a href="#__codelineno-0-1197">1197</a></span>
<span class="normal"><a href="#__codelineno-0-1198">1198</a></span>
<span class="normal"><a href="#__codelineno-0-1199">1199</a></span>
<span class="normal"><a href="#__codelineno-0-1200">1200</a></span>
<span class="normal"><a href="#__codelineno-0-1201">1201</a></span>
<span class="normal"><a href="#__codelineno-0-1202">1202</a></span>
<span class="normal"><a href="#__codelineno-0-1203">1203</a></span>
<span class="normal"><a href="#__codelineno-0-1204">1204</a></span>
<span class="normal"><a href="#__codelineno-0-1205">1205</a></span>
<span class="normal"><a href="#__codelineno-0-1206">1206</a></span>
<span class="normal"><a href="#__codelineno-0-1207">1207</a></span>
<span class="normal"><a href="#__codelineno-0-1208">1208</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1151"><a id="__codelineno-0-1151" name="__codelineno-0-1151"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-1152"><a id="__codelineno-0-1152" name="__codelineno-0-1152"></a><span class="k">def</span><span class="w"> </span><span class="nf">apply_vocabulary</span><span class="p">(</span>
</span><span id="__span-0-1153"><a id="__codelineno-0-1153" name="__codelineno-0-1153"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">,</span>
</span><span id="__span-0-1154"><a id="__codelineno-0-1154" name="__codelineno-0-1154"></a>    <span class="n">deferred_vocab_filename_tensor</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TemporaryAnalyzerOutputType</span><span class="p">,</span>
</span><span id="__span-0-1155"><a id="__codelineno-0-1155" name="__codelineno-0-1155"></a>    <span class="o">*</span><span class="p">,</span>  <span class="c1"># Force passing optional parameters by keys.</span>
</span><span id="__span-0-1156"><a id="__codelineno-0-1156" name="__codelineno-0-1156"></a>    <span class="n">default_value</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-1157"><a id="__codelineno-0-1157" name="__codelineno-0-1157"></a>    <span class="n">num_oov_buckets</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-1158"><a id="__codelineno-0-1158" name="__codelineno-0-1158"></a>    <span class="n">lookup_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
</span><span id="__span-0-1159"><a id="__codelineno-0-1159" name="__codelineno-0-1159"></a>        <span class="n">Callable</span><span class="p">[[</span><span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span>
</span><span id="__span-0-1160"><a id="__codelineno-0-1160" name="__codelineno-0-1160"></a>    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1161"><a id="__codelineno-0-1161" name="__codelineno-0-1161"></a>    <span class="n">file_format</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">VocabularyFileFormatType</span> <span class="o">=</span> <span class="n">analyzers</span><span class="o">.</span><span class="n">DEFAULT_VOCABULARY_FILE_FORMAT</span><span class="p">,</span>
</span><span id="__span-0-1162"><a id="__codelineno-0-1162" name="__codelineno-0-1162"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1163"><a id="__codelineno-0-1163" name="__codelineno-0-1163"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">:</span>
</span><span id="__span-0-1164"><a id="__codelineno-0-1164" name="__codelineno-0-1164"></a><span class="w">    </span><span class="sa">r</span><span class="sd">"""Maps `x` to a vocabulary specified by the deferred tensor.</span>
</span><span id="__span-0-1165"><a id="__codelineno-0-1165" name="__codelineno-0-1165"></a>
</span><span id="__span-0-1166"><a id="__codelineno-0-1166" name="__codelineno-0-1166"></a><span class="sd">    This function also writes domain statistics about the vocabulary min and max</span>
</span><span id="__span-0-1167"><a id="__codelineno-0-1167" name="__codelineno-0-1167"></a><span class="sd">    values. Note that the min and max are inclusive, and depend on the vocab size,</span>
</span><span id="__span-0-1168"><a id="__codelineno-0-1168" name="__codelineno-0-1168"></a><span class="sd">    num_oov_buckets and default_value.</span>
</span><span id="__span-0-1169"><a id="__codelineno-0-1169" name="__codelineno-0-1169"></a>
</span><span id="__span-0-1170"><a id="__codelineno-0-1170" name="__codelineno-0-1170"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1171"><a id="__codelineno-0-1171" name="__codelineno-0-1171"></a><span class="sd">    ----</span>
</span><span id="__span-0-1172"><a id="__codelineno-0-1172" name="__codelineno-0-1172"></a><span class="sd">      x: A categorical `Tensor`, `SparseTensor`, or `RaggedTensor` of type</span>
</span><span id="__span-0-1173"><a id="__codelineno-0-1173" name="__codelineno-0-1173"></a><span class="sd">        tf.string or tf.int[8|16|32|64] to which the vocabulary transformation</span>
</span><span id="__span-0-1174"><a id="__codelineno-0-1174" name="__codelineno-0-1174"></a><span class="sd">        should be applied. The column names are those intended for the transformed</span>
</span><span id="__span-0-1175"><a id="__codelineno-0-1175" name="__codelineno-0-1175"></a><span class="sd">        tensors.</span>
</span><span id="__span-0-1176"><a id="__codelineno-0-1176" name="__codelineno-0-1176"></a><span class="sd">      deferred_vocab_filename_tensor: The deferred vocab filename tensor as</span>
</span><span id="__span-0-1177"><a id="__codelineno-0-1177" name="__codelineno-0-1177"></a><span class="sd">        returned by `tft.vocabulary`, as long as the frequencies were not stored.</span>
</span><span id="__span-0-1178"><a id="__codelineno-0-1178" name="__codelineno-0-1178"></a><span class="sd">      default_value: The value to use for out-of-vocabulary values, unless</span>
</span><span id="__span-0-1179"><a id="__codelineno-0-1179" name="__codelineno-0-1179"></a><span class="sd">        'num_oov_buckets' is greater than zero.</span>
</span><span id="__span-0-1180"><a id="__codelineno-0-1180" name="__codelineno-0-1180"></a><span class="sd">      num_oov_buckets:  Any lookup of an out-of-vocabulary token will return a</span>
</span><span id="__span-0-1181"><a id="__codelineno-0-1181" name="__codelineno-0-1181"></a><span class="sd">        bucket ID based on its hash if `num_oov_buckets` is greater than zero.</span>
</span><span id="__span-0-1182"><a id="__codelineno-0-1182" name="__codelineno-0-1182"></a><span class="sd">        Otherwise it is assigned the `default_value`.</span>
</span><span id="__span-0-1183"><a id="__codelineno-0-1183" name="__codelineno-0-1183"></a><span class="sd">      lookup_fn: Optional lookup function, if specified it should take a tensor</span>
</span><span id="__span-0-1184"><a id="__codelineno-0-1184" name="__codelineno-0-1184"></a><span class="sd">        and a deferred vocab filename as an input and return a lookup `op` along</span>
</span><span id="__span-0-1185"><a id="__codelineno-0-1185" name="__codelineno-0-1185"></a><span class="sd">        with the table size, by default `apply_vocabulary` constructs a</span>
</span><span id="__span-0-1186"><a id="__codelineno-0-1186" name="__codelineno-0-1186"></a><span class="sd">        StaticHashTable for the table lookup.</span>
</span><span id="__span-0-1187"><a id="__codelineno-0-1187" name="__codelineno-0-1187"></a><span class="sd">      file_format: (Optional) A str. The format of the given vocabulary. Accepted</span>
</span><span id="__span-0-1188"><a id="__codelineno-0-1188" name="__codelineno-0-1188"></a><span class="sd">        formats are: 'tfrecord_gzip', 'text'. The default value is 'text'.</span>
</span><span id="__span-0-1189"><a id="__codelineno-0-1189" name="__codelineno-0-1189"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-1190"><a id="__codelineno-0-1190" name="__codelineno-0-1190"></a>
</span><span id="__span-0-1191"><a id="__codelineno-0-1191" name="__codelineno-0-1191"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1192"><a id="__codelineno-0-1192" name="__codelineno-0-1192"></a><span class="sd">    -------</span>
</span><span id="__span-0-1193"><a id="__codelineno-0-1193" name="__codelineno-0-1193"></a><span class="sd">      A `Tensor`, `SparseTensor`, or `RaggedTensor` where each string value is</span>
</span><span id="__span-0-1194"><a id="__codelineno-0-1194" name="__codelineno-0-1194"></a><span class="sd">      mapped to an integer. Each unique string value that appears in the</span>
</span><span id="__span-0-1195"><a id="__codelineno-0-1195" name="__codelineno-0-1195"></a><span class="sd">      vocabulary is mapped to a different integer and integers are consecutive</span>
</span><span id="__span-0-1196"><a id="__codelineno-0-1196" name="__codelineno-0-1196"></a><span class="sd">      starting from zero, and string value not in the vocabulary is</span>
</span><span id="__span-0-1197"><a id="__codelineno-0-1197" name="__codelineno-0-1197"></a><span class="sd">      assigned default_value.</span>
</span><span id="__span-0-1198"><a id="__codelineno-0-1198" name="__codelineno-0-1198"></a><span class="sd">    """</span>
</span><span id="__span-0-1199"><a id="__codelineno-0-1199" name="__codelineno-0-1199"></a>    <span class="k">return</span> <span class="n">_apply_vocabulary_internal</span><span class="p">(</span>
</span><span id="__span-0-1200"><a id="__codelineno-0-1200" name="__codelineno-0-1200"></a>        <span class="n">x</span><span class="p">,</span>
</span><span id="__span-0-1201"><a id="__codelineno-0-1201" name="__codelineno-0-1201"></a>        <span class="n">deferred_vocab_filename_tensor</span><span class="p">,</span>
</span><span id="__span-0-1202"><a id="__codelineno-0-1202" name="__codelineno-0-1202"></a>        <span class="n">default_value</span><span class="p">,</span>
</span><span id="__span-0-1203"><a id="__codelineno-0-1203" name="__codelineno-0-1203"></a>        <span class="n">num_oov_buckets</span><span class="p">,</span>
</span><span id="__span-0-1204"><a id="__codelineno-0-1204" name="__codelineno-0-1204"></a>        <span class="n">lookup_fn</span><span class="p">,</span>
</span><span id="__span-0-1205"><a id="__codelineno-0-1205" name="__codelineno-0-1205"></a>        <span class="n">file_format</span><span class="p">,</span>
</span><span id="__span-0-1206"><a id="__codelineno-0-1206" name="__codelineno-0-1206"></a>        <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-1207"><a id="__codelineno-0-1207" name="__codelineno-0-1207"></a>        <span class="n">name</span><span class="p">,</span>
</span><span id="__span-0-1208"><a id="__codelineno-0-1208" name="__codelineno-0-1208"></a>    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.bag_of_words" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">bag_of_words</span>


<a href="#tensorflow_transform.bag_of_words" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">bag_of_words</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">tokens</span><span class="p">:</span> <span class="n"><span title="tensorflow.SparseTensor">SparseTensor</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">ngram_range</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Tuple


  
      module-attribute
   (typing.Tuple)" href="#tensorflow_transform.Tuple">Tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">separator</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow.SparseTensor">SparseTensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes a bag of "words" based on the specified ngram configuration.</p>
<p>A light wrapper around tft.ngrams. First computes ngrams, then transforms the
ngram representation (list semantics) into a Bag of Words (set semantics) per
row. Each row reflects the set of <em>unique</em> ngrams present in an input record.</p>
<p>See tft.ngrams for more information.</p>
        <hr>
<p>tokens: a two-dimensional <code>SparseTensor</code> of dtype <code>tf.string</code> containing
    tokens that will be used to construct a bag of words.
  ngram_range: A pair with the range (inclusive) of ngram sizes to compute.
  separator: a string that will be inserted between tokens when ngrams are
    constructed.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>A <code>SparseTensor</code> containing the unique set of ngrams from each row of the
    input. Note: the original order of the ngrams may not be preserved.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1590">1590</a></span>
<span class="normal"><a href="#__codelineno-0-1591">1591</a></span>
<span class="normal"><a href="#__codelineno-0-1592">1592</a></span>
<span class="normal"><a href="#__codelineno-0-1593">1593</a></span>
<span class="normal"><a href="#__codelineno-0-1594">1594</a></span>
<span class="normal"><a href="#__codelineno-0-1595">1595</a></span>
<span class="normal"><a href="#__codelineno-0-1596">1596</a></span>
<span class="normal"><a href="#__codelineno-0-1597">1597</a></span>
<span class="normal"><a href="#__codelineno-0-1598">1598</a></span>
<span class="normal"><a href="#__codelineno-0-1599">1599</a></span>
<span class="normal"><a href="#__codelineno-0-1600">1600</a></span>
<span class="normal"><a href="#__codelineno-0-1601">1601</a></span>
<span class="normal"><a href="#__codelineno-0-1602">1602</a></span>
<span class="normal"><a href="#__codelineno-0-1603">1603</a></span>
<span class="normal"><a href="#__codelineno-0-1604">1604</a></span>
<span class="normal"><a href="#__codelineno-0-1605">1605</a></span>
<span class="normal"><a href="#__codelineno-0-1606">1606</a></span>
<span class="normal"><a href="#__codelineno-0-1607">1607</a></span>
<span class="normal"><a href="#__codelineno-0-1608">1608</a></span>
<span class="normal"><a href="#__codelineno-0-1609">1609</a></span>
<span class="normal"><a href="#__codelineno-0-1610">1610</a></span>
<span class="normal"><a href="#__codelineno-0-1611">1611</a></span>
<span class="normal"><a href="#__codelineno-0-1612">1612</a></span>
<span class="normal"><a href="#__codelineno-0-1613">1613</a></span>
<span class="normal"><a href="#__codelineno-0-1614">1614</a></span>
<span class="normal"><a href="#__codelineno-0-1615">1615</a></span>
<span class="normal"><a href="#__codelineno-0-1616">1616</a></span>
<span class="normal"><a href="#__codelineno-0-1617">1617</a></span>
<span class="normal"><a href="#__codelineno-0-1618">1618</a></span>
<span class="normal"><a href="#__codelineno-0-1619">1619</a></span>
<span class="normal"><a href="#__codelineno-0-1620">1620</a></span>
<span class="normal"><a href="#__codelineno-0-1621">1621</a></span>
<span class="normal"><a href="#__codelineno-0-1622">1622</a></span>
<span class="normal"><a href="#__codelineno-0-1623">1623</a></span>
<span class="normal"><a href="#__codelineno-0-1624">1624</a></span>
<span class="normal"><a href="#__codelineno-0-1625">1625</a></span>
<span class="normal"><a href="#__codelineno-0-1626">1626</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1590"><a id="__codelineno-0-1590" name="__codelineno-0-1590"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-1591"><a id="__codelineno-0-1591" name="__codelineno-0-1591"></a><span class="k">def</span><span class="w"> </span><span class="nf">bag_of_words</span><span class="p">(</span>
</span><span id="__span-0-1592"><a id="__codelineno-0-1592" name="__codelineno-0-1592"></a>    <span class="n">tokens</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">,</span>
</span><span id="__span-0-1593"><a id="__codelineno-0-1593" name="__codelineno-0-1593"></a>    <span class="n">ngram_range</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
</span><span id="__span-0-1594"><a id="__codelineno-0-1594" name="__codelineno-0-1594"></a>    <span class="n">separator</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="__span-0-1595"><a id="__codelineno-0-1595" name="__codelineno-0-1595"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1596"><a id="__codelineno-0-1596" name="__codelineno-0-1596"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">:</span>
</span><span id="__span-0-1597"><a id="__codelineno-0-1597" name="__codelineno-0-1597"></a><span class="w">    </span><span class="sd">"""Computes a bag of "words" based on the specified ngram configuration.</span>
</span><span id="__span-0-1598"><a id="__codelineno-0-1598" name="__codelineno-0-1598"></a>
</span><span id="__span-0-1599"><a id="__codelineno-0-1599" name="__codelineno-0-1599"></a><span class="sd">    A light wrapper around tft.ngrams. First computes ngrams, then transforms the</span>
</span><span id="__span-0-1600"><a id="__codelineno-0-1600" name="__codelineno-0-1600"></a><span class="sd">    ngram representation (list semantics) into a Bag of Words (set semantics) per</span>
</span><span id="__span-0-1601"><a id="__codelineno-0-1601" name="__codelineno-0-1601"></a><span class="sd">    row. Each row reflects the set of *unique* ngrams present in an input record.</span>
</span><span id="__span-0-1602"><a id="__codelineno-0-1602" name="__codelineno-0-1602"></a>
</span><span id="__span-0-1603"><a id="__codelineno-0-1603" name="__codelineno-0-1603"></a><span class="sd">    See tft.ngrams for more information.</span>
</span><span id="__span-0-1604"><a id="__codelineno-0-1604" name="__codelineno-0-1604"></a>
</span><span id="__span-0-1605"><a id="__codelineno-0-1605" name="__codelineno-0-1605"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1606"><a id="__codelineno-0-1606" name="__codelineno-0-1606"></a><span class="sd">    ----</span>
</span><span id="__span-0-1607"><a id="__codelineno-0-1607" name="__codelineno-0-1607"></a><span class="sd">      tokens: a two-dimensional `SparseTensor` of dtype `tf.string` containing</span>
</span><span id="__span-0-1608"><a id="__codelineno-0-1608" name="__codelineno-0-1608"></a><span class="sd">        tokens that will be used to construct a bag of words.</span>
</span><span id="__span-0-1609"><a id="__codelineno-0-1609" name="__codelineno-0-1609"></a><span class="sd">      ngram_range: A pair with the range (inclusive) of ngram sizes to compute.</span>
</span><span id="__span-0-1610"><a id="__codelineno-0-1610" name="__codelineno-0-1610"></a><span class="sd">      separator: a string that will be inserted between tokens when ngrams are</span>
</span><span id="__span-0-1611"><a id="__codelineno-0-1611" name="__codelineno-0-1611"></a><span class="sd">        constructed.</span>
</span><span id="__span-0-1612"><a id="__codelineno-0-1612" name="__codelineno-0-1612"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-1613"><a id="__codelineno-0-1613" name="__codelineno-0-1613"></a>
</span><span id="__span-0-1614"><a id="__codelineno-0-1614" name="__codelineno-0-1614"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1615"><a id="__codelineno-0-1615" name="__codelineno-0-1615"></a><span class="sd">    -------</span>
</span><span id="__span-0-1616"><a id="__codelineno-0-1616" name="__codelineno-0-1616"></a><span class="sd">      A `SparseTensor` containing the unique set of ngrams from each row of the</span>
</span><span id="__span-0-1617"><a id="__codelineno-0-1617" name="__codelineno-0-1617"></a><span class="sd">        input. Note: the original order of the ngrams may not be preserved.</span>
</span><span id="__span-0-1618"><a id="__codelineno-0-1618" name="__codelineno-0-1618"></a><span class="sd">    """</span>
</span><span id="__span-0-1619"><a id="__codelineno-0-1619" name="__codelineno-0-1619"></a>    <span class="k">if</span> <span class="n">tokens</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">ndims</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="__span-0-1620"><a id="__codelineno-0-1620" name="__codelineno-0-1620"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"bag_of_words requires `tokens` to be 2-dimensional"</span><span class="p">)</span>
</span><span id="__span-0-1621"><a id="__codelineno-0-1621" name="__codelineno-0-1621"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"bag_of_words"</span><span class="p">):</span>
</span><span id="__span-0-1622"><a id="__codelineno-0-1622" name="__codelineno-0-1622"></a>        <span class="c1"># First compute the ngram representation, which will contain ordered and</span>
</span><span id="__span-0-1623"><a id="__codelineno-0-1623" name="__codelineno-0-1623"></a>        <span class="c1"># possibly duplicated ngrams per row.</span>
</span><span id="__span-0-1624"><a id="__codelineno-0-1624" name="__codelineno-0-1624"></a>        <span class="n">all_ngrams</span> <span class="o">=</span> <span class="n">ngrams</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">ngram_range</span><span class="p">,</span> <span class="n">separator</span><span class="p">)</span>
</span><span id="__span-0-1625"><a id="__codelineno-0-1625" name="__codelineno-0-1625"></a>        <span class="c1"># Then deduplicate the ngrams in each row.</span>
</span><span id="__span-0-1626"><a id="__codelineno-0-1626" name="__codelineno-0-1626"></a>        <span class="k">return</span> <span class="n">deduplicate_tensor_per_row</span><span class="p">(</span><span class="n">all_ngrams</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.bucketize" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">bucketize</span>


<a href="#tensorflow_transform.bucketize" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">bucketize</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">num_buckets</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">epsilon</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">weights</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">elementwise</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Returns a bucketized column, with a bucket index assigned to each input.</p>
        <hr>
<p>x: A numeric input <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> whose values
    should be mapped to buckets.  For a <code>CompositeTensor</code> only non-missing
    values will be included in the quantiles computation, and the result of
    <code>bucketize</code> will be a <code>CompositeTensor</code> with non-missing values mapped to
    buckets. If elementwise=True then <code>x</code> must be dense.
  num_buckets: Values in the input <code>x</code> are divided into approximately
    equal-sized buckets, where the number of buckets is <code>num_buckets</code>.
  epsilon: (Optional) Error tolerance, typically a small fraction close to
    zero. If a value is not specified by the caller, a suitable value is
    computed based on experimental results.  For <code>num_buckets</code> less than 100,
    the value of 0.01 is chosen to handle a dataset of up to ~1 trillion input
    data values.  If <code>num_buckets</code> is larger, then epsilon is set to
    (1/<code>num_buckets</code>) to enforce a stricter error tolerance, because more
    buckets will result in smaller range for each bucket, and so we want the
    boundaries to be less fuzzy. See analyzers.quantiles() for details.
  weights: (Optional) Weights tensor for the quantiles. Tensor must have the
    same shape as x.
  elementwise: (Optional) If true, bucketize each element of the tensor
    independently.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>A <code>Tensor</code> of the same shape as <code>x</code>, with each element in the
  returned tensor representing the bucketized value. Bucketized value is
  in the range [0, actual_num_buckets). Sometimes the actual number of buckets
  can be different than num_buckets hint, for example in case the number of
  distinct values is smaller than num_buckets, or in cases where the
  input values are not uniformly distributed.
  NaN values are mapped to the last bucket. Values with NaN weights are
  ignored in bucket boundaries calculation.</p>
        <hr>
<p>TypeError: If num_buckets is not an int.
  ValueError: If value of num_buckets is not &gt; 1.
  ValueError: If elementwise=True and x is a <code>CompositeTensor</code>.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1888">1888</a></span>
<span class="normal"><a href="#__codelineno-0-1889">1889</a></span>
<span class="normal"><a href="#__codelineno-0-1890">1890</a></span>
<span class="normal"><a href="#__codelineno-0-1891">1891</a></span>
<span class="normal"><a href="#__codelineno-0-1892">1892</a></span>
<span class="normal"><a href="#__codelineno-0-1893">1893</a></span>
<span class="normal"><a href="#__codelineno-0-1894">1894</a></span>
<span class="normal"><a href="#__codelineno-0-1895">1895</a></span>
<span class="normal"><a href="#__codelineno-0-1896">1896</a></span>
<span class="normal"><a href="#__codelineno-0-1897">1897</a></span>
<span class="normal"><a href="#__codelineno-0-1898">1898</a></span>
<span class="normal"><a href="#__codelineno-0-1899">1899</a></span>
<span class="normal"><a href="#__codelineno-0-1900">1900</a></span>
<span class="normal"><a href="#__codelineno-0-1901">1901</a></span>
<span class="normal"><a href="#__codelineno-0-1902">1902</a></span>
<span class="normal"><a href="#__codelineno-0-1903">1903</a></span>
<span class="normal"><a href="#__codelineno-0-1904">1904</a></span>
<span class="normal"><a href="#__codelineno-0-1905">1905</a></span>
<span class="normal"><a href="#__codelineno-0-1906">1906</a></span>
<span class="normal"><a href="#__codelineno-0-1907">1907</a></span>
<span class="normal"><a href="#__codelineno-0-1908">1908</a></span>
<span class="normal"><a href="#__codelineno-0-1909">1909</a></span>
<span class="normal"><a href="#__codelineno-0-1910">1910</a></span>
<span class="normal"><a href="#__codelineno-0-1911">1911</a></span>
<span class="normal"><a href="#__codelineno-0-1912">1912</a></span>
<span class="normal"><a href="#__codelineno-0-1913">1913</a></span>
<span class="normal"><a href="#__codelineno-0-1914">1914</a></span>
<span class="normal"><a href="#__codelineno-0-1915">1915</a></span>
<span class="normal"><a href="#__codelineno-0-1916">1916</a></span>
<span class="normal"><a href="#__codelineno-0-1917">1917</a></span>
<span class="normal"><a href="#__codelineno-0-1918">1918</a></span>
<span class="normal"><a href="#__codelineno-0-1919">1919</a></span>
<span class="normal"><a href="#__codelineno-0-1920">1920</a></span>
<span class="normal"><a href="#__codelineno-0-1921">1921</a></span>
<span class="normal"><a href="#__codelineno-0-1922">1922</a></span>
<span class="normal"><a href="#__codelineno-0-1923">1923</a></span>
<span class="normal"><a href="#__codelineno-0-1924">1924</a></span>
<span class="normal"><a href="#__codelineno-0-1925">1925</a></span>
<span class="normal"><a href="#__codelineno-0-1926">1926</a></span>
<span class="normal"><a href="#__codelineno-0-1927">1927</a></span>
<span class="normal"><a href="#__codelineno-0-1928">1928</a></span>
<span class="normal"><a href="#__codelineno-0-1929">1929</a></span>
<span class="normal"><a href="#__codelineno-0-1930">1930</a></span>
<span class="normal"><a href="#__codelineno-0-1931">1931</a></span>
<span class="normal"><a href="#__codelineno-0-1932">1932</a></span>
<span class="normal"><a href="#__codelineno-0-1933">1933</a></span>
<span class="normal"><a href="#__codelineno-0-1934">1934</a></span>
<span class="normal"><a href="#__codelineno-0-1935">1935</a></span>
<span class="normal"><a href="#__codelineno-0-1936">1936</a></span>
<span class="normal"><a href="#__codelineno-0-1937">1937</a></span>
<span class="normal"><a href="#__codelineno-0-1938">1938</a></span>
<span class="normal"><a href="#__codelineno-0-1939">1939</a></span>
<span class="normal"><a href="#__codelineno-0-1940">1940</a></span>
<span class="normal"><a href="#__codelineno-0-1941">1941</a></span>
<span class="normal"><a href="#__codelineno-0-1942">1942</a></span>
<span class="normal"><a href="#__codelineno-0-1943">1943</a></span>
<span class="normal"><a href="#__codelineno-0-1944">1944</a></span>
<span class="normal"><a href="#__codelineno-0-1945">1945</a></span>
<span class="normal"><a href="#__codelineno-0-1946">1946</a></span>
<span class="normal"><a href="#__codelineno-0-1947">1947</a></span>
<span class="normal"><a href="#__codelineno-0-1948">1948</a></span>
<span class="normal"><a href="#__codelineno-0-1949">1949</a></span>
<span class="normal"><a href="#__codelineno-0-1950">1950</a></span>
<span class="normal"><a href="#__codelineno-0-1951">1951</a></span>
<span class="normal"><a href="#__codelineno-0-1952">1952</a></span>
<span class="normal"><a href="#__codelineno-0-1953">1953</a></span>
<span class="normal"><a href="#__codelineno-0-1954">1954</a></span>
<span class="normal"><a href="#__codelineno-0-1955">1955</a></span>
<span class="normal"><a href="#__codelineno-0-1956">1956</a></span>
<span class="normal"><a href="#__codelineno-0-1957">1957</a></span>
<span class="normal"><a href="#__codelineno-0-1958">1958</a></span>
<span class="normal"><a href="#__codelineno-0-1959">1959</a></span>
<span class="normal"><a href="#__codelineno-0-1960">1960</a></span>
<span class="normal"><a href="#__codelineno-0-1961">1961</a></span>
<span class="normal"><a href="#__codelineno-0-1962">1962</a></span>
<span class="normal"><a href="#__codelineno-0-1963">1963</a></span>
<span class="normal"><a href="#__codelineno-0-1964">1964</a></span>
<span class="normal"><a href="#__codelineno-0-1965">1965</a></span>
<span class="normal"><a href="#__codelineno-0-1966">1966</a></span>
<span class="normal"><a href="#__codelineno-0-1967">1967</a></span>
<span class="normal"><a href="#__codelineno-0-1968">1968</a></span>
<span class="normal"><a href="#__codelineno-0-1969">1969</a></span>
<span class="normal"><a href="#__codelineno-0-1970">1970</a></span>
<span class="normal"><a href="#__codelineno-0-1971">1971</a></span>
<span class="normal"><a href="#__codelineno-0-1972">1972</a></span>
<span class="normal"><a href="#__codelineno-0-1973">1973</a></span>
<span class="normal"><a href="#__codelineno-0-1974">1974</a></span>
<span class="normal"><a href="#__codelineno-0-1975">1975</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1888"><a id="__codelineno-0-1888" name="__codelineno-0-1888"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-1889"><a id="__codelineno-0-1889" name="__codelineno-0-1889"></a><span class="k">def</span><span class="w"> </span><span class="nf">bucketize</span><span class="p">(</span>
</span><span id="__span-0-1890"><a id="__codelineno-0-1890" name="__codelineno-0-1890"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">,</span>
</span><span id="__span-0-1891"><a id="__codelineno-0-1891" name="__codelineno-0-1891"></a>    <span class="n">num_buckets</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-1892"><a id="__codelineno-0-1892" name="__codelineno-0-1892"></a>    <span class="n">epsilon</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1893"><a id="__codelineno-0-1893" name="__codelineno-0-1893"></a>    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1894"><a id="__codelineno-0-1894" name="__codelineno-0-1894"></a>    <span class="n">elementwise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-1895"><a id="__codelineno-0-1895" name="__codelineno-0-1895"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1896"><a id="__codelineno-0-1896" name="__codelineno-0-1896"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">:</span>
</span><span id="__span-0-1897"><a id="__codelineno-0-1897" name="__codelineno-0-1897"></a><span class="w">    </span><span class="sd">"""Returns a bucketized column, with a bucket index assigned to each input.</span>
</span><span id="__span-0-1898"><a id="__codelineno-0-1898" name="__codelineno-0-1898"></a>
</span><span id="__span-0-1899"><a id="__codelineno-0-1899" name="__codelineno-0-1899"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1900"><a id="__codelineno-0-1900" name="__codelineno-0-1900"></a><span class="sd">    ----</span>
</span><span id="__span-0-1901"><a id="__codelineno-0-1901" name="__codelineno-0-1901"></a><span class="sd">      x: A numeric input `Tensor`, `SparseTensor`, or `RaggedTensor` whose values</span>
</span><span id="__span-0-1902"><a id="__codelineno-0-1902" name="__codelineno-0-1902"></a><span class="sd">        should be mapped to buckets.  For a `CompositeTensor` only non-missing</span>
</span><span id="__span-0-1903"><a id="__codelineno-0-1903" name="__codelineno-0-1903"></a><span class="sd">        values will be included in the quantiles computation, and the result of</span>
</span><span id="__span-0-1904"><a id="__codelineno-0-1904" name="__codelineno-0-1904"></a><span class="sd">        `bucketize` will be a `CompositeTensor` with non-missing values mapped to</span>
</span><span id="__span-0-1905"><a id="__codelineno-0-1905" name="__codelineno-0-1905"></a><span class="sd">        buckets. If elementwise=True then `x` must be dense.</span>
</span><span id="__span-0-1906"><a id="__codelineno-0-1906" name="__codelineno-0-1906"></a><span class="sd">      num_buckets: Values in the input `x` are divided into approximately</span>
</span><span id="__span-0-1907"><a id="__codelineno-0-1907" name="__codelineno-0-1907"></a><span class="sd">        equal-sized buckets, where the number of buckets is `num_buckets`.</span>
</span><span id="__span-0-1908"><a id="__codelineno-0-1908" name="__codelineno-0-1908"></a><span class="sd">      epsilon: (Optional) Error tolerance, typically a small fraction close to</span>
</span><span id="__span-0-1909"><a id="__codelineno-0-1909" name="__codelineno-0-1909"></a><span class="sd">        zero. If a value is not specified by the caller, a suitable value is</span>
</span><span id="__span-0-1910"><a id="__codelineno-0-1910" name="__codelineno-0-1910"></a><span class="sd">        computed based on experimental results.  For `num_buckets` less than 100,</span>
</span><span id="__span-0-1911"><a id="__codelineno-0-1911" name="__codelineno-0-1911"></a><span class="sd">        the value of 0.01 is chosen to handle a dataset of up to ~1 trillion input</span>
</span><span id="__span-0-1912"><a id="__codelineno-0-1912" name="__codelineno-0-1912"></a><span class="sd">        data values.  If `num_buckets` is larger, then epsilon is set to</span>
</span><span id="__span-0-1913"><a id="__codelineno-0-1913" name="__codelineno-0-1913"></a><span class="sd">        (1/`num_buckets`) to enforce a stricter error tolerance, because more</span>
</span><span id="__span-0-1914"><a id="__codelineno-0-1914" name="__codelineno-0-1914"></a><span class="sd">        buckets will result in smaller range for each bucket, and so we want the</span>
</span><span id="__span-0-1915"><a id="__codelineno-0-1915" name="__codelineno-0-1915"></a><span class="sd">        boundaries to be less fuzzy. See analyzers.quantiles() for details.</span>
</span><span id="__span-0-1916"><a id="__codelineno-0-1916" name="__codelineno-0-1916"></a><span class="sd">      weights: (Optional) Weights tensor for the quantiles. Tensor must have the</span>
</span><span id="__span-0-1917"><a id="__codelineno-0-1917" name="__codelineno-0-1917"></a><span class="sd">        same shape as x.</span>
</span><span id="__span-0-1918"><a id="__codelineno-0-1918" name="__codelineno-0-1918"></a><span class="sd">      elementwise: (Optional) If true, bucketize each element of the tensor</span>
</span><span id="__span-0-1919"><a id="__codelineno-0-1919" name="__codelineno-0-1919"></a><span class="sd">        independently.</span>
</span><span id="__span-0-1920"><a id="__codelineno-0-1920" name="__codelineno-0-1920"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-1921"><a id="__codelineno-0-1921" name="__codelineno-0-1921"></a>
</span><span id="__span-0-1922"><a id="__codelineno-0-1922" name="__codelineno-0-1922"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1923"><a id="__codelineno-0-1923" name="__codelineno-0-1923"></a><span class="sd">    -------</span>
</span><span id="__span-0-1924"><a id="__codelineno-0-1924" name="__codelineno-0-1924"></a><span class="sd">      A `Tensor` of the same shape as `x`, with each element in the</span>
</span><span id="__span-0-1925"><a id="__codelineno-0-1925" name="__codelineno-0-1925"></a><span class="sd">      returned tensor representing the bucketized value. Bucketized value is</span>
</span><span id="__span-0-1926"><a id="__codelineno-0-1926" name="__codelineno-0-1926"></a><span class="sd">      in the range [0, actual_num_buckets). Sometimes the actual number of buckets</span>
</span><span id="__span-0-1927"><a id="__codelineno-0-1927" name="__codelineno-0-1927"></a><span class="sd">      can be different than num_buckets hint, for example in case the number of</span>
</span><span id="__span-0-1928"><a id="__codelineno-0-1928" name="__codelineno-0-1928"></a><span class="sd">      distinct values is smaller than num_buckets, or in cases where the</span>
</span><span id="__span-0-1929"><a id="__codelineno-0-1929" name="__codelineno-0-1929"></a><span class="sd">      input values are not uniformly distributed.</span>
</span><span id="__span-0-1930"><a id="__codelineno-0-1930" name="__codelineno-0-1930"></a><span class="sd">      NaN values are mapped to the last bucket. Values with NaN weights are</span>
</span><span id="__span-0-1931"><a id="__codelineno-0-1931" name="__codelineno-0-1931"></a><span class="sd">      ignored in bucket boundaries calculation.</span>
</span><span id="__span-0-1932"><a id="__codelineno-0-1932" name="__codelineno-0-1932"></a>
</span><span id="__span-0-1933"><a id="__codelineno-0-1933" name="__codelineno-0-1933"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-1934"><a id="__codelineno-0-1934" name="__codelineno-0-1934"></a><span class="sd">    ------</span>
</span><span id="__span-0-1935"><a id="__codelineno-0-1935" name="__codelineno-0-1935"></a><span class="sd">      TypeError: If num_buckets is not an int.</span>
</span><span id="__span-0-1936"><a id="__codelineno-0-1936" name="__codelineno-0-1936"></a><span class="sd">      ValueError: If value of num_buckets is not &gt; 1.</span>
</span><span id="__span-0-1937"><a id="__codelineno-0-1937" name="__codelineno-0-1937"></a><span class="sd">      ValueError: If elementwise=True and x is a `CompositeTensor`.</span>
</span><span id="__span-0-1938"><a id="__codelineno-0-1938" name="__codelineno-0-1938"></a><span class="sd">    """</span>
</span><span id="__span-0-1939"><a id="__codelineno-0-1939" name="__codelineno-0-1939"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"bucketize"</span><span class="p">):</span>
</span><span id="__span-0-1940"><a id="__codelineno-0-1940" name="__codelineno-0-1940"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_buckets</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
</span><span id="__span-0-1941"><a id="__codelineno-0-1941" name="__codelineno-0-1941"></a>            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">"num_buckets must be an int, got </span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">num_buckets</span><span class="p">))</span>
</span><span id="__span-0-1942"><a id="__codelineno-0-1942" name="__codelineno-0-1942"></a>
</span><span id="__span-0-1943"><a id="__codelineno-0-1943" name="__codelineno-0-1943"></a>        <span class="k">if</span> <span class="n">num_buckets</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="__span-0-1944"><a id="__codelineno-0-1944" name="__codelineno-0-1944"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Invalid num_buckets </span><span class="si">%d</span><span class="s2">"</span> <span class="o">%</span> <span class="n">num_buckets</span><span class="p">)</span>
</span><span id="__span-0-1945"><a id="__codelineno-0-1945" name="__codelineno-0-1945"></a>
</span><span id="__span-0-1946"><a id="__codelineno-0-1946" name="__codelineno-0-1946"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">))</span> <span class="ow">and</span> <span class="n">elementwise</span><span class="p">:</span>
</span><span id="__span-0-1947"><a id="__codelineno-0-1947" name="__codelineno-0-1947"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"bucketize requires `x` to be dense if `elementwise=True`"</span><span class="p">)</span>
</span><span id="__span-0-1948"><a id="__codelineno-0-1948" name="__codelineno-0-1948"></a>
</span><span id="__span-0-1949"><a id="__codelineno-0-1949" name="__codelineno-0-1949"></a>        <span class="k">if</span> <span class="n">epsilon</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-1950"><a id="__codelineno-0-1950" name="__codelineno-0-1950"></a>            <span class="c1"># See explanation in args documentation for epsilon.</span>
</span><span id="__span-0-1951"><a id="__codelineno-0-1951" name="__codelineno-0-1951"></a>            <span class="n">epsilon</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">num_buckets</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
</span><span id="__span-0-1952"><a id="__codelineno-0-1952" name="__codelineno-0-1952"></a>
</span><span id="__span-0-1953"><a id="__codelineno-0-1953" name="__codelineno-0-1953"></a>        <span class="n">x_values</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">get_values</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-0-1954"><a id="__codelineno-0-1954" name="__codelineno-0-1954"></a>        <span class="n">bucket_boundaries</span> <span class="o">=</span> <span class="n">analyzers</span><span class="o">.</span><span class="n">quantiles</span><span class="p">(</span>
</span><span id="__span-0-1955"><a id="__codelineno-0-1955" name="__codelineno-0-1955"></a>            <span class="n">x_values</span><span class="p">,</span>
</span><span id="__span-0-1956"><a id="__codelineno-0-1956" name="__codelineno-0-1956"></a>            <span class="n">num_buckets</span><span class="p">,</span>
</span><span id="__span-0-1957"><a id="__codelineno-0-1957" name="__codelineno-0-1957"></a>            <span class="n">epsilon</span><span class="p">,</span>
</span><span id="__span-0-1958"><a id="__codelineno-0-1958" name="__codelineno-0-1958"></a>            <span class="n">weights</span><span class="p">,</span>
</span><span id="__span-0-1959"><a id="__codelineno-0-1959" name="__codelineno-0-1959"></a>            <span class="n">reduce_instance_dims</span><span class="o">=</span><span class="ow">not</span> <span class="n">elementwise</span><span class="p">,</span>
</span><span id="__span-0-1960"><a id="__codelineno-0-1960" name="__codelineno-0-1960"></a>        <span class="p">)</span>
</span><span id="__span-0-1961"><a id="__codelineno-0-1961" name="__codelineno-0-1961"></a>
</span><span id="__span-0-1962"><a id="__codelineno-0-1962" name="__codelineno-0-1962"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">elementwise</span><span class="p">:</span>
</span><span id="__span-0-1963"><a id="__codelineno-0-1963" name="__codelineno-0-1963"></a>            <span class="k">return</span> <span class="n">apply_buckets</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">bucket_boundaries</span><span class="p">)</span>
</span><span id="__span-0-1964"><a id="__codelineno-0-1964" name="__codelineno-0-1964"></a>
</span><span id="__span-0-1965"><a id="__codelineno-0-1965" name="__codelineno-0-1965"></a>        <span class="n">num_features</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_prod</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
</span><span id="__span-0-1966"><a id="__codelineno-0-1966" name="__codelineno-0-1966"></a>        <span class="n">bucket_boundaries</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">bucket_boundaries</span><span class="p">,</span> <span class="p">[</span><span class="n">num_features</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="__span-0-1967"><a id="__codelineno-0-1967" name="__codelineno-0-1967"></a>        <span class="n">x_reshaped</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_features</span><span class="p">])</span>
</span><span id="__span-0-1968"><a id="__codelineno-0-1968" name="__codelineno-0-1968"></a>        <span class="n">bucketized</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-0-1969"><a id="__codelineno-0-1969" name="__codelineno-0-1969"></a>        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">boundaries</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">bucket_boundaries</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)):</span>
</span><span id="__span-0-1970"><a id="__codelineno-0-1970" name="__codelineno-0-1970"></a>            <span class="n">bucketized</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
</span><span id="__span-0-1971"><a id="__codelineno-0-1971" name="__codelineno-0-1971"></a>                <span class="n">apply_buckets</span><span class="p">(</span><span class="n">x_reshaped</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">boundaries</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</span><span id="__span-0-1972"><a id="__codelineno-0-1972" name="__codelineno-0-1972"></a>            <span class="p">)</span>
</span><span id="__span-0-1973"><a id="__codelineno-0-1973" name="__codelineno-0-1973"></a>        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
</span><span id="__span-0-1974"><a id="__codelineno-0-1974" name="__codelineno-0-1974"></a>            <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">bucketized</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="__span-0-1975"><a id="__codelineno-0-1975" name="__codelineno-0-1975"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.bucketize_per_key" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">bucketize_per_key</span>


<a href="#tensorflow_transform.bucketize_per_key" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">bucketize_per_key</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">key</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">num_buckets</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">epsilon</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">weights</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Returns a bucketized column, with a bucket index assigned to each input.</p>
        <hr>
<p>x: A numeric input <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> with rank 1,
    whose values should be mapped to buckets.  <code>CompositeTensor</code>s will have
    their non-missing values mapped and missing values left as missing.
  key: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> with the same shape as
    <code>x</code> and dtype tf.string.  If <code>x</code> is a <code>CompositeTensor</code>, <code>key</code> must
    exactly match <code>x</code> in everything except values, i.e. indices and
    dense_shape or nested row splits must be identical.
  num_buckets: Values in the input <code>x</code> are divided into approximately
    equal-sized buckets, where the number of buckets is num_buckets.
  epsilon: (Optional) see <code>bucketize</code>.
  weights: (Optional) A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> with the
    same shape as <code>x</code> and dtype tf.float32. Used as weights for quantiles
    calculation. If <code>x</code> is a <code>CompositeTensor</code>, <code>weights</code> must exactly match
    <code>x</code> in everything except values.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of the same shape as <code>x</code>, with
  each element in the returned tensor representing the bucketized value.
  Bucketized value is in the range [0, actual_num_buckets). If the computed
  key vocabulary doesn't have an entry for <code>key</code> then the resulting bucket is
  -1.</p>
        <hr>
<p>ValueError: If value of num_buckets is not &gt; 1.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1979">1979</a></span>
<span class="normal"><a href="#__codelineno-0-1980">1980</a></span>
<span class="normal"><a href="#__codelineno-0-1981">1981</a></span>
<span class="normal"><a href="#__codelineno-0-1982">1982</a></span>
<span class="normal"><a href="#__codelineno-0-1983">1983</a></span>
<span class="normal"><a href="#__codelineno-0-1984">1984</a></span>
<span class="normal"><a href="#__codelineno-0-1985">1985</a></span>
<span class="normal"><a href="#__codelineno-0-1986">1986</a></span>
<span class="normal"><a href="#__codelineno-0-1987">1987</a></span>
<span class="normal"><a href="#__codelineno-0-1988">1988</a></span>
<span class="normal"><a href="#__codelineno-0-1989">1989</a></span>
<span class="normal"><a href="#__codelineno-0-1990">1990</a></span>
<span class="normal"><a href="#__codelineno-0-1991">1991</a></span>
<span class="normal"><a href="#__codelineno-0-1992">1992</a></span>
<span class="normal"><a href="#__codelineno-0-1993">1993</a></span>
<span class="normal"><a href="#__codelineno-0-1994">1994</a></span>
<span class="normal"><a href="#__codelineno-0-1995">1995</a></span>
<span class="normal"><a href="#__codelineno-0-1996">1996</a></span>
<span class="normal"><a href="#__codelineno-0-1997">1997</a></span>
<span class="normal"><a href="#__codelineno-0-1998">1998</a></span>
<span class="normal"><a href="#__codelineno-0-1999">1999</a></span>
<span class="normal"><a href="#__codelineno-0-2000">2000</a></span>
<span class="normal"><a href="#__codelineno-0-2001">2001</a></span>
<span class="normal"><a href="#__codelineno-0-2002">2002</a></span>
<span class="normal"><a href="#__codelineno-0-2003">2003</a></span>
<span class="normal"><a href="#__codelineno-0-2004">2004</a></span>
<span class="normal"><a href="#__codelineno-0-2005">2005</a></span>
<span class="normal"><a href="#__codelineno-0-2006">2006</a></span>
<span class="normal"><a href="#__codelineno-0-2007">2007</a></span>
<span class="normal"><a href="#__codelineno-0-2008">2008</a></span>
<span class="normal"><a href="#__codelineno-0-2009">2009</a></span>
<span class="normal"><a href="#__codelineno-0-2010">2010</a></span>
<span class="normal"><a href="#__codelineno-0-2011">2011</a></span>
<span class="normal"><a href="#__codelineno-0-2012">2012</a></span>
<span class="normal"><a href="#__codelineno-0-2013">2013</a></span>
<span class="normal"><a href="#__codelineno-0-2014">2014</a></span>
<span class="normal"><a href="#__codelineno-0-2015">2015</a></span>
<span class="normal"><a href="#__codelineno-0-2016">2016</a></span>
<span class="normal"><a href="#__codelineno-0-2017">2017</a></span>
<span class="normal"><a href="#__codelineno-0-2018">2018</a></span>
<span class="normal"><a href="#__codelineno-0-2019">2019</a></span>
<span class="normal"><a href="#__codelineno-0-2020">2020</a></span>
<span class="normal"><a href="#__codelineno-0-2021">2021</a></span>
<span class="normal"><a href="#__codelineno-0-2022">2022</a></span>
<span class="normal"><a href="#__codelineno-0-2023">2023</a></span>
<span class="normal"><a href="#__codelineno-0-2024">2024</a></span>
<span class="normal"><a href="#__codelineno-0-2025">2025</a></span>
<span class="normal"><a href="#__codelineno-0-2026">2026</a></span>
<span class="normal"><a href="#__codelineno-0-2027">2027</a></span>
<span class="normal"><a href="#__codelineno-0-2028">2028</a></span>
<span class="normal"><a href="#__codelineno-0-2029">2029</a></span>
<span class="normal"><a href="#__codelineno-0-2030">2030</a></span>
<span class="normal"><a href="#__codelineno-0-2031">2031</a></span>
<span class="normal"><a href="#__codelineno-0-2032">2032</a></span>
<span class="normal"><a href="#__codelineno-0-2033">2033</a></span>
<span class="normal"><a href="#__codelineno-0-2034">2034</a></span>
<span class="normal"><a href="#__codelineno-0-2035">2035</a></span>
<span class="normal"><a href="#__codelineno-0-2036">2036</a></span>
<span class="normal"><a href="#__codelineno-0-2037">2037</a></span>
<span class="normal"><a href="#__codelineno-0-2038">2038</a></span>
<span class="normal"><a href="#__codelineno-0-2039">2039</a></span>
<span class="normal"><a href="#__codelineno-0-2040">2040</a></span>
<span class="normal"><a href="#__codelineno-0-2041">2041</a></span>
<span class="normal"><a href="#__codelineno-0-2042">2042</a></span>
<span class="normal"><a href="#__codelineno-0-2043">2043</a></span>
<span class="normal"><a href="#__codelineno-0-2044">2044</a></span>
<span class="normal"><a href="#__codelineno-0-2045">2045</a></span>
<span class="normal"><a href="#__codelineno-0-2046">2046</a></span>
<span class="normal"><a href="#__codelineno-0-2047">2047</a></span>
<span class="normal"><a href="#__codelineno-0-2048">2048</a></span>
<span class="normal"><a href="#__codelineno-0-2049">2049</a></span>
<span class="normal"><a href="#__codelineno-0-2050">2050</a></span>
<span class="normal"><a href="#__codelineno-0-2051">2051</a></span>
<span class="normal"><a href="#__codelineno-0-2052">2052</a></span>
<span class="normal"><a href="#__codelineno-0-2053">2053</a></span>
<span class="normal"><a href="#__codelineno-0-2054">2054</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1979"><a id="__codelineno-0-1979" name="__codelineno-0-1979"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-1980"><a id="__codelineno-0-1980" name="__codelineno-0-1980"></a><span class="k">def</span><span class="w"> </span><span class="nf">bucketize_per_key</span><span class="p">(</span>
</span><span id="__span-0-1981"><a id="__codelineno-0-1981" name="__codelineno-0-1981"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">,</span>
</span><span id="__span-0-1982"><a id="__codelineno-0-1982" name="__codelineno-0-1982"></a>    <span class="n">key</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">,</span>
</span><span id="__span-0-1983"><a id="__codelineno-0-1983" name="__codelineno-0-1983"></a>    <span class="n">num_buckets</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-1984"><a id="__codelineno-0-1984" name="__codelineno-0-1984"></a>    <span class="n">epsilon</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1985"><a id="__codelineno-0-1985" name="__codelineno-0-1985"></a>    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1986"><a id="__codelineno-0-1986" name="__codelineno-0-1986"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1987"><a id="__codelineno-0-1987" name="__codelineno-0-1987"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">:</span>
</span><span id="__span-0-1988"><a id="__codelineno-0-1988" name="__codelineno-0-1988"></a><span class="w">    </span><span class="sd">"""Returns a bucketized column, with a bucket index assigned to each input.</span>
</span><span id="__span-0-1989"><a id="__codelineno-0-1989" name="__codelineno-0-1989"></a>
</span><span id="__span-0-1990"><a id="__codelineno-0-1990" name="__codelineno-0-1990"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1991"><a id="__codelineno-0-1991" name="__codelineno-0-1991"></a><span class="sd">    ----</span>
</span><span id="__span-0-1992"><a id="__codelineno-0-1992" name="__codelineno-0-1992"></a><span class="sd">      x: A numeric input `Tensor`, `SparseTensor`, or `RaggedTensor` with rank 1,</span>
</span><span id="__span-0-1993"><a id="__codelineno-0-1993" name="__codelineno-0-1993"></a><span class="sd">        whose values should be mapped to buckets.  `CompositeTensor`s will have</span>
</span><span id="__span-0-1994"><a id="__codelineno-0-1994" name="__codelineno-0-1994"></a><span class="sd">        their non-missing values mapped and missing values left as missing.</span>
</span><span id="__span-0-1995"><a id="__codelineno-0-1995" name="__codelineno-0-1995"></a><span class="sd">      key: A `Tensor`, `SparseTensor`, or `RaggedTensor` with the same shape as</span>
</span><span id="__span-0-1996"><a id="__codelineno-0-1996" name="__codelineno-0-1996"></a><span class="sd">        `x` and dtype tf.string.  If `x` is a `CompositeTensor`, `key` must</span>
</span><span id="__span-0-1997"><a id="__codelineno-0-1997" name="__codelineno-0-1997"></a><span class="sd">        exactly match `x` in everything except values, i.e. indices and</span>
</span><span id="__span-0-1998"><a id="__codelineno-0-1998" name="__codelineno-0-1998"></a><span class="sd">        dense_shape or nested row splits must be identical.</span>
</span><span id="__span-0-1999"><a id="__codelineno-0-1999" name="__codelineno-0-1999"></a><span class="sd">      num_buckets: Values in the input `x` are divided into approximately</span>
</span><span id="__span-0-2000"><a id="__codelineno-0-2000" name="__codelineno-0-2000"></a><span class="sd">        equal-sized buckets, where the number of buckets is num_buckets.</span>
</span><span id="__span-0-2001"><a id="__codelineno-0-2001" name="__codelineno-0-2001"></a><span class="sd">      epsilon: (Optional) see `bucketize`.</span>
</span><span id="__span-0-2002"><a id="__codelineno-0-2002" name="__codelineno-0-2002"></a><span class="sd">      weights: (Optional) A `Tensor`, `SparseTensor`, or `RaggedTensor` with the</span>
</span><span id="__span-0-2003"><a id="__codelineno-0-2003" name="__codelineno-0-2003"></a><span class="sd">        same shape as `x` and dtype tf.float32. Used as weights for quantiles</span>
</span><span id="__span-0-2004"><a id="__codelineno-0-2004" name="__codelineno-0-2004"></a><span class="sd">        calculation. If `x` is a `CompositeTensor`, `weights` must exactly match</span>
</span><span id="__span-0-2005"><a id="__codelineno-0-2005" name="__codelineno-0-2005"></a><span class="sd">        `x` in everything except values.</span>
</span><span id="__span-0-2006"><a id="__codelineno-0-2006" name="__codelineno-0-2006"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-2007"><a id="__codelineno-0-2007" name="__codelineno-0-2007"></a>
</span><span id="__span-0-2008"><a id="__codelineno-0-2008" name="__codelineno-0-2008"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-2009"><a id="__codelineno-0-2009" name="__codelineno-0-2009"></a><span class="sd">    -------</span>
</span><span id="__span-0-2010"><a id="__codelineno-0-2010" name="__codelineno-0-2010"></a><span class="sd">      A `Tensor`, `SparseTensor`, or `RaggedTensor` of the same shape as `x`, with</span>
</span><span id="__span-0-2011"><a id="__codelineno-0-2011" name="__codelineno-0-2011"></a><span class="sd">      each element in the returned tensor representing the bucketized value.</span>
</span><span id="__span-0-2012"><a id="__codelineno-0-2012" name="__codelineno-0-2012"></a><span class="sd">      Bucketized value is in the range [0, actual_num_buckets). If the computed</span>
</span><span id="__span-0-2013"><a id="__codelineno-0-2013" name="__codelineno-0-2013"></a><span class="sd">      key vocabulary doesn't have an entry for `key` then the resulting bucket is</span>
</span><span id="__span-0-2014"><a id="__codelineno-0-2014" name="__codelineno-0-2014"></a><span class="sd">      -1.</span>
</span><span id="__span-0-2015"><a id="__codelineno-0-2015" name="__codelineno-0-2015"></a>
</span><span id="__span-0-2016"><a id="__codelineno-0-2016" name="__codelineno-0-2016"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-2017"><a id="__codelineno-0-2017" name="__codelineno-0-2017"></a><span class="sd">    ------</span>
</span><span id="__span-0-2018"><a id="__codelineno-0-2018" name="__codelineno-0-2018"></a><span class="sd">      ValueError: If value of num_buckets is not &gt; 1.</span>
</span><span id="__span-0-2019"><a id="__codelineno-0-2019" name="__codelineno-0-2019"></a><span class="sd">    """</span>
</span><span id="__span-0-2020"><a id="__codelineno-0-2020" name="__codelineno-0-2020"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"bucketize_per_key"</span><span class="p">):</span>
</span><span id="__span-0-2021"><a id="__codelineno-0-2021" name="__codelineno-0-2021"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_buckets</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
</span><span id="__span-0-2022"><a id="__codelineno-0-2022" name="__codelineno-0-2022"></a>            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
</span><span id="__span-0-2023"><a id="__codelineno-0-2023" name="__codelineno-0-2023"></a>                <span class="s2">"num_buckets must be an int, got </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">num_buckets</span><span class="p">))</span>
</span><span id="__span-0-2024"><a id="__codelineno-0-2024" name="__codelineno-0-2024"></a>            <span class="p">)</span>
</span><span id="__span-0-2025"><a id="__codelineno-0-2025" name="__codelineno-0-2025"></a>
</span><span id="__span-0-2026"><a id="__codelineno-0-2026" name="__codelineno-0-2026"></a>        <span class="k">if</span> <span class="n">num_buckets</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="__span-0-2027"><a id="__codelineno-0-2027" name="__codelineno-0-2027"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Invalid num_buckets </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_buckets</span><span class="p">))</span>
</span><span id="__span-0-2028"><a id="__codelineno-0-2028" name="__codelineno-0-2028"></a>
</span><span id="__span-0-2029"><a id="__codelineno-0-2029" name="__codelineno-0-2029"></a>        <span class="k">if</span> <span class="n">epsilon</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-2030"><a id="__codelineno-0-2030" name="__codelineno-0-2030"></a>            <span class="c1"># See explanation in args documentation for epsilon.</span>
</span><span id="__span-0-2031"><a id="__codelineno-0-2031" name="__codelineno-0-2031"></a>            <span class="n">epsilon</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">num_buckets</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
</span><span id="__span-0-2032"><a id="__codelineno-0-2032" name="__codelineno-0-2032"></a>
</span><span id="__span-0-2033"><a id="__codelineno-0-2033" name="__codelineno-0-2033"></a>        <span class="p">(</span>
</span><span id="__span-0-2034"><a id="__codelineno-0-2034" name="__codelineno-0-2034"></a>            <span class="n">key_vocab</span><span class="p">,</span>
</span><span id="__span-0-2035"><a id="__codelineno-0-2035" name="__codelineno-0-2035"></a>            <span class="n">bucket_boundaries</span><span class="p">,</span>
</span><span id="__span-0-2036"><a id="__codelineno-0-2036" name="__codelineno-0-2036"></a>            <span class="n">scale_factor_per_key</span><span class="p">,</span>
</span><span id="__span-0-2037"><a id="__codelineno-0-2037" name="__codelineno-0-2037"></a>            <span class="n">shift_per_key</span><span class="p">,</span>
</span><span id="__span-0-2038"><a id="__codelineno-0-2038" name="__codelineno-0-2038"></a>            <span class="n">actual_num_buckets</span><span class="p">,</span>
</span><span id="__span-0-2039"><a id="__codelineno-0-2039" name="__codelineno-0-2039"></a>        <span class="p">)</span> <span class="o">=</span> <span class="n">analyzers</span><span class="o">.</span><span class="n">_quantiles_per_key</span><span class="p">(</span>  <span class="c1"># pylint: disable=protected-access</span>
</span><span id="__span-0-2040"><a id="__codelineno-0-2040" name="__codelineno-0-2040"></a>            <span class="n">tf_utils</span><span class="o">.</span><span class="n">get_values</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
</span><span id="__span-0-2041"><a id="__codelineno-0-2041" name="__codelineno-0-2041"></a>            <span class="n">tf_utils</span><span class="o">.</span><span class="n">get_values</span><span class="p">(</span><span class="n">key</span><span class="p">),</span>
</span><span id="__span-0-2042"><a id="__codelineno-0-2042" name="__codelineno-0-2042"></a>            <span class="n">num_buckets</span><span class="p">,</span>
</span><span id="__span-0-2043"><a id="__codelineno-0-2043" name="__codelineno-0-2043"></a>            <span class="n">epsilon</span><span class="p">,</span>
</span><span id="__span-0-2044"><a id="__codelineno-0-2044" name="__codelineno-0-2044"></a>            <span class="n">weights</span><span class="o">=</span><span class="n">tf_utils</span><span class="o">.</span><span class="n">get_values</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span>
</span><span id="__span-0-2045"><a id="__codelineno-0-2045" name="__codelineno-0-2045"></a>        <span class="p">)</span>
</span><span id="__span-0-2046"><a id="__codelineno-0-2046" name="__codelineno-0-2046"></a>        <span class="k">return</span> <span class="n">_apply_buckets_with_keys</span><span class="p">(</span>
</span><span id="__span-0-2047"><a id="__codelineno-0-2047" name="__codelineno-0-2047"></a>            <span class="n">x</span><span class="p">,</span>
</span><span id="__span-0-2048"><a id="__codelineno-0-2048" name="__codelineno-0-2048"></a>            <span class="n">key</span><span class="p">,</span>
</span><span id="__span-0-2049"><a id="__codelineno-0-2049" name="__codelineno-0-2049"></a>            <span class="n">key_vocab</span><span class="p">,</span>
</span><span id="__span-0-2050"><a id="__codelineno-0-2050" name="__codelineno-0-2050"></a>            <span class="n">bucket_boundaries</span><span class="p">,</span>
</span><span id="__span-0-2051"><a id="__codelineno-0-2051" name="__codelineno-0-2051"></a>            <span class="n">scale_factor_per_key</span><span class="p">,</span>
</span><span id="__span-0-2052"><a id="__codelineno-0-2052" name="__codelineno-0-2052"></a>            <span class="n">shift_per_key</span><span class="p">,</span>
</span><span id="__span-0-2053"><a id="__codelineno-0-2053" name="__codelineno-0-2053"></a>            <span class="n">actual_num_buckets</span><span class="p">,</span>
</span><span id="__span-0-2054"><a id="__codelineno-0-2054" name="__codelineno-0-2054"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.compute_and_apply_vocabulary" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">compute_and_apply_vocabulary</span>


<a href="#tensorflow_transform.compute_and_apply_vocabulary" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">compute_and_apply_vocabulary</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">default_value</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Any (typing.Any)" href="#tensorflow_transform.Any">Any</a></span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">top_k</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">frequency_threshold</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">num_oov_buckets</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">vocab_filename</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="n">weights</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="n">labels</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="n">use_adjusted_mutual_info</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="n">min_diff_from_avg</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="n">coverage_top_k</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="n">coverage_frequency_threshold</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="n">key_fn</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="            Callable


  
      module-attribute
   (typing.Callable)" href="#tensorflow_transform.Callable">Callable</a></span><span class="p">[[</span><span class="n"><a class="autorefs autorefs-internal" title="            Any (typing.Any)" href="#tensorflow_transform.Any">Any</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-internal" title="            Any (typing.Any)" href="#tensorflow_transform.Any">Any</a></span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-16"><a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="n">fingerprint_shuffle</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-17"><a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="n">file_format</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.VocabularyFileFormatType">VocabularyFileFormatType</span></span> <span class="o">=</span> <span class="n"><span title="tensorflow_transform.analyzers.DEFAULT_VOCABULARY_FILE_FORMAT">DEFAULT_VOCABULARY_FILE_FORMAT</span></span><span class="p">,</span>
</span><span id="__span-0-18"><a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="n">store_frequency</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-19"><a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>    <span class="n">reserved_tokens</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span>
</span><span id="__span-0-20"><a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>        <span class="n"><a class="autorefs autorefs-internal" title="            Union (typing.Union)" href="#tensorflow_transform.Union">Union</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="            Iterable


  
      module-attribute
   (typing.Iterable)" href="#tensorflow_transform.Iterable">Iterable</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">],</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">]</span>
</span><span id="__span-0-21"><a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-22"><a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-23"><a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Generates a vocabulary for <code>x</code> and maps it to an integer with this vocab.</p>
<p>In case one of the tokens contains the '\n' or '\r' characters or is empty it
will be discarded since we are currently writing the vocabularies as text
files. This behavior will likely be fixed/improved in the future.</p>
<p>Note that this function will cause a vocabulary to be computed.  For large
datasets it is highly recommended to either set frequency_threshold or top_k
to control the size of the vocabulary, and also the run time of this
operation.</p>
        <hr>
<p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of type tf.string or
    tf.int[8|16|32|64].
  default_value: The value to use for out-of-vocabulary values, unless
    'num_oov_buckets' is greater than zero.
  top_k: Limit the generated vocabulary to the first <code>top_k</code> elements. If set
    to None, the full vocabulary is generated.
  frequency_threshold: Limit the generated vocabulary only to elements whose
    absolute frequency is &gt;= to the supplied threshold. If set to None, the
    full vocabulary is generated.  Absolute frequency means the number of
    occurences of the element in the dataset, as opposed to the proportion of
    instances that contain that element. If labels are provided and the vocab
    is computed using mutual information, tokens are filtered if their mutual
    information with the label is &lt; the supplied threshold.
  num_oov_buckets:  Any lookup of an out-of-vocabulary token will return a
    bucket ID based on its hash if <code>num_oov_buckets</code> is greater than zero.
    Otherwise it is assigned the <code>default_value</code>.
  vocab_filename: The file name for the vocabulary file. If None, a name based
    on the scope name in the context of this graph will be used as the file
    name. If not None, should be unique within a given preprocessing function.
    NOTE in order to make your pipelines resilient to implementation details
    please set <code>vocab_filename</code> when you are using the vocab_filename on a
    downstream component.
  weights: (Optional) Weights <code>Tensor</code> for the vocabulary. It must have the
    same shape as x.
  labels: (Optional) A <code>Tensor</code> of labels for the vocabulary. If provided, the
    vocabulary is calculated based on mutual information with the label,
    rather than frequency. The labels must have the same batch dimension as x.
    If x is sparse, labels should be a 1D tensor reflecting row-wise labels.
    If x is dense, labels can either be a 1D tensor of row-wise labels, or a
    dense tensor of the identical shape as x (i.e. element-wise labels).
    Labels should be a discrete integerized tensor (If the label is numeric,
    it should first be bucketized; If the label is a string, an integer
    vocabulary should first be applied). Note: <code>CompositeTensor</code> labels are
    not yet supported (b/134931826). WARNING: when labels are provided, the
    frequency_threshold argument functions as a mutual information threshold,
    which is a float. TODO(b/116308354): Fix confusing naming.
  use_adjusted_mutual_info: If true, use adjusted mutual information.
  min_diff_from_avg: Mutual information of a feature will be adjusted to zero
    whenever the difference between count of the feature with any label and
    its expected count is lower than min_diff_from_average.
  coverage_top_k: (Optional), (Experimental) The minimum number of elements
    per key to be included in the vocabulary.
  coverage_frequency_threshold: (Optional), (Experimental) Limit the coverage
    arm of the vocabulary only to elements whose absolute frequency is &gt;= this
    threshold for a given key.
  key_fn: (Optional), (Experimental) A fn that takes in a single entry of <code>x</code>
    and returns the corresponding key for coverage calculation. If this is
    <code>None</code>, no coverage arm is added to the vocabulary.
  fingerprint_shuffle: (Optional), (Experimental) Whether to sort the
    vocabularies by fingerprint instead of counts. This is useful for load
    balancing on the training parameter servers. Shuffle only happens while
    writing the files, so all the filters above will still take effect.
  file_format: (Optional) A str. The format of the resulting vocabulary file.
    Accepted formats are: 'tfrecord_gzip', 'text'. 'tfrecord_gzip' requires
    tensorflow&gt;=2.4. The default value is 'text'.
  store_frequency: If True, frequency of the words is stored in the vocabulary
    file. In the case labels are provided, the mutual information is stored in
    the file instead. Each line in the file will be of the form 'frequency
    word'. NOTE: if True and text_format is 'text' then spaces will be
    replaced to avoid information loss.
  reserved_tokens: (Optional) A list of tokens that should appear in the
    vocabulary regardless of their appearance in the input. These tokens would
    maintain their order, and have a reserved spot at the beginning of the
    vocabulary. Note: this field has no affect on cache.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> where each string value is
  mapped to an integer. Each unique string value that appears in the
  vocabulary is mapped to a different integer and integers are consecutive
  starting from zero. String value not in the vocabulary is assigned
  <code>default_value</code>. Alternatively, if <code>num_oov_buckets</code> is specified, out of
  vocabulary strings are hashed to values in
  [vocab_size, vocab_size + num_oov_buckets) for an overall range of
  [0, vocab_size + num_oov_buckets).</p>
        <hr>
<p>ValueError: If <code>top_k</code> or <code>frequency_threshold</code> is negative.
    If <code>coverage_top_k</code> or <code>coverage_frequency_threshold</code> is negative.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1002">1002</a></span>
<span class="normal"><a href="#__codelineno-0-1003">1003</a></span>
<span class="normal"><a href="#__codelineno-0-1004">1004</a></span>
<span class="normal"><a href="#__codelineno-0-1005">1005</a></span>
<span class="normal"><a href="#__codelineno-0-1006">1006</a></span>
<span class="normal"><a href="#__codelineno-0-1007">1007</a></span>
<span class="normal"><a href="#__codelineno-0-1008">1008</a></span>
<span class="normal"><a href="#__codelineno-0-1009">1009</a></span>
<span class="normal"><a href="#__codelineno-0-1010">1010</a></span>
<span class="normal"><a href="#__codelineno-0-1011">1011</a></span>
<span class="normal"><a href="#__codelineno-0-1012">1012</a></span>
<span class="normal"><a href="#__codelineno-0-1013">1013</a></span>
<span class="normal"><a href="#__codelineno-0-1014">1014</a></span>
<span class="normal"><a href="#__codelineno-0-1015">1015</a></span>
<span class="normal"><a href="#__codelineno-0-1016">1016</a></span>
<span class="normal"><a href="#__codelineno-0-1017">1017</a></span>
<span class="normal"><a href="#__codelineno-0-1018">1018</a></span>
<span class="normal"><a href="#__codelineno-0-1019">1019</a></span>
<span class="normal"><a href="#__codelineno-0-1020">1020</a></span>
<span class="normal"><a href="#__codelineno-0-1021">1021</a></span>
<span class="normal"><a href="#__codelineno-0-1022">1022</a></span>
<span class="normal"><a href="#__codelineno-0-1023">1023</a></span>
<span class="normal"><a href="#__codelineno-0-1024">1024</a></span>
<span class="normal"><a href="#__codelineno-0-1025">1025</a></span>
<span class="normal"><a href="#__codelineno-0-1026">1026</a></span>
<span class="normal"><a href="#__codelineno-0-1027">1027</a></span>
<span class="normal"><a href="#__codelineno-0-1028">1028</a></span>
<span class="normal"><a href="#__codelineno-0-1029">1029</a></span>
<span class="normal"><a href="#__codelineno-0-1030">1030</a></span>
<span class="normal"><a href="#__codelineno-0-1031">1031</a></span>
<span class="normal"><a href="#__codelineno-0-1032">1032</a></span>
<span class="normal"><a href="#__codelineno-0-1033">1033</a></span>
<span class="normal"><a href="#__codelineno-0-1034">1034</a></span>
<span class="normal"><a href="#__codelineno-0-1035">1035</a></span>
<span class="normal"><a href="#__codelineno-0-1036">1036</a></span>
<span class="normal"><a href="#__codelineno-0-1037">1037</a></span>
<span class="normal"><a href="#__codelineno-0-1038">1038</a></span>
<span class="normal"><a href="#__codelineno-0-1039">1039</a></span>
<span class="normal"><a href="#__codelineno-0-1040">1040</a></span>
<span class="normal"><a href="#__codelineno-0-1041">1041</a></span>
<span class="normal"><a href="#__codelineno-0-1042">1042</a></span>
<span class="normal"><a href="#__codelineno-0-1043">1043</a></span>
<span class="normal"><a href="#__codelineno-0-1044">1044</a></span>
<span class="normal"><a href="#__codelineno-0-1045">1045</a></span>
<span class="normal"><a href="#__codelineno-0-1046">1046</a></span>
<span class="normal"><a href="#__codelineno-0-1047">1047</a></span>
<span class="normal"><a href="#__codelineno-0-1048">1048</a></span>
<span class="normal"><a href="#__codelineno-0-1049">1049</a></span>
<span class="normal"><a href="#__codelineno-0-1050">1050</a></span>
<span class="normal"><a href="#__codelineno-0-1051">1051</a></span>
<span class="normal"><a href="#__codelineno-0-1052">1052</a></span>
<span class="normal"><a href="#__codelineno-0-1053">1053</a></span>
<span class="normal"><a href="#__codelineno-0-1054">1054</a></span>
<span class="normal"><a href="#__codelineno-0-1055">1055</a></span>
<span class="normal"><a href="#__codelineno-0-1056">1056</a></span>
<span class="normal"><a href="#__codelineno-0-1057">1057</a></span>
<span class="normal"><a href="#__codelineno-0-1058">1058</a></span>
<span class="normal"><a href="#__codelineno-0-1059">1059</a></span>
<span class="normal"><a href="#__codelineno-0-1060">1060</a></span>
<span class="normal"><a href="#__codelineno-0-1061">1061</a></span>
<span class="normal"><a href="#__codelineno-0-1062">1062</a></span>
<span class="normal"><a href="#__codelineno-0-1063">1063</a></span>
<span class="normal"><a href="#__codelineno-0-1064">1064</a></span>
<span class="normal"><a href="#__codelineno-0-1065">1065</a></span>
<span class="normal"><a href="#__codelineno-0-1066">1066</a></span>
<span class="normal"><a href="#__codelineno-0-1067">1067</a></span>
<span class="normal"><a href="#__codelineno-0-1068">1068</a></span>
<span class="normal"><a href="#__codelineno-0-1069">1069</a></span>
<span class="normal"><a href="#__codelineno-0-1070">1070</a></span>
<span class="normal"><a href="#__codelineno-0-1071">1071</a></span>
<span class="normal"><a href="#__codelineno-0-1072">1072</a></span>
<span class="normal"><a href="#__codelineno-0-1073">1073</a></span>
<span class="normal"><a href="#__codelineno-0-1074">1074</a></span>
<span class="normal"><a href="#__codelineno-0-1075">1075</a></span>
<span class="normal"><a href="#__codelineno-0-1076">1076</a></span>
<span class="normal"><a href="#__codelineno-0-1077">1077</a></span>
<span class="normal"><a href="#__codelineno-0-1078">1078</a></span>
<span class="normal"><a href="#__codelineno-0-1079">1079</a></span>
<span class="normal"><a href="#__codelineno-0-1080">1080</a></span>
<span class="normal"><a href="#__codelineno-0-1081">1081</a></span>
<span class="normal"><a href="#__codelineno-0-1082">1082</a></span>
<span class="normal"><a href="#__codelineno-0-1083">1083</a></span>
<span class="normal"><a href="#__codelineno-0-1084">1084</a></span>
<span class="normal"><a href="#__codelineno-0-1085">1085</a></span>
<span class="normal"><a href="#__codelineno-0-1086">1086</a></span>
<span class="normal"><a href="#__codelineno-0-1087">1087</a></span>
<span class="normal"><a href="#__codelineno-0-1088">1088</a></span>
<span class="normal"><a href="#__codelineno-0-1089">1089</a></span>
<span class="normal"><a href="#__codelineno-0-1090">1090</a></span>
<span class="normal"><a href="#__codelineno-0-1091">1091</a></span>
<span class="normal"><a href="#__codelineno-0-1092">1092</a></span>
<span class="normal"><a href="#__codelineno-0-1093">1093</a></span>
<span class="normal"><a href="#__codelineno-0-1094">1094</a></span>
<span class="normal"><a href="#__codelineno-0-1095">1095</a></span>
<span class="normal"><a href="#__codelineno-0-1096">1096</a></span>
<span class="normal"><a href="#__codelineno-0-1097">1097</a></span>
<span class="normal"><a href="#__codelineno-0-1098">1098</a></span>
<span class="normal"><a href="#__codelineno-0-1099">1099</a></span>
<span class="normal"><a href="#__codelineno-0-1100">1100</a></span>
<span class="normal"><a href="#__codelineno-0-1101">1101</a></span>
<span class="normal"><a href="#__codelineno-0-1102">1102</a></span>
<span class="normal"><a href="#__codelineno-0-1103">1103</a></span>
<span class="normal"><a href="#__codelineno-0-1104">1104</a></span>
<span class="normal"><a href="#__codelineno-0-1105">1105</a></span>
<span class="normal"><a href="#__codelineno-0-1106">1106</a></span>
<span class="normal"><a href="#__codelineno-0-1107">1107</a></span>
<span class="normal"><a href="#__codelineno-0-1108">1108</a></span>
<span class="normal"><a href="#__codelineno-0-1109">1109</a></span>
<span class="normal"><a href="#__codelineno-0-1110">1110</a></span>
<span class="normal"><a href="#__codelineno-0-1111">1111</a></span>
<span class="normal"><a href="#__codelineno-0-1112">1112</a></span>
<span class="normal"><a href="#__codelineno-0-1113">1113</a></span>
<span class="normal"><a href="#__codelineno-0-1114">1114</a></span>
<span class="normal"><a href="#__codelineno-0-1115">1115</a></span>
<span class="normal"><a href="#__codelineno-0-1116">1116</a></span>
<span class="normal"><a href="#__codelineno-0-1117">1117</a></span>
<span class="normal"><a href="#__codelineno-0-1118">1118</a></span>
<span class="normal"><a href="#__codelineno-0-1119">1119</a></span>
<span class="normal"><a href="#__codelineno-0-1120">1120</a></span>
<span class="normal"><a href="#__codelineno-0-1121">1121</a></span>
<span class="normal"><a href="#__codelineno-0-1122">1122</a></span>
<span class="normal"><a href="#__codelineno-0-1123">1123</a></span>
<span class="normal"><a href="#__codelineno-0-1124">1124</a></span>
<span class="normal"><a href="#__codelineno-0-1125">1125</a></span>
<span class="normal"><a href="#__codelineno-0-1126">1126</a></span>
<span class="normal"><a href="#__codelineno-0-1127">1127</a></span>
<span class="normal"><a href="#__codelineno-0-1128">1128</a></span>
<span class="normal"><a href="#__codelineno-0-1129">1129</a></span>
<span class="normal"><a href="#__codelineno-0-1130">1130</a></span>
<span class="normal"><a href="#__codelineno-0-1131">1131</a></span>
<span class="normal"><a href="#__codelineno-0-1132">1132</a></span>
<span class="normal"><a href="#__codelineno-0-1133">1133</a></span>
<span class="normal"><a href="#__codelineno-0-1134">1134</a></span>
<span class="normal"><a href="#__codelineno-0-1135">1135</a></span>
<span class="normal"><a href="#__codelineno-0-1136">1136</a></span>
<span class="normal"><a href="#__codelineno-0-1137">1137</a></span>
<span class="normal"><a href="#__codelineno-0-1138">1138</a></span>
<span class="normal"><a href="#__codelineno-0-1139">1139</a></span>
<span class="normal"><a href="#__codelineno-0-1140">1140</a></span>
<span class="normal"><a href="#__codelineno-0-1141">1141</a></span>
<span class="normal"><a href="#__codelineno-0-1142">1142</a></span>
<span class="normal"><a href="#__codelineno-0-1143">1143</a></span>
<span class="normal"><a href="#__codelineno-0-1144">1144</a></span>
<span class="normal"><a href="#__codelineno-0-1145">1145</a></span>
<span class="normal"><a href="#__codelineno-0-1146">1146</a></span>
<span class="normal"><a href="#__codelineno-0-1147">1147</a></span>
<span class="normal"><a href="#__codelineno-0-1148">1148</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1002"><a id="__codelineno-0-1002" name="__codelineno-0-1002"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-1003"><a id="__codelineno-0-1003" name="__codelineno-0-1003"></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_and_apply_vocabulary</span><span class="p">(</span>
</span><span id="__span-0-1004"><a id="__codelineno-0-1004" name="__codelineno-0-1004"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">,</span>
</span><span id="__span-0-1005"><a id="__codelineno-0-1005" name="__codelineno-0-1005"></a>    <span class="o">*</span><span class="p">,</span>  <span class="c1"># Force passing optional parameters by keys.</span>
</span><span id="__span-0-1006"><a id="__codelineno-0-1006" name="__codelineno-0-1006"></a>    <span class="n">default_value</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-1007"><a id="__codelineno-0-1007" name="__codelineno-0-1007"></a>    <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1008"><a id="__codelineno-0-1008" name="__codelineno-0-1008"></a>    <span class="n">frequency_threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1009"><a id="__codelineno-0-1009" name="__codelineno-0-1009"></a>    <span class="n">num_oov_buckets</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-1010"><a id="__codelineno-0-1010" name="__codelineno-0-1010"></a>    <span class="n">vocab_filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1011"><a id="__codelineno-0-1011" name="__codelineno-0-1011"></a>    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1012"><a id="__codelineno-0-1012" name="__codelineno-0-1012"></a>    <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1013"><a id="__codelineno-0-1013" name="__codelineno-0-1013"></a>    <span class="n">use_adjusted_mutual_info</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-1014"><a id="__codelineno-0-1014" name="__codelineno-0-1014"></a>    <span class="n">min_diff_from_avg</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-1015"><a id="__codelineno-0-1015" name="__codelineno-0-1015"></a>    <span class="n">coverage_top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1016"><a id="__codelineno-0-1016" name="__codelineno-0-1016"></a>    <span class="n">coverage_frequency_threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1017"><a id="__codelineno-0-1017" name="__codelineno-0-1017"></a>    <span class="n">key_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1018"><a id="__codelineno-0-1018" name="__codelineno-0-1018"></a>    <span class="n">fingerprint_shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-1019"><a id="__codelineno-0-1019" name="__codelineno-0-1019"></a>    <span class="n">file_format</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">VocabularyFileFormatType</span> <span class="o">=</span> <span class="n">analyzers</span><span class="o">.</span><span class="n">DEFAULT_VOCABULARY_FILE_FORMAT</span><span class="p">,</span>
</span><span id="__span-0-1020"><a id="__codelineno-0-1020" name="__codelineno-0-1020"></a>    <span class="n">store_frequency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-1021"><a id="__codelineno-0-1021" name="__codelineno-0-1021"></a>    <span class="n">reserved_tokens</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Iterable</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1022"><a id="__codelineno-0-1022" name="__codelineno-0-1022"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1023"><a id="__codelineno-0-1023" name="__codelineno-0-1023"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">:</span>
</span><span id="__span-0-1024"><a id="__codelineno-0-1024" name="__codelineno-0-1024"></a><span class="w">    </span><span class="sa">r</span><span class="sd">"""Generates a vocabulary for `x` and maps it to an integer with this vocab.</span>
</span><span id="__span-0-1025"><a id="__codelineno-0-1025" name="__codelineno-0-1025"></a>
</span><span id="__span-0-1026"><a id="__codelineno-0-1026" name="__codelineno-0-1026"></a><span class="sd">    In case one of the tokens contains the '\n' or '\r' characters or is empty it</span>
</span><span id="__span-0-1027"><a id="__codelineno-0-1027" name="__codelineno-0-1027"></a><span class="sd">    will be discarded since we are currently writing the vocabularies as text</span>
</span><span id="__span-0-1028"><a id="__codelineno-0-1028" name="__codelineno-0-1028"></a><span class="sd">    files. This behavior will likely be fixed/improved in the future.</span>
</span><span id="__span-0-1029"><a id="__codelineno-0-1029" name="__codelineno-0-1029"></a>
</span><span id="__span-0-1030"><a id="__codelineno-0-1030" name="__codelineno-0-1030"></a><span class="sd">    Note that this function will cause a vocabulary to be computed.  For large</span>
</span><span id="__span-0-1031"><a id="__codelineno-0-1031" name="__codelineno-0-1031"></a><span class="sd">    datasets it is highly recommended to either set frequency_threshold or top_k</span>
</span><span id="__span-0-1032"><a id="__codelineno-0-1032" name="__codelineno-0-1032"></a><span class="sd">    to control the size of the vocabulary, and also the run time of this</span>
</span><span id="__span-0-1033"><a id="__codelineno-0-1033" name="__codelineno-0-1033"></a><span class="sd">    operation.</span>
</span><span id="__span-0-1034"><a id="__codelineno-0-1034" name="__codelineno-0-1034"></a>
</span><span id="__span-0-1035"><a id="__codelineno-0-1035" name="__codelineno-0-1035"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1036"><a id="__codelineno-0-1036" name="__codelineno-0-1036"></a><span class="sd">    ----</span>
</span><span id="__span-0-1037"><a id="__codelineno-0-1037" name="__codelineno-0-1037"></a><span class="sd">      x: A `Tensor`, `SparseTensor`, or `RaggedTensor` of type tf.string or</span>
</span><span id="__span-0-1038"><a id="__codelineno-0-1038" name="__codelineno-0-1038"></a><span class="sd">        tf.int[8|16|32|64].</span>
</span><span id="__span-0-1039"><a id="__codelineno-0-1039" name="__codelineno-0-1039"></a><span class="sd">      default_value: The value to use for out-of-vocabulary values, unless</span>
</span><span id="__span-0-1040"><a id="__codelineno-0-1040" name="__codelineno-0-1040"></a><span class="sd">        'num_oov_buckets' is greater than zero.</span>
</span><span id="__span-0-1041"><a id="__codelineno-0-1041" name="__codelineno-0-1041"></a><span class="sd">      top_k: Limit the generated vocabulary to the first `top_k` elements. If set</span>
</span><span id="__span-0-1042"><a id="__codelineno-0-1042" name="__codelineno-0-1042"></a><span class="sd">        to None, the full vocabulary is generated.</span>
</span><span id="__span-0-1043"><a id="__codelineno-0-1043" name="__codelineno-0-1043"></a><span class="sd">      frequency_threshold: Limit the generated vocabulary only to elements whose</span>
</span><span id="__span-0-1044"><a id="__codelineno-0-1044" name="__codelineno-0-1044"></a><span class="sd">        absolute frequency is &gt;= to the supplied threshold. If set to None, the</span>
</span><span id="__span-0-1045"><a id="__codelineno-0-1045" name="__codelineno-0-1045"></a><span class="sd">        full vocabulary is generated.  Absolute frequency means the number of</span>
</span><span id="__span-0-1046"><a id="__codelineno-0-1046" name="__codelineno-0-1046"></a><span class="sd">        occurences of the element in the dataset, as opposed to the proportion of</span>
</span><span id="__span-0-1047"><a id="__codelineno-0-1047" name="__codelineno-0-1047"></a><span class="sd">        instances that contain that element. If labels are provided and the vocab</span>
</span><span id="__span-0-1048"><a id="__codelineno-0-1048" name="__codelineno-0-1048"></a><span class="sd">        is computed using mutual information, tokens are filtered if their mutual</span>
</span><span id="__span-0-1049"><a id="__codelineno-0-1049" name="__codelineno-0-1049"></a><span class="sd">        information with the label is &lt; the supplied threshold.</span>
</span><span id="__span-0-1050"><a id="__codelineno-0-1050" name="__codelineno-0-1050"></a><span class="sd">      num_oov_buckets:  Any lookup of an out-of-vocabulary token will return a</span>
</span><span id="__span-0-1051"><a id="__codelineno-0-1051" name="__codelineno-0-1051"></a><span class="sd">        bucket ID based on its hash if `num_oov_buckets` is greater than zero.</span>
</span><span id="__span-0-1052"><a id="__codelineno-0-1052" name="__codelineno-0-1052"></a><span class="sd">        Otherwise it is assigned the `default_value`.</span>
</span><span id="__span-0-1053"><a id="__codelineno-0-1053" name="__codelineno-0-1053"></a><span class="sd">      vocab_filename: The file name for the vocabulary file. If None, a name based</span>
</span><span id="__span-0-1054"><a id="__codelineno-0-1054" name="__codelineno-0-1054"></a><span class="sd">        on the scope name in the context of this graph will be used as the file</span>
</span><span id="__span-0-1055"><a id="__codelineno-0-1055" name="__codelineno-0-1055"></a><span class="sd">        name. If not None, should be unique within a given preprocessing function.</span>
</span><span id="__span-0-1056"><a id="__codelineno-0-1056" name="__codelineno-0-1056"></a><span class="sd">        NOTE in order to make your pipelines resilient to implementation details</span>
</span><span id="__span-0-1057"><a id="__codelineno-0-1057" name="__codelineno-0-1057"></a><span class="sd">        please set `vocab_filename` when you are using the vocab_filename on a</span>
</span><span id="__span-0-1058"><a id="__codelineno-0-1058" name="__codelineno-0-1058"></a><span class="sd">        downstream component.</span>
</span><span id="__span-0-1059"><a id="__codelineno-0-1059" name="__codelineno-0-1059"></a><span class="sd">      weights: (Optional) Weights `Tensor` for the vocabulary. It must have the</span>
</span><span id="__span-0-1060"><a id="__codelineno-0-1060" name="__codelineno-0-1060"></a><span class="sd">        same shape as x.</span>
</span><span id="__span-0-1061"><a id="__codelineno-0-1061" name="__codelineno-0-1061"></a><span class="sd">      labels: (Optional) A `Tensor` of labels for the vocabulary. If provided, the</span>
</span><span id="__span-0-1062"><a id="__codelineno-0-1062" name="__codelineno-0-1062"></a><span class="sd">        vocabulary is calculated based on mutual information with the label,</span>
</span><span id="__span-0-1063"><a id="__codelineno-0-1063" name="__codelineno-0-1063"></a><span class="sd">        rather than frequency. The labels must have the same batch dimension as x.</span>
</span><span id="__span-0-1064"><a id="__codelineno-0-1064" name="__codelineno-0-1064"></a><span class="sd">        If x is sparse, labels should be a 1D tensor reflecting row-wise labels.</span>
</span><span id="__span-0-1065"><a id="__codelineno-0-1065" name="__codelineno-0-1065"></a><span class="sd">        If x is dense, labels can either be a 1D tensor of row-wise labels, or a</span>
</span><span id="__span-0-1066"><a id="__codelineno-0-1066" name="__codelineno-0-1066"></a><span class="sd">        dense tensor of the identical shape as x (i.e. element-wise labels).</span>
</span><span id="__span-0-1067"><a id="__codelineno-0-1067" name="__codelineno-0-1067"></a><span class="sd">        Labels should be a discrete integerized tensor (If the label is numeric,</span>
</span><span id="__span-0-1068"><a id="__codelineno-0-1068" name="__codelineno-0-1068"></a><span class="sd">        it should first be bucketized; If the label is a string, an integer</span>
</span><span id="__span-0-1069"><a id="__codelineno-0-1069" name="__codelineno-0-1069"></a><span class="sd">        vocabulary should first be applied). Note: `CompositeTensor` labels are</span>
</span><span id="__span-0-1070"><a id="__codelineno-0-1070" name="__codelineno-0-1070"></a><span class="sd">        not yet supported (b/134931826). WARNING: when labels are provided, the</span>
</span><span id="__span-0-1071"><a id="__codelineno-0-1071" name="__codelineno-0-1071"></a><span class="sd">        frequency_threshold argument functions as a mutual information threshold,</span>
</span><span id="__span-0-1072"><a id="__codelineno-0-1072" name="__codelineno-0-1072"></a><span class="sd">        which is a float. TODO(b/116308354): Fix confusing naming.</span>
</span><span id="__span-0-1073"><a id="__codelineno-0-1073" name="__codelineno-0-1073"></a><span class="sd">      use_adjusted_mutual_info: If true, use adjusted mutual information.</span>
</span><span id="__span-0-1074"><a id="__codelineno-0-1074" name="__codelineno-0-1074"></a><span class="sd">      min_diff_from_avg: Mutual information of a feature will be adjusted to zero</span>
</span><span id="__span-0-1075"><a id="__codelineno-0-1075" name="__codelineno-0-1075"></a><span class="sd">        whenever the difference between count of the feature with any label and</span>
</span><span id="__span-0-1076"><a id="__codelineno-0-1076" name="__codelineno-0-1076"></a><span class="sd">        its expected count is lower than min_diff_from_average.</span>
</span><span id="__span-0-1077"><a id="__codelineno-0-1077" name="__codelineno-0-1077"></a><span class="sd">      coverage_top_k: (Optional), (Experimental) The minimum number of elements</span>
</span><span id="__span-0-1078"><a id="__codelineno-0-1078" name="__codelineno-0-1078"></a><span class="sd">        per key to be included in the vocabulary.</span>
</span><span id="__span-0-1079"><a id="__codelineno-0-1079" name="__codelineno-0-1079"></a><span class="sd">      coverage_frequency_threshold: (Optional), (Experimental) Limit the coverage</span>
</span><span id="__span-0-1080"><a id="__codelineno-0-1080" name="__codelineno-0-1080"></a><span class="sd">        arm of the vocabulary only to elements whose absolute frequency is &gt;= this</span>
</span><span id="__span-0-1081"><a id="__codelineno-0-1081" name="__codelineno-0-1081"></a><span class="sd">        threshold for a given key.</span>
</span><span id="__span-0-1082"><a id="__codelineno-0-1082" name="__codelineno-0-1082"></a><span class="sd">      key_fn: (Optional), (Experimental) A fn that takes in a single entry of `x`</span>
</span><span id="__span-0-1083"><a id="__codelineno-0-1083" name="__codelineno-0-1083"></a><span class="sd">        and returns the corresponding key for coverage calculation. If this is</span>
</span><span id="__span-0-1084"><a id="__codelineno-0-1084" name="__codelineno-0-1084"></a><span class="sd">        `None`, no coverage arm is added to the vocabulary.</span>
</span><span id="__span-0-1085"><a id="__codelineno-0-1085" name="__codelineno-0-1085"></a><span class="sd">      fingerprint_shuffle: (Optional), (Experimental) Whether to sort the</span>
</span><span id="__span-0-1086"><a id="__codelineno-0-1086" name="__codelineno-0-1086"></a><span class="sd">        vocabularies by fingerprint instead of counts. This is useful for load</span>
</span><span id="__span-0-1087"><a id="__codelineno-0-1087" name="__codelineno-0-1087"></a><span class="sd">        balancing on the training parameter servers. Shuffle only happens while</span>
</span><span id="__span-0-1088"><a id="__codelineno-0-1088" name="__codelineno-0-1088"></a><span class="sd">        writing the files, so all the filters above will still take effect.</span>
</span><span id="__span-0-1089"><a id="__codelineno-0-1089" name="__codelineno-0-1089"></a><span class="sd">      file_format: (Optional) A str. The format of the resulting vocabulary file.</span>
</span><span id="__span-0-1090"><a id="__codelineno-0-1090" name="__codelineno-0-1090"></a><span class="sd">        Accepted formats are: 'tfrecord_gzip', 'text'. 'tfrecord_gzip' requires</span>
</span><span id="__span-0-1091"><a id="__codelineno-0-1091" name="__codelineno-0-1091"></a><span class="sd">        tensorflow&gt;=2.4. The default value is 'text'.</span>
</span><span id="__span-0-1092"><a id="__codelineno-0-1092" name="__codelineno-0-1092"></a><span class="sd">      store_frequency: If True, frequency of the words is stored in the vocabulary</span>
</span><span id="__span-0-1093"><a id="__codelineno-0-1093" name="__codelineno-0-1093"></a><span class="sd">        file. In the case labels are provided, the mutual information is stored in</span>
</span><span id="__span-0-1094"><a id="__codelineno-0-1094" name="__codelineno-0-1094"></a><span class="sd">        the file instead. Each line in the file will be of the form 'frequency</span>
</span><span id="__span-0-1095"><a id="__codelineno-0-1095" name="__codelineno-0-1095"></a><span class="sd">        word'. NOTE: if True and text_format is 'text' then spaces will be</span>
</span><span id="__span-0-1096"><a id="__codelineno-0-1096" name="__codelineno-0-1096"></a><span class="sd">        replaced to avoid information loss.</span>
</span><span id="__span-0-1097"><a id="__codelineno-0-1097" name="__codelineno-0-1097"></a><span class="sd">      reserved_tokens: (Optional) A list of tokens that should appear in the</span>
</span><span id="__span-0-1098"><a id="__codelineno-0-1098" name="__codelineno-0-1098"></a><span class="sd">        vocabulary regardless of their appearance in the input. These tokens would</span>
</span><span id="__span-0-1099"><a id="__codelineno-0-1099" name="__codelineno-0-1099"></a><span class="sd">        maintain their order, and have a reserved spot at the beginning of the</span>
</span><span id="__span-0-1100"><a id="__codelineno-0-1100" name="__codelineno-0-1100"></a><span class="sd">        vocabulary. Note: this field has no affect on cache.</span>
</span><span id="__span-0-1101"><a id="__codelineno-0-1101" name="__codelineno-0-1101"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-1102"><a id="__codelineno-0-1102" name="__codelineno-0-1102"></a>
</span><span id="__span-0-1103"><a id="__codelineno-0-1103" name="__codelineno-0-1103"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1104"><a id="__codelineno-0-1104" name="__codelineno-0-1104"></a><span class="sd">    -------</span>
</span><span id="__span-0-1105"><a id="__codelineno-0-1105" name="__codelineno-0-1105"></a><span class="sd">      A `Tensor`, `SparseTensor`, or `RaggedTensor` where each string value is</span>
</span><span id="__span-0-1106"><a id="__codelineno-0-1106" name="__codelineno-0-1106"></a><span class="sd">      mapped to an integer. Each unique string value that appears in the</span>
</span><span id="__span-0-1107"><a id="__codelineno-0-1107" name="__codelineno-0-1107"></a><span class="sd">      vocabulary is mapped to a different integer and integers are consecutive</span>
</span><span id="__span-0-1108"><a id="__codelineno-0-1108" name="__codelineno-0-1108"></a><span class="sd">      starting from zero. String value not in the vocabulary is assigned</span>
</span><span id="__span-0-1109"><a id="__codelineno-0-1109" name="__codelineno-0-1109"></a><span class="sd">      `default_value`. Alternatively, if `num_oov_buckets` is specified, out of</span>
</span><span id="__span-0-1110"><a id="__codelineno-0-1110" name="__codelineno-0-1110"></a><span class="sd">      vocabulary strings are hashed to values in</span>
</span><span id="__span-0-1111"><a id="__codelineno-0-1111" name="__codelineno-0-1111"></a><span class="sd">      [vocab_size, vocab_size + num_oov_buckets) for an overall range of</span>
</span><span id="__span-0-1112"><a id="__codelineno-0-1112" name="__codelineno-0-1112"></a><span class="sd">      [0, vocab_size + num_oov_buckets).</span>
</span><span id="__span-0-1113"><a id="__codelineno-0-1113" name="__codelineno-0-1113"></a>
</span><span id="__span-0-1114"><a id="__codelineno-0-1114" name="__codelineno-0-1114"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-1115"><a id="__codelineno-0-1115" name="__codelineno-0-1115"></a><span class="sd">    ------</span>
</span><span id="__span-0-1116"><a id="__codelineno-0-1116" name="__codelineno-0-1116"></a><span class="sd">      ValueError: If `top_k` or `frequency_threshold` is negative.</span>
</span><span id="__span-0-1117"><a id="__codelineno-0-1117" name="__codelineno-0-1117"></a><span class="sd">        If `coverage_top_k` or `coverage_frequency_threshold` is negative.</span>
</span><span id="__span-0-1118"><a id="__codelineno-0-1118" name="__codelineno-0-1118"></a><span class="sd">    """</span>
</span><span id="__span-0-1119"><a id="__codelineno-0-1119" name="__codelineno-0-1119"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"compute_and_apply_vocabulary"</span><span class="p">):</span>
</span><span id="__span-0-1120"><a id="__codelineno-0-1120" name="__codelineno-0-1120"></a>        <span class="k">if</span> <span class="n">store_frequency</span> <span class="ow">and</span> <span class="n">file_format</span> <span class="o">==</span> <span class="s2">"text"</span><span class="p">:</span>
</span><span id="__span-0-1121"><a id="__codelineno-0-1121" name="__codelineno-0-1121"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">maybe_format_vocabulary_input</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-0-1122"><a id="__codelineno-0-1122" name="__codelineno-0-1122"></a>        <span class="n">deferred_vocab_and_filename</span> <span class="o">=</span> <span class="n">analyzers</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">(</span>
</span><span id="__span-0-1123"><a id="__codelineno-0-1123" name="__codelineno-0-1123"></a>            <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
</span><span id="__span-0-1124"><a id="__codelineno-0-1124" name="__codelineno-0-1124"></a>            <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span>
</span><span id="__span-0-1125"><a id="__codelineno-0-1125" name="__codelineno-0-1125"></a>            <span class="n">frequency_threshold</span><span class="o">=</span><span class="n">frequency_threshold</span><span class="p">,</span>
</span><span id="__span-0-1126"><a id="__codelineno-0-1126" name="__codelineno-0-1126"></a>            <span class="n">vocab_filename</span><span class="o">=</span><span class="n">vocab_filename</span><span class="p">,</span>
</span><span id="__span-0-1127"><a id="__codelineno-0-1127" name="__codelineno-0-1127"></a>            <span class="n">store_frequency</span><span class="o">=</span><span class="n">store_frequency</span><span class="p">,</span>
</span><span id="__span-0-1128"><a id="__codelineno-0-1128" name="__codelineno-0-1128"></a>            <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
</span><span id="__span-0-1129"><a id="__codelineno-0-1129" name="__codelineno-0-1129"></a>            <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
</span><span id="__span-0-1130"><a id="__codelineno-0-1130" name="__codelineno-0-1130"></a>            <span class="n">use_adjusted_mutual_info</span><span class="o">=</span><span class="n">use_adjusted_mutual_info</span><span class="p">,</span>
</span><span id="__span-0-1131"><a id="__codelineno-0-1131" name="__codelineno-0-1131"></a>            <span class="n">min_diff_from_avg</span><span class="o">=</span><span class="n">min_diff_from_avg</span><span class="p">,</span>
</span><span id="__span-0-1132"><a id="__codelineno-0-1132" name="__codelineno-0-1132"></a>            <span class="n">coverage_top_k</span><span class="o">=</span><span class="n">coverage_top_k</span><span class="p">,</span>
</span><span id="__span-0-1133"><a id="__codelineno-0-1133" name="__codelineno-0-1133"></a>            <span class="n">coverage_frequency_threshold</span><span class="o">=</span><span class="n">coverage_frequency_threshold</span><span class="p">,</span>
</span><span id="__span-0-1134"><a id="__codelineno-0-1134" name="__codelineno-0-1134"></a>            <span class="n">key_fn</span><span class="o">=</span><span class="n">key_fn</span><span class="p">,</span>
</span><span id="__span-0-1135"><a id="__codelineno-0-1135" name="__codelineno-0-1135"></a>            <span class="n">fingerprint_shuffle</span><span class="o">=</span><span class="n">fingerprint_shuffle</span><span class="p">,</span>
</span><span id="__span-0-1136"><a id="__codelineno-0-1136" name="__codelineno-0-1136"></a>            <span class="n">file_format</span><span class="o">=</span><span class="n">file_format</span><span class="p">,</span>
</span><span id="__span-0-1137"><a id="__codelineno-0-1137" name="__codelineno-0-1137"></a>            <span class="n">reserved_tokens</span><span class="o">=</span><span class="n">reserved_tokens</span><span class="p">,</span>
</span><span id="__span-0-1138"><a id="__codelineno-0-1138" name="__codelineno-0-1138"></a>        <span class="p">)</span>
</span><span id="__span-0-1139"><a id="__codelineno-0-1139" name="__codelineno-0-1139"></a>        <span class="k">return</span> <span class="n">_apply_vocabulary_internal</span><span class="p">(</span>
</span><span id="__span-0-1140"><a id="__codelineno-0-1140" name="__codelineno-0-1140"></a>            <span class="n">x</span><span class="p">,</span>
</span><span id="__span-0-1141"><a id="__codelineno-0-1141" name="__codelineno-0-1141"></a>            <span class="n">deferred_vocab_and_filename</span><span class="p">,</span>
</span><span id="__span-0-1142"><a id="__codelineno-0-1142" name="__codelineno-0-1142"></a>            <span class="n">default_value</span><span class="p">,</span>
</span><span id="__span-0-1143"><a id="__codelineno-0-1143" name="__codelineno-0-1143"></a>            <span class="n">num_oov_buckets</span><span class="p">,</span>
</span><span id="__span-0-1144"><a id="__codelineno-0-1144" name="__codelineno-0-1144"></a>            <span class="n">lookup_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1145"><a id="__codelineno-0-1145" name="__codelineno-0-1145"></a>            <span class="n">store_frequency</span><span class="o">=</span><span class="n">store_frequency</span><span class="p">,</span>
</span><span id="__span-0-1146"><a id="__codelineno-0-1146" name="__codelineno-0-1146"></a>            <span class="n">file_format</span><span class="o">=</span><span class="n">file_format</span><span class="p">,</span>
</span><span id="__span-0-1147"><a id="__codelineno-0-1147" name="__codelineno-0-1147"></a>            <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1148"><a id="__codelineno-0-1148" name="__codelineno-0-1148"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.count_per_key" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">count_per_key</span>


<a href="#tensorflow_transform.count_per_key" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">count_per_key</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">key</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">key_vocabulary_filename</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes the count of each element of a <code>Tensor</code>.</p>
        <hr>
<p>key: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of dtype tf.string or
    tf.int.
  key_vocabulary_filename: (Optional) The file name for the key-output mapping
    file. If None and key are provided, this combiner assumes the keys fit in
    memory and will not store the result in a file. If empty string, a file
    name will be chosen based on the current scope. If not an empty string,
    should be unique within a given preprocessing function.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>Either:
  (A) Two <code>Tensor</code>s: one the key vocab with dtype of input;
      the other the count for each key, dtype tf.int64. (if
      key_vocabulary_filename is None).
  (B) The filename where the key-value mapping is stored (if
      key_vocabulary_filename is not None).</p>
        <hr>
<p>TypeError: If the type of <code>x</code> is not supported.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/analyzers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-836">836</a></span>
<span class="normal"><a href="#__codelineno-0-837">837</a></span>
<span class="normal"><a href="#__codelineno-0-838">838</a></span>
<span class="normal"><a href="#__codelineno-0-839">839</a></span>
<span class="normal"><a href="#__codelineno-0-840">840</a></span>
<span class="normal"><a href="#__codelineno-0-841">841</a></span>
<span class="normal"><a href="#__codelineno-0-842">842</a></span>
<span class="normal"><a href="#__codelineno-0-843">843</a></span>
<span class="normal"><a href="#__codelineno-0-844">844</a></span>
<span class="normal"><a href="#__codelineno-0-845">845</a></span>
<span class="normal"><a href="#__codelineno-0-846">846</a></span>
<span class="normal"><a href="#__codelineno-0-847">847</a></span>
<span class="normal"><a href="#__codelineno-0-848">848</a></span>
<span class="normal"><a href="#__codelineno-0-849">849</a></span>
<span class="normal"><a href="#__codelineno-0-850">850</a></span>
<span class="normal"><a href="#__codelineno-0-851">851</a></span>
<span class="normal"><a href="#__codelineno-0-852">852</a></span>
<span class="normal"><a href="#__codelineno-0-853">853</a></span>
<span class="normal"><a href="#__codelineno-0-854">854</a></span>
<span class="normal"><a href="#__codelineno-0-855">855</a></span>
<span class="normal"><a href="#__codelineno-0-856">856</a></span>
<span class="normal"><a href="#__codelineno-0-857">857</a></span>
<span class="normal"><a href="#__codelineno-0-858">858</a></span>
<span class="normal"><a href="#__codelineno-0-859">859</a></span>
<span class="normal"><a href="#__codelineno-0-860">860</a></span>
<span class="normal"><a href="#__codelineno-0-861">861</a></span>
<span class="normal"><a href="#__codelineno-0-862">862</a></span>
<span class="normal"><a href="#__codelineno-0-863">863</a></span>
<span class="normal"><a href="#__codelineno-0-864">864</a></span>
<span class="normal"><a href="#__codelineno-0-865">865</a></span>
<span class="normal"><a href="#__codelineno-0-866">866</a></span>
<span class="normal"><a href="#__codelineno-0-867">867</a></span>
<span class="normal"><a href="#__codelineno-0-868">868</a></span>
<span class="normal"><a href="#__codelineno-0-869">869</a></span>
<span class="normal"><a href="#__codelineno-0-870">870</a></span>
<span class="normal"><a href="#__codelineno-0-871">871</a></span>
<span class="normal"><a href="#__codelineno-0-872">872</a></span>
<span class="normal"><a href="#__codelineno-0-873">873</a></span>
<span class="normal"><a href="#__codelineno-0-874">874</a></span>
<span class="normal"><a href="#__codelineno-0-875">875</a></span>
<span class="normal"><a href="#__codelineno-0-876">876</a></span>
<span class="normal"><a href="#__codelineno-0-877">877</a></span>
<span class="normal"><a href="#__codelineno-0-878">878</a></span>
<span class="normal"><a href="#__codelineno-0-879">879</a></span>
<span class="normal"><a href="#__codelineno-0-880">880</a></span>
<span class="normal"><a href="#__codelineno-0-881">881</a></span>
<span class="normal"><a href="#__codelineno-0-882">882</a></span>
<span class="normal"><a href="#__codelineno-0-883">883</a></span>
<span class="normal"><a href="#__codelineno-0-884">884</a></span>
<span class="normal"><a href="#__codelineno-0-885">885</a></span>
<span class="normal"><a href="#__codelineno-0-886">886</a></span>
<span class="normal"><a href="#__codelineno-0-887">887</a></span>
<span class="normal"><a href="#__codelineno-0-888">888</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-836"><a id="__codelineno-0-836" name="__codelineno-0-836"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">ANALYZER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-837"><a id="__codelineno-0-837" name="__codelineno-0-837"></a><span class="k">def</span><span class="w"> </span><span class="nf">count_per_key</span><span class="p">(</span>
</span><span id="__span-0-838"><a id="__codelineno-0-838" name="__codelineno-0-838"></a>    <span class="n">key</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span>
</span><span id="__span-0-839"><a id="__codelineno-0-839" name="__codelineno-0-839"></a>    <span class="n">key_vocabulary_filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-840"><a id="__codelineno-0-840" name="__codelineno-0-840"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-841"><a id="__codelineno-0-841" name="__codelineno-0-841"></a><span class="p">):</span>
</span><span id="__span-0-842"><a id="__codelineno-0-842" name="__codelineno-0-842"></a><span class="w">    </span><span class="sd">"""Computes the count of each element of a `Tensor`.</span>
</span><span id="__span-0-843"><a id="__codelineno-0-843" name="__codelineno-0-843"></a>
</span><span id="__span-0-844"><a id="__codelineno-0-844" name="__codelineno-0-844"></a><span class="sd">    Args:</span>
</span><span id="__span-0-845"><a id="__codelineno-0-845" name="__codelineno-0-845"></a><span class="sd">    ----</span>
</span><span id="__span-0-846"><a id="__codelineno-0-846" name="__codelineno-0-846"></a><span class="sd">      key: A `Tensor`, `SparseTensor`, or `RaggedTensor` of dtype tf.string or</span>
</span><span id="__span-0-847"><a id="__codelineno-0-847" name="__codelineno-0-847"></a><span class="sd">        tf.int.</span>
</span><span id="__span-0-848"><a id="__codelineno-0-848" name="__codelineno-0-848"></a><span class="sd">      key_vocabulary_filename: (Optional) The file name for the key-output mapping</span>
</span><span id="__span-0-849"><a id="__codelineno-0-849" name="__codelineno-0-849"></a><span class="sd">        file. If None and key are provided, this combiner assumes the keys fit in</span>
</span><span id="__span-0-850"><a id="__codelineno-0-850" name="__codelineno-0-850"></a><span class="sd">        memory and will not store the result in a file. If empty string, a file</span>
</span><span id="__span-0-851"><a id="__codelineno-0-851" name="__codelineno-0-851"></a><span class="sd">        name will be chosen based on the current scope. If not an empty string,</span>
</span><span id="__span-0-852"><a id="__codelineno-0-852" name="__codelineno-0-852"></a><span class="sd">        should be unique within a given preprocessing function.</span>
</span><span id="__span-0-853"><a id="__codelineno-0-853" name="__codelineno-0-853"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-854"><a id="__codelineno-0-854" name="__codelineno-0-854"></a>
</span><span id="__span-0-855"><a id="__codelineno-0-855" name="__codelineno-0-855"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-856"><a id="__codelineno-0-856" name="__codelineno-0-856"></a><span class="sd">    -------</span>
</span><span id="__span-0-857"><a id="__codelineno-0-857" name="__codelineno-0-857"></a><span class="sd">      Either:</span>
</span><span id="__span-0-858"><a id="__codelineno-0-858" name="__codelineno-0-858"></a><span class="sd">      (A) Two `Tensor`s: one the key vocab with dtype of input;</span>
</span><span id="__span-0-859"><a id="__codelineno-0-859" name="__codelineno-0-859"></a><span class="sd">          the other the count for each key, dtype tf.int64. (if</span>
</span><span id="__span-0-860"><a id="__codelineno-0-860" name="__codelineno-0-860"></a><span class="sd">          key_vocabulary_filename is None).</span>
</span><span id="__span-0-861"><a id="__codelineno-0-861" name="__codelineno-0-861"></a><span class="sd">      (B) The filename where the key-value mapping is stored (if</span>
</span><span id="__span-0-862"><a id="__codelineno-0-862" name="__codelineno-0-862"></a><span class="sd">          key_vocabulary_filename is not None).</span>
</span><span id="__span-0-863"><a id="__codelineno-0-863" name="__codelineno-0-863"></a>
</span><span id="__span-0-864"><a id="__codelineno-0-864" name="__codelineno-0-864"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-865"><a id="__codelineno-0-865" name="__codelineno-0-865"></a><span class="sd">    ------</span>
</span><span id="__span-0-866"><a id="__codelineno-0-866" name="__codelineno-0-866"></a><span class="sd">      TypeError: If the type of `x` is not supported.</span>
</span><span id="__span-0-867"><a id="__codelineno-0-867" name="__codelineno-0-867"></a><span class="sd">    """</span>
</span><span id="__span-0-868"><a id="__codelineno-0-868" name="__codelineno-0-868"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"count_per_key"</span><span class="p">):</span>
</span><span id="__span-0-869"><a id="__codelineno-0-869" name="__codelineno-0-869"></a>        <span class="n">key_dtype</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-870"><a id="__codelineno-0-870" name="__codelineno-0-870"></a>        <span class="n">batch_keys</span><span class="p">,</span> <span class="n">batch_counts</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">reduce_batch_count_per_key</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
</span><span id="__span-0-871"><a id="__codelineno-0-871" name="__codelineno-0-871"></a>
</span><span id="__span-0-872"><a id="__codelineno-0-872" name="__codelineno-0-872"></a>        <span class="n">output_dtype</span><span class="p">,</span> <span class="n">sum_fn</span> <span class="o">=</span> <span class="n">_sum_combine_fn_and_dtype</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span><span id="__span-0-873"><a id="__codelineno-0-873" name="__codelineno-0-873"></a>        <span class="n">numeric_combine_result</span> <span class="o">=</span> <span class="n">_numeric_combine</span><span class="p">(</span>
</span><span id="__span-0-874"><a id="__codelineno-0-874" name="__codelineno-0-874"></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">batch_counts</span><span class="p">],</span>
</span><span id="__span-0-875"><a id="__codelineno-0-875" name="__codelineno-0-875"></a>            <span class="n">fn</span><span class="o">=</span><span class="n">sum_fn</span><span class="p">,</span>
</span><span id="__span-0-876"><a id="__codelineno-0-876" name="__codelineno-0-876"></a>            <span class="n">default_accumulator_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-877"><a id="__codelineno-0-877" name="__codelineno-0-877"></a>            <span class="n">reduce_instance_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-878"><a id="__codelineno-0-878" name="__codelineno-0-878"></a>            <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="n">output_dtype</span><span class="p">],</span>
</span><span id="__span-0-879"><a id="__codelineno-0-879" name="__codelineno-0-879"></a>            <span class="n">key</span><span class="o">=</span><span class="n">batch_keys</span><span class="p">,</span>
</span><span id="__span-0-880"><a id="__codelineno-0-880" name="__codelineno-0-880"></a>            <span class="n">key_vocabulary_filename</span><span class="o">=</span><span class="n">key_vocabulary_filename</span><span class="p">,</span>
</span><span id="__span-0-881"><a id="__codelineno-0-881" name="__codelineno-0-881"></a>        <span class="p">)</span>
</span><span id="__span-0-882"><a id="__codelineno-0-882" name="__codelineno-0-882"></a>
</span><span id="__span-0-883"><a id="__codelineno-0-883" name="__codelineno-0-883"></a>        <span class="k">if</span> <span class="n">key_vocabulary_filename</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-884"><a id="__codelineno-0-884" name="__codelineno-0-884"></a>            <span class="k">return</span> <span class="n">numeric_combine_result</span>
</span><span id="__span-0-885"><a id="__codelineno-0-885" name="__codelineno-0-885"></a>        <span class="n">keys</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">numeric_combine_result</span>
</span><span id="__span-0-886"><a id="__codelineno-0-886" name="__codelineno-0-886"></a>        <span class="k">if</span> <span class="n">key_dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">:</span>
</span><span id="__span-0-887"><a id="__codelineno-0-887" name="__codelineno-0-887"></a>            <span class="n">keys</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">to_number</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="n">key_dtype</span><span class="p">)</span>
</span><span id="__span-0-888"><a id="__codelineno-0-888" name="__codelineno-0-888"></a>        <span class="k">return</span> <span class="n">keys</span><span class="p">,</span> <span class="n">counts</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.covariance" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">covariance</span>


<a href="#tensorflow_transform.covariance" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">covariance</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n"><span title="tensorflow.DType">DType</span></span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes the covariance matrix over the whole dataset.</p>
<p>The covariance matrix M is defined as follows:
Let x[:j] be a tensor of the jth element of all input vectors in x, and let
u_j = mean(x[:j]). The entry M[i,j] = E[(x[:i] - u_i)(x[:j] - u_j)].
Notice that the diagonal entries correspond to variances of individual
elements in the vector, i.e. M[i,i] corresponds to the variance of x[:i].</p>
        <hr>
<p>x: A rank-2 <code>Tensor</code>, 0th dim are rows, 1st dim are indices in each input
    vector.
  dtype: Tensorflow dtype of entries in the returned matrix.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>ValueError: if input is not a rank-2 Tensor.</p>
        <hr>
<p>A rank-2 (matrix) covariance <code>Tensor</code></p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/analyzers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-2762">2762</a></span>
<span class="normal"><a href="#__codelineno-0-2763">2763</a></span>
<span class="normal"><a href="#__codelineno-0-2764">2764</a></span>
<span class="normal"><a href="#__codelineno-0-2765">2765</a></span>
<span class="normal"><a href="#__codelineno-0-2766">2766</a></span>
<span class="normal"><a href="#__codelineno-0-2767">2767</a></span>
<span class="normal"><a href="#__codelineno-0-2768">2768</a></span>
<span class="normal"><a href="#__codelineno-0-2769">2769</a></span>
<span class="normal"><a href="#__codelineno-0-2770">2770</a></span>
<span class="normal"><a href="#__codelineno-0-2771">2771</a></span>
<span class="normal"><a href="#__codelineno-0-2772">2772</a></span>
<span class="normal"><a href="#__codelineno-0-2773">2773</a></span>
<span class="normal"><a href="#__codelineno-0-2774">2774</a></span>
<span class="normal"><a href="#__codelineno-0-2775">2775</a></span>
<span class="normal"><a href="#__codelineno-0-2776">2776</a></span>
<span class="normal"><a href="#__codelineno-0-2777">2777</a></span>
<span class="normal"><a href="#__codelineno-0-2778">2778</a></span>
<span class="normal"><a href="#__codelineno-0-2779">2779</a></span>
<span class="normal"><a href="#__codelineno-0-2780">2780</a></span>
<span class="normal"><a href="#__codelineno-0-2781">2781</a></span>
<span class="normal"><a href="#__codelineno-0-2782">2782</a></span>
<span class="normal"><a href="#__codelineno-0-2783">2783</a></span>
<span class="normal"><a href="#__codelineno-0-2784">2784</a></span>
<span class="normal"><a href="#__codelineno-0-2785">2785</a></span>
<span class="normal"><a href="#__codelineno-0-2786">2786</a></span>
<span class="normal"><a href="#__codelineno-0-2787">2787</a></span>
<span class="normal"><a href="#__codelineno-0-2788">2788</a></span>
<span class="normal"><a href="#__codelineno-0-2789">2789</a></span>
<span class="normal"><a href="#__codelineno-0-2790">2790</a></span>
<span class="normal"><a href="#__codelineno-0-2791">2791</a></span>
<span class="normal"><a href="#__codelineno-0-2792">2792</a></span>
<span class="normal"><a href="#__codelineno-0-2793">2793</a></span>
<span class="normal"><a href="#__codelineno-0-2794">2794</a></span>
<span class="normal"><a href="#__codelineno-0-2795">2795</a></span>
<span class="normal"><a href="#__codelineno-0-2796">2796</a></span>
<span class="normal"><a href="#__codelineno-0-2797">2797</a></span>
<span class="normal"><a href="#__codelineno-0-2798">2798</a></span>
<span class="normal"><a href="#__codelineno-0-2799">2799</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-2762"><a id="__codelineno-0-2762" name="__codelineno-0-2762"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">ANALYZER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-2763"><a id="__codelineno-0-2763" name="__codelineno-0-2763"></a><span class="k">def</span><span class="w"> </span><span class="nf">covariance</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">DType</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-2764"><a id="__codelineno-0-2764" name="__codelineno-0-2764"></a><span class="w">    </span><span class="sd">"""Computes the covariance matrix over the whole dataset.</span>
</span><span id="__span-0-2765"><a id="__codelineno-0-2765" name="__codelineno-0-2765"></a>
</span><span id="__span-0-2766"><a id="__codelineno-0-2766" name="__codelineno-0-2766"></a><span class="sd">    The covariance matrix M is defined as follows:</span>
</span><span id="__span-0-2767"><a id="__codelineno-0-2767" name="__codelineno-0-2767"></a><span class="sd">    Let x[:j] be a tensor of the jth element of all input vectors in x, and let</span>
</span><span id="__span-0-2768"><a id="__codelineno-0-2768" name="__codelineno-0-2768"></a><span class="sd">    u_j = mean(x[:j]). The entry M[i,j] = E[(x[:i] - u_i)(x[:j] - u_j)].</span>
</span><span id="__span-0-2769"><a id="__codelineno-0-2769" name="__codelineno-0-2769"></a><span class="sd">    Notice that the diagonal entries correspond to variances of individual</span>
</span><span id="__span-0-2770"><a id="__codelineno-0-2770" name="__codelineno-0-2770"></a><span class="sd">    elements in the vector, i.e. M[i,i] corresponds to the variance of x[:i].</span>
</span><span id="__span-0-2771"><a id="__codelineno-0-2771" name="__codelineno-0-2771"></a>
</span><span id="__span-0-2772"><a id="__codelineno-0-2772" name="__codelineno-0-2772"></a><span class="sd">    Args:</span>
</span><span id="__span-0-2773"><a id="__codelineno-0-2773" name="__codelineno-0-2773"></a><span class="sd">    ----</span>
</span><span id="__span-0-2774"><a id="__codelineno-0-2774" name="__codelineno-0-2774"></a><span class="sd">      x: A rank-2 `Tensor`, 0th dim are rows, 1st dim are indices in each input</span>
</span><span id="__span-0-2775"><a id="__codelineno-0-2775" name="__codelineno-0-2775"></a><span class="sd">        vector.</span>
</span><span id="__span-0-2776"><a id="__codelineno-0-2776" name="__codelineno-0-2776"></a><span class="sd">      dtype: Tensorflow dtype of entries in the returned matrix.</span>
</span><span id="__span-0-2777"><a id="__codelineno-0-2777" name="__codelineno-0-2777"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-2778"><a id="__codelineno-0-2778" name="__codelineno-0-2778"></a>
</span><span id="__span-0-2779"><a id="__codelineno-0-2779" name="__codelineno-0-2779"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-2780"><a id="__codelineno-0-2780" name="__codelineno-0-2780"></a><span class="sd">    ------</span>
</span><span id="__span-0-2781"><a id="__codelineno-0-2781" name="__codelineno-0-2781"></a><span class="sd">      ValueError: if input is not a rank-2 Tensor.</span>
</span><span id="__span-0-2782"><a id="__codelineno-0-2782" name="__codelineno-0-2782"></a>
</span><span id="__span-0-2783"><a id="__codelineno-0-2783" name="__codelineno-0-2783"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-2784"><a id="__codelineno-0-2784" name="__codelineno-0-2784"></a><span class="sd">    -------</span>
</span><span id="__span-0-2785"><a id="__codelineno-0-2785" name="__codelineno-0-2785"></a><span class="sd">      A rank-2 (matrix) covariance `Tensor`</span>
</span><span id="__span-0-2786"><a id="__codelineno-0-2786" name="__codelineno-0-2786"></a><span class="sd">    """</span>
</span><span id="__span-0-2787"><a id="__codelineno-0-2787" name="__codelineno-0-2787"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
</span><span id="__span-0-2788"><a id="__codelineno-0-2788" name="__codelineno-0-2788"></a>        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">"Expected a Tensor, but got </span><span class="si">%r</span><span class="s2">"</span> <span class="o">%</span> <span class="n">x</span><span class="p">)</span>
</span><span id="__span-0-2789"><a id="__codelineno-0-2789" name="__codelineno-0-2789"></a>
</span><span id="__span-0-2790"><a id="__codelineno-0-2790" name="__codelineno-0-2790"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"covariance"</span><span class="p">):</span>
</span><span id="__span-0-2791"><a id="__codelineno-0-2791" name="__codelineno-0-2791"></a>        <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">assert_has_rank</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-0-2792"><a id="__codelineno-0-2792" name="__codelineno-0-2792"></a>
</span><span id="__span-0-2793"><a id="__codelineno-0-2793" name="__codelineno-0-2793"></a>        <span class="n">input_dim</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="__span-0-2794"><a id="__codelineno-0-2794" name="__codelineno-0-2794"></a>        <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>
</span><span id="__span-0-2795"><a id="__codelineno-0-2795" name="__codelineno-0-2795"></a>
</span><span id="__span-0-2796"><a id="__codelineno-0-2796" name="__codelineno-0-2796"></a>        <span class="p">(</span><span class="n">result</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_apply_cacheable_combiner</span><span class="p">(</span>
</span><span id="__span-0-2797"><a id="__codelineno-0-2797" name="__codelineno-0-2797"></a>            <span class="n">CovarianceCombiner</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">.</span><span class="n">as_numpy_dtype</span><span class="p">),</span> <span class="n">x</span>
</span><span id="__span-0-2798"><a id="__codelineno-0-2798" name="__codelineno-0-2798"></a>        <span class="p">)</span>
</span><span id="__span-0-2799"><a id="__codelineno-0-2799" name="__codelineno-0-2799"></a>        <span class="k">return</span> <span class="n">result</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.deduplicate_tensor_per_row" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">deduplicate_tensor_per_row</span>


<a href="#tensorflow_transform.deduplicate_tensor_per_row" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">deduplicate_tensor_per_row</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Deduplicates each row (0-th dimension) of the provided tensor.</p>
        <hr>
<p>input_tensor: A two-dimensional <code>Tensor</code> or <code>SparseTensor</code>. The first
    dimension is assumed to be the batch or "row" dimension, and deduplication
    is done on the 2nd dimension. If the Tensor is 1D it is returned as the
    equivalent <code>SparseTensor</code> since the "row" is a scalar can't be further
    deduplicated.
  name: Optional name for the operation.</p>
        <hr>
<p>A  <code>SparseTensor</code> containing the unique set of values from each
    row of the input. Note: the original order of the input may not be
    preserved.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1418">1418</a></span>
<span class="normal"><a href="#__codelineno-0-1419">1419</a></span>
<span class="normal"><a href="#__codelineno-0-1420">1420</a></span>
<span class="normal"><a href="#__codelineno-0-1421">1421</a></span>
<span class="normal"><a href="#__codelineno-0-1422">1422</a></span>
<span class="normal"><a href="#__codelineno-0-1423">1423</a></span>
<span class="normal"><a href="#__codelineno-0-1424">1424</a></span>
<span class="normal"><a href="#__codelineno-0-1425">1425</a></span>
<span class="normal"><a href="#__codelineno-0-1426">1426</a></span>
<span class="normal"><a href="#__codelineno-0-1427">1427</a></span>
<span class="normal"><a href="#__codelineno-0-1428">1428</a></span>
<span class="normal"><a href="#__codelineno-0-1429">1429</a></span>
<span class="normal"><a href="#__codelineno-0-1430">1430</a></span>
<span class="normal"><a href="#__codelineno-0-1431">1431</a></span>
<span class="normal"><a href="#__codelineno-0-1432">1432</a></span>
<span class="normal"><a href="#__codelineno-0-1433">1433</a></span>
<span class="normal"><a href="#__codelineno-0-1434">1434</a></span>
<span class="normal"><a href="#__codelineno-0-1435">1435</a></span>
<span class="normal"><a href="#__codelineno-0-1436">1436</a></span>
<span class="normal"><a href="#__codelineno-0-1437">1437</a></span>
<span class="normal"><a href="#__codelineno-0-1438">1438</a></span>
<span class="normal"><a href="#__codelineno-0-1439">1439</a></span>
<span class="normal"><a href="#__codelineno-0-1440">1440</a></span>
<span class="normal"><a href="#__codelineno-0-1441">1441</a></span>
<span class="normal"><a href="#__codelineno-0-1442">1442</a></span>
<span class="normal"><a href="#__codelineno-0-1443">1443</a></span>
<span class="normal"><a href="#__codelineno-0-1444">1444</a></span>
<span class="normal"><a href="#__codelineno-0-1445">1445</a></span>
<span class="normal"><a href="#__codelineno-0-1446">1446</a></span>
<span class="normal"><a href="#__codelineno-0-1447">1447</a></span>
<span class="normal"><a href="#__codelineno-0-1448">1448</a></span>
<span class="normal"><a href="#__codelineno-0-1449">1449</a></span>
<span class="normal"><a href="#__codelineno-0-1450">1450</a></span>
<span class="normal"><a href="#__codelineno-0-1451">1451</a></span>
<span class="normal"><a href="#__codelineno-0-1452">1452</a></span>
<span class="normal"><a href="#__codelineno-0-1453">1453</a></span>
<span class="normal"><a href="#__codelineno-0-1454">1454</a></span>
<span class="normal"><a href="#__codelineno-0-1455">1455</a></span>
<span class="normal"><a href="#__codelineno-0-1456">1456</a></span>
<span class="normal"><a href="#__codelineno-0-1457">1457</a></span>
<span class="normal"><a href="#__codelineno-0-1458">1458</a></span>
<span class="normal"><a href="#__codelineno-0-1459">1459</a></span>
<span class="normal"><a href="#__codelineno-0-1460">1460</a></span>
<span class="normal"><a href="#__codelineno-0-1461">1461</a></span>
<span class="normal"><a href="#__codelineno-0-1462">1462</a></span>
<span class="normal"><a href="#__codelineno-0-1463">1463</a></span>
<span class="normal"><a href="#__codelineno-0-1464">1464</a></span>
<span class="normal"><a href="#__codelineno-0-1465">1465</a></span>
<span class="normal"><a href="#__codelineno-0-1466">1466</a></span>
<span class="normal"><a href="#__codelineno-0-1467">1467</a></span>
<span class="normal"><a href="#__codelineno-0-1468">1468</a></span>
<span class="normal"><a href="#__codelineno-0-1469">1469</a></span>
<span class="normal"><a href="#__codelineno-0-1470">1470</a></span>
<span class="normal"><a href="#__codelineno-0-1471">1471</a></span>
<span class="normal"><a href="#__codelineno-0-1472">1472</a></span>
<span class="normal"><a href="#__codelineno-0-1473">1473</a></span>
<span class="normal"><a href="#__codelineno-0-1474">1474</a></span>
<span class="normal"><a href="#__codelineno-0-1475">1475</a></span>
<span class="normal"><a href="#__codelineno-0-1476">1476</a></span>
<span class="normal"><a href="#__codelineno-0-1477">1477</a></span>
<span class="normal"><a href="#__codelineno-0-1478">1478</a></span>
<span class="normal"><a href="#__codelineno-0-1479">1479</a></span>
<span class="normal"><a href="#__codelineno-0-1480">1480</a></span>
<span class="normal"><a href="#__codelineno-0-1481">1481</a></span>
<span class="normal"><a href="#__codelineno-0-1482">1482</a></span>
<span class="normal"><a href="#__codelineno-0-1483">1483</a></span>
<span class="normal"><a href="#__codelineno-0-1484">1484</a></span>
<span class="normal"><a href="#__codelineno-0-1485">1485</a></span>
<span class="normal"><a href="#__codelineno-0-1486">1486</a></span>
<span class="normal"><a href="#__codelineno-0-1487">1487</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1418"><a id="__codelineno-0-1418" name="__codelineno-0-1418"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-1419"><a id="__codelineno-0-1419" name="__codelineno-0-1419"></a><span class="k">def</span><span class="w"> </span><span class="nf">deduplicate_tensor_per_row</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="__span-0-1420"><a id="__codelineno-0-1420" name="__codelineno-0-1420"></a><span class="w">    </span><span class="sd">"""Deduplicates each row (0-th dimension) of the provided tensor.</span>
</span><span id="__span-0-1421"><a id="__codelineno-0-1421" name="__codelineno-0-1421"></a>
</span><span id="__span-0-1422"><a id="__codelineno-0-1422" name="__codelineno-0-1422"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1423"><a id="__codelineno-0-1423" name="__codelineno-0-1423"></a><span class="sd">    ----</span>
</span><span id="__span-0-1424"><a id="__codelineno-0-1424" name="__codelineno-0-1424"></a><span class="sd">      input_tensor: A two-dimensional `Tensor` or `SparseTensor`. The first</span>
</span><span id="__span-0-1425"><a id="__codelineno-0-1425" name="__codelineno-0-1425"></a><span class="sd">        dimension is assumed to be the batch or "row" dimension, and deduplication</span>
</span><span id="__span-0-1426"><a id="__codelineno-0-1426" name="__codelineno-0-1426"></a><span class="sd">        is done on the 2nd dimension. If the Tensor is 1D it is returned as the</span>
</span><span id="__span-0-1427"><a id="__codelineno-0-1427" name="__codelineno-0-1427"></a><span class="sd">        equivalent `SparseTensor` since the "row" is a scalar can't be further</span>
</span><span id="__span-0-1428"><a id="__codelineno-0-1428" name="__codelineno-0-1428"></a><span class="sd">        deduplicated.</span>
</span><span id="__span-0-1429"><a id="__codelineno-0-1429" name="__codelineno-0-1429"></a><span class="sd">      name: Optional name for the operation.</span>
</span><span id="__span-0-1430"><a id="__codelineno-0-1430" name="__codelineno-0-1430"></a>
</span><span id="__span-0-1431"><a id="__codelineno-0-1431" name="__codelineno-0-1431"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1432"><a id="__codelineno-0-1432" name="__codelineno-0-1432"></a><span class="sd">    -------</span>
</span><span id="__span-0-1433"><a id="__codelineno-0-1433" name="__codelineno-0-1433"></a><span class="sd">      A  `SparseTensor` containing the unique set of values from each</span>
</span><span id="__span-0-1434"><a id="__codelineno-0-1434" name="__codelineno-0-1434"></a><span class="sd">        row of the input. Note: the original order of the input may not be</span>
</span><span id="__span-0-1435"><a id="__codelineno-0-1435" name="__codelineno-0-1435"></a><span class="sd">        preserved.</span>
</span><span id="__span-0-1436"><a id="__codelineno-0-1436" name="__codelineno-0-1436"></a><span class="sd">    """</span>
</span><span id="__span-0-1437"><a id="__codelineno-0-1437" name="__codelineno-0-1437"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"deduplicate_per_row"</span><span class="p">):</span>
</span><span id="__span-0-1438"><a id="__codelineno-0-1438" name="__codelineno-0-1438"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">):</span>
</span><span id="__span-0-1439"><a id="__codelineno-0-1439" name="__codelineno-0-1439"></a>            <span class="n">batch_dim</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">input_tensor</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</span><span id="__span-0-1440"><a id="__codelineno-0-1440" name="__codelineno-0-1440"></a>            <span class="n">rank</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">dense_shape</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="__span-0-1441"><a id="__codelineno-0-1441" name="__codelineno-0-1441"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-1442"><a id="__codelineno-0-1442" name="__codelineno-0-1442"></a>            <span class="n">batch_dim</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</span><span id="__span-0-1443"><a id="__codelineno-0-1443" name="__codelineno-0-1443"></a>            <span class="n">rank</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">rank</span>
</span><span id="__span-0-1444"><a id="__codelineno-0-1444" name="__codelineno-0-1444"></a>
</span><span id="__span-0-1445"><a id="__codelineno-0-1445" name="__codelineno-0-1445"></a>        <span class="k">def</span><span class="w"> </span><span class="nf">_univalent_dense_to_sparse</span><span class="p">(</span><span class="n">batch_dim</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">):</span>
</span><span id="__span-0-1446"><a id="__codelineno-0-1446" name="__codelineno-0-1446"></a><span class="w">            </span><span class="sd">"""Helper to convert a 1D dense `Tensor` to a `SparseTensor`."""</span>
</span><span id="__span-0-1447"><a id="__codelineno-0-1447" name="__codelineno-0-1447"></a>            <span class="n">indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
</span><span id="__span-0-1448"><a id="__codelineno-0-1448" name="__codelineno-0-1448"></a>                <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
</span><span id="__span-0-1449"><a id="__codelineno-0-1449" name="__codelineno-0-1449"></a>                    <span class="p">[</span>
</span><span id="__span-0-1450"><a id="__codelineno-0-1450" name="__codelineno-0-1450"></a>                        <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">batch_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
</span><span id="__span-0-1451"><a id="__codelineno-0-1451" name="__codelineno-0-1451"></a>                        <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
</span><span id="__span-0-1452"><a id="__codelineno-0-1452" name="__codelineno-0-1452"></a>                    <span class="p">],</span>
</span><span id="__span-0-1453"><a id="__codelineno-0-1453" name="__codelineno-0-1453"></a>                    <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-1454"><a id="__codelineno-0-1454" name="__codelineno-0-1454"></a>                <span class="p">),</span>
</span><span id="__span-0-1455"><a id="__codelineno-0-1455" name="__codelineno-0-1455"></a>                <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
</span><span id="__span-0-1456"><a id="__codelineno-0-1456" name="__codelineno-0-1456"></a>            <span class="p">)</span>
</span><span id="__span-0-1457"><a id="__codelineno-0-1457" name="__codelineno-0-1457"></a>
</span><span id="__span-0-1458"><a id="__codelineno-0-1458" name="__codelineno-0-1458"></a>            <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">(</span>
</span><span id="__span-0-1459"><a id="__codelineno-0-1459" name="__codelineno-0-1459"></a>                <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">dense_shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-1460"><a id="__codelineno-0-1460" name="__codelineno-0-1460"></a>            <span class="p">)</span>
</span><span id="__span-0-1461"><a id="__codelineno-0-1461" name="__codelineno-0-1461"></a>
</span><span id="__span-0-1462"><a id="__codelineno-0-1462" name="__codelineno-0-1462"></a>        <span class="k">if</span> <span class="n">rank</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-1463"><a id="__codelineno-0-1463" name="__codelineno-0-1463"></a>            <span class="c1"># If the rank is known at graph construction time, and it's rank 1, there</span>
</span><span id="__span-0-1464"><a id="__codelineno-0-1464" name="__codelineno-0-1464"></a>            <span class="c1"># is no deduplication to be done so we can return early.</span>
</span><span id="__span-0-1465"><a id="__codelineno-0-1465" name="__codelineno-0-1465"></a>            <span class="k">if</span> <span class="n">rank</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="__span-0-1466"><a id="__codelineno-0-1466" name="__codelineno-0-1466"></a>                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">):</span>
</span><span id="__span-0-1467"><a id="__codelineno-0-1467" name="__codelineno-0-1467"></a>                    <span class="k">return</span> <span class="n">input_tensor</span>
</span><span id="__span-0-1468"><a id="__codelineno-0-1468" name="__codelineno-0-1468"></a>                <span class="c1"># Even though we are just returning as is, we convert to a SparseTensor</span>
</span><span id="__span-0-1469"><a id="__codelineno-0-1469" name="__codelineno-0-1469"></a>                <span class="c1"># to ensure consistent output type.</span>
</span><span id="__span-0-1470"><a id="__codelineno-0-1470" name="__codelineno-0-1470"></a>                <span class="k">return</span> <span class="n">_univalent_dense_to_sparse</span><span class="p">(</span><span class="n">batch_dim</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">)</span>
</span><span id="__span-0-1471"><a id="__codelineno-0-1471" name="__codelineno-0-1471"></a>            <span class="k">if</span> <span class="n">rank</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="__span-0-1472"><a id="__codelineno-0-1472" name="__codelineno-0-1472"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="__span-0-1473"><a id="__codelineno-0-1473" name="__codelineno-0-1473"></a>                    <span class="s2">"Deduplication assumes a rank 2 tensor, got </span><span class="si">{}</span><span class="s2">."</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
</span><span id="__span-0-1474"><a id="__codelineno-0-1474" name="__codelineno-0-1474"></a>                <span class="p">)</span>
</span><span id="__span-0-1475"><a id="__codelineno-0-1475" name="__codelineno-0-1475"></a>            <span class="k">return</span> <span class="n">_deduplicate_tensor_per_row</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">batch_dim</span><span class="p">)</span>
</span><span id="__span-0-1476"><a id="__codelineno-0-1476" name="__codelineno-0-1476"></a>
</span><span id="__span-0-1477"><a id="__codelineno-0-1477" name="__codelineno-0-1477"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">):</span>
</span><span id="__span-0-1478"><a id="__codelineno-0-1478" name="__codelineno-0-1478"></a>            <span class="k">return</span> <span class="n">_deduplicate_tensor_per_row</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">batch_dim</span><span class="p">)</span>
</span><span id="__span-0-1479"><a id="__codelineno-0-1479" name="__codelineno-0-1479"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-1480"><a id="__codelineno-0-1480" name="__codelineno-0-1480"></a>            <span class="c1"># Again check for rank 1 tensor (that doesn't need deduplication), this</span>
</span><span id="__span-0-1481"><a id="__codelineno-0-1481" name="__codelineno-0-1481"></a>            <span class="c1"># time handling inputs where rank isn't known until execution time.</span>
</span><span id="__span-0-1482"><a id="__codelineno-0-1482" name="__codelineno-0-1482"></a>            <span class="n">dynamic_rank</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
</span><span id="__span-0-1483"><a id="__codelineno-0-1483" name="__codelineno-0-1483"></a>            <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
</span><span id="__span-0-1484"><a id="__codelineno-0-1484" name="__codelineno-0-1484"></a>                <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">dynamic_rank</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span><span id="__span-0-1485"><a id="__codelineno-0-1485" name="__codelineno-0-1485"></a>                <span class="k">lambda</span><span class="p">:</span> <span class="n">_univalent_dense_to_sparse</span><span class="p">(</span><span class="n">batch_dim</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">),</span>
</span><span id="__span-0-1486"><a id="__codelineno-0-1486" name="__codelineno-0-1486"></a>                <span class="k">lambda</span><span class="p">:</span> <span class="n">_deduplicate_tensor_per_row</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">batch_dim</span><span class="p">),</span>
</span><span id="__span-0-1487"><a id="__codelineno-0-1487" name="__codelineno-0-1487"></a>            <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.estimated_probability_density" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">estimated_probability_density</span>


<a href="#tensorflow_transform.estimated_probability_density" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">estimated_probability_density</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">boundaries</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="            Union (typing.Union)" href="#tensorflow_transform.Union">Union</a></span><span class="p">[</span><span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">categorical</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes an approximate probability density at each x, given the bins.</p>
<p>Using this type of fixed-interval method has several benefits compared to
  bucketization, although may not always be preferred.
  1. Quantiles does not work on categorical data.
  2. The quantiles algorithm does not currently operate on multiple features
  jointly, only independently.</p>


<details class="ex" open>
  <summary>Outlier detection in a multi-modal or arbitrary distribution.</summary>
  <p>Imagine a value x where a simple model is highly predictive of a target y
within certain densely populated ranges. Outside these ranges, we may want
to treat the data differently, but there are too few samples for the model
to detect them by case-by-case treatment.
One option would be to use the density estimate for this purpose:</p>
<p>outputs['x_density'] = tft.estimated_prob(inputs['x'], bins=100)
outputs['outlier_x'] = tf.where(outputs['x_density'] &lt; OUTLIER_THRESHOLD,
                                tf.constant([1]), tf.constant([0]))</p>
<p>This exercise uses a single variable for illustration, but a direct density
metric would become more useful with higher dimensions.</p>
</details>        <p>Note that we normalize by average bin_width to arrive at a probability density
estimate. The result resembles a pdf, not the probability that a value falls
in the bucket (except in the categorical case).</p>
        <hr>
<p>x: A <code>Tensor</code>.
  boundaries: (Optional) A <code>Tensor</code> or int used to approximate the density.
      If possible provide boundaries as a Tensor of multiple sorted values.
      Will default to 10 intervals over the 0-1 range, or find the min/max
      if an int is provided (not recommended because multi-phase analysis is
      inefficient). If the boundaries are known as potentially arbitrary
      interval boundaries, sizes are assumed to be equal. If the sizes are
      unequal, density may be inaccurate. Ignored if <code>categorical</code> is true.
  categorical: (Optional) A <code>bool</code> that will treat x as categorical if true.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>A <code>Tensor</code> the same shape as x, the probability density estimate at x (or
  probability mass estimate if <code>categorical</code> is True).</p>
        <hr>
<p>NotImplementedError: If <code>x</code> is CompositeTensor.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-2397">2397</a></span>
<span class="normal"><a href="#__codelineno-0-2398">2398</a></span>
<span class="normal"><a href="#__codelineno-0-2399">2399</a></span>
<span class="normal"><a href="#__codelineno-0-2400">2400</a></span>
<span class="normal"><a href="#__codelineno-0-2401">2401</a></span>
<span class="normal"><a href="#__codelineno-0-2402">2402</a></span>
<span class="normal"><a href="#__codelineno-0-2403">2403</a></span>
<span class="normal"><a href="#__codelineno-0-2404">2404</a></span>
<span class="normal"><a href="#__codelineno-0-2405">2405</a></span>
<span class="normal"><a href="#__codelineno-0-2406">2406</a></span>
<span class="normal"><a href="#__codelineno-0-2407">2407</a></span>
<span class="normal"><a href="#__codelineno-0-2408">2408</a></span>
<span class="normal"><a href="#__codelineno-0-2409">2409</a></span>
<span class="normal"><a href="#__codelineno-0-2410">2410</a></span>
<span class="normal"><a href="#__codelineno-0-2411">2411</a></span>
<span class="normal"><a href="#__codelineno-0-2412">2412</a></span>
<span class="normal"><a href="#__codelineno-0-2413">2413</a></span>
<span class="normal"><a href="#__codelineno-0-2414">2414</a></span>
<span class="normal"><a href="#__codelineno-0-2415">2415</a></span>
<span class="normal"><a href="#__codelineno-0-2416">2416</a></span>
<span class="normal"><a href="#__codelineno-0-2417">2417</a></span>
<span class="normal"><a href="#__codelineno-0-2418">2418</a></span>
<span class="normal"><a href="#__codelineno-0-2419">2419</a></span>
<span class="normal"><a href="#__codelineno-0-2420">2420</a></span>
<span class="normal"><a href="#__codelineno-0-2421">2421</a></span>
<span class="normal"><a href="#__codelineno-0-2422">2422</a></span>
<span class="normal"><a href="#__codelineno-0-2423">2423</a></span>
<span class="normal"><a href="#__codelineno-0-2424">2424</a></span>
<span class="normal"><a href="#__codelineno-0-2425">2425</a></span>
<span class="normal"><a href="#__codelineno-0-2426">2426</a></span>
<span class="normal"><a href="#__codelineno-0-2427">2427</a></span>
<span class="normal"><a href="#__codelineno-0-2428">2428</a></span>
<span class="normal"><a href="#__codelineno-0-2429">2429</a></span>
<span class="normal"><a href="#__codelineno-0-2430">2430</a></span>
<span class="normal"><a href="#__codelineno-0-2431">2431</a></span>
<span class="normal"><a href="#__codelineno-0-2432">2432</a></span>
<span class="normal"><a href="#__codelineno-0-2433">2433</a></span>
<span class="normal"><a href="#__codelineno-0-2434">2434</a></span>
<span class="normal"><a href="#__codelineno-0-2435">2435</a></span>
<span class="normal"><a href="#__codelineno-0-2436">2436</a></span>
<span class="normal"><a href="#__codelineno-0-2437">2437</a></span>
<span class="normal"><a href="#__codelineno-0-2438">2438</a></span>
<span class="normal"><a href="#__codelineno-0-2439">2439</a></span>
<span class="normal"><a href="#__codelineno-0-2440">2440</a></span>
<span class="normal"><a href="#__codelineno-0-2441">2441</a></span>
<span class="normal"><a href="#__codelineno-0-2442">2442</a></span>
<span class="normal"><a href="#__codelineno-0-2443">2443</a></span>
<span class="normal"><a href="#__codelineno-0-2444">2444</a></span>
<span class="normal"><a href="#__codelineno-0-2445">2445</a></span>
<span class="normal"><a href="#__codelineno-0-2446">2446</a></span>
<span class="normal"><a href="#__codelineno-0-2447">2447</a></span>
<span class="normal"><a href="#__codelineno-0-2448">2448</a></span>
<span class="normal"><a href="#__codelineno-0-2449">2449</a></span>
<span class="normal"><a href="#__codelineno-0-2450">2450</a></span>
<span class="normal"><a href="#__codelineno-0-2451">2451</a></span>
<span class="normal"><a href="#__codelineno-0-2452">2452</a></span>
<span class="normal"><a href="#__codelineno-0-2453">2453</a></span>
<span class="normal"><a href="#__codelineno-0-2454">2454</a></span>
<span class="normal"><a href="#__codelineno-0-2455">2455</a></span>
<span class="normal"><a href="#__codelineno-0-2456">2456</a></span>
<span class="normal"><a href="#__codelineno-0-2457">2457</a></span>
<span class="normal"><a href="#__codelineno-0-2458">2458</a></span>
<span class="normal"><a href="#__codelineno-0-2459">2459</a></span>
<span class="normal"><a href="#__codelineno-0-2460">2460</a></span>
<span class="normal"><a href="#__codelineno-0-2461">2461</a></span>
<span class="normal"><a href="#__codelineno-0-2462">2462</a></span>
<span class="normal"><a href="#__codelineno-0-2463">2463</a></span>
<span class="normal"><a href="#__codelineno-0-2464">2464</a></span>
<span class="normal"><a href="#__codelineno-0-2465">2465</a></span>
<span class="normal"><a href="#__codelineno-0-2466">2466</a></span>
<span class="normal"><a href="#__codelineno-0-2467">2467</a></span>
<span class="normal"><a href="#__codelineno-0-2468">2468</a></span>
<span class="normal"><a href="#__codelineno-0-2469">2469</a></span>
<span class="normal"><a href="#__codelineno-0-2470">2470</a></span>
<span class="normal"><a href="#__codelineno-0-2471">2471</a></span>
<span class="normal"><a href="#__codelineno-0-2472">2472</a></span>
<span class="normal"><a href="#__codelineno-0-2473">2473</a></span>
<span class="normal"><a href="#__codelineno-0-2474">2474</a></span>
<span class="normal"><a href="#__codelineno-0-2475">2475</a></span>
<span class="normal"><a href="#__codelineno-0-2476">2476</a></span>
<span class="normal"><a href="#__codelineno-0-2477">2477</a></span>
<span class="normal"><a href="#__codelineno-0-2478">2478</a></span>
<span class="normal"><a href="#__codelineno-0-2479">2479</a></span>
<span class="normal"><a href="#__codelineno-0-2480">2480</a></span>
<span class="normal"><a href="#__codelineno-0-2481">2481</a></span>
<span class="normal"><a href="#__codelineno-0-2482">2482</a></span>
<span class="normal"><a href="#__codelineno-0-2483">2483</a></span>
<span class="normal"><a href="#__codelineno-0-2484">2484</a></span>
<span class="normal"><a href="#__codelineno-0-2485">2485</a></span>
<span class="normal"><a href="#__codelineno-0-2486">2486</a></span>
<span class="normal"><a href="#__codelineno-0-2487">2487</a></span>
<span class="normal"><a href="#__codelineno-0-2488">2488</a></span>
<span class="normal"><a href="#__codelineno-0-2489">2489</a></span>
<span class="normal"><a href="#__codelineno-0-2490">2490</a></span>
<span class="normal"><a href="#__codelineno-0-2491">2491</a></span>
<span class="normal"><a href="#__codelineno-0-2492">2492</a></span>
<span class="normal"><a href="#__codelineno-0-2493">2493</a></span>
<span class="normal"><a href="#__codelineno-0-2494">2494</a></span>
<span class="normal"><a href="#__codelineno-0-2495">2495</a></span>
<span class="normal"><a href="#__codelineno-0-2496">2496</a></span>
<span class="normal"><a href="#__codelineno-0-2497">2497</a></span>
<span class="normal"><a href="#__codelineno-0-2498">2498</a></span>
<span class="normal"><a href="#__codelineno-0-2499">2499</a></span>
<span class="normal"><a href="#__codelineno-0-2500">2500</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-2397"><a id="__codelineno-0-2397" name="__codelineno-0-2397"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-2398"><a id="__codelineno-0-2398" name="__codelineno-0-2398"></a><span class="k">def</span><span class="w"> </span><span class="nf">estimated_probability_density</span><span class="p">(</span>
</span><span id="__span-0-2399"><a id="__codelineno-0-2399" name="__codelineno-0-2399"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-2400"><a id="__codelineno-0-2400" name="__codelineno-0-2400"></a>    <span class="n">boundaries</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-2401"><a id="__codelineno-0-2401" name="__codelineno-0-2401"></a>    <span class="n">categorical</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-2402"><a id="__codelineno-0-2402" name="__codelineno-0-2402"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-2403"><a id="__codelineno-0-2403" name="__codelineno-0-2403"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-2404"><a id="__codelineno-0-2404" name="__codelineno-0-2404"></a><span class="w">    </span><span class="sd">"""Computes an approximate probability density at each x, given the bins.</span>
</span><span id="__span-0-2405"><a id="__codelineno-0-2405" name="__codelineno-0-2405"></a>
</span><span id="__span-0-2406"><a id="__codelineno-0-2406" name="__codelineno-0-2406"></a><span class="sd">    Using this type of fixed-interval method has several benefits compared to</span>
</span><span id="__span-0-2407"><a id="__codelineno-0-2407" name="__codelineno-0-2407"></a><span class="sd">      bucketization, although may not always be preferred.</span>
</span><span id="__span-0-2408"><a id="__codelineno-0-2408" name="__codelineno-0-2408"></a><span class="sd">      1. Quantiles does not work on categorical data.</span>
</span><span id="__span-0-2409"><a id="__codelineno-0-2409" name="__codelineno-0-2409"></a><span class="sd">      2. The quantiles algorithm does not currently operate on multiple features</span>
</span><span id="__span-0-2410"><a id="__codelineno-0-2410" name="__codelineno-0-2410"></a><span class="sd">      jointly, only independently.</span>
</span><span id="__span-0-2411"><a id="__codelineno-0-2411" name="__codelineno-0-2411"></a>
</span><span id="__span-0-2412"><a id="__codelineno-0-2412" name="__codelineno-0-2412"></a><span class="sd">    Ex: Outlier detection in a multi-modal or arbitrary distribution.</span>
</span><span id="__span-0-2413"><a id="__codelineno-0-2413" name="__codelineno-0-2413"></a><span class="sd">      Imagine a value x where a simple model is highly predictive of a target y</span>
</span><span id="__span-0-2414"><a id="__codelineno-0-2414" name="__codelineno-0-2414"></a><span class="sd">      within certain densely populated ranges. Outside these ranges, we may want</span>
</span><span id="__span-0-2415"><a id="__codelineno-0-2415" name="__codelineno-0-2415"></a><span class="sd">      to treat the data differently, but there are too few samples for the model</span>
</span><span id="__span-0-2416"><a id="__codelineno-0-2416" name="__codelineno-0-2416"></a><span class="sd">      to detect them by case-by-case treatment.</span>
</span><span id="__span-0-2417"><a id="__codelineno-0-2417" name="__codelineno-0-2417"></a><span class="sd">      One option would be to use the density estimate for this purpose:</span>
</span><span id="__span-0-2418"><a id="__codelineno-0-2418" name="__codelineno-0-2418"></a>
</span><span id="__span-0-2419"><a id="__codelineno-0-2419" name="__codelineno-0-2419"></a><span class="sd">      outputs['x_density'] = tft.estimated_prob(inputs['x'], bins=100)</span>
</span><span id="__span-0-2420"><a id="__codelineno-0-2420" name="__codelineno-0-2420"></a><span class="sd">      outputs['outlier_x'] = tf.where(outputs['x_density'] &lt; OUTLIER_THRESHOLD,</span>
</span><span id="__span-0-2421"><a id="__codelineno-0-2421" name="__codelineno-0-2421"></a><span class="sd">                                      tf.constant([1]), tf.constant([0]))</span>
</span><span id="__span-0-2422"><a id="__codelineno-0-2422" name="__codelineno-0-2422"></a>
</span><span id="__span-0-2423"><a id="__codelineno-0-2423" name="__codelineno-0-2423"></a><span class="sd">      This exercise uses a single variable for illustration, but a direct density</span>
</span><span id="__span-0-2424"><a id="__codelineno-0-2424" name="__codelineno-0-2424"></a><span class="sd">      metric would become more useful with higher dimensions.</span>
</span><span id="__span-0-2425"><a id="__codelineno-0-2425" name="__codelineno-0-2425"></a>
</span><span id="__span-0-2426"><a id="__codelineno-0-2426" name="__codelineno-0-2426"></a><span class="sd">    Note that we normalize by average bin_width to arrive at a probability density</span>
</span><span id="__span-0-2427"><a id="__codelineno-0-2427" name="__codelineno-0-2427"></a><span class="sd">    estimate. The result resembles a pdf, not the probability that a value falls</span>
</span><span id="__span-0-2428"><a id="__codelineno-0-2428" name="__codelineno-0-2428"></a><span class="sd">    in the bucket (except in the categorical case).</span>
</span><span id="__span-0-2429"><a id="__codelineno-0-2429" name="__codelineno-0-2429"></a>
</span><span id="__span-0-2430"><a id="__codelineno-0-2430" name="__codelineno-0-2430"></a><span class="sd">    Args:</span>
</span><span id="__span-0-2431"><a id="__codelineno-0-2431" name="__codelineno-0-2431"></a><span class="sd">    ----</span>
</span><span id="__span-0-2432"><a id="__codelineno-0-2432" name="__codelineno-0-2432"></a><span class="sd">      x: A `Tensor`.</span>
</span><span id="__span-0-2433"><a id="__codelineno-0-2433" name="__codelineno-0-2433"></a><span class="sd">      boundaries: (Optional) A `Tensor` or int used to approximate the density.</span>
</span><span id="__span-0-2434"><a id="__codelineno-0-2434" name="__codelineno-0-2434"></a><span class="sd">          If possible provide boundaries as a Tensor of multiple sorted values.</span>
</span><span id="__span-0-2435"><a id="__codelineno-0-2435" name="__codelineno-0-2435"></a><span class="sd">          Will default to 10 intervals over the 0-1 range, or find the min/max</span>
</span><span id="__span-0-2436"><a id="__codelineno-0-2436" name="__codelineno-0-2436"></a><span class="sd">          if an int is provided (not recommended because multi-phase analysis is</span>
</span><span id="__span-0-2437"><a id="__codelineno-0-2437" name="__codelineno-0-2437"></a><span class="sd">          inefficient). If the boundaries are known as potentially arbitrary</span>
</span><span id="__span-0-2438"><a id="__codelineno-0-2438" name="__codelineno-0-2438"></a><span class="sd">          interval boundaries, sizes are assumed to be equal. If the sizes are</span>
</span><span id="__span-0-2439"><a id="__codelineno-0-2439" name="__codelineno-0-2439"></a><span class="sd">          unequal, density may be inaccurate. Ignored if `categorical` is true.</span>
</span><span id="__span-0-2440"><a id="__codelineno-0-2440" name="__codelineno-0-2440"></a><span class="sd">      categorical: (Optional) A `bool` that will treat x as categorical if true.</span>
</span><span id="__span-0-2441"><a id="__codelineno-0-2441" name="__codelineno-0-2441"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-2442"><a id="__codelineno-0-2442" name="__codelineno-0-2442"></a>
</span><span id="__span-0-2443"><a id="__codelineno-0-2443" name="__codelineno-0-2443"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-2444"><a id="__codelineno-0-2444" name="__codelineno-0-2444"></a><span class="sd">    -------</span>
</span><span id="__span-0-2445"><a id="__codelineno-0-2445" name="__codelineno-0-2445"></a><span class="sd">      A `Tensor` the same shape as x, the probability density estimate at x (or</span>
</span><span id="__span-0-2446"><a id="__codelineno-0-2446" name="__codelineno-0-2446"></a><span class="sd">      probability mass estimate if `categorical` is True).</span>
</span><span id="__span-0-2447"><a id="__codelineno-0-2447" name="__codelineno-0-2447"></a>
</span><span id="__span-0-2448"><a id="__codelineno-0-2448" name="__codelineno-0-2448"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-2449"><a id="__codelineno-0-2449" name="__codelineno-0-2449"></a><span class="sd">    ------</span>
</span><span id="__span-0-2450"><a id="__codelineno-0-2450" name="__codelineno-0-2450"></a><span class="sd">      NotImplementedError: If `x` is CompositeTensor.</span>
</span><span id="__span-0-2451"><a id="__codelineno-0-2451" name="__codelineno-0-2451"></a><span class="sd">    """</span>
</span><span id="__span-0-2452"><a id="__codelineno-0-2452" name="__codelineno-0-2452"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"estimated_probability_density"</span><span class="p">):</span>
</span><span id="__span-0-2453"><a id="__codelineno-0-2453" name="__codelineno-0-2453"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">)):</span>
</span><span id="__span-0-2454"><a id="__codelineno-0-2454" name="__codelineno-0-2454"></a>            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
</span><span id="__span-0-2455"><a id="__codelineno-0-2455" name="__codelineno-0-2455"></a>                <span class="s2">"estimated probability density does not support Composite Tensors"</span>
</span><span id="__span-0-2456"><a id="__codelineno-0-2456" name="__codelineno-0-2456"></a>            <span class="p">)</span>
</span><span id="__span-0-2457"><a id="__codelineno-0-2457" name="__codelineno-0-2457"></a>        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">ndims</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="__span-0-2458"><a id="__codelineno-0-2458" name="__codelineno-0-2458"></a>            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
</span><span id="__span-0-2459"><a id="__codelineno-0-2459" name="__codelineno-0-2459"></a>                <span class="s2">"estimated probability density does not support multiple dimensions"</span>
</span><span id="__span-0-2460"><a id="__codelineno-0-2460" name="__codelineno-0-2460"></a>            <span class="p">)</span>
</span><span id="__span-0-2461"><a id="__codelineno-0-2461" name="__codelineno-0-2461"></a>
</span><span id="__span-0-2462"><a id="__codelineno-0-2462" name="__codelineno-0-2462"></a>        <span class="n">counts</span><span class="p">,</span> <span class="n">boundaries</span> <span class="o">=</span> <span class="n">analyzers</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span>
</span><span id="__span-0-2463"><a id="__codelineno-0-2463" name="__codelineno-0-2463"></a>            <span class="n">x</span><span class="p">,</span> <span class="n">boundaries</span><span class="o">=</span><span class="n">boundaries</span><span class="p">,</span> <span class="n">categorical</span><span class="o">=</span><span class="n">categorical</span>
</span><span id="__span-0-2464"><a id="__codelineno-0-2464" name="__codelineno-0-2464"></a>        <span class="p">)</span>
</span><span id="__span-0-2465"><a id="__codelineno-0-2465" name="__codelineno-0-2465"></a>
</span><span id="__span-0-2466"><a id="__codelineno-0-2466" name="__codelineno-0-2466"></a>        <span class="n">xdims</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">ndims</span>
</span><span id="__span-0-2467"><a id="__codelineno-0-2467" name="__codelineno-0-2467"></a>        <span class="n">counts</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="__span-0-2468"><a id="__codelineno-0-2468" name="__codelineno-0-2468"></a>        <span class="n">probabilities</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span>
</span><span id="__span-0-2469"><a id="__codelineno-0-2469" name="__codelineno-0-2469"></a>
</span><span id="__span-0-2470"><a id="__codelineno-0-2470" name="__codelineno-0-2470"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="__span-0-2471"><a id="__codelineno-0-2471" name="__codelineno-0-2471"></a>
</span><span id="__span-0-2472"><a id="__codelineno-0-2472" name="__codelineno-0-2472"></a>        <span class="k">if</span> <span class="n">categorical</span><span class="p">:</span>
</span><span id="__span-0-2473"><a id="__codelineno-0-2473" name="__codelineno-0-2473"></a>            <span class="n">bucket_indices</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">lookup_key</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">boundaries</span><span class="p">)</span>
</span><span id="__span-0-2474"><a id="__codelineno-0-2474" name="__codelineno-0-2474"></a>            <span class="n">bucket_densities</span> <span class="o">=</span> <span class="n">probabilities</span>
</span><span id="__span-0-2475"><a id="__codelineno-0-2475" name="__codelineno-0-2475"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-2476"><a id="__codelineno-0-2476" name="__codelineno-0-2476"></a>            <span class="c1"># We need to compute the bin width so that density does not depend on</span>
</span><span id="__span-0-2477"><a id="__codelineno-0-2477" name="__codelineno-0-2477"></a>            <span class="c1"># number of intervals.</span>
</span><span id="__span-0-2478"><a id="__codelineno-0-2478" name="__codelineno-0-2478"></a>            <span class="n">bin_width</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">boundaries</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">boundaries</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span>
</span><span id="__span-0-2479"><a id="__codelineno-0-2479" name="__codelineno-0-2479"></a>                <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">probabilities</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="__span-0-2480"><a id="__codelineno-0-2480" name="__codelineno-0-2480"></a>            <span class="p">)</span>
</span><span id="__span-0-2481"><a id="__codelineno-0-2481" name="__codelineno-0-2481"></a>            <span class="n">bucket_densities</span> <span class="o">=</span> <span class="n">probabilities</span> <span class="o">/</span> <span class="n">bin_width</span>
</span><span id="__span-0-2482"><a id="__codelineno-0-2482" name="__codelineno-0-2482"></a>
</span><span id="__span-0-2483"><a id="__codelineno-0-2483" name="__codelineno-0-2483"></a>            <span class="n">bucket_indices</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">assign_buckets</span><span class="p">(</span>
</span><span id="__span-0-2484"><a id="__codelineno-0-2484" name="__codelineno-0-2484"></a>                <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">analyzers</span><span class="o">.</span><span class="n">remove_leftmost_boundary</span><span class="p">(</span><span class="n">boundaries</span><span class="p">)</span>
</span><span id="__span-0-2485"><a id="__codelineno-0-2485" name="__codelineno-0-2485"></a>            <span class="p">)</span>
</span><span id="__span-0-2486"><a id="__codelineno-0-2486" name="__codelineno-0-2486"></a>        <span class="n">bucket_indices</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">_align_dims</span><span class="p">(</span><span class="n">bucket_indices</span><span class="p">,</span> <span class="n">xdims</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>
</span><span id="__span-0-2487"><a id="__codelineno-0-2487" name="__codelineno-0-2487"></a>
</span><span id="__span-0-2488"><a id="__codelineno-0-2488" name="__codelineno-0-2488"></a>        <span class="c1"># In the categorical case, when keys are missing, the indices may be -1,</span>
</span><span id="__span-0-2489"><a id="__codelineno-0-2489" name="__codelineno-0-2489"></a>        <span class="c1"># therefore we replace those with 0 in order to use tf.gather.</span>
</span><span id="__span-0-2490"><a id="__codelineno-0-2490" name="__codelineno-0-2490"></a>        <span class="n">adjusted_bucket_indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
</span><span id="__span-0-2491"><a id="__codelineno-0-2491" name="__codelineno-0-2491"></a>            <span class="n">bucket_indices</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-2492"><a id="__codelineno-0-2492" name="__codelineno-0-2492"></a>            <span class="n">_fill_shape</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">bucket_indices</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
</span><span id="__span-0-2493"><a id="__codelineno-0-2493" name="__codelineno-0-2493"></a>            <span class="n">bucket_indices</span><span class="p">,</span>
</span><span id="__span-0-2494"><a id="__codelineno-0-2494" name="__codelineno-0-2494"></a>        <span class="p">)</span>
</span><span id="__span-0-2495"><a id="__codelineno-0-2495" name="__codelineno-0-2495"></a>        <span class="n">bucket_densities</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">bucket_densities</span><span class="p">,</span> <span class="n">adjusted_bucket_indices</span><span class="p">)</span>
</span><span id="__span-0-2496"><a id="__codelineno-0-2496" name="__codelineno-0-2496"></a>        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
</span><span id="__span-0-2497"><a id="__codelineno-0-2497" name="__codelineno-0-2497"></a>            <span class="n">bucket_indices</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-2498"><a id="__codelineno-0-2498" name="__codelineno-0-2498"></a>            <span class="n">_fill_shape</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">bucket_indices</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
</span><span id="__span-0-2499"><a id="__codelineno-0-2499" name="__codelineno-0-2499"></a>            <span class="n">bucket_densities</span><span class="p">,</span>
</span><span id="__span-0-2500"><a id="__codelineno-0-2500" name="__codelineno-0-2500"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.get_analyze_input_columns" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">get_analyze_input_columns</span>


<a href="#tensorflow_transform.get_analyze_input_columns" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">get_analyze_input_columns</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">preprocessing_fn</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Callable


  
      module-attribute
   (typing.Callable)" href="#tensorflow_transform.Callable">Callable</a></span><span class="p">[</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>        <span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="            Mapping


  
      module-attribute
   (typing.Mapping)" href="#tensorflow_transform.Mapping">Mapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">]],</span> <span class="n"><a class="autorefs autorefs-internal" title="            Mapping


  
      module-attribute
   (typing.Mapping)" href="#tensorflow_transform.Mapping">Mapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">]</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="p">],</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">specs</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Mapping


  
      module-attribute
   (typing.Mapping)" href="#tensorflow_transform.Mapping">Mapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" title="            Union (typing.Union)" href="#tensorflow_transform.Union">Union</a></span><span class="p">[</span><span class="n"><span title="tensorflow_transform.common_types.FeatureSpecType">FeatureSpecType</span></span><span class="p">,</span> <span class="n"><span title="tensorflow.TypeSpec">TypeSpec</span></span><span class="p">]],</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">force_tf_compat_v1</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="            List


  
      module-attribute
   (typing.List)" href="#tensorflow_transform.List">List</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Return columns that are required inputs of <code>AnalyzeDataset</code>.</p>
        <hr>
<p>preprocessing_fn: A tf.transform preprocessing_fn.
  specs: A dict of feature name to tf.TypeSpecs. If <code>force_tf_compat_v1</code> is
    True, this can also be feature specifications.
  force_tf_compat_v1: (Optional) If <code>True</code>, use Tensorflow in compat.v1 mode.
    Defaults to <code>False</code>.</p>
        <hr>
<p>A list of columns that are required inputs of analyzers.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/inspect_preprocessing_fn.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-31">31</a></span>
<span class="normal"><a href="#__codelineno-0-32">32</a></span>
<span class="normal"><a href="#__codelineno-0-33">33</a></span>
<span class="normal"><a href="#__codelineno-0-34">34</a></span>
<span class="normal"><a href="#__codelineno-0-35">35</a></span>
<span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span>
<span class="normal"><a href="#__codelineno-0-75">75</a></span>
<span class="normal"><a href="#__codelineno-0-76">76</a></span>
<span class="normal"><a href="#__codelineno-0-77">77</a></span>
<span class="normal"><a href="#__codelineno-0-78">78</a></span>
<span class="normal"><a href="#__codelineno-0-79">79</a></span>
<span class="normal"><a href="#__codelineno-0-80">80</a></span>
<span class="normal"><a href="#__codelineno-0-81">81</a></span>
<span class="normal"><a href="#__codelineno-0-82">82</a></span>
<span class="normal"><a href="#__codelineno-0-83">83</a></span>
<span class="normal"><a href="#__codelineno-0-84">84</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-31"><a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="k">def</span><span class="w"> </span><span class="nf">get_analyze_input_columns</span><span class="p">(</span>
</span><span id="__span-0-32"><a id="__codelineno-0-32" name="__codelineno-0-32"></a>    <span class="n">preprocessing_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span>
</span><span id="__span-0-33"><a id="__codelineno-0-33" name="__codelineno-0-33"></a>        <span class="p">[</span><span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">]],</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">]</span>
</span><span id="__span-0-34"><a id="__codelineno-0-34" name="__codelineno-0-34"></a>    <span class="p">],</span>
</span><span id="__span-0-35"><a id="__codelineno-0-35" name="__codelineno-0-35"></a>    <span class="n">specs</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">common_types</span><span class="o">.</span><span class="n">FeatureSpecType</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">TypeSpec</span><span class="p">]],</span>
</span><span id="__span-0-36"><a id="__codelineno-0-36" name="__codelineno-0-36"></a>    <span class="n">force_tf_compat_v1</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-37"><a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
</span><span id="__span-0-38"><a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="w">    </span><span class="sd">"""Return columns that are required inputs of `AnalyzeDataset`.</span>
</span><span id="__span-0-39"><a id="__codelineno-0-39" name="__codelineno-0-39"></a>
</span><span id="__span-0-40"><a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">    Args:</span>
</span><span id="__span-0-41"><a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="sd">    ----</span>
</span><span id="__span-0-42"><a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">      preprocessing_fn: A tf.transform preprocessing_fn.</span>
</span><span id="__span-0-43"><a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">      specs: A dict of feature name to tf.TypeSpecs. If `force_tf_compat_v1` is</span>
</span><span id="__span-0-44"><a id="__codelineno-0-44" name="__codelineno-0-44"></a><span class="sd">        True, this can also be feature specifications.</span>
</span><span id="__span-0-45"><a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">      force_tf_compat_v1: (Optional) If `True`, use Tensorflow in compat.v1 mode.</span>
</span><span id="__span-0-46"><a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">        Defaults to `False`.</span>
</span><span id="__span-0-47"><a id="__codelineno-0-47" name="__codelineno-0-47"></a>
</span><span id="__span-0-48"><a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-49"><a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">    -------</span>
</span><span id="__span-0-50"><a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">      A list of columns that are required inputs of analyzers.</span>
</span><span id="__span-0-51"><a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">    """</span>
</span><span id="__span-0-52"><a id="__codelineno-0-52" name="__codelineno-0-52"></a>    <span class="n">use_tf_compat_v1</span> <span class="o">=</span> <span class="n">tf2_utils</span><span class="o">.</span><span class="n">use_tf_compat_v1</span><span class="p">(</span><span class="n">force_tf_compat_v1</span><span class="p">)</span>
</span><span id="__span-0-53"><a id="__codelineno-0-53" name="__codelineno-0-53"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">use_tf_compat_v1</span><span class="p">:</span>
</span><span id="__span-0-54"><a id="__codelineno-0-54" name="__codelineno-0-54"></a>        <span class="k">assert</span> <span class="nb">all</span><span class="p">([</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">TypeSpec</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">specs</span><span class="o">.</span><span class="n">values</span><span class="p">()]),</span> <span class="n">specs</span>
</span><span id="__span-0-55"><a id="__codelineno-0-55" name="__codelineno-0-55"></a>    <span class="n">graph</span><span class="p">,</span> <span class="n">structured_inputs</span><span class="p">,</span> <span class="n">structured_outputs</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-56"><a id="__codelineno-0-56" name="__codelineno-0-56"></a>        <span class="n">impl_helper</span><span class="o">.</span><span class="n">trace_preprocessing_function</span><span class="p">(</span>
</span><span id="__span-0-57"><a id="__codelineno-0-57" name="__codelineno-0-57"></a>            <span class="n">preprocessing_fn</span><span class="p">,</span> <span class="n">specs</span><span class="p">,</span> <span class="n">use_tf_compat_v1</span><span class="o">=</span><span class="n">use_tf_compat_v1</span>
</span><span id="__span-0-58"><a id="__codelineno-0-58" name="__codelineno-0-58"></a>        <span class="p">)</span>
</span><span id="__span-0-59"><a id="__codelineno-0-59" name="__codelineno-0-59"></a>    <span class="p">)</span>
</span><span id="__span-0-60"><a id="__codelineno-0-60" name="__codelineno-0-60"></a>
</span><span id="__span-0-61"><a id="__codelineno-0-61" name="__codelineno-0-61"></a>    <span class="n">tensor_sinks</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">analyzer_nodes</span><span class="o">.</span><span class="n">TENSOR_REPLACEMENTS</span><span class="p">)</span>
</span><span id="__span-0-62"><a id="__codelineno-0-62" name="__codelineno-0-62"></a>    <span class="n">visitor</span> <span class="o">=</span> <span class="n">graph_tools</span><span class="o">.</span><span class="n">SourcedTensorsVisitor</span><span class="p">()</span>
</span><span id="__span-0-63"><a id="__codelineno-0-63" name="__codelineno-0-63"></a>    <span class="k">for</span> <span class="n">tensor_sink</span> <span class="ow">in</span> <span class="n">tensor_sinks</span><span class="p">:</span>
</span><span id="__span-0-64"><a id="__codelineno-0-64" name="__codelineno-0-64"></a>        <span class="n">nodes</span><span class="o">.</span><span class="n">Traverser</span><span class="p">(</span><span class="n">visitor</span><span class="p">)</span><span class="o">.</span><span class="n">visit_value_node</span><span class="p">(</span><span class="n">tensor_sink</span><span class="o">.</span><span class="n">future</span><span class="p">)</span>
</span><span id="__span-0-65"><a id="__codelineno-0-65" name="__codelineno-0-65"></a>
</span><span id="__span-0-66"><a id="__codelineno-0-66" name="__codelineno-0-66"></a>    <span class="k">if</span> <span class="n">use_tf_compat_v1</span><span class="p">:</span>
</span><span id="__span-0-67"><a id="__codelineno-0-67" name="__codelineno-0-67"></a>        <span class="n">control_dependency_ops</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-0-68"><a id="__codelineno-0-68" name="__codelineno-0-68"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-69"><a id="__codelineno-0-69" name="__codelineno-0-69"></a>        <span class="c1"># If traced in TF2 as a tf.function, inputs that end up in control</span>
</span><span id="__span-0-70"><a id="__codelineno-0-70" name="__codelineno-0-70"></a>        <span class="c1"># dependencies are required for the function to execute. Return such inputs</span>
</span><span id="__span-0-71"><a id="__codelineno-0-71" name="__codelineno-0-71"></a>        <span class="c1"># as required inputs of analyzers as well.</span>
</span><span id="__span-0-72"><a id="__codelineno-0-72" name="__codelineno-0-72"></a>        <span class="n">_</span><span class="p">,</span> <span class="n">control_dependency_ops</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-73"><a id="__codelineno-0-73" name="__codelineno-0-73"></a>            <span class="n">tf2_utils</span><span class="o">.</span><span class="n">strip_and_get_tensors_and_control_dependencies</span><span class="p">(</span>
</span><span id="__span-0-74"><a id="__codelineno-0-74" name="__codelineno-0-74"></a>                <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">structured_outputs</span><span class="p">,</span> <span class="n">expand_composites</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-0-75"><a id="__codelineno-0-75" name="__codelineno-0-75"></a>            <span class="p">)</span>
</span><span id="__span-0-76"><a id="__codelineno-0-76" name="__codelineno-0-76"></a>        <span class="p">)</span>
</span><span id="__span-0-77"><a id="__codelineno-0-77" name="__codelineno-0-77"></a>
</span><span id="__span-0-78"><a id="__codelineno-0-78" name="__codelineno-0-78"></a>    <span class="n">output_tensors</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
</span><span id="__span-0-79"><a id="__codelineno-0-79" name="__codelineno-0-79"></a>        <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="n">visitor</span><span class="o">.</span><span class="n">sourced_tensors</span><span class="p">,</span> <span class="n">control_dependency_ops</span><span class="p">)</span>
</span><span id="__span-0-80"><a id="__codelineno-0-80" name="__codelineno-0-80"></a>    <span class="p">)</span>
</span><span id="__span-0-81"><a id="__codelineno-0-81" name="__codelineno-0-81"></a>    <span class="n">analyze_input_tensors</span> <span class="o">=</span> <span class="n">graph_tools</span><span class="o">.</span><span class="n">get_dependent_inputs</span><span class="p">(</span>
</span><span id="__span-0-82"><a id="__codelineno-0-82" name="__codelineno-0-82"></a>        <span class="n">graph</span><span class="p">,</span> <span class="n">structured_inputs</span><span class="p">,</span> <span class="n">output_tensors</span>
</span><span id="__span-0-83"><a id="__codelineno-0-83" name="__codelineno-0-83"></a>    <span class="p">)</span>
</span><span id="__span-0-84"><a id="__codelineno-0-84" name="__codelineno-0-84"></a>    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">analyze_input_tensors</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.get_num_buckets_for_transformed_feature" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">get_num_buckets_for_transformed_feature</span>


<a href="#tensorflow_transform.get_num_buckets_for_transformed_feature" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">get_num_buckets_for_transformed_feature</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">transformed_feature</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Provides the number of buckets for a transformed feature if annotated.</p>
<p>This for example can be used for the direct output of <code>tft.bucketize</code>,
<code>tft.apply_buckets</code>, <code>tft.compute_and_apply_vocabulary</code>,
<code>tft.apply_vocabulary</code>.
These methods annotate the transformed feature with additional information.
If the given <code>transformed_feature</code> isn't annotated, this method will fail.</p>
<h6 id="tensorflow_transform.get_num_buckets_for_transformed_feature--example">Example:<a class="headerlink" href="#tensorflow_transform.get_num_buckets_for_transformed_feature--example" title="Permanent link">Â¶</a></h6>
<blockquote>
<blockquote>
<blockquote>
<p>def preprocessing_fn(inputs):
...   bucketized = tft.bucketize(inputs['x'], num_buckets=3)
...   integerized = tft.compute_and_apply_vocabulary(inputs['x'])
...   zeros = tf.zeros_like(inputs['x'], tf.int64)
...   return {
...      'bucketized': bucketized,
...      'bucketized_num_buckets': (
...         zeros + tft.get_num_buckets_for_transformed_feature(bucketized)),
...      'integerized': integerized,
...      'integerized_num_buckets': (
...         zeros + tft.get_num_buckets_for_transformed_feature(integerized)),
...   }
raw_data = [dict(x=3),dict(x=23)]
feature_spec = dict(x=tf.io.FixedLenFeature([], tf.int64))
raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec)
with tft_beam.Context(temp_dir=tempfile.mkdtemp()):
...   transformed_dataset, transform_fn = (
...       (raw_data, raw_data_metadata)
...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))
transformed_data, transformed_metadata = transformed_dataset
transformed_data
[{'bucketized': 1, 'bucketized_num_buckets': 3,
 'integerized': 0, 'integerized_num_buckets': 2},
{'bucketized': 2, 'bucketized_num_buckets': 3,
 'integerized': 1, 'integerized_num_buckets': 2}]</p>
</blockquote>
</blockquote>
</blockquote>
        <hr>
<p>transformed_feature: A <code>Tensor</code> or <code>SparseTensor</code> which is the direct output
    of <code>tft.bucketize</code>, <code>tft.apply_buckets</code>,
    <code>tft.compute_and_apply_vocabulary</code> or <code>tft.apply_vocabulary</code>.</p>
        <hr>
<p>ValueError: If the given tensor has not been annotated a the number of
  buckets.</p>
        <hr>
<p>A <code>Tensor</code> with the number of buckets for the given <code>transformed_feature</code>.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1309">1309</a></span>
<span class="normal"><a href="#__codelineno-0-1310">1310</a></span>
<span class="normal"><a href="#__codelineno-0-1311">1311</a></span>
<span class="normal"><a href="#__codelineno-0-1312">1312</a></span>
<span class="normal"><a href="#__codelineno-0-1313">1313</a></span>
<span class="normal"><a href="#__codelineno-0-1314">1314</a></span>
<span class="normal"><a href="#__codelineno-0-1315">1315</a></span>
<span class="normal"><a href="#__codelineno-0-1316">1316</a></span>
<span class="normal"><a href="#__codelineno-0-1317">1317</a></span>
<span class="normal"><a href="#__codelineno-0-1318">1318</a></span>
<span class="normal"><a href="#__codelineno-0-1319">1319</a></span>
<span class="normal"><a href="#__codelineno-0-1320">1320</a></span>
<span class="normal"><a href="#__codelineno-0-1321">1321</a></span>
<span class="normal"><a href="#__codelineno-0-1322">1322</a></span>
<span class="normal"><a href="#__codelineno-0-1323">1323</a></span>
<span class="normal"><a href="#__codelineno-0-1324">1324</a></span>
<span class="normal"><a href="#__codelineno-0-1325">1325</a></span>
<span class="normal"><a href="#__codelineno-0-1326">1326</a></span>
<span class="normal"><a href="#__codelineno-0-1327">1327</a></span>
<span class="normal"><a href="#__codelineno-0-1328">1328</a></span>
<span class="normal"><a href="#__codelineno-0-1329">1329</a></span>
<span class="normal"><a href="#__codelineno-0-1330">1330</a></span>
<span class="normal"><a href="#__codelineno-0-1331">1331</a></span>
<span class="normal"><a href="#__codelineno-0-1332">1332</a></span>
<span class="normal"><a href="#__codelineno-0-1333">1333</a></span>
<span class="normal"><a href="#__codelineno-0-1334">1334</a></span>
<span class="normal"><a href="#__codelineno-0-1335">1335</a></span>
<span class="normal"><a href="#__codelineno-0-1336">1336</a></span>
<span class="normal"><a href="#__codelineno-0-1337">1337</a></span>
<span class="normal"><a href="#__codelineno-0-1338">1338</a></span>
<span class="normal"><a href="#__codelineno-0-1339">1339</a></span>
<span class="normal"><a href="#__codelineno-0-1340">1340</a></span>
<span class="normal"><a href="#__codelineno-0-1341">1341</a></span>
<span class="normal"><a href="#__codelineno-0-1342">1342</a></span>
<span class="normal"><a href="#__codelineno-0-1343">1343</a></span>
<span class="normal"><a href="#__codelineno-0-1344">1344</a></span>
<span class="normal"><a href="#__codelineno-0-1345">1345</a></span>
<span class="normal"><a href="#__codelineno-0-1346">1346</a></span>
<span class="normal"><a href="#__codelineno-0-1347">1347</a></span>
<span class="normal"><a href="#__codelineno-0-1348">1348</a></span>
<span class="normal"><a href="#__codelineno-0-1349">1349</a></span>
<span class="normal"><a href="#__codelineno-0-1350">1350</a></span>
<span class="normal"><a href="#__codelineno-0-1351">1351</a></span>
<span class="normal"><a href="#__codelineno-0-1352">1352</a></span>
<span class="normal"><a href="#__codelineno-0-1353">1353</a></span>
<span class="normal"><a href="#__codelineno-0-1354">1354</a></span>
<span class="normal"><a href="#__codelineno-0-1355">1355</a></span>
<span class="normal"><a href="#__codelineno-0-1356">1356</a></span>
<span class="normal"><a href="#__codelineno-0-1357">1357</a></span>
<span class="normal"><a href="#__codelineno-0-1358">1358</a></span>
<span class="normal"><a href="#__codelineno-0-1359">1359</a></span>
<span class="normal"><a href="#__codelineno-0-1360">1360</a></span>
<span class="normal"><a href="#__codelineno-0-1361">1361</a></span>
<span class="normal"><a href="#__codelineno-0-1362">1362</a></span>
<span class="normal"><a href="#__codelineno-0-1363">1363</a></span>
<span class="normal"><a href="#__codelineno-0-1364">1364</a></span>
<span class="normal"><a href="#__codelineno-0-1365">1365</a></span>
<span class="normal"><a href="#__codelineno-0-1366">1366</a></span>
<span class="normal"><a href="#__codelineno-0-1367">1367</a></span>
<span class="normal"><a href="#__codelineno-0-1368">1368</a></span>
<span class="normal"><a href="#__codelineno-0-1369">1369</a></span>
<span class="normal"><a href="#__codelineno-0-1370">1370</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1309"><a id="__codelineno-0-1309" name="__codelineno-0-1309"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-1310"><a id="__codelineno-0-1310" name="__codelineno-0-1310"></a><span class="k">def</span><span class="w"> </span><span class="nf">get_num_buckets_for_transformed_feature</span><span class="p">(</span>
</span><span id="__span-0-1311"><a id="__codelineno-0-1311" name="__codelineno-0-1311"></a>    <span class="n">transformed_feature</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span>
</span><span id="__span-0-1312"><a id="__codelineno-0-1312" name="__codelineno-0-1312"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-1313"><a id="__codelineno-0-1313" name="__codelineno-0-1313"></a>    <span class="c1"># pyformat: disable</span>
</span><span id="__span-0-1314"><a id="__codelineno-0-1314" name="__codelineno-0-1314"></a><span class="w">    </span><span class="sd">"""Provides the number of buckets for a transformed feature if annotated.</span>
</span><span id="__span-0-1315"><a id="__codelineno-0-1315" name="__codelineno-0-1315"></a>
</span><span id="__span-0-1316"><a id="__codelineno-0-1316" name="__codelineno-0-1316"></a><span class="sd">    This for example can be used for the direct output of `tft.bucketize`,</span>
</span><span id="__span-0-1317"><a id="__codelineno-0-1317" name="__codelineno-0-1317"></a><span class="sd">    `tft.apply_buckets`, `tft.compute_and_apply_vocabulary`,</span>
</span><span id="__span-0-1318"><a id="__codelineno-0-1318" name="__codelineno-0-1318"></a><span class="sd">    `tft.apply_vocabulary`.</span>
</span><span id="__span-0-1319"><a id="__codelineno-0-1319" name="__codelineno-0-1319"></a><span class="sd">    These methods annotate the transformed feature with additional information.</span>
</span><span id="__span-0-1320"><a id="__codelineno-0-1320" name="__codelineno-0-1320"></a><span class="sd">    If the given `transformed_feature` isn't annotated, this method will fail.</span>
</span><span id="__span-0-1321"><a id="__codelineno-0-1321" name="__codelineno-0-1321"></a>
</span><span id="__span-0-1322"><a id="__codelineno-0-1322" name="__codelineno-0-1322"></a><span class="sd">    Example:</span>
</span><span id="__span-0-1323"><a id="__codelineno-0-1323" name="__codelineno-0-1323"></a><span class="sd">    -------</span>
</span><span id="__span-0-1324"><a id="__codelineno-0-1324" name="__codelineno-0-1324"></a><span class="sd">    &gt;&gt;&gt; def preprocessing_fn(inputs):</span>
</span><span id="__span-0-1325"><a id="__codelineno-0-1325" name="__codelineno-0-1325"></a><span class="sd">    ...   bucketized = tft.bucketize(inputs['x'], num_buckets=3)</span>
</span><span id="__span-0-1326"><a id="__codelineno-0-1326" name="__codelineno-0-1326"></a><span class="sd">    ...   integerized = tft.compute_and_apply_vocabulary(inputs['x'])</span>
</span><span id="__span-0-1327"><a id="__codelineno-0-1327" name="__codelineno-0-1327"></a><span class="sd">    ...   zeros = tf.zeros_like(inputs['x'], tf.int64)</span>
</span><span id="__span-0-1328"><a id="__codelineno-0-1328" name="__codelineno-0-1328"></a><span class="sd">    ...   return {</span>
</span><span id="__span-0-1329"><a id="__codelineno-0-1329" name="__codelineno-0-1329"></a><span class="sd">    ...      'bucketized': bucketized,</span>
</span><span id="__span-0-1330"><a id="__codelineno-0-1330" name="__codelineno-0-1330"></a><span class="sd">    ...      'bucketized_num_buckets': (</span>
</span><span id="__span-0-1331"><a id="__codelineno-0-1331" name="__codelineno-0-1331"></a><span class="sd">    ...         zeros + tft.get_num_buckets_for_transformed_feature(bucketized)),</span>
</span><span id="__span-0-1332"><a id="__codelineno-0-1332" name="__codelineno-0-1332"></a><span class="sd">    ...      'integerized': integerized,</span>
</span><span id="__span-0-1333"><a id="__codelineno-0-1333" name="__codelineno-0-1333"></a><span class="sd">    ...      'integerized_num_buckets': (</span>
</span><span id="__span-0-1334"><a id="__codelineno-0-1334" name="__codelineno-0-1334"></a><span class="sd">    ...         zeros + tft.get_num_buckets_for_transformed_feature(integerized)),</span>
</span><span id="__span-0-1335"><a id="__codelineno-0-1335" name="__codelineno-0-1335"></a><span class="sd">    ...   }</span>
</span><span id="__span-0-1336"><a id="__codelineno-0-1336" name="__codelineno-0-1336"></a><span class="sd">    &gt;&gt;&gt; raw_data = [dict(x=3),dict(x=23)]</span>
</span><span id="__span-0-1337"><a id="__codelineno-0-1337" name="__codelineno-0-1337"></a><span class="sd">    &gt;&gt;&gt; feature_spec = dict(x=tf.io.FixedLenFeature([], tf.int64))</span>
</span><span id="__span-0-1338"><a id="__codelineno-0-1338" name="__codelineno-0-1338"></a><span class="sd">    &gt;&gt;&gt; raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec)</span>
</span><span id="__span-0-1339"><a id="__codelineno-0-1339" name="__codelineno-0-1339"></a><span class="sd">    &gt;&gt;&gt; with tft_beam.Context(temp_dir=tempfile.mkdtemp()):</span>
</span><span id="__span-0-1340"><a id="__codelineno-0-1340" name="__codelineno-0-1340"></a><span class="sd">    ...   transformed_dataset, transform_fn = (</span>
</span><span id="__span-0-1341"><a id="__codelineno-0-1341" name="__codelineno-0-1341"></a><span class="sd">    ...       (raw_data, raw_data_metadata)</span>
</span><span id="__span-0-1342"><a id="__codelineno-0-1342" name="__codelineno-0-1342"></a><span class="sd">    ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))</span>
</span><span id="__span-0-1343"><a id="__codelineno-0-1343" name="__codelineno-0-1343"></a><span class="sd">    &gt;&gt;&gt; transformed_data, transformed_metadata = transformed_dataset</span>
</span><span id="__span-0-1344"><a id="__codelineno-0-1344" name="__codelineno-0-1344"></a><span class="sd">    &gt;&gt;&gt; transformed_data</span>
</span><span id="__span-0-1345"><a id="__codelineno-0-1345" name="__codelineno-0-1345"></a><span class="sd">    [{'bucketized': 1, 'bucketized_num_buckets': 3,</span>
</span><span id="__span-0-1346"><a id="__codelineno-0-1346" name="__codelineno-0-1346"></a><span class="sd">     'integerized': 0, 'integerized_num_buckets': 2},</span>
</span><span id="__span-0-1347"><a id="__codelineno-0-1347" name="__codelineno-0-1347"></a><span class="sd">    {'bucketized': 2, 'bucketized_num_buckets': 3,</span>
</span><span id="__span-0-1348"><a id="__codelineno-0-1348" name="__codelineno-0-1348"></a><span class="sd">     'integerized': 1, 'integerized_num_buckets': 2}]</span>
</span><span id="__span-0-1349"><a id="__codelineno-0-1349" name="__codelineno-0-1349"></a>
</span><span id="__span-0-1350"><a id="__codelineno-0-1350" name="__codelineno-0-1350"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1351"><a id="__codelineno-0-1351" name="__codelineno-0-1351"></a><span class="sd">    ----</span>
</span><span id="__span-0-1352"><a id="__codelineno-0-1352" name="__codelineno-0-1352"></a><span class="sd">      transformed_feature: A `Tensor` or `SparseTensor` which is the direct output</span>
</span><span id="__span-0-1353"><a id="__codelineno-0-1353" name="__codelineno-0-1353"></a><span class="sd">        of `tft.bucketize`, `tft.apply_buckets`,</span>
</span><span id="__span-0-1354"><a id="__codelineno-0-1354" name="__codelineno-0-1354"></a><span class="sd">        `tft.compute_and_apply_vocabulary` or `tft.apply_vocabulary`.</span>
</span><span id="__span-0-1355"><a id="__codelineno-0-1355" name="__codelineno-0-1355"></a>
</span><span id="__span-0-1356"><a id="__codelineno-0-1356" name="__codelineno-0-1356"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-1357"><a id="__codelineno-0-1357" name="__codelineno-0-1357"></a><span class="sd">    ------</span>
</span><span id="__span-0-1358"><a id="__codelineno-0-1358" name="__codelineno-0-1358"></a><span class="sd">      ValueError: If the given tensor has not been annotated a the number of</span>
</span><span id="__span-0-1359"><a id="__codelineno-0-1359" name="__codelineno-0-1359"></a><span class="sd">      buckets.</span>
</span><span id="__span-0-1360"><a id="__codelineno-0-1360" name="__codelineno-0-1360"></a>
</span><span id="__span-0-1361"><a id="__codelineno-0-1361" name="__codelineno-0-1361"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1362"><a id="__codelineno-0-1362" name="__codelineno-0-1362"></a><span class="sd">    -------</span>
</span><span id="__span-0-1363"><a id="__codelineno-0-1363" name="__codelineno-0-1363"></a><span class="sd">      A `Tensor` with the number of buckets for the given `transformed_feature`.</span>
</span><span id="__span-0-1364"><a id="__codelineno-0-1364" name="__codelineno-0-1364"></a><span class="sd">    """</span>
</span><span id="__span-0-1365"><a id="__codelineno-0-1365" name="__codelineno-0-1365"></a>    <span class="c1"># pyformat: enable</span>
</span><span id="__span-0-1366"><a id="__codelineno-0-1366" name="__codelineno-0-1366"></a>    <span class="c1"># Adding 1 to the 2nd Tensor of the returned pair in order to compute max + 1.</span>
</span><span id="__span-0-1367"><a id="__codelineno-0-1367" name="__codelineno-0-1367"></a>    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
</span><span id="__span-0-1368"><a id="__codelineno-0-1368" name="__codelineno-0-1368"></a>        <span class="n">schema_inference</span><span class="o">.</span><span class="n">get_tensor_schema_override</span><span class="p">(</span><span class="n">transformed_feature</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-1369"><a id="__codelineno-0-1369" name="__codelineno-0-1369"></a>        <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
</span><span id="__span-0-1370"><a id="__codelineno-0-1370" name="__codelineno-0-1370"></a>    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.get_transform_input_columns" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">get_transform_input_columns</span>


<a href="#tensorflow_transform.get_transform_input_columns" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">get_transform_input_columns</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">preprocessing_fn</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Callable


  
      module-attribute
   (typing.Callable)" href="#tensorflow_transform.Callable">Callable</a></span><span class="p">[</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>        <span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="            Mapping


  
      module-attribute
   (typing.Mapping)" href="#tensorflow_transform.Mapping">Mapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">]],</span> <span class="n"><a class="autorefs autorefs-internal" title="            Mapping


  
      module-attribute
   (typing.Mapping)" href="#tensorflow_transform.Mapping">Mapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">]</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="p">],</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">specs</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Mapping


  
      module-attribute
   (typing.Mapping)" href="#tensorflow_transform.Mapping">Mapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" title="            Union (typing.Union)" href="#tensorflow_transform.Union">Union</a></span><span class="p">[</span><span class="n"><span title="tensorflow_transform.common_types.FeatureSpecType">FeatureSpecType</span></span><span class="p">,</span> <span class="n"><span title="tensorflow.TypeSpec">TypeSpec</span></span><span class="p">]],</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">force_tf_compat_v1</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="            List


  
      module-attribute
   (typing.List)" href="#tensorflow_transform.List">List</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Return columns that are required inputs of <code>TransformDataset</code>.</p>
        <hr>
<p>preprocessing_fn: A tf.transform preprocessing_fn.
  specs: A dict of feature name to tf.TypeSpecs. If <code>force_tf_compat_v1</code> is
    True, this can also be feature specifications.
  force_tf_compat_v1: (Optional) If <code>True</code>, use Tensorflow in compat.v1 mode.
    Defaults to <code>False</code>.</p>
        <hr>
<p>A list of columns that are required inputs of the transform <code>tf.Graph</code>
  defined by <code>preprocessing_fn</code>.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/inspect_preprocessing_fn.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-87"><a id="__codelineno-0-87" name="__codelineno-0-87"></a><span class="k">def</span><span class="w"> </span><span class="nf">get_transform_input_columns</span><span class="p">(</span>
</span><span id="__span-0-88"><a id="__codelineno-0-88" name="__codelineno-0-88"></a>    <span class="n">preprocessing_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span>
</span><span id="__span-0-89"><a id="__codelineno-0-89" name="__codelineno-0-89"></a>        <span class="p">[</span><span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">]],</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">]</span>
</span><span id="__span-0-90"><a id="__codelineno-0-90" name="__codelineno-0-90"></a>    <span class="p">],</span>
</span><span id="__span-0-91"><a id="__codelineno-0-91" name="__codelineno-0-91"></a>    <span class="n">specs</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">common_types</span><span class="o">.</span><span class="n">FeatureSpecType</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">TypeSpec</span><span class="p">]],</span>
</span><span id="__span-0-92"><a id="__codelineno-0-92" name="__codelineno-0-92"></a>    <span class="n">force_tf_compat_v1</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-93"><a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
</span><span id="__span-0-94"><a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="w">    </span><span class="sd">"""Return columns that are required inputs of `TransformDataset`.</span>
</span><span id="__span-0-95"><a id="__codelineno-0-95" name="__codelineno-0-95"></a>
</span><span id="__span-0-96"><a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">    Args:</span>
</span><span id="__span-0-97"><a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">    ----</span>
</span><span id="__span-0-98"><a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="sd">      preprocessing_fn: A tf.transform preprocessing_fn.</span>
</span><span id="__span-0-99"><a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">      specs: A dict of feature name to tf.TypeSpecs. If `force_tf_compat_v1` is</span>
</span><span id="__span-0-100"><a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">        True, this can also be feature specifications.</span>
</span><span id="__span-0-101"><a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">      force_tf_compat_v1: (Optional) If `True`, use Tensorflow in compat.v1 mode.</span>
</span><span id="__span-0-102"><a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">        Defaults to `False`.</span>
</span><span id="__span-0-103"><a id="__codelineno-0-103" name="__codelineno-0-103"></a>
</span><span id="__span-0-104"><a id="__codelineno-0-104" name="__codelineno-0-104"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-105"><a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">    -------</span>
</span><span id="__span-0-106"><a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="sd">      A list of columns that are required inputs of the transform `tf.Graph`</span>
</span><span id="__span-0-107"><a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="sd">      defined by `preprocessing_fn`.</span>
</span><span id="__span-0-108"><a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="sd">    """</span>
</span><span id="__span-0-109"><a id="__codelineno-0-109" name="__codelineno-0-109"></a>    <span class="n">use_tf_compat_v1</span> <span class="o">=</span> <span class="n">tf2_utils</span><span class="o">.</span><span class="n">use_tf_compat_v1</span><span class="p">(</span><span class="n">force_tf_compat_v1</span><span class="p">)</span>
</span><span id="__span-0-110"><a id="__codelineno-0-110" name="__codelineno-0-110"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">use_tf_compat_v1</span><span class="p">:</span>
</span><span id="__span-0-111"><a id="__codelineno-0-111" name="__codelineno-0-111"></a>        <span class="k">assert</span> <span class="nb">all</span><span class="p">([</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">TypeSpec</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">specs</span><span class="o">.</span><span class="n">values</span><span class="p">()]),</span> <span class="n">specs</span>
</span><span id="__span-0-112"><a id="__codelineno-0-112" name="__codelineno-0-112"></a>    <span class="n">graph</span><span class="p">,</span> <span class="n">structured_inputs</span><span class="p">,</span> <span class="n">structured_outputs</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-113"><a id="__codelineno-0-113" name="__codelineno-0-113"></a>        <span class="n">impl_helper</span><span class="o">.</span><span class="n">trace_preprocessing_function</span><span class="p">(</span>
</span><span id="__span-0-114"><a id="__codelineno-0-114" name="__codelineno-0-114"></a>            <span class="n">preprocessing_fn</span><span class="p">,</span> <span class="n">specs</span><span class="p">,</span> <span class="n">use_tf_compat_v1</span><span class="o">=</span><span class="n">use_tf_compat_v1</span>
</span><span id="__span-0-115"><a id="__codelineno-0-115" name="__codelineno-0-115"></a>        <span class="p">)</span>
</span><span id="__span-0-116"><a id="__codelineno-0-116" name="__codelineno-0-116"></a>    <span class="p">)</span>
</span><span id="__span-0-117"><a id="__codelineno-0-117" name="__codelineno-0-117"></a>
</span><span id="__span-0-118"><a id="__codelineno-0-118" name="__codelineno-0-118"></a>    <span class="n">transform_input_tensors</span> <span class="o">=</span> <span class="n">graph_tools</span><span class="o">.</span><span class="n">get_dependent_inputs</span><span class="p">(</span>
</span><span id="__span-0-119"><a id="__codelineno-0-119" name="__codelineno-0-119"></a>        <span class="n">graph</span><span class="p">,</span> <span class="n">structured_inputs</span><span class="p">,</span> <span class="n">structured_outputs</span>
</span><span id="__span-0-120"><a id="__codelineno-0-120" name="__codelineno-0-120"></a>    <span class="p">)</span>
</span><span id="__span-0-121"><a id="__codelineno-0-121" name="__codelineno-0-121"></a>    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">transform_input_tensors</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.hash_strings" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">hash_strings</span>


<a href="#tensorflow_transform.hash_strings" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">hash_strings</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">strings</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">hash_buckets</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">key</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="            Iterable


  
      module-attribute
   (typing.Iterable)" href="#tensorflow_transform.Iterable">Iterable</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Hash strings into buckets.</p>
        <hr>
<p>strings: a <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of dtype <code>tf.string</code>.
  hash_buckets: the number of hash buckets.
  key: optional. An array of two Python <code>uint64</code>. If passed, output will be a
    deterministic function of <code>strings</code> and <code>key</code>. Note that hashing will be
    slower if this value is specified.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of dtype <code>tf.int64</code> with the
  same shape as
  the input <code>strings</code>.</p>
        <hr>
<p>TypeError: if <code>strings</code> is not a <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>
  of dtype <code>tf.string</code>.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1839">1839</a></span>
<span class="normal"><a href="#__codelineno-0-1840">1840</a></span>
<span class="normal"><a href="#__codelineno-0-1841">1841</a></span>
<span class="normal"><a href="#__codelineno-0-1842">1842</a></span>
<span class="normal"><a href="#__codelineno-0-1843">1843</a></span>
<span class="normal"><a href="#__codelineno-0-1844">1844</a></span>
<span class="normal"><a href="#__codelineno-0-1845">1845</a></span>
<span class="normal"><a href="#__codelineno-0-1846">1846</a></span>
<span class="normal"><a href="#__codelineno-0-1847">1847</a></span>
<span class="normal"><a href="#__codelineno-0-1848">1848</a></span>
<span class="normal"><a href="#__codelineno-0-1849">1849</a></span>
<span class="normal"><a href="#__codelineno-0-1850">1850</a></span>
<span class="normal"><a href="#__codelineno-0-1851">1851</a></span>
<span class="normal"><a href="#__codelineno-0-1852">1852</a></span>
<span class="normal"><a href="#__codelineno-0-1853">1853</a></span>
<span class="normal"><a href="#__codelineno-0-1854">1854</a></span>
<span class="normal"><a href="#__codelineno-0-1855">1855</a></span>
<span class="normal"><a href="#__codelineno-0-1856">1856</a></span>
<span class="normal"><a href="#__codelineno-0-1857">1857</a></span>
<span class="normal"><a href="#__codelineno-0-1858">1858</a></span>
<span class="normal"><a href="#__codelineno-0-1859">1859</a></span>
<span class="normal"><a href="#__codelineno-0-1860">1860</a></span>
<span class="normal"><a href="#__codelineno-0-1861">1861</a></span>
<span class="normal"><a href="#__codelineno-0-1862">1862</a></span>
<span class="normal"><a href="#__codelineno-0-1863">1863</a></span>
<span class="normal"><a href="#__codelineno-0-1864">1864</a></span>
<span class="normal"><a href="#__codelineno-0-1865">1865</a></span>
<span class="normal"><a href="#__codelineno-0-1866">1866</a></span>
<span class="normal"><a href="#__codelineno-0-1867">1867</a></span>
<span class="normal"><a href="#__codelineno-0-1868">1868</a></span>
<span class="normal"><a href="#__codelineno-0-1869">1869</a></span>
<span class="normal"><a href="#__codelineno-0-1870">1870</a></span>
<span class="normal"><a href="#__codelineno-0-1871">1871</a></span>
<span class="normal"><a href="#__codelineno-0-1872">1872</a></span>
<span class="normal"><a href="#__codelineno-0-1873">1873</a></span>
<span class="normal"><a href="#__codelineno-0-1874">1874</a></span>
<span class="normal"><a href="#__codelineno-0-1875">1875</a></span>
<span class="normal"><a href="#__codelineno-0-1876">1876</a></span>
<span class="normal"><a href="#__codelineno-0-1877">1877</a></span>
<span class="normal"><a href="#__codelineno-0-1878">1878</a></span>
<span class="normal"><a href="#__codelineno-0-1879">1879</a></span>
<span class="normal"><a href="#__codelineno-0-1880">1880</a></span>
<span class="normal"><a href="#__codelineno-0-1881">1881</a></span>
<span class="normal"><a href="#__codelineno-0-1882">1882</a></span>
<span class="normal"><a href="#__codelineno-0-1883">1883</a></span>
<span class="normal"><a href="#__codelineno-0-1884">1884</a></span>
<span class="normal"><a href="#__codelineno-0-1885">1885</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1839"><a id="__codelineno-0-1839" name="__codelineno-0-1839"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-1840"><a id="__codelineno-0-1840" name="__codelineno-0-1840"></a><span class="k">def</span><span class="w"> </span><span class="nf">hash_strings</span><span class="p">(</span>
</span><span id="__span-0-1841"><a id="__codelineno-0-1841" name="__codelineno-0-1841"></a>    <span class="n">strings</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">,</span>
</span><span id="__span-0-1842"><a id="__codelineno-0-1842" name="__codelineno-0-1842"></a>    <span class="n">hash_buckets</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-1843"><a id="__codelineno-0-1843" name="__codelineno-0-1843"></a>    <span class="n">key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1844"><a id="__codelineno-0-1844" name="__codelineno-0-1844"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1845"><a id="__codelineno-0-1845" name="__codelineno-0-1845"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">:</span>
</span><span id="__span-0-1846"><a id="__codelineno-0-1846" name="__codelineno-0-1846"></a><span class="w">    </span><span class="sd">"""Hash strings into buckets.</span>
</span><span id="__span-0-1847"><a id="__codelineno-0-1847" name="__codelineno-0-1847"></a>
</span><span id="__span-0-1848"><a id="__codelineno-0-1848" name="__codelineno-0-1848"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1849"><a id="__codelineno-0-1849" name="__codelineno-0-1849"></a><span class="sd">    ----</span>
</span><span id="__span-0-1850"><a id="__codelineno-0-1850" name="__codelineno-0-1850"></a><span class="sd">      strings: a `Tensor`, `SparseTensor`, or `RaggedTensor` of dtype `tf.string`.</span>
</span><span id="__span-0-1851"><a id="__codelineno-0-1851" name="__codelineno-0-1851"></a><span class="sd">      hash_buckets: the number of hash buckets.</span>
</span><span id="__span-0-1852"><a id="__codelineno-0-1852" name="__codelineno-0-1852"></a><span class="sd">      key: optional. An array of two Python `uint64`. If passed, output will be a</span>
</span><span id="__span-0-1853"><a id="__codelineno-0-1853" name="__codelineno-0-1853"></a><span class="sd">        deterministic function of `strings` and `key`. Note that hashing will be</span>
</span><span id="__span-0-1854"><a id="__codelineno-0-1854" name="__codelineno-0-1854"></a><span class="sd">        slower if this value is specified.</span>
</span><span id="__span-0-1855"><a id="__codelineno-0-1855" name="__codelineno-0-1855"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-1856"><a id="__codelineno-0-1856" name="__codelineno-0-1856"></a>
</span><span id="__span-0-1857"><a id="__codelineno-0-1857" name="__codelineno-0-1857"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1858"><a id="__codelineno-0-1858" name="__codelineno-0-1858"></a><span class="sd">    -------</span>
</span><span id="__span-0-1859"><a id="__codelineno-0-1859" name="__codelineno-0-1859"></a><span class="sd">      A `Tensor`, `SparseTensor`, or `RaggedTensor` of dtype `tf.int64` with the</span>
</span><span id="__span-0-1860"><a id="__codelineno-0-1860" name="__codelineno-0-1860"></a><span class="sd">      same shape as</span>
</span><span id="__span-0-1861"><a id="__codelineno-0-1861" name="__codelineno-0-1861"></a><span class="sd">      the input `strings`.</span>
</span><span id="__span-0-1862"><a id="__codelineno-0-1862" name="__codelineno-0-1862"></a>
</span><span id="__span-0-1863"><a id="__codelineno-0-1863" name="__codelineno-0-1863"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-1864"><a id="__codelineno-0-1864" name="__codelineno-0-1864"></a><span class="sd">    ------</span>
</span><span id="__span-0-1865"><a id="__codelineno-0-1865" name="__codelineno-0-1865"></a><span class="sd">      TypeError: if `strings` is not a `Tensor`, `SparseTensor`, or `RaggedTensor`</span>
</span><span id="__span-0-1866"><a id="__codelineno-0-1866" name="__codelineno-0-1866"></a><span class="sd">      of dtype `tf.string`.</span>
</span><span id="__span-0-1867"><a id="__codelineno-0-1867" name="__codelineno-0-1867"></a><span class="sd">    """</span>
</span><span id="__span-0-1868"><a id="__codelineno-0-1868" name="__codelineno-0-1868"></a>    <span class="k">if</span> <span class="p">(</span>
</span><span id="__span-0-1869"><a id="__codelineno-0-1869" name="__codelineno-0-1869"></a>        <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">strings</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">))</span>
</span><span id="__span-0-1870"><a id="__codelineno-0-1870" name="__codelineno-0-1870"></a>        <span class="ow">or</span> <span class="n">strings</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">tf</span><span class="o">.</span><span class="n">string</span>
</span><span id="__span-0-1871"><a id="__codelineno-0-1871" name="__codelineno-0-1871"></a>    <span class="p">):</span>
</span><span id="__span-0-1872"><a id="__codelineno-0-1872" name="__codelineno-0-1872"></a>        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
</span><span id="__span-0-1873"><a id="__codelineno-0-1873" name="__codelineno-0-1873"></a>            <span class="s2">"Input to hash_strings must be a `Tensor`, `SparseTensor`, or "</span>
</span><span id="__span-0-1874"><a id="__codelineno-0-1874" name="__codelineno-0-1874"></a>            <span class="sa">f</span><span class="s2">"`RaggedTensor` of dtype string; got </span><span class="si">{</span><span class="n">strings</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">"</span>
</span><span id="__span-0-1875"><a id="__codelineno-0-1875" name="__codelineno-0-1875"></a>        <span class="p">)</span>
</span><span id="__span-0-1876"><a id="__codelineno-0-1876" name="__codelineno-0-1876"></a>    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">strings</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
</span><span id="__span-0-1877"><a id="__codelineno-0-1877" name="__codelineno-0-1877"></a>        <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-1878"><a id="__codelineno-0-1878" name="__codelineno-0-1878"></a>            <span class="n">name</span> <span class="o">=</span> <span class="s2">"hash_strings"</span>
</span><span id="__span-0-1879"><a id="__codelineno-0-1879" name="__codelineno-0-1879"></a>        <span class="k">if</span> <span class="n">key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-1880"><a id="__codelineno-0-1880" name="__codelineno-0-1880"></a>            <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">to_hash_bucket_fast</span><span class="p">(</span><span class="n">strings</span><span class="p">,</span> <span class="n">hash_buckets</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
</span><span id="__span-0-1881"><a id="__codelineno-0-1881" name="__codelineno-0-1881"></a>        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">to_hash_bucket_strong</span><span class="p">(</span><span class="n">strings</span><span class="p">,</span> <span class="n">hash_buckets</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
</span><span id="__span-0-1882"><a id="__codelineno-0-1882" name="__codelineno-0-1882"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-1883"><a id="__codelineno-0-1883" name="__codelineno-0-1883"></a>        <span class="n">compose_result_fn</span> <span class="o">=</span> <span class="n">_make_composite_tensor_wrapper_if_composite</span><span class="p">(</span><span class="n">strings</span><span class="p">)</span>
</span><span id="__span-0-1884"><a id="__codelineno-0-1884" name="__codelineno-0-1884"></a>        <span class="n">values</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">get_values</span><span class="p">(</span><span class="n">strings</span><span class="p">)</span>
</span><span id="__span-0-1885"><a id="__codelineno-0-1885" name="__codelineno-0-1885"></a>        <span class="k">return</span> <span class="n">compose_result_fn</span><span class="p">(</span><span class="n">hash_strings</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">hash_buckets</span><span class="p">,</span> <span class="n">key</span><span class="p">))</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.histogram" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">histogram</span>


<a href="#tensorflow_transform.histogram" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">histogram</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">boundaries</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="            Union (typing.Union)" href="#tensorflow_transform.Union">Union</a></span><span class="p">[</span><span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">categorical</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="            Tuple


  
      module-attribute
   (typing.Tuple)" href="#tensorflow_transform.Tuple">Tuple</a></span><span class="p">[</span><span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes a histogram over x, given the bin boundaries or bin count.</p>
<p>Ex (1):
counts, boundaries = histogram([0, 1, 0, 1, 0, 3, 0, 1], range(5))
counts: [4, 3, 0, 1, 0]
boundaries: [0, 1, 2, 3, 4]</p>
<p>Ex (2):
Can be used to compute class weights.
counts, classes = histogram([0, 1, 0, 1, 0, 3, 0, 1], categorical=True)
probabilities = counts / tf.reduce_sum(counts)
class_weights = dict(map(lambda (a, b): (a.numpy(), 1.0 / b.numpy()),
                         zip(classes, probabilities)))</p>
        <hr>
<p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.
  boundaries: (Optional) A <code>Tensor</code> or <code>int</code> used to build the histogram;
    ignored if <code>categorical</code> is True. If possible, provide boundaries as
    multiple sorted values.  Default to 10 intervals over the 0-1 range, or
    find the min/max if an int is provided (not recommended because
    multi-phase analysis is inefficient).
  categorical: (Optional) A <code>bool</code> that treats <code>x</code> as discrete values if true.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>counts: The histogram, as counts per bin.
  boundaries: A <code>Tensor</code> used to build the histogram representing boundaries.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/analyzers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-730">730</a></span>
<span class="normal"><a href="#__codelineno-0-731">731</a></span>
<span class="normal"><a href="#__codelineno-0-732">732</a></span>
<span class="normal"><a href="#__codelineno-0-733">733</a></span>
<span class="normal"><a href="#__codelineno-0-734">734</a></span>
<span class="normal"><a href="#__codelineno-0-735">735</a></span>
<span class="normal"><a href="#__codelineno-0-736">736</a></span>
<span class="normal"><a href="#__codelineno-0-737">737</a></span>
<span class="normal"><a href="#__codelineno-0-738">738</a></span>
<span class="normal"><a href="#__codelineno-0-739">739</a></span>
<span class="normal"><a href="#__codelineno-0-740">740</a></span>
<span class="normal"><a href="#__codelineno-0-741">741</a></span>
<span class="normal"><a href="#__codelineno-0-742">742</a></span>
<span class="normal"><a href="#__codelineno-0-743">743</a></span>
<span class="normal"><a href="#__codelineno-0-744">744</a></span>
<span class="normal"><a href="#__codelineno-0-745">745</a></span>
<span class="normal"><a href="#__codelineno-0-746">746</a></span>
<span class="normal"><a href="#__codelineno-0-747">747</a></span>
<span class="normal"><a href="#__codelineno-0-748">748</a></span>
<span class="normal"><a href="#__codelineno-0-749">749</a></span>
<span class="normal"><a href="#__codelineno-0-750">750</a></span>
<span class="normal"><a href="#__codelineno-0-751">751</a></span>
<span class="normal"><a href="#__codelineno-0-752">752</a></span>
<span class="normal"><a href="#__codelineno-0-753">753</a></span>
<span class="normal"><a href="#__codelineno-0-754">754</a></span>
<span class="normal"><a href="#__codelineno-0-755">755</a></span>
<span class="normal"><a href="#__codelineno-0-756">756</a></span>
<span class="normal"><a href="#__codelineno-0-757">757</a></span>
<span class="normal"><a href="#__codelineno-0-758">758</a></span>
<span class="normal"><a href="#__codelineno-0-759">759</a></span>
<span class="normal"><a href="#__codelineno-0-760">760</a></span>
<span class="normal"><a href="#__codelineno-0-761">761</a></span>
<span class="normal"><a href="#__codelineno-0-762">762</a></span>
<span class="normal"><a href="#__codelineno-0-763">763</a></span>
<span class="normal"><a href="#__codelineno-0-764">764</a></span>
<span class="normal"><a href="#__codelineno-0-765">765</a></span>
<span class="normal"><a href="#__codelineno-0-766">766</a></span>
<span class="normal"><a href="#__codelineno-0-767">767</a></span>
<span class="normal"><a href="#__codelineno-0-768">768</a></span>
<span class="normal"><a href="#__codelineno-0-769">769</a></span>
<span class="normal"><a href="#__codelineno-0-770">770</a></span>
<span class="normal"><a href="#__codelineno-0-771">771</a></span>
<span class="normal"><a href="#__codelineno-0-772">772</a></span>
<span class="normal"><a href="#__codelineno-0-773">773</a></span>
<span class="normal"><a href="#__codelineno-0-774">774</a></span>
<span class="normal"><a href="#__codelineno-0-775">775</a></span>
<span class="normal"><a href="#__codelineno-0-776">776</a></span>
<span class="normal"><a href="#__codelineno-0-777">777</a></span>
<span class="normal"><a href="#__codelineno-0-778">778</a></span>
<span class="normal"><a href="#__codelineno-0-779">779</a></span>
<span class="normal"><a href="#__codelineno-0-780">780</a></span>
<span class="normal"><a href="#__codelineno-0-781">781</a></span>
<span class="normal"><a href="#__codelineno-0-782">782</a></span>
<span class="normal"><a href="#__codelineno-0-783">783</a></span>
<span class="normal"><a href="#__codelineno-0-784">784</a></span>
<span class="normal"><a href="#__codelineno-0-785">785</a></span>
<span class="normal"><a href="#__codelineno-0-786">786</a></span>
<span class="normal"><a href="#__codelineno-0-787">787</a></span>
<span class="normal"><a href="#__codelineno-0-788">788</a></span>
<span class="normal"><a href="#__codelineno-0-789">789</a></span>
<span class="normal"><a href="#__codelineno-0-790">790</a></span>
<span class="normal"><a href="#__codelineno-0-791">791</a></span>
<span class="normal"><a href="#__codelineno-0-792">792</a></span>
<span class="normal"><a href="#__codelineno-0-793">793</a></span>
<span class="normal"><a href="#__codelineno-0-794">794</a></span>
<span class="normal"><a href="#__codelineno-0-795">795</a></span>
<span class="normal"><a href="#__codelineno-0-796">796</a></span>
<span class="normal"><a href="#__codelineno-0-797">797</a></span>
<span class="normal"><a href="#__codelineno-0-798">798</a></span>
<span class="normal"><a href="#__codelineno-0-799">799</a></span>
<span class="normal"><a href="#__codelineno-0-800">800</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-730"><a id="__codelineno-0-730" name="__codelineno-0-730"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">ANALYZER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-731"><a id="__codelineno-0-731" name="__codelineno-0-731"></a><span class="k">def</span><span class="w"> </span><span class="nf">histogram</span><span class="p">(</span>
</span><span id="__span-0-732"><a id="__codelineno-0-732" name="__codelineno-0-732"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span>
</span><span id="__span-0-733"><a id="__codelineno-0-733" name="__codelineno-0-733"></a>    <span class="n">boundaries</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-734"><a id="__codelineno-0-734" name="__codelineno-0-734"></a>    <span class="n">categorical</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-735"><a id="__codelineno-0-735" name="__codelineno-0-735"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-736"><a id="__codelineno-0-736" name="__codelineno-0-736"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span id="__span-0-737"><a id="__codelineno-0-737" name="__codelineno-0-737"></a><span class="w">    </span><span class="sd">"""Computes a histogram over x, given the bin boundaries or bin count.</span>
</span><span id="__span-0-738"><a id="__codelineno-0-738" name="__codelineno-0-738"></a>
</span><span id="__span-0-739"><a id="__codelineno-0-739" name="__codelineno-0-739"></a><span class="sd">    Ex (1):</span>
</span><span id="__span-0-740"><a id="__codelineno-0-740" name="__codelineno-0-740"></a><span class="sd">    counts, boundaries = histogram([0, 1, 0, 1, 0, 3, 0, 1], range(5))</span>
</span><span id="__span-0-741"><a id="__codelineno-0-741" name="__codelineno-0-741"></a><span class="sd">    counts: [4, 3, 0, 1, 0]</span>
</span><span id="__span-0-742"><a id="__codelineno-0-742" name="__codelineno-0-742"></a><span class="sd">    boundaries: [0, 1, 2, 3, 4]</span>
</span><span id="__span-0-743"><a id="__codelineno-0-743" name="__codelineno-0-743"></a>
</span><span id="__span-0-744"><a id="__codelineno-0-744" name="__codelineno-0-744"></a><span class="sd">    Ex (2):</span>
</span><span id="__span-0-745"><a id="__codelineno-0-745" name="__codelineno-0-745"></a><span class="sd">    Can be used to compute class weights.</span>
</span><span id="__span-0-746"><a id="__codelineno-0-746" name="__codelineno-0-746"></a><span class="sd">    counts, classes = histogram([0, 1, 0, 1, 0, 3, 0, 1], categorical=True)</span>
</span><span id="__span-0-747"><a id="__codelineno-0-747" name="__codelineno-0-747"></a><span class="sd">    probabilities = counts / tf.reduce_sum(counts)</span>
</span><span id="__span-0-748"><a id="__codelineno-0-748" name="__codelineno-0-748"></a><span class="sd">    class_weights = dict(map(lambda (a, b): (a.numpy(), 1.0 / b.numpy()),</span>
</span><span id="__span-0-749"><a id="__codelineno-0-749" name="__codelineno-0-749"></a><span class="sd">                             zip(classes, probabilities)))</span>
</span><span id="__span-0-750"><a id="__codelineno-0-750" name="__codelineno-0-750"></a>
</span><span id="__span-0-751"><a id="__codelineno-0-751" name="__codelineno-0-751"></a><span class="sd">    Args:</span>
</span><span id="__span-0-752"><a id="__codelineno-0-752" name="__codelineno-0-752"></a><span class="sd">    ----</span>
</span><span id="__span-0-753"><a id="__codelineno-0-753" name="__codelineno-0-753"></a><span class="sd">      x: A `Tensor`, `SparseTensor`, or `RaggedTensor`.</span>
</span><span id="__span-0-754"><a id="__codelineno-0-754" name="__codelineno-0-754"></a><span class="sd">      boundaries: (Optional) A `Tensor` or `int` used to build the histogram;</span>
</span><span id="__span-0-755"><a id="__codelineno-0-755" name="__codelineno-0-755"></a><span class="sd">        ignored if `categorical` is True. If possible, provide boundaries as</span>
</span><span id="__span-0-756"><a id="__codelineno-0-756" name="__codelineno-0-756"></a><span class="sd">        multiple sorted values.  Default to 10 intervals over the 0-1 range, or</span>
</span><span id="__span-0-757"><a id="__codelineno-0-757" name="__codelineno-0-757"></a><span class="sd">        find the min/max if an int is provided (not recommended because</span>
</span><span id="__span-0-758"><a id="__codelineno-0-758" name="__codelineno-0-758"></a><span class="sd">        multi-phase analysis is inefficient).</span>
</span><span id="__span-0-759"><a id="__codelineno-0-759" name="__codelineno-0-759"></a><span class="sd">      categorical: (Optional) A `bool` that treats `x` as discrete values if true.</span>
</span><span id="__span-0-760"><a id="__codelineno-0-760" name="__codelineno-0-760"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-761"><a id="__codelineno-0-761" name="__codelineno-0-761"></a>
</span><span id="__span-0-762"><a id="__codelineno-0-762" name="__codelineno-0-762"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-763"><a id="__codelineno-0-763" name="__codelineno-0-763"></a><span class="sd">    -------</span>
</span><span id="__span-0-764"><a id="__codelineno-0-764" name="__codelineno-0-764"></a><span class="sd">      counts: The histogram, as counts per bin.</span>
</span><span id="__span-0-765"><a id="__codelineno-0-765" name="__codelineno-0-765"></a><span class="sd">      boundaries: A `Tensor` used to build the histogram representing boundaries.</span>
</span><span id="__span-0-766"><a id="__codelineno-0-766" name="__codelineno-0-766"></a><span class="sd">    """</span>
</span><span id="__span-0-767"><a id="__codelineno-0-767" name="__codelineno-0-767"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"histogram"</span><span class="p">):</span>
</span><span id="__span-0-768"><a id="__codelineno-0-768" name="__codelineno-0-768"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf_utils</span><span class="o">.</span><span class="n">get_values</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="__span-0-769"><a id="__codelineno-0-769" name="__codelineno-0-769"></a>        <span class="k">if</span> <span class="n">categorical</span><span class="p">:</span>
</span><span id="__span-0-770"><a id="__codelineno-0-770" name="__codelineno-0-770"></a>            <span class="n">x_dtype</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-0-771"><a id="__codelineno-0-771" name="__codelineno-0-771"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="k">if</span> <span class="n">x_dtype</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">string</span> <span class="k">else</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">as_string</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-0-772"><a id="__codelineno-0-772" name="__codelineno-0-772"></a>            <span class="n">elements</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">count_per_key</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-0-773"><a id="__codelineno-0-773" name="__codelineno-0-773"></a>            <span class="k">if</span> <span class="n">x_dtype</span> <span class="o">!=</span> <span class="n">elements</span><span class="o">.</span><span class="n">dtype</span><span class="p">:</span>
</span><span id="__span-0-774"><a id="__codelineno-0-774" name="__codelineno-0-774"></a>                <span class="n">elements</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">to_number</span><span class="p">(</span><span class="n">elements</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span><span id="__span-0-775"><a id="__codelineno-0-775" name="__codelineno-0-775"></a>            <span class="k">return</span> <span class="n">counts</span><span class="p">,</span> <span class="n">elements</span>
</span><span id="__span-0-776"><a id="__codelineno-0-776" name="__codelineno-0-776"></a>
</span><span id="__span-0-777"><a id="__codelineno-0-777" name="__codelineno-0-777"></a>        <span class="k">if</span> <span class="n">boundaries</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-778"><a id="__codelineno-0-778" name="__codelineno-0-778"></a>            <span class="n">boundaries</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="mf">10.0</span>
</span><span id="__span-0-779"><a id="__codelineno-0-779" name="__codelineno-0-779"></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">boundaries</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
</span><span id="__span-0-780"><a id="__codelineno-0-780" name="__codelineno-0-780"></a>            <span class="nb">isinstance</span><span class="p">(</span><span class="n">boundaries</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">boundaries</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">ndims</span> <span class="o">==</span> <span class="mi">0</span>
</span><span id="__span-0-781"><a id="__codelineno-0-781" name="__codelineno-0-781"></a>        <span class="p">):</span>
</span><span id="__span-0-782"><a id="__codelineno-0-782" name="__codelineno-0-782"></a>            <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span> <span class="o">=</span> <span class="n">_min_and_max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="__span-0-783"><a id="__codelineno-0-783" name="__codelineno-0-783"></a>            <span class="n">boundaries</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span>
</span><span id="__span-0-784"><a id="__codelineno-0-784" name="__codelineno-0-784"></a>                <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">min_value</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
</span><span id="__span-0-785"><a id="__codelineno-0-785" name="__codelineno-0-785"></a>                <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">max_value</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
</span><span id="__span-0-786"><a id="__codelineno-0-786" name="__codelineno-0-786"></a>                <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">boundaries</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
</span><span id="__span-0-787"><a id="__codelineno-0-787" name="__codelineno-0-787"></a>            <span class="p">)</span>
</span><span id="__span-0-788"><a id="__codelineno-0-788" name="__codelineno-0-788"></a>
</span><span id="__span-0-789"><a id="__codelineno-0-789" name="__codelineno-0-789"></a>        <span class="c1"># Shift the boundaries slightly to account for floating point errors,</span>
</span><span id="__span-0-790"><a id="__codelineno-0-790" name="__codelineno-0-790"></a>        <span class="c1"># and due to the fact that the rightmost boundary is essentially ignored.</span>
</span><span id="__span-0-791"><a id="__codelineno-0-791" name="__codelineno-0-791"></a>        <span class="n">boundaries</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">boundaries</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.0001</span>
</span><span id="__span-0-792"><a id="__codelineno-0-792" name="__codelineno-0-792"></a>
</span><span id="__span-0-793"><a id="__codelineno-0-793" name="__codelineno-0-793"></a>        <span class="n">bucket_indices</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">assign_buckets</span><span class="p">(</span>
</span><span id="__span-0-794"><a id="__codelineno-0-794" name="__codelineno-0-794"></a>            <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">remove_leftmost_boundary</span><span class="p">(</span><span class="n">boundaries</span><span class="p">)</span>
</span><span id="__span-0-795"><a id="__codelineno-0-795" name="__codelineno-0-795"></a>        <span class="p">)</span>
</span><span id="__span-0-796"><a id="__codelineno-0-796" name="__codelineno-0-796"></a>        <span class="n">bucket_vocab</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">count_per_key</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">as_string</span><span class="p">(</span><span class="n">bucket_indices</span><span class="p">))</span>
</span><span id="__span-0-797"><a id="__codelineno-0-797" name="__codelineno-0-797"></a>        <span class="n">counts</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">reorder_histogram</span><span class="p">(</span>
</span><span id="__span-0-798"><a id="__codelineno-0-798" name="__codelineno-0-798"></a>            <span class="n">bucket_vocab</span><span class="p">,</span> <span class="n">counts</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">boundaries</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
</span><span id="__span-0-799"><a id="__codelineno-0-799" name="__codelineno-0-799"></a>        <span class="p">)</span>
</span><span id="__span-0-800"><a id="__codelineno-0-800" name="__codelineno-0-800"></a>        <span class="k">return</span> <span class="n">counts</span><span class="p">,</span> <span class="n">boundaries</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.make_and_track_object" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">make_and_track_object</span>


<a href="#tensorflow_transform.make_and_track_object" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">make_and_track_object</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">trackable_factory_callable</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Callable


  
      module-attribute
   (typing.Callable)" href="#tensorflow_transform.Callable">Callable</a></span><span class="p">[[],</span> <span class="n"><span title="tensorflow.python.trackable.base.Trackable">Trackable</span></span><span class="p">],</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow.python.trackable.base.Trackable">Trackable</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Keeps track of the object created by invoking <code>trackable_factory_callable</code>.</p>
<p>This API is only for use when Transform APIs are run with TF2 behaviors
enabled and <code>tft_beam.Context.force_tf_compat_v1</code> is set to False.</p>
<p>Use this API to track TF Trackable objects created in the <code>preprocessing_fn</code>
such as tf.hub modules, tf.data.Dataset etc. This ensures they are serialized
correctly when exporting to SavedModel.</p>
        <hr>
<p>trackable_factory_callable: A callable that creates and returns a Trackable
    object.
  name: (Optional) Provide a unique name to track this object with. If the
    Trackable object created is a Keras Layer or Model this is needed for
    proper tracking.</p>
<h6 id="tensorflow_transform.make_and_track_object--example">Example:<a class="headerlink" href="#tensorflow_transform.make_and_track_object--example" title="Permanent link">Â¶</a></h6>
<blockquote>
<blockquote>
<blockquote>
<p>def preprocessing_fn(inputs):
...   dataset = tft.make_and_track_object(
...       lambda: tf.data.Dataset.from_tensor_slices([1, 2, 3]))
...   with tf.init_scope():
...     dataset_list = list(dataset.as_numpy_iterator())
...   return {'x_0': dataset_list[0] + inputs['x']}
raw_data = [dict(x=1), dict(x=2), dict(x=3)]
feature_spec = dict(x=tf.io.FixedLenFeature([], tf.int64))
raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec)
with tft_beam.Context(temp_dir=tempfile.mkdtemp(),
...                       force_tf_compat_v1=False):
...   transformed_dataset, transform_fn = (
...       (raw_data, raw_data_metadata)
...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))
transformed_data, transformed_metadata = transformed_dataset
transformed_data
[{'x_0': 2}, {'x_0': 3}, {'x_0': 4}]</p>
</blockquote>
</blockquote>
</blockquote>
        <hr>
<p>The object returned when trackable_factory_callable is invoked. The object
  creation is lifted out to the eager context using <code>tf.init_scope</code>.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/annotators.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-128"><a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="k">def</span><span class="w"> </span><span class="nf">make_and_track_object</span><span class="p">(</span>
</span><span id="__span-0-129"><a id="__codelineno-0-129" name="__codelineno-0-129"></a>    <span class="n">trackable_factory_callable</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">base</span><span class="o">.</span><span class="n">Trackable</span><span class="p">],</span> <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-130"><a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">base</span><span class="o">.</span><span class="n">Trackable</span><span class="p">:</span>
</span><span id="__span-0-131"><a id="__codelineno-0-131" name="__codelineno-0-131"></a>    <span class="c1"># pyformat: disable</span>
</span><span id="__span-0-132"><a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="w">    </span><span class="sd">"""Keeps track of the object created by invoking `trackable_factory_callable`.</span>
</span><span id="__span-0-133"><a id="__codelineno-0-133" name="__codelineno-0-133"></a>
</span><span id="__span-0-134"><a id="__codelineno-0-134" name="__codelineno-0-134"></a><span class="sd">    This API is only for use when Transform APIs are run with TF2 behaviors</span>
</span><span id="__span-0-135"><a id="__codelineno-0-135" name="__codelineno-0-135"></a><span class="sd">    enabled and `tft_beam.Context.force_tf_compat_v1` is set to False.</span>
</span><span id="__span-0-136"><a id="__codelineno-0-136" name="__codelineno-0-136"></a>
</span><span id="__span-0-137"><a id="__codelineno-0-137" name="__codelineno-0-137"></a><span class="sd">    Use this API to track TF Trackable objects created in the `preprocessing_fn`</span>
</span><span id="__span-0-138"><a id="__codelineno-0-138" name="__codelineno-0-138"></a><span class="sd">    such as tf.hub modules, tf.data.Dataset etc. This ensures they are serialized</span>
</span><span id="__span-0-139"><a id="__codelineno-0-139" name="__codelineno-0-139"></a><span class="sd">    correctly when exporting to SavedModel.</span>
</span><span id="__span-0-140"><a id="__codelineno-0-140" name="__codelineno-0-140"></a>
</span><span id="__span-0-141"><a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="sd">    Args:</span>
</span><span id="__span-0-142"><a id="__codelineno-0-142" name="__codelineno-0-142"></a><span class="sd">    ----</span>
</span><span id="__span-0-143"><a id="__codelineno-0-143" name="__codelineno-0-143"></a><span class="sd">      trackable_factory_callable: A callable that creates and returns a Trackable</span>
</span><span id="__span-0-144"><a id="__codelineno-0-144" name="__codelineno-0-144"></a><span class="sd">        object.</span>
</span><span id="__span-0-145"><a id="__codelineno-0-145" name="__codelineno-0-145"></a><span class="sd">      name: (Optional) Provide a unique name to track this object with. If the</span>
</span><span id="__span-0-146"><a id="__codelineno-0-146" name="__codelineno-0-146"></a><span class="sd">        Trackable object created is a Keras Layer or Model this is needed for</span>
</span><span id="__span-0-147"><a id="__codelineno-0-147" name="__codelineno-0-147"></a><span class="sd">        proper tracking.</span>
</span><span id="__span-0-148"><a id="__codelineno-0-148" name="__codelineno-0-148"></a>
</span><span id="__span-0-149"><a id="__codelineno-0-149" name="__codelineno-0-149"></a><span class="sd">    Example:</span>
</span><span id="__span-0-150"><a id="__codelineno-0-150" name="__codelineno-0-150"></a><span class="sd">    -------</span>
</span><span id="__span-0-151"><a id="__codelineno-0-151" name="__codelineno-0-151"></a><span class="sd">    &gt;&gt;&gt; def preprocessing_fn(inputs):</span>
</span><span id="__span-0-152"><a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="sd">    ...   dataset = tft.make_and_track_object(</span>
</span><span id="__span-0-153"><a id="__codelineno-0-153" name="__codelineno-0-153"></a><span class="sd">    ...       lambda: tf.data.Dataset.from_tensor_slices([1, 2, 3]))</span>
</span><span id="__span-0-154"><a id="__codelineno-0-154" name="__codelineno-0-154"></a><span class="sd">    ...   with tf.init_scope():</span>
</span><span id="__span-0-155"><a id="__codelineno-0-155" name="__codelineno-0-155"></a><span class="sd">    ...     dataset_list = list(dataset.as_numpy_iterator())</span>
</span><span id="__span-0-156"><a id="__codelineno-0-156" name="__codelineno-0-156"></a><span class="sd">    ...   return {'x_0': dataset_list[0] + inputs['x']}</span>
</span><span id="__span-0-157"><a id="__codelineno-0-157" name="__codelineno-0-157"></a><span class="sd">    &gt;&gt;&gt; raw_data = [dict(x=1), dict(x=2), dict(x=3)]</span>
</span><span id="__span-0-158"><a id="__codelineno-0-158" name="__codelineno-0-158"></a><span class="sd">    &gt;&gt;&gt; feature_spec = dict(x=tf.io.FixedLenFeature([], tf.int64))</span>
</span><span id="__span-0-159"><a id="__codelineno-0-159" name="__codelineno-0-159"></a><span class="sd">    &gt;&gt;&gt; raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec)</span>
</span><span id="__span-0-160"><a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="sd">    &gt;&gt;&gt; with tft_beam.Context(temp_dir=tempfile.mkdtemp(),</span>
</span><span id="__span-0-161"><a id="__codelineno-0-161" name="__codelineno-0-161"></a><span class="sd">    ...                       force_tf_compat_v1=False):</span>
</span><span id="__span-0-162"><a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="sd">    ...   transformed_dataset, transform_fn = (</span>
</span><span id="__span-0-163"><a id="__codelineno-0-163" name="__codelineno-0-163"></a><span class="sd">    ...       (raw_data, raw_data_metadata)</span>
</span><span id="__span-0-164"><a id="__codelineno-0-164" name="__codelineno-0-164"></a><span class="sd">    ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))</span>
</span><span id="__span-0-165"><a id="__codelineno-0-165" name="__codelineno-0-165"></a><span class="sd">    &gt;&gt;&gt; transformed_data, transformed_metadata = transformed_dataset</span>
</span><span id="__span-0-166"><a id="__codelineno-0-166" name="__codelineno-0-166"></a><span class="sd">    &gt;&gt;&gt; transformed_data</span>
</span><span id="__span-0-167"><a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="sd">    [{'x_0': 2}, {'x_0': 3}, {'x_0': 4}]</span>
</span><span id="__span-0-168"><a id="__codelineno-0-168" name="__codelineno-0-168"></a>
</span><span id="__span-0-169"><a id="__codelineno-0-169" name="__codelineno-0-169"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-170"><a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">    -------</span>
</span><span id="__span-0-171"><a id="__codelineno-0-171" name="__codelineno-0-171"></a><span class="sd">      The object returned when trackable_factory_callable is invoked. The object</span>
</span><span id="__span-0-172"><a id="__codelineno-0-172" name="__codelineno-0-172"></a><span class="sd">      creation is lifted out to the eager context using `tf.init_scope`.</span>
</span><span id="__span-0-173"><a id="__codelineno-0-173" name="__codelineno-0-173"></a><span class="sd">    """</span>
</span><span id="__span-0-174"><a id="__codelineno-0-174" name="__codelineno-0-174"></a>    <span class="c1"># pyformat: enable</span>
</span><span id="__span-0-175"><a id="__codelineno-0-175" name="__codelineno-0-175"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">inside_function</span><span class="p">():</span>
</span><span id="__span-0-176"><a id="__codelineno-0-176" name="__codelineno-0-176"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="__span-0-177"><a id="__codelineno-0-177" name="__codelineno-0-177"></a>            <span class="s2">"This API should only be invoked inside the user defined "</span>
</span><span id="__span-0-178"><a id="__codelineno-0-178" name="__codelineno-0-178"></a>            <span class="s2">"`preprocessing_fn` with TF2 behaviors enabled and "</span>
</span><span id="__span-0-179"><a id="__codelineno-0-179" name="__codelineno-0-179"></a>            <span class="s2">"`force_tf_compat_v1=False`. "</span>
</span><span id="__span-0-180"><a id="__codelineno-0-180" name="__codelineno-0-180"></a>        <span class="p">)</span>
</span><span id="__span-0-181"><a id="__codelineno-0-181" name="__codelineno-0-181"></a>    <span class="n">result</span> <span class="o">=</span> <span class="n">_get_object</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="__span-0-182"><a id="__codelineno-0-182" name="__codelineno-0-182"></a>    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-183"><a id="__codelineno-0-183" name="__codelineno-0-183"></a>        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">init_scope</span><span class="p">():</span>
</span><span id="__span-0-184"><a id="__codelineno-0-184" name="__codelineno-0-184"></a>            <span class="n">result</span> <span class="o">=</span> <span class="n">trackable_factory_callable</span><span class="p">()</span>
</span><span id="__span-0-185"><a id="__codelineno-0-185" name="__codelineno-0-185"></a>            <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">tf_keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
</span><span id="__span-0-186"><a id="__codelineno-0-186" name="__codelineno-0-186"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="__span-0-187"><a id="__codelineno-0-187" name="__codelineno-0-187"></a>                    <span class="s2">"Please pass a unique `name` to this API to ensure Keras objects "</span>
</span><span id="__span-0-188"><a id="__codelineno-0-188" name="__codelineno-0-188"></a>                    <span class="s2">"are tracked correctly."</span>
</span><span id="__span-0-189"><a id="__codelineno-0-189" name="__codelineno-0-189"></a>                <span class="p">)</span>
</span><span id="__span-0-190"><a id="__codelineno-0-190" name="__codelineno-0-190"></a>            <span class="n">track_object</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
</span><span id="__span-0-191"><a id="__codelineno-0-191" name="__codelineno-0-191"></a>    <span class="k">return</span> <span class="n">result</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.max" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">max</span>


<a href="#tensorflow_transform.max" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">max</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">reduce_instance_dims</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes the maximum of the values of <code>x</code> over the whole dataset.</p>
<p>In the case of a <code>CompositeTensor</code> missing values will be used in return
value: for float, NaN is used and for other dtypes the min is used.</p>
        <hr>
<p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.
  reduce_instance_dims: By default collapses the batch and instance dimensions
    to arrive at a single scalar output. If False, only collapses the batch
    dimension and outputs a vector of the same shape as the input.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>A <code>Tensor</code>. Has the same type as <code>x</code>.</p>
        <hr>
<p>TypeError: If the type of <code>x</code> is not supported.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/analyzers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-473">473</a></span>
<span class="normal"><a href="#__codelineno-0-474">474</a></span>
<span class="normal"><a href="#__codelineno-0-475">475</a></span>
<span class="normal"><a href="#__codelineno-0-476">476</a></span>
<span class="normal"><a href="#__codelineno-0-477">477</a></span>
<span class="normal"><a href="#__codelineno-0-478">478</a></span>
<span class="normal"><a href="#__codelineno-0-479">479</a></span>
<span class="normal"><a href="#__codelineno-0-480">480</a></span>
<span class="normal"><a href="#__codelineno-0-481">481</a></span>
<span class="normal"><a href="#__codelineno-0-482">482</a></span>
<span class="normal"><a href="#__codelineno-0-483">483</a></span>
<span class="normal"><a href="#__codelineno-0-484">484</a></span>
<span class="normal"><a href="#__codelineno-0-485">485</a></span>
<span class="normal"><a href="#__codelineno-0-486">486</a></span>
<span class="normal"><a href="#__codelineno-0-487">487</a></span>
<span class="normal"><a href="#__codelineno-0-488">488</a></span>
<span class="normal"><a href="#__codelineno-0-489">489</a></span>
<span class="normal"><a href="#__codelineno-0-490">490</a></span>
<span class="normal"><a href="#__codelineno-0-491">491</a></span>
<span class="normal"><a href="#__codelineno-0-492">492</a></span>
<span class="normal"><a href="#__codelineno-0-493">493</a></span>
<span class="normal"><a href="#__codelineno-0-494">494</a></span>
<span class="normal"><a href="#__codelineno-0-495">495</a></span>
<span class="normal"><a href="#__codelineno-0-496">496</a></span>
<span class="normal"><a href="#__codelineno-0-497">497</a></span>
<span class="normal"><a href="#__codelineno-0-498">498</a></span>
<span class="normal"><a href="#__codelineno-0-499">499</a></span>
<span class="normal"><a href="#__codelineno-0-500">500</a></span>
<span class="normal"><a href="#__codelineno-0-501">501</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-473"><a id="__codelineno-0-473" name="__codelineno-0-473"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">ANALYZER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-474"><a id="__codelineno-0-474" name="__codelineno-0-474"></a><span class="k">def</span><span class="w"> </span><span class="nf">max</span><span class="p">(</span>  <span class="c1"># pylint: disable=redefined-builtin</span>
</span><span id="__span-0-475"><a id="__codelineno-0-475" name="__codelineno-0-475"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span>
</span><span id="__span-0-476"><a id="__codelineno-0-476" name="__codelineno-0-476"></a>    <span class="n">reduce_instance_dims</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-477"><a id="__codelineno-0-477" name="__codelineno-0-477"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-478"><a id="__codelineno-0-478" name="__codelineno-0-478"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-479"><a id="__codelineno-0-479" name="__codelineno-0-479"></a><span class="w">    </span><span class="sd">"""Computes the maximum of the values of `x` over the whole dataset.</span>
</span><span id="__span-0-480"><a id="__codelineno-0-480" name="__codelineno-0-480"></a>
</span><span id="__span-0-481"><a id="__codelineno-0-481" name="__codelineno-0-481"></a><span class="sd">    In the case of a `CompositeTensor` missing values will be used in return</span>
</span><span id="__span-0-482"><a id="__codelineno-0-482" name="__codelineno-0-482"></a><span class="sd">    value: for float, NaN is used and for other dtypes the min is used.</span>
</span><span id="__span-0-483"><a id="__codelineno-0-483" name="__codelineno-0-483"></a>
</span><span id="__span-0-484"><a id="__codelineno-0-484" name="__codelineno-0-484"></a><span class="sd">    Args:</span>
</span><span id="__span-0-485"><a id="__codelineno-0-485" name="__codelineno-0-485"></a><span class="sd">    ----</span>
</span><span id="__span-0-486"><a id="__codelineno-0-486" name="__codelineno-0-486"></a><span class="sd">      x: A `Tensor`, `SparseTensor`, or `RaggedTensor`.</span>
</span><span id="__span-0-487"><a id="__codelineno-0-487" name="__codelineno-0-487"></a><span class="sd">      reduce_instance_dims: By default collapses the batch and instance dimensions</span>
</span><span id="__span-0-488"><a id="__codelineno-0-488" name="__codelineno-0-488"></a><span class="sd">        to arrive at a single scalar output. If False, only collapses the batch</span>
</span><span id="__span-0-489"><a id="__codelineno-0-489" name="__codelineno-0-489"></a><span class="sd">        dimension and outputs a vector of the same shape as the input.</span>
</span><span id="__span-0-490"><a id="__codelineno-0-490" name="__codelineno-0-490"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-491"><a id="__codelineno-0-491" name="__codelineno-0-491"></a>
</span><span id="__span-0-492"><a id="__codelineno-0-492" name="__codelineno-0-492"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-493"><a id="__codelineno-0-493" name="__codelineno-0-493"></a><span class="sd">    -------</span>
</span><span id="__span-0-494"><a id="__codelineno-0-494" name="__codelineno-0-494"></a><span class="sd">      A `Tensor`. Has the same type as `x`.</span>
</span><span id="__span-0-495"><a id="__codelineno-0-495" name="__codelineno-0-495"></a>
</span><span id="__span-0-496"><a id="__codelineno-0-496" name="__codelineno-0-496"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-497"><a id="__codelineno-0-497" name="__codelineno-0-497"></a><span class="sd">    ------</span>
</span><span id="__span-0-498"><a id="__codelineno-0-498" name="__codelineno-0-498"></a><span class="sd">      TypeError: If the type of `x` is not supported.</span>
</span><span id="__span-0-499"><a id="__codelineno-0-499" name="__codelineno-0-499"></a><span class="sd">    """</span>
</span><span id="__span-0-500"><a id="__codelineno-0-500" name="__codelineno-0-500"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"max"</span><span class="p">):</span>
</span><span id="__span-0-501"><a id="__codelineno-0-501" name="__codelineno-0-501"></a>        <span class="k">return</span> <span class="n">_min_and_max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">reduce_instance_dims</span><span class="p">,</span> <span class="n">name</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.mean" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">mean</span>


<a href="#tensorflow_transform.mean" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">mean</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">reduce_instance_dims</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">output_dtype</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><span title="tensorflow.DType">DType</span></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes the mean of the values of a <code>Tensor</code> over the whole dataset.</p>
        <hr>
<p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>. Its type must be floating
      point (float{16|32|64}), or integral ([u]int{8|16|32|64}).
  reduce_instance_dims: By default collapses the batch and instance dimensions
      to arrive at a single scalar output. If False, only collapses the batch
      dimension and outputs a vector of the same shape as the input.
  name: (Optional) A name for this operation.
  output_dtype: (Optional) If not None, casts the output tensor to this type.</p>
        <hr>
<p>A <code>Tensor</code> containing the mean. If <code>x</code> is floating point, the mean will have
  the same type as <code>x</code>. If <code>x</code> is integral, the output is cast to float32.
  NaNs and infinite input values are ignored.</p>
        <hr>
<p>TypeError: If the type of <code>x</code> is not supported.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/analyzers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-891">891</a></span>
<span class="normal"><a href="#__codelineno-0-892">892</a></span>
<span class="normal"><a href="#__codelineno-0-893">893</a></span>
<span class="normal"><a href="#__codelineno-0-894">894</a></span>
<span class="normal"><a href="#__codelineno-0-895">895</a></span>
<span class="normal"><a href="#__codelineno-0-896">896</a></span>
<span class="normal"><a href="#__codelineno-0-897">897</a></span>
<span class="normal"><a href="#__codelineno-0-898">898</a></span>
<span class="normal"><a href="#__codelineno-0-899">899</a></span>
<span class="normal"><a href="#__codelineno-0-900">900</a></span>
<span class="normal"><a href="#__codelineno-0-901">901</a></span>
<span class="normal"><a href="#__codelineno-0-902">902</a></span>
<span class="normal"><a href="#__codelineno-0-903">903</a></span>
<span class="normal"><a href="#__codelineno-0-904">904</a></span>
<span class="normal"><a href="#__codelineno-0-905">905</a></span>
<span class="normal"><a href="#__codelineno-0-906">906</a></span>
<span class="normal"><a href="#__codelineno-0-907">907</a></span>
<span class="normal"><a href="#__codelineno-0-908">908</a></span>
<span class="normal"><a href="#__codelineno-0-909">909</a></span>
<span class="normal"><a href="#__codelineno-0-910">910</a></span>
<span class="normal"><a href="#__codelineno-0-911">911</a></span>
<span class="normal"><a href="#__codelineno-0-912">912</a></span>
<span class="normal"><a href="#__codelineno-0-913">913</a></span>
<span class="normal"><a href="#__codelineno-0-914">914</a></span>
<span class="normal"><a href="#__codelineno-0-915">915</a></span>
<span class="normal"><a href="#__codelineno-0-916">916</a></span>
<span class="normal"><a href="#__codelineno-0-917">917</a></span>
<span class="normal"><a href="#__codelineno-0-918">918</a></span>
<span class="normal"><a href="#__codelineno-0-919">919</a></span>
<span class="normal"><a href="#__codelineno-0-920">920</a></span>
<span class="normal"><a href="#__codelineno-0-921">921</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-891"><a id="__codelineno-0-891" name="__codelineno-0-891"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">ANALYZER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-892"><a id="__codelineno-0-892" name="__codelineno-0-892"></a><span class="k">def</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span>
</span><span id="__span-0-893"><a id="__codelineno-0-893" name="__codelineno-0-893"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span>
</span><span id="__span-0-894"><a id="__codelineno-0-894" name="__codelineno-0-894"></a>    <span class="n">reduce_instance_dims</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-895"><a id="__codelineno-0-895" name="__codelineno-0-895"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-896"><a id="__codelineno-0-896" name="__codelineno-0-896"></a>    <span class="n">output_dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">DType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-897"><a id="__codelineno-0-897" name="__codelineno-0-897"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-898"><a id="__codelineno-0-898" name="__codelineno-0-898"></a><span class="w">    </span><span class="sd">"""Computes the mean of the values of a `Tensor` over the whole dataset.</span>
</span><span id="__span-0-899"><a id="__codelineno-0-899" name="__codelineno-0-899"></a>
</span><span id="__span-0-900"><a id="__codelineno-0-900" name="__codelineno-0-900"></a><span class="sd">    Args:</span>
</span><span id="__span-0-901"><a id="__codelineno-0-901" name="__codelineno-0-901"></a><span class="sd">    ----</span>
</span><span id="__span-0-902"><a id="__codelineno-0-902" name="__codelineno-0-902"></a><span class="sd">      x: A `Tensor`, `SparseTensor`, or `RaggedTensor`. Its type must be floating</span>
</span><span id="__span-0-903"><a id="__codelineno-0-903" name="__codelineno-0-903"></a><span class="sd">          point (float{16|32|64}), or integral ([u]int{8|16|32|64}).</span>
</span><span id="__span-0-904"><a id="__codelineno-0-904" name="__codelineno-0-904"></a><span class="sd">      reduce_instance_dims: By default collapses the batch and instance dimensions</span>
</span><span id="__span-0-905"><a id="__codelineno-0-905" name="__codelineno-0-905"></a><span class="sd">          to arrive at a single scalar output. If False, only collapses the batch</span>
</span><span id="__span-0-906"><a id="__codelineno-0-906" name="__codelineno-0-906"></a><span class="sd">          dimension and outputs a vector of the same shape as the input.</span>
</span><span id="__span-0-907"><a id="__codelineno-0-907" name="__codelineno-0-907"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-908"><a id="__codelineno-0-908" name="__codelineno-0-908"></a><span class="sd">      output_dtype: (Optional) If not None, casts the output tensor to this type.</span>
</span><span id="__span-0-909"><a id="__codelineno-0-909" name="__codelineno-0-909"></a>
</span><span id="__span-0-910"><a id="__codelineno-0-910" name="__codelineno-0-910"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-911"><a id="__codelineno-0-911" name="__codelineno-0-911"></a><span class="sd">    -------</span>
</span><span id="__span-0-912"><a id="__codelineno-0-912" name="__codelineno-0-912"></a><span class="sd">      A `Tensor` containing the mean. If `x` is floating point, the mean will have</span>
</span><span id="__span-0-913"><a id="__codelineno-0-913" name="__codelineno-0-913"></a><span class="sd">      the same type as `x`. If `x` is integral, the output is cast to float32.</span>
</span><span id="__span-0-914"><a id="__codelineno-0-914" name="__codelineno-0-914"></a><span class="sd">      NaNs and infinite input values are ignored.</span>
</span><span id="__span-0-915"><a id="__codelineno-0-915" name="__codelineno-0-915"></a>
</span><span id="__span-0-916"><a id="__codelineno-0-916" name="__codelineno-0-916"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-917"><a id="__codelineno-0-917" name="__codelineno-0-917"></a><span class="sd">    ------</span>
</span><span id="__span-0-918"><a id="__codelineno-0-918" name="__codelineno-0-918"></a><span class="sd">      TypeError: If the type of `x` is not supported.</span>
</span><span id="__span-0-919"><a id="__codelineno-0-919" name="__codelineno-0-919"></a><span class="sd">    """</span>
</span><span id="__span-0-920"><a id="__codelineno-0-920" name="__codelineno-0-920"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"mean"</span><span class="p">):</span>
</span><span id="__span-0-921"><a id="__codelineno-0-921" name="__codelineno-0-921"></a>        <span class="k">return</span> <span class="n">_mean_and_var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">reduce_instance_dims</span><span class="p">,</span> <span class="n">output_dtype</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.min" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">min</span>


<a href="#tensorflow_transform.min" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">min</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">reduce_instance_dims</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes the minimum of the values of <code>x</code> over the whole dataset.</p>
<p>In the case of a <code>CompositeTensor</code> missing values will be used in return
value: for float, NaN is used and for other dtypes the max is used.</p>
        <hr>
<p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.
  reduce_instance_dims: By default collapses the batch and instance dimensions
    to arrive at a single scalar output. If False, only collapses the batch
    dimension and outputs a <code>Tensor</code> of the same shape as the input.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>A <code>Tensor</code> with the same type as <code>x</code>.</p>
        <hr>
<p>TypeError: If the type of <code>x</code> is not supported.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/analyzers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-442">442</a></span>
<span class="normal"><a href="#__codelineno-0-443">443</a></span>
<span class="normal"><a href="#__codelineno-0-444">444</a></span>
<span class="normal"><a href="#__codelineno-0-445">445</a></span>
<span class="normal"><a href="#__codelineno-0-446">446</a></span>
<span class="normal"><a href="#__codelineno-0-447">447</a></span>
<span class="normal"><a href="#__codelineno-0-448">448</a></span>
<span class="normal"><a href="#__codelineno-0-449">449</a></span>
<span class="normal"><a href="#__codelineno-0-450">450</a></span>
<span class="normal"><a href="#__codelineno-0-451">451</a></span>
<span class="normal"><a href="#__codelineno-0-452">452</a></span>
<span class="normal"><a href="#__codelineno-0-453">453</a></span>
<span class="normal"><a href="#__codelineno-0-454">454</a></span>
<span class="normal"><a href="#__codelineno-0-455">455</a></span>
<span class="normal"><a href="#__codelineno-0-456">456</a></span>
<span class="normal"><a href="#__codelineno-0-457">457</a></span>
<span class="normal"><a href="#__codelineno-0-458">458</a></span>
<span class="normal"><a href="#__codelineno-0-459">459</a></span>
<span class="normal"><a href="#__codelineno-0-460">460</a></span>
<span class="normal"><a href="#__codelineno-0-461">461</a></span>
<span class="normal"><a href="#__codelineno-0-462">462</a></span>
<span class="normal"><a href="#__codelineno-0-463">463</a></span>
<span class="normal"><a href="#__codelineno-0-464">464</a></span>
<span class="normal"><a href="#__codelineno-0-465">465</a></span>
<span class="normal"><a href="#__codelineno-0-466">466</a></span>
<span class="normal"><a href="#__codelineno-0-467">467</a></span>
<span class="normal"><a href="#__codelineno-0-468">468</a></span>
<span class="normal"><a href="#__codelineno-0-469">469</a></span>
<span class="normal"><a href="#__codelineno-0-470">470</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-442"><a id="__codelineno-0-442" name="__codelineno-0-442"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">ANALYZER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-443"><a id="__codelineno-0-443" name="__codelineno-0-443"></a><span class="k">def</span><span class="w"> </span><span class="nf">min</span><span class="p">(</span>  <span class="c1"># pylint: disable=redefined-builtin</span>
</span><span id="__span-0-444"><a id="__codelineno-0-444" name="__codelineno-0-444"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span>
</span><span id="__span-0-445"><a id="__codelineno-0-445" name="__codelineno-0-445"></a>    <span class="n">reduce_instance_dims</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-446"><a id="__codelineno-0-446" name="__codelineno-0-446"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-447"><a id="__codelineno-0-447" name="__codelineno-0-447"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-448"><a id="__codelineno-0-448" name="__codelineno-0-448"></a><span class="w">    </span><span class="sd">"""Computes the minimum of the values of `x` over the whole dataset.</span>
</span><span id="__span-0-449"><a id="__codelineno-0-449" name="__codelineno-0-449"></a>
</span><span id="__span-0-450"><a id="__codelineno-0-450" name="__codelineno-0-450"></a><span class="sd">    In the case of a `CompositeTensor` missing values will be used in return</span>
</span><span id="__span-0-451"><a id="__codelineno-0-451" name="__codelineno-0-451"></a><span class="sd">    value: for float, NaN is used and for other dtypes the max is used.</span>
</span><span id="__span-0-452"><a id="__codelineno-0-452" name="__codelineno-0-452"></a>
</span><span id="__span-0-453"><a id="__codelineno-0-453" name="__codelineno-0-453"></a><span class="sd">    Args:</span>
</span><span id="__span-0-454"><a id="__codelineno-0-454" name="__codelineno-0-454"></a><span class="sd">    ----</span>
</span><span id="__span-0-455"><a id="__codelineno-0-455" name="__codelineno-0-455"></a><span class="sd">      x: A `Tensor`, `SparseTensor`, or `RaggedTensor`.</span>
</span><span id="__span-0-456"><a id="__codelineno-0-456" name="__codelineno-0-456"></a><span class="sd">      reduce_instance_dims: By default collapses the batch and instance dimensions</span>
</span><span id="__span-0-457"><a id="__codelineno-0-457" name="__codelineno-0-457"></a><span class="sd">        to arrive at a single scalar output. If False, only collapses the batch</span>
</span><span id="__span-0-458"><a id="__codelineno-0-458" name="__codelineno-0-458"></a><span class="sd">        dimension and outputs a `Tensor` of the same shape as the input.</span>
</span><span id="__span-0-459"><a id="__codelineno-0-459" name="__codelineno-0-459"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-460"><a id="__codelineno-0-460" name="__codelineno-0-460"></a>
</span><span id="__span-0-461"><a id="__codelineno-0-461" name="__codelineno-0-461"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-462"><a id="__codelineno-0-462" name="__codelineno-0-462"></a><span class="sd">    -------</span>
</span><span id="__span-0-463"><a id="__codelineno-0-463" name="__codelineno-0-463"></a><span class="sd">      A `Tensor` with the same type as `x`.</span>
</span><span id="__span-0-464"><a id="__codelineno-0-464" name="__codelineno-0-464"></a>
</span><span id="__span-0-465"><a id="__codelineno-0-465" name="__codelineno-0-465"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-466"><a id="__codelineno-0-466" name="__codelineno-0-466"></a><span class="sd">    ------</span>
</span><span id="__span-0-467"><a id="__codelineno-0-467" name="__codelineno-0-467"></a><span class="sd">      TypeError: If the type of `x` is not supported.</span>
</span><span id="__span-0-468"><a id="__codelineno-0-468" name="__codelineno-0-468"></a><span class="sd">    """</span>
</span><span id="__span-0-469"><a id="__codelineno-0-469" name="__codelineno-0-469"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"min"</span><span class="p">):</span>
</span><span id="__span-0-470"><a id="__codelineno-0-470" name="__codelineno-0-470"></a>        <span class="k">return</span> <span class="n">_min_and_max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">reduce_instance_dims</span><span class="p">,</span> <span class="n">name</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.ngrams" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">ngrams</span>


<a href="#tensorflow_transform.ngrams" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">ngrams</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">tokens</span><span class="p">:</span> <span class="n"><span title="tensorflow.SparseTensor">SparseTensor</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">ngram_range</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Tuple


  
      module-attribute
   (typing.Tuple)" href="#tensorflow_transform.Tuple">Tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">separator</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow.SparseTensor">SparseTensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Create a <code>SparseTensor</code> of n-grams.</p>
<p>Given a <code>SparseTensor</code> of tokens, returns a <code>SparseTensor</code> containing the
ngrams that can be constructed from each row.</p>
<p><code>separator</code> is inserted between each pair of tokens, so " " would be an
appropriate choice if the tokens are words, while "" would be an appropriate
choice if they are characters.</p>
<h6 id="tensorflow_transform.ngrams--example">Example:<a class="headerlink" href="#tensorflow_transform.ngrams--example" title="Permanent link">Â¶</a></h6>
<blockquote>
<blockquote>
<blockquote>
<p>tokens = tf.SparseTensor(
...         indices=[[0, 0], [0, 1], [0, 2], [1, 0], [1, 1], [1, 2], [1, 3]],
...         values=['One', 'was', 'Johnny', 'Two', 'was', 'a', 'rat'],
...         dense_shape=[2, 4])
print(tft.ngrams(tokens, ngram_range=(1, 3), separator=' '))
SparseTensor(indices=tf.Tensor(
    [[0 0][0 1] [0 2][0 3] [0 4][0 5]
     [1 0][1 1] [1 2][1 3] [1 4][1 5] [1 6][1 7] [1 8]],
     shape=(15, 2), dtype=int64),
  values=tf.Tensor(
    [b'One' b'One was' b'One was Johnny' b'was' b'was Johnny' b'Johnny' b'Two'
     b'Two was' b'Two was a' b'was' b'was a' b'was a rat' b'a' b'a rat'
     b'rat'], shape=(15,), dtype=string),
  dense_shape=tf.Tensor([2 9], shape=(2,), dtype=int64))</p>
</blockquote>
</blockquote>
</blockquote>
        <hr>
<p>tokens: a two-dimensional<code>SparseTensor</code> of dtype <code>tf.string</code> containing
    tokens that will be used to construct ngrams.
  ngram_range: A pair with the range (inclusive) of ngram sizes to return.
  separator: a string that will be inserted between tokens when ngrams are
    constructed.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>A <code>SparseTensor</code> containing all ngrams from each row of the input. Note:
  if an ngram appears multiple times in the input row, it will be present the
  same number of times in the output. For unique ngrams, see tft.bag_of_words.</p>
        <hr>
<p>ValueError: if <code>tokens</code> is not 2D.
  ValueError: if ngram_range[0] &lt; 1 or ngram_range[1] &lt; ngram_range[0]</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1629">1629</a></span>
<span class="normal"><a href="#__codelineno-0-1630">1630</a></span>
<span class="normal"><a href="#__codelineno-0-1631">1631</a></span>
<span class="normal"><a href="#__codelineno-0-1632">1632</a></span>
<span class="normal"><a href="#__codelineno-0-1633">1633</a></span>
<span class="normal"><a href="#__codelineno-0-1634">1634</a></span>
<span class="normal"><a href="#__codelineno-0-1635">1635</a></span>
<span class="normal"><a href="#__codelineno-0-1636">1636</a></span>
<span class="normal"><a href="#__codelineno-0-1637">1637</a></span>
<span class="normal"><a href="#__codelineno-0-1638">1638</a></span>
<span class="normal"><a href="#__codelineno-0-1639">1639</a></span>
<span class="normal"><a href="#__codelineno-0-1640">1640</a></span>
<span class="normal"><a href="#__codelineno-0-1641">1641</a></span>
<span class="normal"><a href="#__codelineno-0-1642">1642</a></span>
<span class="normal"><a href="#__codelineno-0-1643">1643</a></span>
<span class="normal"><a href="#__codelineno-0-1644">1644</a></span>
<span class="normal"><a href="#__codelineno-0-1645">1645</a></span>
<span class="normal"><a href="#__codelineno-0-1646">1646</a></span>
<span class="normal"><a href="#__codelineno-0-1647">1647</a></span>
<span class="normal"><a href="#__codelineno-0-1648">1648</a></span>
<span class="normal"><a href="#__codelineno-0-1649">1649</a></span>
<span class="normal"><a href="#__codelineno-0-1650">1650</a></span>
<span class="normal"><a href="#__codelineno-0-1651">1651</a></span>
<span class="normal"><a href="#__codelineno-0-1652">1652</a></span>
<span class="normal"><a href="#__codelineno-0-1653">1653</a></span>
<span class="normal"><a href="#__codelineno-0-1654">1654</a></span>
<span class="normal"><a href="#__codelineno-0-1655">1655</a></span>
<span class="normal"><a href="#__codelineno-0-1656">1656</a></span>
<span class="normal"><a href="#__codelineno-0-1657">1657</a></span>
<span class="normal"><a href="#__codelineno-0-1658">1658</a></span>
<span class="normal"><a href="#__codelineno-0-1659">1659</a></span>
<span class="normal"><a href="#__codelineno-0-1660">1660</a></span>
<span class="normal"><a href="#__codelineno-0-1661">1661</a></span>
<span class="normal"><a href="#__codelineno-0-1662">1662</a></span>
<span class="normal"><a href="#__codelineno-0-1663">1663</a></span>
<span class="normal"><a href="#__codelineno-0-1664">1664</a></span>
<span class="normal"><a href="#__codelineno-0-1665">1665</a></span>
<span class="normal"><a href="#__codelineno-0-1666">1666</a></span>
<span class="normal"><a href="#__codelineno-0-1667">1667</a></span>
<span class="normal"><a href="#__codelineno-0-1668">1668</a></span>
<span class="normal"><a href="#__codelineno-0-1669">1669</a></span>
<span class="normal"><a href="#__codelineno-0-1670">1670</a></span>
<span class="normal"><a href="#__codelineno-0-1671">1671</a></span>
<span class="normal"><a href="#__codelineno-0-1672">1672</a></span>
<span class="normal"><a href="#__codelineno-0-1673">1673</a></span>
<span class="normal"><a href="#__codelineno-0-1674">1674</a></span>
<span class="normal"><a href="#__codelineno-0-1675">1675</a></span>
<span class="normal"><a href="#__codelineno-0-1676">1676</a></span>
<span class="normal"><a href="#__codelineno-0-1677">1677</a></span>
<span class="normal"><a href="#__codelineno-0-1678">1678</a></span>
<span class="normal"><a href="#__codelineno-0-1679">1679</a></span>
<span class="normal"><a href="#__codelineno-0-1680">1680</a></span>
<span class="normal"><a href="#__codelineno-0-1681">1681</a></span>
<span class="normal"><a href="#__codelineno-0-1682">1682</a></span>
<span class="normal"><a href="#__codelineno-0-1683">1683</a></span>
<span class="normal"><a href="#__codelineno-0-1684">1684</a></span>
<span class="normal"><a href="#__codelineno-0-1685">1685</a></span>
<span class="normal"><a href="#__codelineno-0-1686">1686</a></span>
<span class="normal"><a href="#__codelineno-0-1687">1687</a></span>
<span class="normal"><a href="#__codelineno-0-1688">1688</a></span>
<span class="normal"><a href="#__codelineno-0-1689">1689</a></span>
<span class="normal"><a href="#__codelineno-0-1690">1690</a></span>
<span class="normal"><a href="#__codelineno-0-1691">1691</a></span>
<span class="normal"><a href="#__codelineno-0-1692">1692</a></span>
<span class="normal"><a href="#__codelineno-0-1693">1693</a></span>
<span class="normal"><a href="#__codelineno-0-1694">1694</a></span>
<span class="normal"><a href="#__codelineno-0-1695">1695</a></span>
<span class="normal"><a href="#__codelineno-0-1696">1696</a></span>
<span class="normal"><a href="#__codelineno-0-1697">1697</a></span>
<span class="normal"><a href="#__codelineno-0-1698">1698</a></span>
<span class="normal"><a href="#__codelineno-0-1699">1699</a></span>
<span class="normal"><a href="#__codelineno-0-1700">1700</a></span>
<span class="normal"><a href="#__codelineno-0-1701">1701</a></span>
<span class="normal"><a href="#__codelineno-0-1702">1702</a></span>
<span class="normal"><a href="#__codelineno-0-1703">1703</a></span>
<span class="normal"><a href="#__codelineno-0-1704">1704</a></span>
<span class="normal"><a href="#__codelineno-0-1705">1705</a></span>
<span class="normal"><a href="#__codelineno-0-1706">1706</a></span>
<span class="normal"><a href="#__codelineno-0-1707">1707</a></span>
<span class="normal"><a href="#__codelineno-0-1708">1708</a></span>
<span class="normal"><a href="#__codelineno-0-1709">1709</a></span>
<span class="normal"><a href="#__codelineno-0-1710">1710</a></span>
<span class="normal"><a href="#__codelineno-0-1711">1711</a></span>
<span class="normal"><a href="#__codelineno-0-1712">1712</a></span>
<span class="normal"><a href="#__codelineno-0-1713">1713</a></span>
<span class="normal"><a href="#__codelineno-0-1714">1714</a></span>
<span class="normal"><a href="#__codelineno-0-1715">1715</a></span>
<span class="normal"><a href="#__codelineno-0-1716">1716</a></span>
<span class="normal"><a href="#__codelineno-0-1717">1717</a></span>
<span class="normal"><a href="#__codelineno-0-1718">1718</a></span>
<span class="normal"><a href="#__codelineno-0-1719">1719</a></span>
<span class="normal"><a href="#__codelineno-0-1720">1720</a></span>
<span class="normal"><a href="#__codelineno-0-1721">1721</a></span>
<span class="normal"><a href="#__codelineno-0-1722">1722</a></span>
<span class="normal"><a href="#__codelineno-0-1723">1723</a></span>
<span class="normal"><a href="#__codelineno-0-1724">1724</a></span>
<span class="normal"><a href="#__codelineno-0-1725">1725</a></span>
<span class="normal"><a href="#__codelineno-0-1726">1726</a></span>
<span class="normal"><a href="#__codelineno-0-1727">1727</a></span>
<span class="normal"><a href="#__codelineno-0-1728">1728</a></span>
<span class="normal"><a href="#__codelineno-0-1729">1729</a></span>
<span class="normal"><a href="#__codelineno-0-1730">1730</a></span>
<span class="normal"><a href="#__codelineno-0-1731">1731</a></span>
<span class="normal"><a href="#__codelineno-0-1732">1732</a></span>
<span class="normal"><a href="#__codelineno-0-1733">1733</a></span>
<span class="normal"><a href="#__codelineno-0-1734">1734</a></span>
<span class="normal"><a href="#__codelineno-0-1735">1735</a></span>
<span class="normal"><a href="#__codelineno-0-1736">1736</a></span>
<span class="normal"><a href="#__codelineno-0-1737">1737</a></span>
<span class="normal"><a href="#__codelineno-0-1738">1738</a></span>
<span class="normal"><a href="#__codelineno-0-1739">1739</a></span>
<span class="normal"><a href="#__codelineno-0-1740">1740</a></span>
<span class="normal"><a href="#__codelineno-0-1741">1741</a></span>
<span class="normal"><a href="#__codelineno-0-1742">1742</a></span>
<span class="normal"><a href="#__codelineno-0-1743">1743</a></span>
<span class="normal"><a href="#__codelineno-0-1744">1744</a></span>
<span class="normal"><a href="#__codelineno-0-1745">1745</a></span>
<span class="normal"><a href="#__codelineno-0-1746">1746</a></span>
<span class="normal"><a href="#__codelineno-0-1747">1747</a></span>
<span class="normal"><a href="#__codelineno-0-1748">1748</a></span>
<span class="normal"><a href="#__codelineno-0-1749">1749</a></span>
<span class="normal"><a href="#__codelineno-0-1750">1750</a></span>
<span class="normal"><a href="#__codelineno-0-1751">1751</a></span>
<span class="normal"><a href="#__codelineno-0-1752">1752</a></span>
<span class="normal"><a href="#__codelineno-0-1753">1753</a></span>
<span class="normal"><a href="#__codelineno-0-1754">1754</a></span>
<span class="normal"><a href="#__codelineno-0-1755">1755</a></span>
<span class="normal"><a href="#__codelineno-0-1756">1756</a></span>
<span class="normal"><a href="#__codelineno-0-1757">1757</a></span>
<span class="normal"><a href="#__codelineno-0-1758">1758</a></span>
<span class="normal"><a href="#__codelineno-0-1759">1759</a></span>
<span class="normal"><a href="#__codelineno-0-1760">1760</a></span>
<span class="normal"><a href="#__codelineno-0-1761">1761</a></span>
<span class="normal"><a href="#__codelineno-0-1762">1762</a></span>
<span class="normal"><a href="#__codelineno-0-1763">1763</a></span>
<span class="normal"><a href="#__codelineno-0-1764">1764</a></span>
<span class="normal"><a href="#__codelineno-0-1765">1765</a></span>
<span class="normal"><a href="#__codelineno-0-1766">1766</a></span>
<span class="normal"><a href="#__codelineno-0-1767">1767</a></span>
<span class="normal"><a href="#__codelineno-0-1768">1768</a></span>
<span class="normal"><a href="#__codelineno-0-1769">1769</a></span>
<span class="normal"><a href="#__codelineno-0-1770">1770</a></span>
<span class="normal"><a href="#__codelineno-0-1771">1771</a></span>
<span class="normal"><a href="#__codelineno-0-1772">1772</a></span>
<span class="normal"><a href="#__codelineno-0-1773">1773</a></span>
<span class="normal"><a href="#__codelineno-0-1774">1774</a></span>
<span class="normal"><a href="#__codelineno-0-1775">1775</a></span>
<span class="normal"><a href="#__codelineno-0-1776">1776</a></span>
<span class="normal"><a href="#__codelineno-0-1777">1777</a></span>
<span class="normal"><a href="#__codelineno-0-1778">1778</a></span>
<span class="normal"><a href="#__codelineno-0-1779">1779</a></span>
<span class="normal"><a href="#__codelineno-0-1780">1780</a></span>
<span class="normal"><a href="#__codelineno-0-1781">1781</a></span>
<span class="normal"><a href="#__codelineno-0-1782">1782</a></span>
<span class="normal"><a href="#__codelineno-0-1783">1783</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1629"><a id="__codelineno-0-1629" name="__codelineno-0-1629"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-1630"><a id="__codelineno-0-1630" name="__codelineno-0-1630"></a><span class="k">def</span><span class="w"> </span><span class="nf">ngrams</span><span class="p">(</span>
</span><span id="__span-0-1631"><a id="__codelineno-0-1631" name="__codelineno-0-1631"></a>    <span class="n">tokens</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">,</span>
</span><span id="__span-0-1632"><a id="__codelineno-0-1632" name="__codelineno-0-1632"></a>    <span class="n">ngram_range</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
</span><span id="__span-0-1633"><a id="__codelineno-0-1633" name="__codelineno-0-1633"></a>    <span class="n">separator</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="__span-0-1634"><a id="__codelineno-0-1634" name="__codelineno-0-1634"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1635"><a id="__codelineno-0-1635" name="__codelineno-0-1635"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">:</span>
</span><span id="__span-0-1636"><a id="__codelineno-0-1636" name="__codelineno-0-1636"></a><span class="w">    </span><span class="sd">"""Create a `SparseTensor` of n-grams.</span>
</span><span id="__span-0-1637"><a id="__codelineno-0-1637" name="__codelineno-0-1637"></a>
</span><span id="__span-0-1638"><a id="__codelineno-0-1638" name="__codelineno-0-1638"></a><span class="sd">    Given a `SparseTensor` of tokens, returns a `SparseTensor` containing the</span>
</span><span id="__span-0-1639"><a id="__codelineno-0-1639" name="__codelineno-0-1639"></a><span class="sd">    ngrams that can be constructed from each row.</span>
</span><span id="__span-0-1640"><a id="__codelineno-0-1640" name="__codelineno-0-1640"></a>
</span><span id="__span-0-1641"><a id="__codelineno-0-1641" name="__codelineno-0-1641"></a><span class="sd">    `separator` is inserted between each pair of tokens, so " " would be an</span>
</span><span id="__span-0-1642"><a id="__codelineno-0-1642" name="__codelineno-0-1642"></a><span class="sd">    appropriate choice if the tokens are words, while "" would be an appropriate</span>
</span><span id="__span-0-1643"><a id="__codelineno-0-1643" name="__codelineno-0-1643"></a><span class="sd">    choice if they are characters.</span>
</span><span id="__span-0-1644"><a id="__codelineno-0-1644" name="__codelineno-0-1644"></a>
</span><span id="__span-0-1645"><a id="__codelineno-0-1645" name="__codelineno-0-1645"></a><span class="sd">    Example:</span>
</span><span id="__span-0-1646"><a id="__codelineno-0-1646" name="__codelineno-0-1646"></a><span class="sd">    -------</span>
</span><span id="__span-0-1647"><a id="__codelineno-0-1647" name="__codelineno-0-1647"></a><span class="sd">    &gt;&gt;&gt; tokens = tf.SparseTensor(</span>
</span><span id="__span-0-1648"><a id="__codelineno-0-1648" name="__codelineno-0-1648"></a><span class="sd">    ...         indices=[[0, 0], [0, 1], [0, 2], [1, 0], [1, 1], [1, 2], [1, 3]],</span>
</span><span id="__span-0-1649"><a id="__codelineno-0-1649" name="__codelineno-0-1649"></a><span class="sd">    ...         values=['One', 'was', 'Johnny', 'Two', 'was', 'a', 'rat'],</span>
</span><span id="__span-0-1650"><a id="__codelineno-0-1650" name="__codelineno-0-1650"></a><span class="sd">    ...         dense_shape=[2, 4])</span>
</span><span id="__span-0-1651"><a id="__codelineno-0-1651" name="__codelineno-0-1651"></a><span class="sd">    &gt;&gt;&gt; print(tft.ngrams(tokens, ngram_range=(1, 3), separator=' '))</span>
</span><span id="__span-0-1652"><a id="__codelineno-0-1652" name="__codelineno-0-1652"></a><span class="sd">    SparseTensor(indices=tf.Tensor(</span>
</span><span id="__span-0-1653"><a id="__codelineno-0-1653" name="__codelineno-0-1653"></a><span class="sd">        [[0 0] [0 1] [0 2] [0 3] [0 4] [0 5]</span>
</span><span id="__span-0-1654"><a id="__codelineno-0-1654" name="__codelineno-0-1654"></a><span class="sd">         [1 0] [1 1] [1 2] [1 3] [1 4] [1 5] [1 6] [1 7] [1 8]],</span>
</span><span id="__span-0-1655"><a id="__codelineno-0-1655" name="__codelineno-0-1655"></a><span class="sd">         shape=(15, 2), dtype=int64),</span>
</span><span id="__span-0-1656"><a id="__codelineno-0-1656" name="__codelineno-0-1656"></a><span class="sd">      values=tf.Tensor(</span>
</span><span id="__span-0-1657"><a id="__codelineno-0-1657" name="__codelineno-0-1657"></a><span class="sd">        [b'One' b'One was' b'One was Johnny' b'was' b'was Johnny' b'Johnny' b'Two'</span>
</span><span id="__span-0-1658"><a id="__codelineno-0-1658" name="__codelineno-0-1658"></a><span class="sd">         b'Two was' b'Two was a' b'was' b'was a' b'was a rat' b'a' b'a rat'</span>
</span><span id="__span-0-1659"><a id="__codelineno-0-1659" name="__codelineno-0-1659"></a><span class="sd">         b'rat'], shape=(15,), dtype=string),</span>
</span><span id="__span-0-1660"><a id="__codelineno-0-1660" name="__codelineno-0-1660"></a><span class="sd">      dense_shape=tf.Tensor([2 9], shape=(2,), dtype=int64))</span>
</span><span id="__span-0-1661"><a id="__codelineno-0-1661" name="__codelineno-0-1661"></a>
</span><span id="__span-0-1662"><a id="__codelineno-0-1662" name="__codelineno-0-1662"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1663"><a id="__codelineno-0-1663" name="__codelineno-0-1663"></a><span class="sd">    ----</span>
</span><span id="__span-0-1664"><a id="__codelineno-0-1664" name="__codelineno-0-1664"></a><span class="sd">      tokens: a two-dimensional`SparseTensor` of dtype `tf.string` containing</span>
</span><span id="__span-0-1665"><a id="__codelineno-0-1665" name="__codelineno-0-1665"></a><span class="sd">        tokens that will be used to construct ngrams.</span>
</span><span id="__span-0-1666"><a id="__codelineno-0-1666" name="__codelineno-0-1666"></a><span class="sd">      ngram_range: A pair with the range (inclusive) of ngram sizes to return.</span>
</span><span id="__span-0-1667"><a id="__codelineno-0-1667" name="__codelineno-0-1667"></a><span class="sd">      separator: a string that will be inserted between tokens when ngrams are</span>
</span><span id="__span-0-1668"><a id="__codelineno-0-1668" name="__codelineno-0-1668"></a><span class="sd">        constructed.</span>
</span><span id="__span-0-1669"><a id="__codelineno-0-1669" name="__codelineno-0-1669"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-1670"><a id="__codelineno-0-1670" name="__codelineno-0-1670"></a>
</span><span id="__span-0-1671"><a id="__codelineno-0-1671" name="__codelineno-0-1671"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1672"><a id="__codelineno-0-1672" name="__codelineno-0-1672"></a><span class="sd">    -------</span>
</span><span id="__span-0-1673"><a id="__codelineno-0-1673" name="__codelineno-0-1673"></a><span class="sd">      A `SparseTensor` containing all ngrams from each row of the input. Note:</span>
</span><span id="__span-0-1674"><a id="__codelineno-0-1674" name="__codelineno-0-1674"></a><span class="sd">      if an ngram appears multiple times in the input row, it will be present the</span>
</span><span id="__span-0-1675"><a id="__codelineno-0-1675" name="__codelineno-0-1675"></a><span class="sd">      same number of times in the output. For unique ngrams, see tft.bag_of_words.</span>
</span><span id="__span-0-1676"><a id="__codelineno-0-1676" name="__codelineno-0-1676"></a>
</span><span id="__span-0-1677"><a id="__codelineno-0-1677" name="__codelineno-0-1677"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-1678"><a id="__codelineno-0-1678" name="__codelineno-0-1678"></a><span class="sd">    ------</span>
</span><span id="__span-0-1679"><a id="__codelineno-0-1679" name="__codelineno-0-1679"></a><span class="sd">      ValueError: if `tokens` is not 2D.</span>
</span><span id="__span-0-1680"><a id="__codelineno-0-1680" name="__codelineno-0-1680"></a><span class="sd">      ValueError: if ngram_range[0] &lt; 1 or ngram_range[1] &lt; ngram_range[0]</span>
</span><span id="__span-0-1681"><a id="__codelineno-0-1681" name="__codelineno-0-1681"></a><span class="sd">    """</span>
</span><span id="__span-0-1682"><a id="__codelineno-0-1682" name="__codelineno-0-1682"></a>    <span class="c1"># This function is implemented as follows.  Assume we start with the following</span>
</span><span id="__span-0-1683"><a id="__codelineno-0-1683" name="__codelineno-0-1683"></a>    <span class="c1"># `SparseTensor`:</span>
</span><span id="__span-0-1684"><a id="__codelineno-0-1684" name="__codelineno-0-1684"></a>    <span class="c1">#</span>
</span><span id="__span-0-1685"><a id="__codelineno-0-1685" name="__codelineno-0-1685"></a>    <span class="c1"># indices=[[0, 0], [0, 1], [0, 2], [0, 3], [1, 0], [2, 0], [2, 1], [2, 2]]</span>
</span><span id="__span-0-1686"><a id="__codelineno-0-1686" name="__codelineno-0-1686"></a>    <span class="c1"># values=['a', 'b', 'c', 'd', 'q', 'x', 'y', 'z']</span>
</span><span id="__span-0-1687"><a id="__codelineno-0-1687" name="__codelineno-0-1687"></a>    <span class="c1"># dense_shape=[3, 4]</span>
</span><span id="__span-0-1688"><a id="__codelineno-0-1688" name="__codelineno-0-1688"></a>    <span class="c1">#</span>
</span><span id="__span-0-1689"><a id="__codelineno-0-1689" name="__codelineno-0-1689"></a>    <span class="c1"># First we then create shifts of the values and first column of indices,</span>
</span><span id="__span-0-1690"><a id="__codelineno-0-1690" name="__codelineno-0-1690"></a>    <span class="c1"># buffering to avoid overrunning the end of the array, so the shifted values</span>
</span><span id="__span-0-1691"><a id="__codelineno-0-1691" name="__codelineno-0-1691"></a>    <span class="c1"># (if we are ngrams up to size 3) are</span>
</span><span id="__span-0-1692"><a id="__codelineno-0-1692" name="__codelineno-0-1692"></a>    <span class="c1">#</span>
</span><span id="__span-0-1693"><a id="__codelineno-0-1693" name="__codelineno-0-1693"></a>    <span class="c1"># shifted_batch_indices[0]=[0, 0, 0, 0, 1, 2, 2, 2]</span>
</span><span id="__span-0-1694"><a id="__codelineno-0-1694" name="__codelineno-0-1694"></a>    <span class="c1"># shifted_tokens[0]=['a', 'b', 'c', 'd', 'q', 'x', 'y', 'z']</span>
</span><span id="__span-0-1695"><a id="__codelineno-0-1695" name="__codelineno-0-1695"></a>    <span class="c1">#</span>
</span><span id="__span-0-1696"><a id="__codelineno-0-1696" name="__codelineno-0-1696"></a>    <span class="c1"># shifted_batch_indices[1]=[0, 0, 0, 1, 2, 2, 2, -1]</span>
</span><span id="__span-0-1697"><a id="__codelineno-0-1697" name="__codelineno-0-1697"></a>    <span class="c1"># shifted_tokens[1]=['b', 'c', 'd', 'q', 'x', 'y', 'z', '']</span>
</span><span id="__span-0-1698"><a id="__codelineno-0-1698" name="__codelineno-0-1698"></a>    <span class="c1">#</span>
</span><span id="__span-0-1699"><a id="__codelineno-0-1699" name="__codelineno-0-1699"></a>    <span class="c1"># shifted_batch_indices[2]=[0, 0, 1, 2, 2, 2, -1, -1]</span>
</span><span id="__span-0-1700"><a id="__codelineno-0-1700" name="__codelineno-0-1700"></a>    <span class="c1"># shifted_tokens[2]=['c', 'd', 'q', 'x', 'y', 'z', '', '']</span>
</span><span id="__span-0-1701"><a id="__codelineno-0-1701" name="__codelineno-0-1701"></a>    <span class="c1">#</span>
</span><span id="__span-0-1702"><a id="__codelineno-0-1702" name="__codelineno-0-1702"></a>    <span class="c1"># These shifted ngrams are used to create the ngrams as follows.  We use</span>
</span><span id="__span-0-1703"><a id="__codelineno-0-1703" name="__codelineno-0-1703"></a>    <span class="c1"># tf.string_join to join shifted_tokens[:k] to create k-grams. The `separator`</span>
</span><span id="__span-0-1704"><a id="__codelineno-0-1704" name="__codelineno-0-1704"></a>    <span class="c1"># string is inserted between each pair of tokens in the k-gram.</span>
</span><span id="__span-0-1705"><a id="__codelineno-0-1705" name="__codelineno-0-1705"></a>    <span class="c1"># The batch that the first of these belonged to is given by</span>
</span><span id="__span-0-1706"><a id="__codelineno-0-1706" name="__codelineno-0-1706"></a>    <span class="c1"># shifted_batch_indices[0]. However some of these will cross the boundaries</span>
</span><span id="__span-0-1707"><a id="__codelineno-0-1707" name="__codelineno-0-1707"></a>    <span class="c1"># between 'batches' and so we we create a boolean mask which is True when</span>
</span><span id="__span-0-1708"><a id="__codelineno-0-1708" name="__codelineno-0-1708"></a>    <span class="c1"># shifted_indices[:k] are all equal.</span>
</span><span id="__span-0-1709"><a id="__codelineno-0-1709" name="__codelineno-0-1709"></a>    <span class="c1">#</span>
</span><span id="__span-0-1710"><a id="__codelineno-0-1710" name="__codelineno-0-1710"></a>    <span class="c1"># This results in tensors of ngrams, their batch indices and a boolean mask,</span>
</span><span id="__span-0-1711"><a id="__codelineno-0-1711" name="__codelineno-0-1711"></a>    <span class="c1"># which we then use to construct the output SparseTensor.</span>
</span><span id="__span-0-1712"><a id="__codelineno-0-1712" name="__codelineno-0-1712"></a>    <span class="k">if</span> <span class="n">tokens</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">ndims</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="__span-0-1713"><a id="__codelineno-0-1713" name="__codelineno-0-1713"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"ngrams requires `tokens` to be 2-dimensional"</span><span class="p">)</span>
</span><span id="__span-0-1714"><a id="__codelineno-0-1714" name="__codelineno-0-1714"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"ngrams"</span><span class="p">):</span>
</span><span id="__span-0-1715"><a id="__codelineno-0-1715" name="__codelineno-0-1715"></a>        <span class="k">if</span> <span class="n">ngram_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">ngram_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">ngram_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
</span><span id="__span-0-1716"><a id="__codelineno-0-1716" name="__codelineno-0-1716"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Invalid ngram_range: </span><span class="si">%r</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">ngram_range</span><span class="p">,))</span>
</span><span id="__span-0-1717"><a id="__codelineno-0-1717" name="__codelineno-0-1717"></a>
</span><span id="__span-0-1718"><a id="__codelineno-0-1718" name="__codelineno-0-1718"></a>        <span class="k">def</span><span class="w"> </span><span class="nf">_sliding_windows</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">num_shifts</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">):</span>
</span><span id="__span-0-1719"><a id="__codelineno-0-1719" name="__codelineno-0-1719"></a>            <span class="n">buffered_values</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
</span><span id="__span-0-1720"><a id="__codelineno-0-1720" name="__codelineno-0-1720"></a>                <span class="p">[</span><span class="n">values</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">([</span><span class="n">num_shifts</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="n">fill_value</span><span class="p">)],</span> <span class="mi">0</span>
</span><span id="__span-0-1721"><a id="__codelineno-0-1721" name="__codelineno-0-1721"></a>            <span class="p">)</span>
</span><span id="__span-0-1722"><a id="__codelineno-0-1722" name="__codelineno-0-1722"></a>            <span class="k">return</span> <span class="p">[</span>
</span><span id="__span-0-1723"><a id="__codelineno-0-1723" name="__codelineno-0-1723"></a>                <span class="n">tf</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">buffered_values</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">values</span><span class="p">))</span>
</span><span id="__span-0-1724"><a id="__codelineno-0-1724" name="__codelineno-0-1724"></a>                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_shifts</span><span class="p">)</span>
</span><span id="__span-0-1725"><a id="__codelineno-0-1725" name="__codelineno-0-1725"></a>            <span class="p">]</span>
</span><span id="__span-0-1726"><a id="__codelineno-0-1726" name="__codelineno-0-1726"></a>
</span><span id="__span-0-1727"><a id="__codelineno-0-1727" name="__codelineno-0-1727"></a>        <span class="n">shifted_batch_indices</span> <span class="o">=</span> <span class="n">_sliding_windows</span><span class="p">(</span>
</span><span id="__span-0-1728"><a id="__codelineno-0-1728" name="__codelineno-0-1728"></a>            <span class="n">tokens</span><span class="o">.</span><span class="n">indices</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">ngram_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span><span id="__span-0-1729"><a id="__codelineno-0-1729" name="__codelineno-0-1729"></a>        <span class="p">)</span>
</span><span id="__span-0-1730"><a id="__codelineno-0-1730" name="__codelineno-0-1730"></a>        <span class="n">shifted_tokens</span> <span class="o">=</span> <span class="n">_sliding_windows</span><span class="p">(</span><span class="n">tokens</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">ngram_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span>
</span><span id="__span-0-1731"><a id="__codelineno-0-1731" name="__codelineno-0-1731"></a>
</span><span id="__span-0-1732"><a id="__codelineno-0-1732" name="__codelineno-0-1732"></a>        <span class="c1"># Construct a tensor of the form</span>
</span><span id="__span-0-1733"><a id="__codelineno-0-1733" name="__codelineno-0-1733"></a>        <span class="c1"># [['a', 'ab, 'abc'], ['b', 'bcd', cde'], ...]</span>
</span><span id="__span-0-1734"><a id="__codelineno-0-1734" name="__codelineno-0-1734"></a>        <span class="k">def</span><span class="w"> </span><span class="nf">_string_join</span><span class="p">(</span><span class="n">tensors</span><span class="p">):</span>
</span><span id="__span-0-1735"><a id="__codelineno-0-1735" name="__codelineno-0-1735"></a>            <span class="k">if</span> <span class="n">tensors</span><span class="p">:</span>
</span><span id="__span-0-1736"><a id="__codelineno-0-1736" name="__codelineno-0-1736"></a>                <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">separator</span><span class="o">=</span><span class="n">separator</span><span class="p">)</span>
</span><span id="__span-0-1737"><a id="__codelineno-0-1737" name="__codelineno-0-1737"></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-1738"><a id="__codelineno-0-1738" name="__codelineno-0-1738"></a>                <span class="k">return</span> <span class="kc">None</span>
</span><span id="__span-0-1739"><a id="__codelineno-0-1739" name="__codelineno-0-1739"></a>
</span><span id="__span-0-1740"><a id="__codelineno-0-1740" name="__codelineno-0-1740"></a>        <span class="n">ngrams_array</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-0-1741"><a id="__codelineno-0-1741" name="__codelineno-0-1741"></a>            <span class="n">_string_join</span><span class="p">(</span><span class="n">shifted_tokens</span><span class="p">[:</span><span class="n">k</span><span class="p">])</span>
</span><span id="__span-0-1742"><a id="__codelineno-0-1742" name="__codelineno-0-1742"></a>            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ngram_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ngram_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-1743"><a id="__codelineno-0-1743" name="__codelineno-0-1743"></a>        <span class="p">]</span>
</span><span id="__span-0-1744"><a id="__codelineno-0-1744" name="__codelineno-0-1744"></a>        <span class="n">ngrams_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">ngrams_array</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-1745"><a id="__codelineno-0-1745" name="__codelineno-0-1745"></a>
</span><span id="__span-0-1746"><a id="__codelineno-0-1746" name="__codelineno-0-1746"></a>        <span class="c1"># Construct a boolean mask for whether each ngram in ngram_tensor is valid,</span>
</span><span id="__span-0-1747"><a id="__codelineno-0-1747" name="__codelineno-0-1747"></a>        <span class="c1"># in that each character came from the same batch.</span>
</span><span id="__span-0-1748"><a id="__codelineno-0-1748" name="__codelineno-0-1748"></a>        <span class="n">valid_ngram</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span>
</span><span id="__span-0-1749"><a id="__codelineno-0-1749" name="__codelineno-0-1749"></a>            <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span>
</span><span id="__span-0-1750"><a id="__codelineno-0-1750" name="__codelineno-0-1750"></a>                <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
</span><span id="__span-0-1751"><a id="__codelineno-0-1751" name="__codelineno-0-1751"></a>                    <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span>
</span><span id="__span-0-1752"><a id="__codelineno-0-1752" name="__codelineno-0-1752"></a>                        <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">shifted_batch_indices</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span><span id="__span-0-1753"><a id="__codelineno-0-1753" name="__codelineno-0-1753"></a>                        <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">shifted_batch_indices</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span>
</span><span id="__span-0-1754"><a id="__codelineno-0-1754" name="__codelineno-0-1754"></a>                    <span class="p">),</span>
</span><span id="__span-0-1755"><a id="__codelineno-0-1755" name="__codelineno-0-1755"></a>                    <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
</span><span id="__span-0-1756"><a id="__codelineno-0-1756" name="__codelineno-0-1756"></a>                <span class="p">),</span>
</span><span id="__span-0-1757"><a id="__codelineno-0-1757" name="__codelineno-0-1757"></a>                <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-1758"><a id="__codelineno-0-1758" name="__codelineno-0-1758"></a>            <span class="p">),</span>
</span><span id="__span-0-1759"><a id="__codelineno-0-1759" name="__codelineno-0-1759"></a>            <span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-1760"><a id="__codelineno-0-1760" name="__codelineno-0-1760"></a>        <span class="p">)</span>
</span><span id="__span-0-1761"><a id="__codelineno-0-1761" name="__codelineno-0-1761"></a>        <span class="n">valid_ngram</span> <span class="o">=</span> <span class="n">valid_ngram</span><span class="p">[:,</span> <span class="p">(</span><span class="n">ngram_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="p">:</span> <span class="n">ngram_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
</span><span id="__span-0-1762"><a id="__codelineno-0-1762" name="__codelineno-0-1762"></a>
</span><span id="__span-0-1763"><a id="__codelineno-0-1763" name="__codelineno-0-1763"></a>        <span class="c1"># Construct a tensor with the batch that each ngram in ngram_tensor belongs</span>
</span><span id="__span-0-1764"><a id="__codelineno-0-1764" name="__codelineno-0-1764"></a>        <span class="c1"># to.</span>
</span><span id="__span-0-1765"><a id="__codelineno-0-1765" name="__codelineno-0-1765"></a>        <span class="n">batch_indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
</span><span id="__span-0-1766"><a id="__codelineno-0-1766" name="__codelineno-0-1766"></a>            <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tokens</span><span class="o">.</span><span class="n">indices</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span>
</span><span id="__span-0-1767"><a id="__codelineno-0-1767" name="__codelineno-0-1767"></a>            <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">ngram_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">ngram_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
</span><span id="__span-0-1768"><a id="__codelineno-0-1768" name="__codelineno-0-1768"></a>        <span class="p">)</span>
</span><span id="__span-0-1769"><a id="__codelineno-0-1769" name="__codelineno-0-1769"></a>
</span><span id="__span-0-1770"><a id="__codelineno-0-1770" name="__codelineno-0-1770"></a>        <span class="c1"># Apply the boolean mask and construct a SparseTensor with the given indices</span>
</span><span id="__span-0-1771"><a id="__codelineno-0-1771" name="__codelineno-0-1771"></a>        <span class="c1"># and values, where another index is added to give the position within a</span>
</span><span id="__span-0-1772"><a id="__codelineno-0-1772" name="__codelineno-0-1772"></a>        <span class="c1"># batch.</span>
</span><span id="__span-0-1773"><a id="__codelineno-0-1773" name="__codelineno-0-1773"></a>        <span class="n">batch_indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">batch_indices</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">valid_ngram</span><span class="p">)</span>
</span><span id="__span-0-1774"><a id="__codelineno-0-1774" name="__codelineno-0-1774"></a>        <span class="n">ngrams_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">ngrams_tensor</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">valid_ngram</span><span class="p">)</span>
</span><span id="__span-0-1775"><a id="__codelineno-0-1775" name="__codelineno-0-1775"></a>        <span class="n">instance_indices</span> <span class="o">=</span> <span class="n">segment_indices</span><span class="p">(</span><span class="n">batch_indices</span><span class="p">)</span>
</span><span id="__span-0-1776"><a id="__codelineno-0-1776" name="__codelineno-0-1776"></a>        <span class="n">dense_shape_second_dim</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-1777"><a id="__codelineno-0-1777" name="__codelineno-0-1777"></a>            <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">input_tensor</span><span class="o">=</span><span class="n">instance_indices</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="__span-0-1778"><a id="__codelineno-0-1778" name="__codelineno-0-1778"></a>        <span class="p">)</span>
</span><span id="__span-0-1779"><a id="__codelineno-0-1779" name="__codelineno-0-1779"></a>        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">(</span>
</span><span id="__span-0-1780"><a id="__codelineno-0-1780" name="__codelineno-0-1780"></a>            <span class="n">indices</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">batch_indices</span><span class="p">,</span> <span class="n">instance_indices</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span>
</span><span id="__span-0-1781"><a id="__codelineno-0-1781" name="__codelineno-0-1781"></a>            <span class="n">values</span><span class="o">=</span><span class="n">ngrams_tensor</span><span class="p">,</span>
</span><span id="__span-0-1782"><a id="__codelineno-0-1782" name="__codelineno-0-1782"></a>            <span class="n">dense_shape</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">tokens</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dense_shape_second_dim</span><span class="p">]),</span>
</span><span id="__span-0-1783"><a id="__codelineno-0-1783" name="__codelineno-0-1783"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.pca" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">pca</span>


<a href="#tensorflow_transform.pca" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">pca</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">output_dim</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">dtype</span><span class="p">:</span> <span class="n"><span title="tensorflow.DType">DType</span></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes PCA on the dataset using biased covariance.</p>
<p>The PCA analyzer computes output_dim orthonormal vectors that capture
directions/axes corresponding to the highest variances in the input vectors of
<code>x</code>. The output vectors are returned as a rank-2 tensor with shape
<code>(input_dim, output_dim)</code>, where the 0th dimension are the components of each
output vector, and the 1st dimension are the output vectors representing
orthogonal directions in the input space, sorted in order of decreasing
variances.</p>
<p>The output rank-2 tensor (matrix) serves a useful transform purpose. Formally,
the matrix can be used downstream in the transform step by multiplying it to
the input tensor <code>x</code>. This transform reduces the dimension of input vectors to
output_dim in a way that retains the maximal variance.</p>
<p>NOTE: To properly use PCA, input vector components should be converted to
similar units of measurement such that the vectors represent a Euclidean
space. If no such conversion is available (e.g. one element represents time,
another element distance), the canonical approach is to first apply a
transformation to the input data to normalize numerical variances, i.e.
<code>tft.scale_to_z_score()</code>. Normalization allows PCA to choose output axes that
help decorrelate input axes.</p>
<p>Below are a couple intuitive examples of PCA.</p>
<p>Consider a simple 2-dimensional example:</p>
<p>Input x is a series of vectors <code>[e, e]</code> where <code>e</code> is Gaussian with mean 0,
variance 1. The two components are perfectly correlated, and the resulting
covariance matrix is</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>[[1 1],
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a> [1 1]].
</span></code></pre></div>
<p>Applying PCA with <code>output_dim = 1</code> would discover the first principal
component <code>[1 / sqrt(2), 1 / sqrt(2)]</code>. When multipled to the original
example, each vector <code>[e, e]</code> would be mapped to a scalar <code>sqrt(2) * e</code>. The
second principal component would be <code>[-1 / sqrt(2), 1 / sqrt(2)]</code> and would
map <code>[e, e]</code> to 0, which indicates that the second component captures no
variance at all. This agrees with our intuition since we know that the two
axes in the input are perfectly correlated and can be fully explained by a
single scalar <code>e</code>.</p>
<p>Consider a 3-dimensional example:</p>
<p>Input <code>x</code> is a series of vectors <code>[a, a, b]</code>, where <code>a</code> is a zero-mean, unit
variance Gaussian and <code>b</code> is a zero-mean, variance 4 Gaussian and is
independent of <code>a</code>. The first principal component of the unnormalized vector
would be <code>[0, 0, 1]</code> since <code>b</code> has a much larger variance than any linear
combination of the first two components. This would map <code>[a, a, b]</code> onto <code>b</code>,
asserting that the axis with highest energy is the third component. While this
may be the desired output if <code>a</code> and <code>b</code> correspond to the same units, it is
not statistically desireable when the units are irreconciliable. In such a
case, one should first normalize each component to unit variance first, i.e.
<code>b := b / 2</code>. The first principal component of a normalized vector would yield
<code>[1 / sqrt(2), 1 / sqrt(2), 0]</code>, and would map <code>[a, a, b]</code> to <code>sqrt(2) * a</code>.
The second component would be <code>[0, 0, 1]</code> and map <code>[a, a, b]</code> to <code>b</code>. As can
be seen, the benefit of normalization is that PCA would capture highly
correlated components first and collapse them into a lower dimension.</p>
        <hr>
<p>x: A rank-2 <code>Tensor</code>, 0th dim are rows, 1st dim are indices in row vectors.
  output_dim: The PCA output dimension (number of eigenvectors to return).
  dtype: Tensorflow dtype of entries in the returned matrix.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>ValueError: if input is not a rank-2 Tensor.</p>
        <hr>
<p>A 2D <code>Tensor</code> (matrix) M of shape (input_dim, output_dim).</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/analyzers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-2850">2850</a></span>
<span class="normal"><a href="#__codelineno-0-2851">2851</a></span>
<span class="normal"><a href="#__codelineno-0-2852">2852</a></span>
<span class="normal"><a href="#__codelineno-0-2853">2853</a></span>
<span class="normal"><a href="#__codelineno-0-2854">2854</a></span>
<span class="normal"><a href="#__codelineno-0-2855">2855</a></span>
<span class="normal"><a href="#__codelineno-0-2856">2856</a></span>
<span class="normal"><a href="#__codelineno-0-2857">2857</a></span>
<span class="normal"><a href="#__codelineno-0-2858">2858</a></span>
<span class="normal"><a href="#__codelineno-0-2859">2859</a></span>
<span class="normal"><a href="#__codelineno-0-2860">2860</a></span>
<span class="normal"><a href="#__codelineno-0-2861">2861</a></span>
<span class="normal"><a href="#__codelineno-0-2862">2862</a></span>
<span class="normal"><a href="#__codelineno-0-2863">2863</a></span>
<span class="normal"><a href="#__codelineno-0-2864">2864</a></span>
<span class="normal"><a href="#__codelineno-0-2865">2865</a></span>
<span class="normal"><a href="#__codelineno-0-2866">2866</a></span>
<span class="normal"><a href="#__codelineno-0-2867">2867</a></span>
<span class="normal"><a href="#__codelineno-0-2868">2868</a></span>
<span class="normal"><a href="#__codelineno-0-2869">2869</a></span>
<span class="normal"><a href="#__codelineno-0-2870">2870</a></span>
<span class="normal"><a href="#__codelineno-0-2871">2871</a></span>
<span class="normal"><a href="#__codelineno-0-2872">2872</a></span>
<span class="normal"><a href="#__codelineno-0-2873">2873</a></span>
<span class="normal"><a href="#__codelineno-0-2874">2874</a></span>
<span class="normal"><a href="#__codelineno-0-2875">2875</a></span>
<span class="normal"><a href="#__codelineno-0-2876">2876</a></span>
<span class="normal"><a href="#__codelineno-0-2877">2877</a></span>
<span class="normal"><a href="#__codelineno-0-2878">2878</a></span>
<span class="normal"><a href="#__codelineno-0-2879">2879</a></span>
<span class="normal"><a href="#__codelineno-0-2880">2880</a></span>
<span class="normal"><a href="#__codelineno-0-2881">2881</a></span>
<span class="normal"><a href="#__codelineno-0-2882">2882</a></span>
<span class="normal"><a href="#__codelineno-0-2883">2883</a></span>
<span class="normal"><a href="#__codelineno-0-2884">2884</a></span>
<span class="normal"><a href="#__codelineno-0-2885">2885</a></span>
<span class="normal"><a href="#__codelineno-0-2886">2886</a></span>
<span class="normal"><a href="#__codelineno-0-2887">2887</a></span>
<span class="normal"><a href="#__codelineno-0-2888">2888</a></span>
<span class="normal"><a href="#__codelineno-0-2889">2889</a></span>
<span class="normal"><a href="#__codelineno-0-2890">2890</a></span>
<span class="normal"><a href="#__codelineno-0-2891">2891</a></span>
<span class="normal"><a href="#__codelineno-0-2892">2892</a></span>
<span class="normal"><a href="#__codelineno-0-2893">2893</a></span>
<span class="normal"><a href="#__codelineno-0-2894">2894</a></span>
<span class="normal"><a href="#__codelineno-0-2895">2895</a></span>
<span class="normal"><a href="#__codelineno-0-2896">2896</a></span>
<span class="normal"><a href="#__codelineno-0-2897">2897</a></span>
<span class="normal"><a href="#__codelineno-0-2898">2898</a></span>
<span class="normal"><a href="#__codelineno-0-2899">2899</a></span>
<span class="normal"><a href="#__codelineno-0-2900">2900</a></span>
<span class="normal"><a href="#__codelineno-0-2901">2901</a></span>
<span class="normal"><a href="#__codelineno-0-2902">2902</a></span>
<span class="normal"><a href="#__codelineno-0-2903">2903</a></span>
<span class="normal"><a href="#__codelineno-0-2904">2904</a></span>
<span class="normal"><a href="#__codelineno-0-2905">2905</a></span>
<span class="normal"><a href="#__codelineno-0-2906">2906</a></span>
<span class="normal"><a href="#__codelineno-0-2907">2907</a></span>
<span class="normal"><a href="#__codelineno-0-2908">2908</a></span>
<span class="normal"><a href="#__codelineno-0-2909">2909</a></span>
<span class="normal"><a href="#__codelineno-0-2910">2910</a></span>
<span class="normal"><a href="#__codelineno-0-2911">2911</a></span>
<span class="normal"><a href="#__codelineno-0-2912">2912</a></span>
<span class="normal"><a href="#__codelineno-0-2913">2913</a></span>
<span class="normal"><a href="#__codelineno-0-2914">2914</a></span>
<span class="normal"><a href="#__codelineno-0-2915">2915</a></span>
<span class="normal"><a href="#__codelineno-0-2916">2916</a></span>
<span class="normal"><a href="#__codelineno-0-2917">2917</a></span>
<span class="normal"><a href="#__codelineno-0-2918">2918</a></span>
<span class="normal"><a href="#__codelineno-0-2919">2919</a></span>
<span class="normal"><a href="#__codelineno-0-2920">2920</a></span>
<span class="normal"><a href="#__codelineno-0-2921">2921</a></span>
<span class="normal"><a href="#__codelineno-0-2922">2922</a></span>
<span class="normal"><a href="#__codelineno-0-2923">2923</a></span>
<span class="normal"><a href="#__codelineno-0-2924">2924</a></span>
<span class="normal"><a href="#__codelineno-0-2925">2925</a></span>
<span class="normal"><a href="#__codelineno-0-2926">2926</a></span>
<span class="normal"><a href="#__codelineno-0-2927">2927</a></span>
<span class="normal"><a href="#__codelineno-0-2928">2928</a></span>
<span class="normal"><a href="#__codelineno-0-2929">2929</a></span>
<span class="normal"><a href="#__codelineno-0-2930">2930</a></span>
<span class="normal"><a href="#__codelineno-0-2931">2931</a></span>
<span class="normal"><a href="#__codelineno-0-2932">2932</a></span>
<span class="normal"><a href="#__codelineno-0-2933">2933</a></span>
<span class="normal"><a href="#__codelineno-0-2934">2934</a></span>
<span class="normal"><a href="#__codelineno-0-2935">2935</a></span>
<span class="normal"><a href="#__codelineno-0-2936">2936</a></span>
<span class="normal"><a href="#__codelineno-0-2937">2937</a></span>
<span class="normal"><a href="#__codelineno-0-2938">2938</a></span>
<span class="normal"><a href="#__codelineno-0-2939">2939</a></span>
<span class="normal"><a href="#__codelineno-0-2940">2940</a></span>
<span class="normal"><a href="#__codelineno-0-2941">2941</a></span>
<span class="normal"><a href="#__codelineno-0-2942">2942</a></span>
<span class="normal"><a href="#__codelineno-0-2943">2943</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-2850"><a id="__codelineno-0-2850" name="__codelineno-0-2850"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">ANALYZER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-2851"><a id="__codelineno-0-2851" name="__codelineno-0-2851"></a><span class="k">def</span><span class="w"> </span><span class="nf">pca</span><span class="p">(</span>
</span><span id="__span-0-2852"><a id="__codelineno-0-2852" name="__codelineno-0-2852"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">DType</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-2853"><a id="__codelineno-0-2853" name="__codelineno-0-2853"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-2854"><a id="__codelineno-0-2854" name="__codelineno-0-2854"></a><span class="w">    </span><span class="sd">"""Computes PCA on the dataset using biased covariance.</span>
</span><span id="__span-0-2855"><a id="__codelineno-0-2855" name="__codelineno-0-2855"></a>
</span><span id="__span-0-2856"><a id="__codelineno-0-2856" name="__codelineno-0-2856"></a><span class="sd">    The PCA analyzer computes output_dim orthonormal vectors that capture</span>
</span><span id="__span-0-2857"><a id="__codelineno-0-2857" name="__codelineno-0-2857"></a><span class="sd">    directions/axes corresponding to the highest variances in the input vectors of</span>
</span><span id="__span-0-2858"><a id="__codelineno-0-2858" name="__codelineno-0-2858"></a><span class="sd">    `x`. The output vectors are returned as a rank-2 tensor with shape</span>
</span><span id="__span-0-2859"><a id="__codelineno-0-2859" name="__codelineno-0-2859"></a><span class="sd">    `(input_dim, output_dim)`, where the 0th dimension are the components of each</span>
</span><span id="__span-0-2860"><a id="__codelineno-0-2860" name="__codelineno-0-2860"></a><span class="sd">    output vector, and the 1st dimension are the output vectors representing</span>
</span><span id="__span-0-2861"><a id="__codelineno-0-2861" name="__codelineno-0-2861"></a><span class="sd">    orthogonal directions in the input space, sorted in order of decreasing</span>
</span><span id="__span-0-2862"><a id="__codelineno-0-2862" name="__codelineno-0-2862"></a><span class="sd">    variances.</span>
</span><span id="__span-0-2863"><a id="__codelineno-0-2863" name="__codelineno-0-2863"></a>
</span><span id="__span-0-2864"><a id="__codelineno-0-2864" name="__codelineno-0-2864"></a><span class="sd">    The output rank-2 tensor (matrix) serves a useful transform purpose. Formally,</span>
</span><span id="__span-0-2865"><a id="__codelineno-0-2865" name="__codelineno-0-2865"></a><span class="sd">    the matrix can be used downstream in the transform step by multiplying it to</span>
</span><span id="__span-0-2866"><a id="__codelineno-0-2866" name="__codelineno-0-2866"></a><span class="sd">    the input tensor `x`. This transform reduces the dimension of input vectors to</span>
</span><span id="__span-0-2867"><a id="__codelineno-0-2867" name="__codelineno-0-2867"></a><span class="sd">    output_dim in a way that retains the maximal variance.</span>
</span><span id="__span-0-2868"><a id="__codelineno-0-2868" name="__codelineno-0-2868"></a>
</span><span id="__span-0-2869"><a id="__codelineno-0-2869" name="__codelineno-0-2869"></a><span class="sd">    NOTE: To properly use PCA, input vector components should be converted to</span>
</span><span id="__span-0-2870"><a id="__codelineno-0-2870" name="__codelineno-0-2870"></a><span class="sd">    similar units of measurement such that the vectors represent a Euclidean</span>
</span><span id="__span-0-2871"><a id="__codelineno-0-2871" name="__codelineno-0-2871"></a><span class="sd">    space. If no such conversion is available (e.g. one element represents time,</span>
</span><span id="__span-0-2872"><a id="__codelineno-0-2872" name="__codelineno-0-2872"></a><span class="sd">    another element distance), the canonical approach is to first apply a</span>
</span><span id="__span-0-2873"><a id="__codelineno-0-2873" name="__codelineno-0-2873"></a><span class="sd">    transformation to the input data to normalize numerical variances, i.e.</span>
</span><span id="__span-0-2874"><a id="__codelineno-0-2874" name="__codelineno-0-2874"></a><span class="sd">    `tft.scale_to_z_score()`. Normalization allows PCA to choose output axes that</span>
</span><span id="__span-0-2875"><a id="__codelineno-0-2875" name="__codelineno-0-2875"></a><span class="sd">    help decorrelate input axes.</span>
</span><span id="__span-0-2876"><a id="__codelineno-0-2876" name="__codelineno-0-2876"></a>
</span><span id="__span-0-2877"><a id="__codelineno-0-2877" name="__codelineno-0-2877"></a><span class="sd">    Below are a couple intuitive examples of PCA.</span>
</span><span id="__span-0-2878"><a id="__codelineno-0-2878" name="__codelineno-0-2878"></a>
</span><span id="__span-0-2879"><a id="__codelineno-0-2879" name="__codelineno-0-2879"></a><span class="sd">    Consider a simple 2-dimensional example:</span>
</span><span id="__span-0-2880"><a id="__codelineno-0-2880" name="__codelineno-0-2880"></a>
</span><span id="__span-0-2881"><a id="__codelineno-0-2881" name="__codelineno-0-2881"></a><span class="sd">    Input x is a series of vectors `[e, e]` where `e` is Gaussian with mean 0,</span>
</span><span id="__span-0-2882"><a id="__codelineno-0-2882" name="__codelineno-0-2882"></a><span class="sd">    variance 1. The two components are perfectly correlated, and the resulting</span>
</span><span id="__span-0-2883"><a id="__codelineno-0-2883" name="__codelineno-0-2883"></a><span class="sd">    covariance matrix is</span>
</span><span id="__span-0-2884"><a id="__codelineno-0-2884" name="__codelineno-0-2884"></a>
</span><span id="__span-0-2885"><a id="__codelineno-0-2885" name="__codelineno-0-2885"></a><span class="sd">    ```</span>
</span><span id="__span-0-2886"><a id="__codelineno-0-2886" name="__codelineno-0-2886"></a><span class="sd">    [[1 1],</span>
</span><span id="__span-0-2887"><a id="__codelineno-0-2887" name="__codelineno-0-2887"></a><span class="sd">     [1 1]].</span>
</span><span id="__span-0-2888"><a id="__codelineno-0-2888" name="__codelineno-0-2888"></a><span class="sd">    ```</span>
</span><span id="__span-0-2889"><a id="__codelineno-0-2889" name="__codelineno-0-2889"></a>
</span><span id="__span-0-2890"><a id="__codelineno-0-2890" name="__codelineno-0-2890"></a><span class="sd">    Applying PCA with `output_dim = 1` would discover the first principal</span>
</span><span id="__span-0-2891"><a id="__codelineno-0-2891" name="__codelineno-0-2891"></a><span class="sd">    component `[1 / sqrt(2), 1 / sqrt(2)]`. When multipled to the original</span>
</span><span id="__span-0-2892"><a id="__codelineno-0-2892" name="__codelineno-0-2892"></a><span class="sd">    example, each vector `[e, e]` would be mapped to a scalar `sqrt(2) * e`. The</span>
</span><span id="__span-0-2893"><a id="__codelineno-0-2893" name="__codelineno-0-2893"></a><span class="sd">    second principal component would be `[-1 / sqrt(2), 1 / sqrt(2)]` and would</span>
</span><span id="__span-0-2894"><a id="__codelineno-0-2894" name="__codelineno-0-2894"></a><span class="sd">    map `[e, e]` to 0, which indicates that the second component captures no</span>
</span><span id="__span-0-2895"><a id="__codelineno-0-2895" name="__codelineno-0-2895"></a><span class="sd">    variance at all. This agrees with our intuition since we know that the two</span>
</span><span id="__span-0-2896"><a id="__codelineno-0-2896" name="__codelineno-0-2896"></a><span class="sd">    axes in the input are perfectly correlated and can be fully explained by a</span>
</span><span id="__span-0-2897"><a id="__codelineno-0-2897" name="__codelineno-0-2897"></a><span class="sd">    single scalar `e`.</span>
</span><span id="__span-0-2898"><a id="__codelineno-0-2898" name="__codelineno-0-2898"></a>
</span><span id="__span-0-2899"><a id="__codelineno-0-2899" name="__codelineno-0-2899"></a><span class="sd">    Consider a 3-dimensional example:</span>
</span><span id="__span-0-2900"><a id="__codelineno-0-2900" name="__codelineno-0-2900"></a>
</span><span id="__span-0-2901"><a id="__codelineno-0-2901" name="__codelineno-0-2901"></a><span class="sd">    Input `x` is a series of vectors `[a, a, b]`, where `a` is a zero-mean, unit</span>
</span><span id="__span-0-2902"><a id="__codelineno-0-2902" name="__codelineno-0-2902"></a><span class="sd">    variance Gaussian and `b` is a zero-mean, variance 4 Gaussian and is</span>
</span><span id="__span-0-2903"><a id="__codelineno-0-2903" name="__codelineno-0-2903"></a><span class="sd">    independent of `a`. The first principal component of the unnormalized vector</span>
</span><span id="__span-0-2904"><a id="__codelineno-0-2904" name="__codelineno-0-2904"></a><span class="sd">    would be `[0, 0, 1]` since `b` has a much larger variance than any linear</span>
</span><span id="__span-0-2905"><a id="__codelineno-0-2905" name="__codelineno-0-2905"></a><span class="sd">    combination of the first two components. This would map `[a, a, b]` onto `b`,</span>
</span><span id="__span-0-2906"><a id="__codelineno-0-2906" name="__codelineno-0-2906"></a><span class="sd">    asserting that the axis with highest energy is the third component. While this</span>
</span><span id="__span-0-2907"><a id="__codelineno-0-2907" name="__codelineno-0-2907"></a><span class="sd">    may be the desired output if `a` and `b` correspond to the same units, it is</span>
</span><span id="__span-0-2908"><a id="__codelineno-0-2908" name="__codelineno-0-2908"></a><span class="sd">    not statistically desireable when the units are irreconciliable. In such a</span>
</span><span id="__span-0-2909"><a id="__codelineno-0-2909" name="__codelineno-0-2909"></a><span class="sd">    case, one should first normalize each component to unit variance first, i.e.</span>
</span><span id="__span-0-2910"><a id="__codelineno-0-2910" name="__codelineno-0-2910"></a><span class="sd">    `b := b / 2`. The first principal component of a normalized vector would yield</span>
</span><span id="__span-0-2911"><a id="__codelineno-0-2911" name="__codelineno-0-2911"></a><span class="sd">    `[1 / sqrt(2), 1 / sqrt(2), 0]`, and would map `[a, a, b]` to `sqrt(2) * a`.</span>
</span><span id="__span-0-2912"><a id="__codelineno-0-2912" name="__codelineno-0-2912"></a><span class="sd">    The second component would be `[0, 0, 1]` and map `[a, a, b]` to `b`. As can</span>
</span><span id="__span-0-2913"><a id="__codelineno-0-2913" name="__codelineno-0-2913"></a><span class="sd">    be seen, the benefit of normalization is that PCA would capture highly</span>
</span><span id="__span-0-2914"><a id="__codelineno-0-2914" name="__codelineno-0-2914"></a><span class="sd">    correlated components first and collapse them into a lower dimension.</span>
</span><span id="__span-0-2915"><a id="__codelineno-0-2915" name="__codelineno-0-2915"></a>
</span><span id="__span-0-2916"><a id="__codelineno-0-2916" name="__codelineno-0-2916"></a><span class="sd">    Args:</span>
</span><span id="__span-0-2917"><a id="__codelineno-0-2917" name="__codelineno-0-2917"></a><span class="sd">    ----</span>
</span><span id="__span-0-2918"><a id="__codelineno-0-2918" name="__codelineno-0-2918"></a><span class="sd">      x: A rank-2 `Tensor`, 0th dim are rows, 1st dim are indices in row vectors.</span>
</span><span id="__span-0-2919"><a id="__codelineno-0-2919" name="__codelineno-0-2919"></a><span class="sd">      output_dim: The PCA output dimension (number of eigenvectors to return).</span>
</span><span id="__span-0-2920"><a id="__codelineno-0-2920" name="__codelineno-0-2920"></a><span class="sd">      dtype: Tensorflow dtype of entries in the returned matrix.</span>
</span><span id="__span-0-2921"><a id="__codelineno-0-2921" name="__codelineno-0-2921"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-2922"><a id="__codelineno-0-2922" name="__codelineno-0-2922"></a>
</span><span id="__span-0-2923"><a id="__codelineno-0-2923" name="__codelineno-0-2923"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-2924"><a id="__codelineno-0-2924" name="__codelineno-0-2924"></a><span class="sd">    ------</span>
</span><span id="__span-0-2925"><a id="__codelineno-0-2925" name="__codelineno-0-2925"></a><span class="sd">      ValueError: if input is not a rank-2 Tensor.</span>
</span><span id="__span-0-2926"><a id="__codelineno-0-2926" name="__codelineno-0-2926"></a>
</span><span id="__span-0-2927"><a id="__codelineno-0-2927" name="__codelineno-0-2927"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-2928"><a id="__codelineno-0-2928" name="__codelineno-0-2928"></a><span class="sd">    -------</span>
</span><span id="__span-0-2929"><a id="__codelineno-0-2929" name="__codelineno-0-2929"></a><span class="sd">      A 2D `Tensor` (matrix) M of shape (input_dim, output_dim).</span>
</span><span id="__span-0-2930"><a id="__codelineno-0-2930" name="__codelineno-0-2930"></a><span class="sd">    """</span>
</span><span id="__span-0-2931"><a id="__codelineno-0-2931" name="__codelineno-0-2931"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
</span><span id="__span-0-2932"><a id="__codelineno-0-2932" name="__codelineno-0-2932"></a>        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">"Expected a Tensor, but got </span><span class="si">%r</span><span class="s2">"</span> <span class="o">%</span> <span class="n">x</span><span class="p">)</span>
</span><span id="__span-0-2933"><a id="__codelineno-0-2933" name="__codelineno-0-2933"></a>
</span><span id="__span-0-2934"><a id="__codelineno-0-2934" name="__codelineno-0-2934"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"pca"</span><span class="p">):</span>
</span><span id="__span-0-2935"><a id="__codelineno-0-2935" name="__codelineno-0-2935"></a>        <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">assert_has_rank</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-0-2936"><a id="__codelineno-0-2936" name="__codelineno-0-2936"></a>
</span><span id="__span-0-2937"><a id="__codelineno-0-2937" name="__codelineno-0-2937"></a>        <span class="n">input_dim</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="__span-0-2938"><a id="__codelineno-0-2938" name="__codelineno-0-2938"></a>        <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
</span><span id="__span-0-2939"><a id="__codelineno-0-2939" name="__codelineno-0-2939"></a>
</span><span id="__span-0-2940"><a id="__codelineno-0-2940" name="__codelineno-0-2940"></a>        <span class="p">(</span><span class="n">result</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_apply_cacheable_combiner</span><span class="p">(</span>
</span><span id="__span-0-2941"><a id="__codelineno-0-2941" name="__codelineno-0-2941"></a>            <span class="n">PCACombiner</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">.</span><span class="n">as_numpy_dtype</span><span class="p">),</span> <span class="n">x</span>
</span><span id="__span-0-2942"><a id="__codelineno-0-2942" name="__codelineno-0-2942"></a>        <span class="p">)</span>
</span><span id="__span-0-2943"><a id="__codelineno-0-2943" name="__codelineno-0-2943"></a>        <span class="k">return</span> <span class="n">result</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.quantiles" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">quantiles</span>


<a href="#tensorflow_transform.quantiles" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">quantiles</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">num_buckets</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">epsilon</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">weights</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">reduce_instance_dims</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes the quantile boundaries of a <code>Tensor</code> over the whole dataset.</p>
<p>Quantile boundaries are computed using approximate quantiles,
and error tolerance is specified using <code>epsilon</code>. The boundaries divide the
input tensor into approximately equal <code>num_buckets</code> parts.
See go/squawd for details, and how to control the error due to approximation.
NaN input values and values with NaN weights are ignored.</p>
        <hr>
<p>x: An input <code>Tensor</code>.
  num_buckets: Values in the <code>x</code> are divided into approximately equal-sized
    buckets, where the number of buckets is <code>num_buckets</code>. The number of
    returned quantiles is <code>num_buckets</code> - 1.
  epsilon: Error tolerance, typically a small fraction close to zero (e.g.
    0.01). Higher values of epsilon increase the quantile approximation, and
    hence result in more unequal buckets, but could improve performance,
    and resource consumption.  Some measured results on memory consumption:
      For epsilon = 0.001, the amount of memory for each buffer to hold the
      summary for 1 trillion input values is ~25000 bytes. If epsilon is
      relaxed to 0.01, the buffer size drops to ~2000 bytes for the same input
      size. The buffer size also determines the amount of work in the
      different stages of the beam pipeline, in general, larger epsilon
      results in fewer and smaller stages, and less time. For more performance
      trade-offs see also http://web.cs.ucla.edu/~weiwang/paper/SSDBM07_2.pdf
  weights: (Optional) Weights tensor for the quantiles. Tensor must have the
    same batch size as x.
  reduce_instance_dims: By default collapses the batch and instance dimensions
      to arrive at a single output vector. If False, only collapses the batch
      dimension and outputs a vector of the same shape as the input.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>The bucket boundaries represented as a list, with num_bucket-1 elements,
  unless reduce_instance_dims is False, which results in a Tensor of
  shape x.shape + [num_bucket-1].
  See code below for discussion on the type of bucket boundaries.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/analyzers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-2483">2483</a></span>
<span class="normal"><a href="#__codelineno-0-2484">2484</a></span>
<span class="normal"><a href="#__codelineno-0-2485">2485</a></span>
<span class="normal"><a href="#__codelineno-0-2486">2486</a></span>
<span class="normal"><a href="#__codelineno-0-2487">2487</a></span>
<span class="normal"><a href="#__codelineno-0-2488">2488</a></span>
<span class="normal"><a href="#__codelineno-0-2489">2489</a></span>
<span class="normal"><a href="#__codelineno-0-2490">2490</a></span>
<span class="normal"><a href="#__codelineno-0-2491">2491</a></span>
<span class="normal"><a href="#__codelineno-0-2492">2492</a></span>
<span class="normal"><a href="#__codelineno-0-2493">2493</a></span>
<span class="normal"><a href="#__codelineno-0-2494">2494</a></span>
<span class="normal"><a href="#__codelineno-0-2495">2495</a></span>
<span class="normal"><a href="#__codelineno-0-2496">2496</a></span>
<span class="normal"><a href="#__codelineno-0-2497">2497</a></span>
<span class="normal"><a href="#__codelineno-0-2498">2498</a></span>
<span class="normal"><a href="#__codelineno-0-2499">2499</a></span>
<span class="normal"><a href="#__codelineno-0-2500">2500</a></span>
<span class="normal"><a href="#__codelineno-0-2501">2501</a></span>
<span class="normal"><a href="#__codelineno-0-2502">2502</a></span>
<span class="normal"><a href="#__codelineno-0-2503">2503</a></span>
<span class="normal"><a href="#__codelineno-0-2504">2504</a></span>
<span class="normal"><a href="#__codelineno-0-2505">2505</a></span>
<span class="normal"><a href="#__codelineno-0-2506">2506</a></span>
<span class="normal"><a href="#__codelineno-0-2507">2507</a></span>
<span class="normal"><a href="#__codelineno-0-2508">2508</a></span>
<span class="normal"><a href="#__codelineno-0-2509">2509</a></span>
<span class="normal"><a href="#__codelineno-0-2510">2510</a></span>
<span class="normal"><a href="#__codelineno-0-2511">2511</a></span>
<span class="normal"><a href="#__codelineno-0-2512">2512</a></span>
<span class="normal"><a href="#__codelineno-0-2513">2513</a></span>
<span class="normal"><a href="#__codelineno-0-2514">2514</a></span>
<span class="normal"><a href="#__codelineno-0-2515">2515</a></span>
<span class="normal"><a href="#__codelineno-0-2516">2516</a></span>
<span class="normal"><a href="#__codelineno-0-2517">2517</a></span>
<span class="normal"><a href="#__codelineno-0-2518">2518</a></span>
<span class="normal"><a href="#__codelineno-0-2519">2519</a></span>
<span class="normal"><a href="#__codelineno-0-2520">2520</a></span>
<span class="normal"><a href="#__codelineno-0-2521">2521</a></span>
<span class="normal"><a href="#__codelineno-0-2522">2522</a></span>
<span class="normal"><a href="#__codelineno-0-2523">2523</a></span>
<span class="normal"><a href="#__codelineno-0-2524">2524</a></span>
<span class="normal"><a href="#__codelineno-0-2525">2525</a></span>
<span class="normal"><a href="#__codelineno-0-2526">2526</a></span>
<span class="normal"><a href="#__codelineno-0-2527">2527</a></span>
<span class="normal"><a href="#__codelineno-0-2528">2528</a></span>
<span class="normal"><a href="#__codelineno-0-2529">2529</a></span>
<span class="normal"><a href="#__codelineno-0-2530">2530</a></span>
<span class="normal"><a href="#__codelineno-0-2531">2531</a></span>
<span class="normal"><a href="#__codelineno-0-2532">2532</a></span>
<span class="normal"><a href="#__codelineno-0-2533">2533</a></span>
<span class="normal"><a href="#__codelineno-0-2534">2534</a></span>
<span class="normal"><a href="#__codelineno-0-2535">2535</a></span>
<span class="normal"><a href="#__codelineno-0-2536">2536</a></span>
<span class="normal"><a href="#__codelineno-0-2537">2537</a></span>
<span class="normal"><a href="#__codelineno-0-2538">2538</a></span>
<span class="normal"><a href="#__codelineno-0-2539">2539</a></span>
<span class="normal"><a href="#__codelineno-0-2540">2540</a></span>
<span class="normal"><a href="#__codelineno-0-2541">2541</a></span>
<span class="normal"><a href="#__codelineno-0-2542">2542</a></span>
<span class="normal"><a href="#__codelineno-0-2543">2543</a></span>
<span class="normal"><a href="#__codelineno-0-2544">2544</a></span>
<span class="normal"><a href="#__codelineno-0-2545">2545</a></span>
<span class="normal"><a href="#__codelineno-0-2546">2546</a></span>
<span class="normal"><a href="#__codelineno-0-2547">2547</a></span>
<span class="normal"><a href="#__codelineno-0-2548">2548</a></span>
<span class="normal"><a href="#__codelineno-0-2549">2549</a></span>
<span class="normal"><a href="#__codelineno-0-2550">2550</a></span>
<span class="normal"><a href="#__codelineno-0-2551">2551</a></span>
<span class="normal"><a href="#__codelineno-0-2552">2552</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-2483"><a id="__codelineno-0-2483" name="__codelineno-0-2483"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">ANALYZER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-2484"><a id="__codelineno-0-2484" name="__codelineno-0-2484"></a><span class="k">def</span><span class="w"> </span><span class="nf">quantiles</span><span class="p">(</span>
</span><span id="__span-0-2485"><a id="__codelineno-0-2485" name="__codelineno-0-2485"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-2486"><a id="__codelineno-0-2486" name="__codelineno-0-2486"></a>    <span class="n">num_buckets</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-2487"><a id="__codelineno-0-2487" name="__codelineno-0-2487"></a>    <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
</span><span id="__span-0-2488"><a id="__codelineno-0-2488" name="__codelineno-0-2488"></a>    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-2489"><a id="__codelineno-0-2489" name="__codelineno-0-2489"></a>    <span class="n">reduce_instance_dims</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-2490"><a id="__codelineno-0-2490" name="__codelineno-0-2490"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-2491"><a id="__codelineno-0-2491" name="__codelineno-0-2491"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-2492"><a id="__codelineno-0-2492" name="__codelineno-0-2492"></a><span class="w">    </span><span class="sd">"""Computes the quantile boundaries of a `Tensor` over the whole dataset.</span>
</span><span id="__span-0-2493"><a id="__codelineno-0-2493" name="__codelineno-0-2493"></a>
</span><span id="__span-0-2494"><a id="__codelineno-0-2494" name="__codelineno-0-2494"></a><span class="sd">    Quantile boundaries are computed using approximate quantiles,</span>
</span><span id="__span-0-2495"><a id="__codelineno-0-2495" name="__codelineno-0-2495"></a><span class="sd">    and error tolerance is specified using `epsilon`. The boundaries divide the</span>
</span><span id="__span-0-2496"><a id="__codelineno-0-2496" name="__codelineno-0-2496"></a><span class="sd">    input tensor into approximately equal `num_buckets` parts.</span>
</span><span id="__span-0-2497"><a id="__codelineno-0-2497" name="__codelineno-0-2497"></a><span class="sd">    See go/squawd for details, and how to control the error due to approximation.</span>
</span><span id="__span-0-2498"><a id="__codelineno-0-2498" name="__codelineno-0-2498"></a><span class="sd">    NaN input values and values with NaN weights are ignored.</span>
</span><span id="__span-0-2499"><a id="__codelineno-0-2499" name="__codelineno-0-2499"></a>
</span><span id="__span-0-2500"><a id="__codelineno-0-2500" name="__codelineno-0-2500"></a><span class="sd">    Args:</span>
</span><span id="__span-0-2501"><a id="__codelineno-0-2501" name="__codelineno-0-2501"></a><span class="sd">    ----</span>
</span><span id="__span-0-2502"><a id="__codelineno-0-2502" name="__codelineno-0-2502"></a><span class="sd">      x: An input `Tensor`.</span>
</span><span id="__span-0-2503"><a id="__codelineno-0-2503" name="__codelineno-0-2503"></a><span class="sd">      num_buckets: Values in the `x` are divided into approximately equal-sized</span>
</span><span id="__span-0-2504"><a id="__codelineno-0-2504" name="__codelineno-0-2504"></a><span class="sd">        buckets, where the number of buckets is `num_buckets`. The number of</span>
</span><span id="__span-0-2505"><a id="__codelineno-0-2505" name="__codelineno-0-2505"></a><span class="sd">        returned quantiles is `num_buckets` - 1.</span>
</span><span id="__span-0-2506"><a id="__codelineno-0-2506" name="__codelineno-0-2506"></a><span class="sd">      epsilon: Error tolerance, typically a small fraction close to zero (e.g.</span>
</span><span id="__span-0-2507"><a id="__codelineno-0-2507" name="__codelineno-0-2507"></a><span class="sd">        0.01). Higher values of epsilon increase the quantile approximation, and</span>
</span><span id="__span-0-2508"><a id="__codelineno-0-2508" name="__codelineno-0-2508"></a><span class="sd">        hence result in more unequal buckets, but could improve performance,</span>
</span><span id="__span-0-2509"><a id="__codelineno-0-2509" name="__codelineno-0-2509"></a><span class="sd">        and resource consumption.  Some measured results on memory consumption:</span>
</span><span id="__span-0-2510"><a id="__codelineno-0-2510" name="__codelineno-0-2510"></a><span class="sd">          For epsilon = 0.001, the amount of memory for each buffer to hold the</span>
</span><span id="__span-0-2511"><a id="__codelineno-0-2511" name="__codelineno-0-2511"></a><span class="sd">          summary for 1 trillion input values is ~25000 bytes. If epsilon is</span>
</span><span id="__span-0-2512"><a id="__codelineno-0-2512" name="__codelineno-0-2512"></a><span class="sd">          relaxed to 0.01, the buffer size drops to ~2000 bytes for the same input</span>
</span><span id="__span-0-2513"><a id="__codelineno-0-2513" name="__codelineno-0-2513"></a><span class="sd">          size. The buffer size also determines the amount of work in the</span>
</span><span id="__span-0-2514"><a id="__codelineno-0-2514" name="__codelineno-0-2514"></a><span class="sd">          different stages of the beam pipeline, in general, larger epsilon</span>
</span><span id="__span-0-2515"><a id="__codelineno-0-2515" name="__codelineno-0-2515"></a><span class="sd">          results in fewer and smaller stages, and less time. For more performance</span>
</span><span id="__span-0-2516"><a id="__codelineno-0-2516" name="__codelineno-0-2516"></a><span class="sd">          trade-offs see also http://web.cs.ucla.edu/~weiwang/paper/SSDBM07_2.pdf</span>
</span><span id="__span-0-2517"><a id="__codelineno-0-2517" name="__codelineno-0-2517"></a><span class="sd">      weights: (Optional) Weights tensor for the quantiles. Tensor must have the</span>
</span><span id="__span-0-2518"><a id="__codelineno-0-2518" name="__codelineno-0-2518"></a><span class="sd">        same batch size as x.</span>
</span><span id="__span-0-2519"><a id="__codelineno-0-2519" name="__codelineno-0-2519"></a><span class="sd">      reduce_instance_dims: By default collapses the batch and instance dimensions</span>
</span><span id="__span-0-2520"><a id="__codelineno-0-2520" name="__codelineno-0-2520"></a><span class="sd">          to arrive at a single output vector. If False, only collapses the batch</span>
</span><span id="__span-0-2521"><a id="__codelineno-0-2521" name="__codelineno-0-2521"></a><span class="sd">          dimension and outputs a vector of the same shape as the input.</span>
</span><span id="__span-0-2522"><a id="__codelineno-0-2522" name="__codelineno-0-2522"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-2523"><a id="__codelineno-0-2523" name="__codelineno-0-2523"></a>
</span><span id="__span-0-2524"><a id="__codelineno-0-2524" name="__codelineno-0-2524"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-2525"><a id="__codelineno-0-2525" name="__codelineno-0-2525"></a><span class="sd">    -------</span>
</span><span id="__span-0-2526"><a id="__codelineno-0-2526" name="__codelineno-0-2526"></a><span class="sd">      The bucket boundaries represented as a list, with num_bucket-1 elements,</span>
</span><span id="__span-0-2527"><a id="__codelineno-0-2527" name="__codelineno-0-2527"></a><span class="sd">      unless reduce_instance_dims is False, which results in a Tensor of</span>
</span><span id="__span-0-2528"><a id="__codelineno-0-2528" name="__codelineno-0-2528"></a><span class="sd">      shape x.shape + [num_bucket-1].</span>
</span><span id="__span-0-2529"><a id="__codelineno-0-2529" name="__codelineno-0-2529"></a><span class="sd">      See code below for discussion on the type of bucket boundaries.</span>
</span><span id="__span-0-2530"><a id="__codelineno-0-2530" name="__codelineno-0-2530"></a><span class="sd">    """</span>
</span><span id="__span-0-2531"><a id="__codelineno-0-2531" name="__codelineno-0-2531"></a>    <span class="c1"># Quantile ops convert input values to double under the hood. Keep bucket</span>
</span><span id="__span-0-2532"><a id="__codelineno-0-2532" name="__codelineno-0-2532"></a>    <span class="c1"># boundaries as float for all numeric types.</span>
</span><span id="__span-0-2533"><a id="__codelineno-0-2533" name="__codelineno-0-2533"></a>    <span class="n">bucket_dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
</span><span id="__span-0-2534"><a id="__codelineno-0-2534" name="__codelineno-0-2534"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"quantiles"</span><span class="p">):</span>
</span><span id="__span-0-2535"><a id="__codelineno-0-2535" name="__codelineno-0-2535"></a>        <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-2536"><a id="__codelineno-0-2536" name="__codelineno-0-2536"></a>            <span class="n">analyzer_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
</span><span id="__span-0-2537"><a id="__codelineno-0-2537" name="__codelineno-0-2537"></a>            <span class="n">has_weights</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="__span-0-2538"><a id="__codelineno-0-2538" name="__codelineno-0-2538"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-2539"><a id="__codelineno-0-2539" name="__codelineno-0-2539"></a>            <span class="n">analyzer_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">weights</span><span class="p">]</span>
</span><span id="__span-0-2540"><a id="__codelineno-0-2540" name="__codelineno-0-2540"></a>            <span class="n">has_weights</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="__span-0-2541"><a id="__codelineno-0-2541" name="__codelineno-0-2541"></a>        <span class="n">feature_shape</span> <span class="o">=</span> <span class="p">[]</span> <span class="k">if</span> <span class="n">reduce_instance_dims</span> <span class="k">else</span> <span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="__span-0-2542"><a id="__codelineno-0-2542" name="__codelineno-0-2542"></a>        <span class="n">output_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">feature_shape</span> <span class="k">if</span> <span class="n">feature_shape</span> <span class="k">else</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="p">[</span><span class="n">num_buckets</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
</span><span id="__span-0-2543"><a id="__codelineno-0-2543" name="__codelineno-0-2543"></a>        <span class="n">combiner</span> <span class="o">=</span> <span class="n">QuantilesCombiner</span><span class="p">(</span>
</span><span id="__span-0-2544"><a id="__codelineno-0-2544" name="__codelineno-0-2544"></a>            <span class="n">num_buckets</span><span class="p">,</span>
</span><span id="__span-0-2545"><a id="__codelineno-0-2545" name="__codelineno-0-2545"></a>            <span class="n">epsilon</span><span class="p">,</span>
</span><span id="__span-0-2546"><a id="__codelineno-0-2546" name="__codelineno-0-2546"></a>            <span class="n">bucket_dtype</span><span class="o">.</span><span class="n">as_numpy_dtype</span><span class="p">,</span>
</span><span id="__span-0-2547"><a id="__codelineno-0-2547" name="__codelineno-0-2547"></a>            <span class="n">has_weights</span><span class="o">=</span><span class="n">has_weights</span><span class="p">,</span>
</span><span id="__span-0-2548"><a id="__codelineno-0-2548" name="__codelineno-0-2548"></a>            <span class="n">output_shape</span><span class="o">=</span><span class="n">output_shape</span><span class="p">,</span>
</span><span id="__span-0-2549"><a id="__codelineno-0-2549" name="__codelineno-0-2549"></a>            <span class="n">feature_shape</span><span class="o">=</span><span class="n">feature_shape</span><span class="p">,</span>
</span><span id="__span-0-2550"><a id="__codelineno-0-2550" name="__codelineno-0-2550"></a>        <span class="p">)</span>
</span><span id="__span-0-2551"><a id="__codelineno-0-2551" name="__codelineno-0-2551"></a>        <span class="p">(</span><span class="n">quantile_boundaries</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_apply_cacheable_combiner</span><span class="p">(</span><span class="n">combiner</span><span class="p">,</span> <span class="o">*</span><span class="n">analyzer_inputs</span><span class="p">)</span>
</span><span id="__span-0-2552"><a id="__codelineno-0-2552" name="__codelineno-0-2552"></a>        <span class="k">return</span> <span class="n">quantile_boundaries</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.scale_by_min_max" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">scale_by_min_max</span>


<a href="#tensorflow_transform.scale_by_min_max" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">scale_by_min_max</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">output_min</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">output_max</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">elementwise</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Scale a numerical column into the range [output_min, output_max].</p>
        <hr>
<p>x: A numeric <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.
  output_min: The minimum of the range of output values.
  output_max: The maximum of the range of output values.
  elementwise: If true, scale each element of the tensor independently.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>A <code>Tensor</code> containing the input column scaled to [output_min, output_max].
  If the analysis dataset is empty or contains a singe distinct value, then
  <code>x</code> is scaled using a sigmoid function.</p>
        <hr>
<p>ValueError: If output_min, output_max have the wrong order.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span>
<span class="normal"><a href="#__codelineno-0-263">263</a></span>
<span class="normal"><a href="#__codelineno-0-264">264</a></span>
<span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span>
<span class="normal"><a href="#__codelineno-0-274">274</a></span>
<span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span>
<span class="normal"><a href="#__codelineno-0-282">282</a></span>
<span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span>
<span class="normal"><a href="#__codelineno-0-285">285</a></span>
<span class="normal"><a href="#__codelineno-0-286">286</a></span>
<span class="normal"><a href="#__codelineno-0-287">287</a></span>
<span class="normal"><a href="#__codelineno-0-288">288</a></span>
<span class="normal"><a href="#__codelineno-0-289">289</a></span>
<span class="normal"><a href="#__codelineno-0-290">290</a></span>
<span class="normal"><a href="#__codelineno-0-291">291</a></span>
<span class="normal"><a href="#__codelineno-0-292">292</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-256"><a id="__codelineno-0-256" name="__codelineno-0-256"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-257"><a id="__codelineno-0-257" name="__codelineno-0-257"></a><span class="k">def</span><span class="w"> </span><span class="nf">scale_by_min_max</span><span class="p">(</span>
</span><span id="__span-0-258"><a id="__codelineno-0-258" name="__codelineno-0-258"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">,</span>
</span><span id="__span-0-259"><a id="__codelineno-0-259" name="__codelineno-0-259"></a>    <span class="n">output_min</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-260"><a id="__codelineno-0-260" name="__codelineno-0-260"></a>    <span class="n">output_max</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span id="__span-0-261"><a id="__codelineno-0-261" name="__codelineno-0-261"></a>    <span class="n">elementwise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-262"><a id="__codelineno-0-262" name="__codelineno-0-262"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-263"><a id="__codelineno-0-263" name="__codelineno-0-263"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">:</span>
</span><span id="__span-0-264"><a id="__codelineno-0-264" name="__codelineno-0-264"></a><span class="w">    </span><span class="sd">"""Scale a numerical column into the range [output_min, output_max].</span>
</span><span id="__span-0-265"><a id="__codelineno-0-265" name="__codelineno-0-265"></a>
</span><span id="__span-0-266"><a id="__codelineno-0-266" name="__codelineno-0-266"></a><span class="sd">    Args:</span>
</span><span id="__span-0-267"><a id="__codelineno-0-267" name="__codelineno-0-267"></a><span class="sd">    ----</span>
</span><span id="__span-0-268"><a id="__codelineno-0-268" name="__codelineno-0-268"></a><span class="sd">      x: A numeric `Tensor`, `SparseTensor`, or `RaggedTensor`.</span>
</span><span id="__span-0-269"><a id="__codelineno-0-269" name="__codelineno-0-269"></a><span class="sd">      output_min: The minimum of the range of output values.</span>
</span><span id="__span-0-270"><a id="__codelineno-0-270" name="__codelineno-0-270"></a><span class="sd">      output_max: The maximum of the range of output values.</span>
</span><span id="__span-0-271"><a id="__codelineno-0-271" name="__codelineno-0-271"></a><span class="sd">      elementwise: If true, scale each element of the tensor independently.</span>
</span><span id="__span-0-272"><a id="__codelineno-0-272" name="__codelineno-0-272"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-273"><a id="__codelineno-0-273" name="__codelineno-0-273"></a>
</span><span id="__span-0-274"><a id="__codelineno-0-274" name="__codelineno-0-274"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-275"><a id="__codelineno-0-275" name="__codelineno-0-275"></a><span class="sd">    -------</span>
</span><span id="__span-0-276"><a id="__codelineno-0-276" name="__codelineno-0-276"></a><span class="sd">      A `Tensor` containing the input column scaled to [output_min, output_max].</span>
</span><span id="__span-0-277"><a id="__codelineno-0-277" name="__codelineno-0-277"></a><span class="sd">      If the analysis dataset is empty or contains a singe distinct value, then</span>
</span><span id="__span-0-278"><a id="__codelineno-0-278" name="__codelineno-0-278"></a><span class="sd">      `x` is scaled using a sigmoid function.</span>
</span><span id="__span-0-279"><a id="__codelineno-0-279" name="__codelineno-0-279"></a>
</span><span id="__span-0-280"><a id="__codelineno-0-280" name="__codelineno-0-280"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-281"><a id="__codelineno-0-281" name="__codelineno-0-281"></a><span class="sd">    ------</span>
</span><span id="__span-0-282"><a id="__codelineno-0-282" name="__codelineno-0-282"></a><span class="sd">      ValueError: If output_min, output_max have the wrong order.</span>
</span><span id="__span-0-283"><a id="__codelineno-0-283" name="__codelineno-0-283"></a><span class="sd">    """</span>
</span><span id="__span-0-284"><a id="__codelineno-0-284" name="__codelineno-0-284"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"scale_by_min_max"</span><span class="p">):</span>
</span><span id="__span-0-285"><a id="__codelineno-0-285" name="__codelineno-0-285"></a>        <span class="k">return</span> <span class="n">_scale_by_min_max_internal</span><span class="p">(</span>
</span><span id="__span-0-286"><a id="__codelineno-0-286" name="__codelineno-0-286"></a>            <span class="n">x</span><span class="p">,</span>
</span><span id="__span-0-287"><a id="__codelineno-0-287" name="__codelineno-0-287"></a>            <span class="n">key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-288"><a id="__codelineno-0-288" name="__codelineno-0-288"></a>            <span class="n">output_min</span><span class="o">=</span><span class="n">output_min</span><span class="p">,</span>
</span><span id="__span-0-289"><a id="__codelineno-0-289" name="__codelineno-0-289"></a>            <span class="n">output_max</span><span class="o">=</span><span class="n">output_max</span><span class="p">,</span>
</span><span id="__span-0-290"><a id="__codelineno-0-290" name="__codelineno-0-290"></a>            <span class="n">elementwise</span><span class="o">=</span><span class="n">elementwise</span><span class="p">,</span>
</span><span id="__span-0-291"><a id="__codelineno-0-291" name="__codelineno-0-291"></a>            <span class="n">key_vocabulary_filename</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-292"><a id="__codelineno-0-292" name="__codelineno-0-292"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.scale_by_min_max_per_key" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">scale_by_min_max_per_key</span>


<a href="#tensorflow_transform.scale_by_min_max_per_key" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">scale_by_min_max_per_key</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">key</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">output_min</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">output_max</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">elementwise</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">key_vocabulary_filename</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Scale a numerical column into a predefined range on a per-key basis.</p>
        <hr>
<p>x: A numeric <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.
  key: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of dtype tf.string.
      Must meet one of the following conditions:
      0. key is None
      1. Both x and key are dense,
      2. Both x and key are composite and <code>key</code> must exactly match <code>x</code> in
         everything except values,
      3. The axis=1 index of each x matches its index of dense key.
  output_min: The minimum of the range of output values.
  output_max: The maximum of the range of output values.
  elementwise: If true, scale each element of the tensor independently.
  key_vocabulary_filename: (Optional) The file name for the per-key file.
    If None, this combiner will assume the keys fit in memory and will not
    store the analyzer result in a file. If '', a file name will be chosen
    based on the current TensorFlow scope. If not '', it should be unique
    within a given preprocessing function.
  name: (Optional) A name for this operation.</p>
<h6 id="tensorflow_transform.scale_by_min_max_per_key--example">Example:<a class="headerlink" href="#tensorflow_transform.scale_by_min_max_per_key--example" title="Permanent link">Â¶</a></h6>
<blockquote>
<blockquote>
<blockquote>
<p>def preprocessing_fn(inputs):
...   return {
...      'scaled': tft.scale_by_min_max_per_key(inputs['x'], inputs['s'])
...   }
raw_data = [dict(x=1, s='a'), dict(x=0, s='b'), dict(x=3, s='a')]
feature_spec = dict(
...     x=tf.io.FixedLenFeature([], tf.float32),
...     s=tf.io.FixedLenFeature([], tf.string))
raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec)
with tft_beam.Context(temp_dir=tempfile.mkdtemp()):
...   transformed_dataset, transform_fn = (
...       (raw_data, raw_data_metadata)
...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))
transformed_data, transformed_metadata = transformed_dataset
transformed_data
[{'scaled': 0.0}, {'scaled': 0.5}, {'scaled': 1.0}]</p>
</blockquote>
</blockquote>
</blockquote>
        <hr>
<p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> containing the input column scaled to
  [output_min, output_max] on a per-key basis if a key is provided. If the
  analysis dataset is empty, a certain key contains a single distinct value or
  the computed key vocabulary doesn't have an entry for <code>key</code>, then <code>x</code> is
  scaled using a sigmoid function.</p>
        <hr>
<p>ValueError: If output_min, output_max have the wrong order.
  NotImplementedError: If elementwise is True and key is not None.
  InvalidArgumentError: If indices of sparse x and key do not match.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span>
<span class="normal"><a href="#__codelineno-0-298">298</a></span>
<span class="normal"><a href="#__codelineno-0-299">299</a></span>
<span class="normal"><a href="#__codelineno-0-300">300</a></span>
<span class="normal"><a href="#__codelineno-0-301">301</a></span>
<span class="normal"><a href="#__codelineno-0-302">302</a></span>
<span class="normal"><a href="#__codelineno-0-303">303</a></span>
<span class="normal"><a href="#__codelineno-0-304">304</a></span>
<span class="normal"><a href="#__codelineno-0-305">305</a></span>
<span class="normal"><a href="#__codelineno-0-306">306</a></span>
<span class="normal"><a href="#__codelineno-0-307">307</a></span>
<span class="normal"><a href="#__codelineno-0-308">308</a></span>
<span class="normal"><a href="#__codelineno-0-309">309</a></span>
<span class="normal"><a href="#__codelineno-0-310">310</a></span>
<span class="normal"><a href="#__codelineno-0-311">311</a></span>
<span class="normal"><a href="#__codelineno-0-312">312</a></span>
<span class="normal"><a href="#__codelineno-0-313">313</a></span>
<span class="normal"><a href="#__codelineno-0-314">314</a></span>
<span class="normal"><a href="#__codelineno-0-315">315</a></span>
<span class="normal"><a href="#__codelineno-0-316">316</a></span>
<span class="normal"><a href="#__codelineno-0-317">317</a></span>
<span class="normal"><a href="#__codelineno-0-318">318</a></span>
<span class="normal"><a href="#__codelineno-0-319">319</a></span>
<span class="normal"><a href="#__codelineno-0-320">320</a></span>
<span class="normal"><a href="#__codelineno-0-321">321</a></span>
<span class="normal"><a href="#__codelineno-0-322">322</a></span>
<span class="normal"><a href="#__codelineno-0-323">323</a></span>
<span class="normal"><a href="#__codelineno-0-324">324</a></span>
<span class="normal"><a href="#__codelineno-0-325">325</a></span>
<span class="normal"><a href="#__codelineno-0-326">326</a></span>
<span class="normal"><a href="#__codelineno-0-327">327</a></span>
<span class="normal"><a href="#__codelineno-0-328">328</a></span>
<span class="normal"><a href="#__codelineno-0-329">329</a></span>
<span class="normal"><a href="#__codelineno-0-330">330</a></span>
<span class="normal"><a href="#__codelineno-0-331">331</a></span>
<span class="normal"><a href="#__codelineno-0-332">332</a></span>
<span class="normal"><a href="#__codelineno-0-333">333</a></span>
<span class="normal"><a href="#__codelineno-0-334">334</a></span>
<span class="normal"><a href="#__codelineno-0-335">335</a></span>
<span class="normal"><a href="#__codelineno-0-336">336</a></span>
<span class="normal"><a href="#__codelineno-0-337">337</a></span>
<span class="normal"><a href="#__codelineno-0-338">338</a></span>
<span class="normal"><a href="#__codelineno-0-339">339</a></span>
<span class="normal"><a href="#__codelineno-0-340">340</a></span>
<span class="normal"><a href="#__codelineno-0-341">341</a></span>
<span class="normal"><a href="#__codelineno-0-342">342</a></span>
<span class="normal"><a href="#__codelineno-0-343">343</a></span>
<span class="normal"><a href="#__codelineno-0-344">344</a></span>
<span class="normal"><a href="#__codelineno-0-345">345</a></span>
<span class="normal"><a href="#__codelineno-0-346">346</a></span>
<span class="normal"><a href="#__codelineno-0-347">347</a></span>
<span class="normal"><a href="#__codelineno-0-348">348</a></span>
<span class="normal"><a href="#__codelineno-0-349">349</a></span>
<span class="normal"><a href="#__codelineno-0-350">350</a></span>
<span class="normal"><a href="#__codelineno-0-351">351</a></span>
<span class="normal"><a href="#__codelineno-0-352">352</a></span>
<span class="normal"><a href="#__codelineno-0-353">353</a></span>
<span class="normal"><a href="#__codelineno-0-354">354</a></span>
<span class="normal"><a href="#__codelineno-0-355">355</a></span>
<span class="normal"><a href="#__codelineno-0-356">356</a></span>
<span class="normal"><a href="#__codelineno-0-357">357</a></span>
<span class="normal"><a href="#__codelineno-0-358">358</a></span>
<span class="normal"><a href="#__codelineno-0-359">359</a></span>
<span class="normal"><a href="#__codelineno-0-360">360</a></span>
<span class="normal"><a href="#__codelineno-0-361">361</a></span>
<span class="normal"><a href="#__codelineno-0-362">362</a></span>
<span class="normal"><a href="#__codelineno-0-363">363</a></span>
<span class="normal"><a href="#__codelineno-0-364">364</a></span>
<span class="normal"><a href="#__codelineno-0-365">365</a></span>
<span class="normal"><a href="#__codelineno-0-366">366</a></span>
<span class="normal"><a href="#__codelineno-0-367">367</a></span>
<span class="normal"><a href="#__codelineno-0-368">368</a></span>
<span class="normal"><a href="#__codelineno-0-369">369</a></span>
<span class="normal"><a href="#__codelineno-0-370">370</a></span>
<span class="normal"><a href="#__codelineno-0-371">371</a></span>
<span class="normal"><a href="#__codelineno-0-372">372</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-295"><a id="__codelineno-0-295" name="__codelineno-0-295"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-296"><a id="__codelineno-0-296" name="__codelineno-0-296"></a><span class="k">def</span><span class="w"> </span><span class="nf">scale_by_min_max_per_key</span><span class="p">(</span>
</span><span id="__span-0-297"><a id="__codelineno-0-297" name="__codelineno-0-297"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">,</span>
</span><span id="__span-0-298"><a id="__codelineno-0-298" name="__codelineno-0-298"></a>    <span class="n">key</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span>
</span><span id="__span-0-299"><a id="__codelineno-0-299" name="__codelineno-0-299"></a>    <span class="n">output_min</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-300"><a id="__codelineno-0-300" name="__codelineno-0-300"></a>    <span class="n">output_max</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span id="__span-0-301"><a id="__codelineno-0-301" name="__codelineno-0-301"></a>    <span class="n">elementwise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-302"><a id="__codelineno-0-302" name="__codelineno-0-302"></a>    <span class="n">key_vocabulary_filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-303"><a id="__codelineno-0-303" name="__codelineno-0-303"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-304"><a id="__codelineno-0-304" name="__codelineno-0-304"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">:</span>
</span><span id="__span-0-305"><a id="__codelineno-0-305" name="__codelineno-0-305"></a>    <span class="c1"># pyformat: disable</span>
</span><span id="__span-0-306"><a id="__codelineno-0-306" name="__codelineno-0-306"></a><span class="w">    </span><span class="sd">"""Scale a numerical column into a predefined range on a per-key basis.</span>
</span><span id="__span-0-307"><a id="__codelineno-0-307" name="__codelineno-0-307"></a>
</span><span id="__span-0-308"><a id="__codelineno-0-308" name="__codelineno-0-308"></a><span class="sd">    Args:</span>
</span><span id="__span-0-309"><a id="__codelineno-0-309" name="__codelineno-0-309"></a><span class="sd">    ----</span>
</span><span id="__span-0-310"><a id="__codelineno-0-310" name="__codelineno-0-310"></a><span class="sd">      x: A numeric `Tensor`, `SparseTensor`, or `RaggedTensor`.</span>
</span><span id="__span-0-311"><a id="__codelineno-0-311" name="__codelineno-0-311"></a><span class="sd">      key: A `Tensor`, `SparseTensor`, or `RaggedTensor` of dtype tf.string.</span>
</span><span id="__span-0-312"><a id="__codelineno-0-312" name="__codelineno-0-312"></a><span class="sd">          Must meet one of the following conditions:</span>
</span><span id="__span-0-313"><a id="__codelineno-0-313" name="__codelineno-0-313"></a><span class="sd">          0. key is None</span>
</span><span id="__span-0-314"><a id="__codelineno-0-314" name="__codelineno-0-314"></a><span class="sd">          1. Both x and key are dense,</span>
</span><span id="__span-0-315"><a id="__codelineno-0-315" name="__codelineno-0-315"></a><span class="sd">          2. Both x and key are composite and `key` must exactly match `x` in</span>
</span><span id="__span-0-316"><a id="__codelineno-0-316" name="__codelineno-0-316"></a><span class="sd">             everything except values,</span>
</span><span id="__span-0-317"><a id="__codelineno-0-317" name="__codelineno-0-317"></a><span class="sd">          3. The axis=1 index of each x matches its index of dense key.</span>
</span><span id="__span-0-318"><a id="__codelineno-0-318" name="__codelineno-0-318"></a><span class="sd">      output_min: The minimum of the range of output values.</span>
</span><span id="__span-0-319"><a id="__codelineno-0-319" name="__codelineno-0-319"></a><span class="sd">      output_max: The maximum of the range of output values.</span>
</span><span id="__span-0-320"><a id="__codelineno-0-320" name="__codelineno-0-320"></a><span class="sd">      elementwise: If true, scale each element of the tensor independently.</span>
</span><span id="__span-0-321"><a id="__codelineno-0-321" name="__codelineno-0-321"></a><span class="sd">      key_vocabulary_filename: (Optional) The file name for the per-key file.</span>
</span><span id="__span-0-322"><a id="__codelineno-0-322" name="__codelineno-0-322"></a><span class="sd">        If None, this combiner will assume the keys fit in memory and will not</span>
</span><span id="__span-0-323"><a id="__codelineno-0-323" name="__codelineno-0-323"></a><span class="sd">        store the analyzer result in a file. If '', a file name will be chosen</span>
</span><span id="__span-0-324"><a id="__codelineno-0-324" name="__codelineno-0-324"></a><span class="sd">        based on the current TensorFlow scope. If not '', it should be unique</span>
</span><span id="__span-0-325"><a id="__codelineno-0-325" name="__codelineno-0-325"></a><span class="sd">        within a given preprocessing function.</span>
</span><span id="__span-0-326"><a id="__codelineno-0-326" name="__codelineno-0-326"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-327"><a id="__codelineno-0-327" name="__codelineno-0-327"></a>
</span><span id="__span-0-328"><a id="__codelineno-0-328" name="__codelineno-0-328"></a><span class="sd">    Example:</span>
</span><span id="__span-0-329"><a id="__codelineno-0-329" name="__codelineno-0-329"></a><span class="sd">    -------</span>
</span><span id="__span-0-330"><a id="__codelineno-0-330" name="__codelineno-0-330"></a><span class="sd">    &gt;&gt;&gt; def preprocessing_fn(inputs):</span>
</span><span id="__span-0-331"><a id="__codelineno-0-331" name="__codelineno-0-331"></a><span class="sd">    ...   return {</span>
</span><span id="__span-0-332"><a id="__codelineno-0-332" name="__codelineno-0-332"></a><span class="sd">    ...      'scaled': tft.scale_by_min_max_per_key(inputs['x'], inputs['s'])</span>
</span><span id="__span-0-333"><a id="__codelineno-0-333" name="__codelineno-0-333"></a><span class="sd">    ...   }</span>
</span><span id="__span-0-334"><a id="__codelineno-0-334" name="__codelineno-0-334"></a><span class="sd">    &gt;&gt;&gt; raw_data = [dict(x=1, s='a'), dict(x=0, s='b'), dict(x=3, s='a')]</span>
</span><span id="__span-0-335"><a id="__codelineno-0-335" name="__codelineno-0-335"></a><span class="sd">    &gt;&gt;&gt; feature_spec = dict(</span>
</span><span id="__span-0-336"><a id="__codelineno-0-336" name="__codelineno-0-336"></a><span class="sd">    ...     x=tf.io.FixedLenFeature([], tf.float32),</span>
</span><span id="__span-0-337"><a id="__codelineno-0-337" name="__codelineno-0-337"></a><span class="sd">    ...     s=tf.io.FixedLenFeature([], tf.string))</span>
</span><span id="__span-0-338"><a id="__codelineno-0-338" name="__codelineno-0-338"></a><span class="sd">    &gt;&gt;&gt; raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec)</span>
</span><span id="__span-0-339"><a id="__codelineno-0-339" name="__codelineno-0-339"></a><span class="sd">    &gt;&gt;&gt; with tft_beam.Context(temp_dir=tempfile.mkdtemp()):</span>
</span><span id="__span-0-340"><a id="__codelineno-0-340" name="__codelineno-0-340"></a><span class="sd">    ...   transformed_dataset, transform_fn = (</span>
</span><span id="__span-0-341"><a id="__codelineno-0-341" name="__codelineno-0-341"></a><span class="sd">    ...       (raw_data, raw_data_metadata)</span>
</span><span id="__span-0-342"><a id="__codelineno-0-342" name="__codelineno-0-342"></a><span class="sd">    ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))</span>
</span><span id="__span-0-343"><a id="__codelineno-0-343" name="__codelineno-0-343"></a><span class="sd">    &gt;&gt;&gt; transformed_data, transformed_metadata = transformed_dataset</span>
</span><span id="__span-0-344"><a id="__codelineno-0-344" name="__codelineno-0-344"></a><span class="sd">    &gt;&gt;&gt; transformed_data</span>
</span><span id="__span-0-345"><a id="__codelineno-0-345" name="__codelineno-0-345"></a><span class="sd">    [{'scaled': 0.0}, {'scaled': 0.5}, {'scaled': 1.0}]</span>
</span><span id="__span-0-346"><a id="__codelineno-0-346" name="__codelineno-0-346"></a>
</span><span id="__span-0-347"><a id="__codelineno-0-347" name="__codelineno-0-347"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-348"><a id="__codelineno-0-348" name="__codelineno-0-348"></a><span class="sd">    -------</span>
</span><span id="__span-0-349"><a id="__codelineno-0-349" name="__codelineno-0-349"></a><span class="sd">      A `Tensor`, `SparseTensor`, or `RaggedTensor` containing the input column scaled to</span>
</span><span id="__span-0-350"><a id="__codelineno-0-350" name="__codelineno-0-350"></a><span class="sd">      [output_min, output_max] on a per-key basis if a key is provided. If the</span>
</span><span id="__span-0-351"><a id="__codelineno-0-351" name="__codelineno-0-351"></a><span class="sd">      analysis dataset is empty, a certain key contains a single distinct value or</span>
</span><span id="__span-0-352"><a id="__codelineno-0-352" name="__codelineno-0-352"></a><span class="sd">      the computed key vocabulary doesn't have an entry for `key`, then `x` is</span>
</span><span id="__span-0-353"><a id="__codelineno-0-353" name="__codelineno-0-353"></a><span class="sd">      scaled using a sigmoid function.</span>
</span><span id="__span-0-354"><a id="__codelineno-0-354" name="__codelineno-0-354"></a>
</span><span id="__span-0-355"><a id="__codelineno-0-355" name="__codelineno-0-355"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-356"><a id="__codelineno-0-356" name="__codelineno-0-356"></a><span class="sd">    ------</span>
</span><span id="__span-0-357"><a id="__codelineno-0-357" name="__codelineno-0-357"></a><span class="sd">      ValueError: If output_min, output_max have the wrong order.</span>
</span><span id="__span-0-358"><a id="__codelineno-0-358" name="__codelineno-0-358"></a><span class="sd">      NotImplementedError: If elementwise is True and key is not None.</span>
</span><span id="__span-0-359"><a id="__codelineno-0-359" name="__codelineno-0-359"></a><span class="sd">      InvalidArgumentError: If indices of sparse x and key do not match.</span>
</span><span id="__span-0-360"><a id="__codelineno-0-360" name="__codelineno-0-360"></a><span class="sd">    """</span>
</span><span id="__span-0-361"><a id="__codelineno-0-361" name="__codelineno-0-361"></a>    <span class="c1"># pyformat: enable</span>
</span><span id="__span-0-362"><a id="__codelineno-0-362" name="__codelineno-0-362"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"scale_by_min_max_per_key"</span><span class="p">):</span>
</span><span id="__span-0-363"><a id="__codelineno-0-363" name="__codelineno-0-363"></a>        <span class="k">if</span> <span class="n">key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-364"><a id="__codelineno-0-364" name="__codelineno-0-364"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"key is None, call `tft.scale_by_min_max` instead"</span><span class="p">)</span>
</span><span id="__span-0-365"><a id="__codelineno-0-365" name="__codelineno-0-365"></a>        <span class="k">return</span> <span class="n">_scale_by_min_max_internal</span><span class="p">(</span>
</span><span id="__span-0-366"><a id="__codelineno-0-366" name="__codelineno-0-366"></a>            <span class="n">x</span><span class="p">,</span>
</span><span id="__span-0-367"><a id="__codelineno-0-367" name="__codelineno-0-367"></a>            <span class="n">key</span><span class="o">=</span><span class="n">key</span><span class="p">,</span>
</span><span id="__span-0-368"><a id="__codelineno-0-368" name="__codelineno-0-368"></a>            <span class="n">output_min</span><span class="o">=</span><span class="n">output_min</span><span class="p">,</span>
</span><span id="__span-0-369"><a id="__codelineno-0-369" name="__codelineno-0-369"></a>            <span class="n">output_max</span><span class="o">=</span><span class="n">output_max</span><span class="p">,</span>
</span><span id="__span-0-370"><a id="__codelineno-0-370" name="__codelineno-0-370"></a>            <span class="n">elementwise</span><span class="o">=</span><span class="n">elementwise</span><span class="p">,</span>
</span><span id="__span-0-371"><a id="__codelineno-0-371" name="__codelineno-0-371"></a>            <span class="n">key_vocabulary_filename</span><span class="o">=</span><span class="n">key_vocabulary_filename</span><span class="p">,</span>
</span><span id="__span-0-372"><a id="__codelineno-0-372" name="__codelineno-0-372"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.scale_to_0_1" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">scale_to_0_1</span>


<a href="#tensorflow_transform.scale_to_0_1" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">scale_to_0_1</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">elementwise</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Returns a column which is the input column scaled to have range [0,1].</p>
        <hr>
<p>x: A numeric <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.
  elementwise: If true, scale each element of the tensor independently.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> containing the input column
  scaled to
  [0, 1]. If the analysis dataset is empty or contains a single distinct
  value, then <code>x</code> is scaled using a sigmoid function.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-457">457</a></span>
<span class="normal"><a href="#__codelineno-0-458">458</a></span>
<span class="normal"><a href="#__codelineno-0-459">459</a></span>
<span class="normal"><a href="#__codelineno-0-460">460</a></span>
<span class="normal"><a href="#__codelineno-0-461">461</a></span>
<span class="normal"><a href="#__codelineno-0-462">462</a></span>
<span class="normal"><a href="#__codelineno-0-463">463</a></span>
<span class="normal"><a href="#__codelineno-0-464">464</a></span>
<span class="normal"><a href="#__codelineno-0-465">465</a></span>
<span class="normal"><a href="#__codelineno-0-466">466</a></span>
<span class="normal"><a href="#__codelineno-0-467">467</a></span>
<span class="normal"><a href="#__codelineno-0-468">468</a></span>
<span class="normal"><a href="#__codelineno-0-469">469</a></span>
<span class="normal"><a href="#__codelineno-0-470">470</a></span>
<span class="normal"><a href="#__codelineno-0-471">471</a></span>
<span class="normal"><a href="#__codelineno-0-472">472</a></span>
<span class="normal"><a href="#__codelineno-0-473">473</a></span>
<span class="normal"><a href="#__codelineno-0-474">474</a></span>
<span class="normal"><a href="#__codelineno-0-475">475</a></span>
<span class="normal"><a href="#__codelineno-0-476">476</a></span>
<span class="normal"><a href="#__codelineno-0-477">477</a></span>
<span class="normal"><a href="#__codelineno-0-478">478</a></span>
<span class="normal"><a href="#__codelineno-0-479">479</a></span>
<span class="normal"><a href="#__codelineno-0-480">480</a></span>
<span class="normal"><a href="#__codelineno-0-481">481</a></span>
<span class="normal"><a href="#__codelineno-0-482">482</a></span>
<span class="normal"><a href="#__codelineno-0-483">483</a></span>
<span class="normal"><a href="#__codelineno-0-484">484</a></span>
<span class="normal"><a href="#__codelineno-0-485">485</a></span>
<span class="normal"><a href="#__codelineno-0-486">486</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-457"><a id="__codelineno-0-457" name="__codelineno-0-457"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-458"><a id="__codelineno-0-458" name="__codelineno-0-458"></a><span class="k">def</span><span class="w"> </span><span class="nf">scale_to_0_1</span><span class="p">(</span>
</span><span id="__span-0-459"><a id="__codelineno-0-459" name="__codelineno-0-459"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">,</span>
</span><span id="__span-0-460"><a id="__codelineno-0-460" name="__codelineno-0-460"></a>    <span class="n">elementwise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-461"><a id="__codelineno-0-461" name="__codelineno-0-461"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-462"><a id="__codelineno-0-462" name="__codelineno-0-462"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">:</span>
</span><span id="__span-0-463"><a id="__codelineno-0-463" name="__codelineno-0-463"></a><span class="w">    </span><span class="sd">"""Returns a column which is the input column scaled to have range [0,1].</span>
</span><span id="__span-0-464"><a id="__codelineno-0-464" name="__codelineno-0-464"></a>
</span><span id="__span-0-465"><a id="__codelineno-0-465" name="__codelineno-0-465"></a><span class="sd">    Args:</span>
</span><span id="__span-0-466"><a id="__codelineno-0-466" name="__codelineno-0-466"></a><span class="sd">    ----</span>
</span><span id="__span-0-467"><a id="__codelineno-0-467" name="__codelineno-0-467"></a><span class="sd">      x: A numeric `Tensor`, `SparseTensor`, or `RaggedTensor`.</span>
</span><span id="__span-0-468"><a id="__codelineno-0-468" name="__codelineno-0-468"></a><span class="sd">      elementwise: If true, scale each element of the tensor independently.</span>
</span><span id="__span-0-469"><a id="__codelineno-0-469" name="__codelineno-0-469"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-470"><a id="__codelineno-0-470" name="__codelineno-0-470"></a>
</span><span id="__span-0-471"><a id="__codelineno-0-471" name="__codelineno-0-471"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-472"><a id="__codelineno-0-472" name="__codelineno-0-472"></a><span class="sd">    -------</span>
</span><span id="__span-0-473"><a id="__codelineno-0-473" name="__codelineno-0-473"></a><span class="sd">      A `Tensor`, `SparseTensor`, or `RaggedTensor` containing the input column</span>
</span><span id="__span-0-474"><a id="__codelineno-0-474" name="__codelineno-0-474"></a><span class="sd">      scaled to</span>
</span><span id="__span-0-475"><a id="__codelineno-0-475" name="__codelineno-0-475"></a><span class="sd">      [0, 1]. If the analysis dataset is empty or contains a single distinct</span>
</span><span id="__span-0-476"><a id="__codelineno-0-476" name="__codelineno-0-476"></a><span class="sd">      value, then `x` is scaled using a sigmoid function.</span>
</span><span id="__span-0-477"><a id="__codelineno-0-477" name="__codelineno-0-477"></a><span class="sd">    """</span>
</span><span id="__span-0-478"><a id="__codelineno-0-478" name="__codelineno-0-478"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"scale_to_0_1"</span><span class="p">):</span>
</span><span id="__span-0-479"><a id="__codelineno-0-479" name="__codelineno-0-479"></a>        <span class="k">return</span> <span class="n">_scale_by_min_max_internal</span><span class="p">(</span>
</span><span id="__span-0-480"><a id="__codelineno-0-480" name="__codelineno-0-480"></a>            <span class="n">x</span><span class="p">,</span>
</span><span id="__span-0-481"><a id="__codelineno-0-481" name="__codelineno-0-481"></a>            <span class="n">key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-482"><a id="__codelineno-0-482" name="__codelineno-0-482"></a>            <span class="n">output_min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-483"><a id="__codelineno-0-483" name="__codelineno-0-483"></a>            <span class="n">output_max</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-484"><a id="__codelineno-0-484" name="__codelineno-0-484"></a>            <span class="n">elementwise</span><span class="o">=</span><span class="n">elementwise</span><span class="p">,</span>
</span><span id="__span-0-485"><a id="__codelineno-0-485" name="__codelineno-0-485"></a>            <span class="n">key_vocabulary_filename</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-486"><a id="__codelineno-0-486" name="__codelineno-0-486"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.scale_to_0_1_per_key" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">scale_to_0_1_per_key</span>


<a href="#tensorflow_transform.scale_to_0_1_per_key" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">scale_to_0_1_per_key</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">key</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">elementwise</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">key_vocabulary_filename</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Returns a column which is the input column scaled to have range [0,1].</p>
        <hr>
<p>x: A numeric <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.
  key: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of type string.
  elementwise: If true, scale each element of the tensor independently.
  key_vocabulary_filename: (Optional) The file name for the per-key file. If
    None, this combiner will assume the keys fit in memory and will not store
    the analyzer result in a file. If '', a file name will be chosen based on
    the current TensorFlow scope. If not '', it should be unique within a
    given preprocessing function.
  name: (Optional) A name for this operation.</p>
<h6 id="tensorflow_transform.scale_to_0_1_per_key--example">Example:<a class="headerlink" href="#tensorflow_transform.scale_to_0_1_per_key--example" title="Permanent link">Â¶</a></h6>
<blockquote>
<blockquote>
<blockquote>
<p>def preprocessing_fn(inputs):
...   return {
...      'scaled': tft.scale_to_0_1_per_key(inputs['x'], inputs['s'])
...   }
raw_data = [dict(x=1, s='a'), dict(x=0, s='b'), dict(x=3, s='a')]
feature_spec = dict(
...     x=tf.io.FixedLenFeature([], tf.float32),
...     s=tf.io.FixedLenFeature([], tf.string))
raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec)
with tft_beam.Context(temp_dir=tempfile.mkdtemp()):
...   transformed_dataset, transform_fn = (
...       (raw_data, raw_data_metadata)
...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))
transformed_data, transformed_metadata = transformed_dataset
transformed_data
[{'scaled': 0.0}, {'scaled': 0.5}, {'scaled': 1.0}]</p>
</blockquote>
</blockquote>
</blockquote>
        <hr>
<p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> containing the input column scaled to [0, 1],
  per key. If the analysis dataset is empty, contains a single distinct value
  or the computed key vocabulary doesn't have an entry for <code>key</code>, then <code>x</code> is
  scaled using a sigmoid function.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-489">489</a></span>
<span class="normal"><a href="#__codelineno-0-490">490</a></span>
<span class="normal"><a href="#__codelineno-0-491">491</a></span>
<span class="normal"><a href="#__codelineno-0-492">492</a></span>
<span class="normal"><a href="#__codelineno-0-493">493</a></span>
<span class="normal"><a href="#__codelineno-0-494">494</a></span>
<span class="normal"><a href="#__codelineno-0-495">495</a></span>
<span class="normal"><a href="#__codelineno-0-496">496</a></span>
<span class="normal"><a href="#__codelineno-0-497">497</a></span>
<span class="normal"><a href="#__codelineno-0-498">498</a></span>
<span class="normal"><a href="#__codelineno-0-499">499</a></span>
<span class="normal"><a href="#__codelineno-0-500">500</a></span>
<span class="normal"><a href="#__codelineno-0-501">501</a></span>
<span class="normal"><a href="#__codelineno-0-502">502</a></span>
<span class="normal"><a href="#__codelineno-0-503">503</a></span>
<span class="normal"><a href="#__codelineno-0-504">504</a></span>
<span class="normal"><a href="#__codelineno-0-505">505</a></span>
<span class="normal"><a href="#__codelineno-0-506">506</a></span>
<span class="normal"><a href="#__codelineno-0-507">507</a></span>
<span class="normal"><a href="#__codelineno-0-508">508</a></span>
<span class="normal"><a href="#__codelineno-0-509">509</a></span>
<span class="normal"><a href="#__codelineno-0-510">510</a></span>
<span class="normal"><a href="#__codelineno-0-511">511</a></span>
<span class="normal"><a href="#__codelineno-0-512">512</a></span>
<span class="normal"><a href="#__codelineno-0-513">513</a></span>
<span class="normal"><a href="#__codelineno-0-514">514</a></span>
<span class="normal"><a href="#__codelineno-0-515">515</a></span>
<span class="normal"><a href="#__codelineno-0-516">516</a></span>
<span class="normal"><a href="#__codelineno-0-517">517</a></span>
<span class="normal"><a href="#__codelineno-0-518">518</a></span>
<span class="normal"><a href="#__codelineno-0-519">519</a></span>
<span class="normal"><a href="#__codelineno-0-520">520</a></span>
<span class="normal"><a href="#__codelineno-0-521">521</a></span>
<span class="normal"><a href="#__codelineno-0-522">522</a></span>
<span class="normal"><a href="#__codelineno-0-523">523</a></span>
<span class="normal"><a href="#__codelineno-0-524">524</a></span>
<span class="normal"><a href="#__codelineno-0-525">525</a></span>
<span class="normal"><a href="#__codelineno-0-526">526</a></span>
<span class="normal"><a href="#__codelineno-0-527">527</a></span>
<span class="normal"><a href="#__codelineno-0-528">528</a></span>
<span class="normal"><a href="#__codelineno-0-529">529</a></span>
<span class="normal"><a href="#__codelineno-0-530">530</a></span>
<span class="normal"><a href="#__codelineno-0-531">531</a></span>
<span class="normal"><a href="#__codelineno-0-532">532</a></span>
<span class="normal"><a href="#__codelineno-0-533">533</a></span>
<span class="normal"><a href="#__codelineno-0-534">534</a></span>
<span class="normal"><a href="#__codelineno-0-535">535</a></span>
<span class="normal"><a href="#__codelineno-0-536">536</a></span>
<span class="normal"><a href="#__codelineno-0-537">537</a></span>
<span class="normal"><a href="#__codelineno-0-538">538</a></span>
<span class="normal"><a href="#__codelineno-0-539">539</a></span>
<span class="normal"><a href="#__codelineno-0-540">540</a></span>
<span class="normal"><a href="#__codelineno-0-541">541</a></span>
<span class="normal"><a href="#__codelineno-0-542">542</a></span>
<span class="normal"><a href="#__codelineno-0-543">543</a></span>
<span class="normal"><a href="#__codelineno-0-544">544</a></span>
<span class="normal"><a href="#__codelineno-0-545">545</a></span>
<span class="normal"><a href="#__codelineno-0-546">546</a></span>
<span class="normal"><a href="#__codelineno-0-547">547</a></span>
<span class="normal"><a href="#__codelineno-0-548">548</a></span>
<span class="normal"><a href="#__codelineno-0-549">549</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-489"><a id="__codelineno-0-489" name="__codelineno-0-489"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-490"><a id="__codelineno-0-490" name="__codelineno-0-490"></a><span class="k">def</span><span class="w"> </span><span class="nf">scale_to_0_1_per_key</span><span class="p">(</span>
</span><span id="__span-0-491"><a id="__codelineno-0-491" name="__codelineno-0-491"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">,</span>
</span><span id="__span-0-492"><a id="__codelineno-0-492" name="__codelineno-0-492"></a>    <span class="n">key</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span>
</span><span id="__span-0-493"><a id="__codelineno-0-493" name="__codelineno-0-493"></a>    <span class="n">elementwise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-494"><a id="__codelineno-0-494" name="__codelineno-0-494"></a>    <span class="n">key_vocabulary_filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-495"><a id="__codelineno-0-495" name="__codelineno-0-495"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-496"><a id="__codelineno-0-496" name="__codelineno-0-496"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">:</span>
</span><span id="__span-0-497"><a id="__codelineno-0-497" name="__codelineno-0-497"></a>    <span class="c1"># pyformat: disable</span>
</span><span id="__span-0-498"><a id="__codelineno-0-498" name="__codelineno-0-498"></a><span class="w">    </span><span class="sd">"""Returns a column which is the input column scaled to have range [0,1].</span>
</span><span id="__span-0-499"><a id="__codelineno-0-499" name="__codelineno-0-499"></a>
</span><span id="__span-0-500"><a id="__codelineno-0-500" name="__codelineno-0-500"></a><span class="sd">    Args:</span>
</span><span id="__span-0-501"><a id="__codelineno-0-501" name="__codelineno-0-501"></a><span class="sd">    ----</span>
</span><span id="__span-0-502"><a id="__codelineno-0-502" name="__codelineno-0-502"></a><span class="sd">      x: A numeric `Tensor`, `SparseTensor`, or `RaggedTensor`.</span>
</span><span id="__span-0-503"><a id="__codelineno-0-503" name="__codelineno-0-503"></a><span class="sd">      key: A `Tensor`, `SparseTensor`, or `RaggedTensor` of type string.</span>
</span><span id="__span-0-504"><a id="__codelineno-0-504" name="__codelineno-0-504"></a><span class="sd">      elementwise: If true, scale each element of the tensor independently.</span>
</span><span id="__span-0-505"><a id="__codelineno-0-505" name="__codelineno-0-505"></a><span class="sd">      key_vocabulary_filename: (Optional) The file name for the per-key file. If</span>
</span><span id="__span-0-506"><a id="__codelineno-0-506" name="__codelineno-0-506"></a><span class="sd">        None, this combiner will assume the keys fit in memory and will not store</span>
</span><span id="__span-0-507"><a id="__codelineno-0-507" name="__codelineno-0-507"></a><span class="sd">        the analyzer result in a file. If '', a file name will be chosen based on</span>
</span><span id="__span-0-508"><a id="__codelineno-0-508" name="__codelineno-0-508"></a><span class="sd">        the current TensorFlow scope. If not '', it should be unique within a</span>
</span><span id="__span-0-509"><a id="__codelineno-0-509" name="__codelineno-0-509"></a><span class="sd">        given preprocessing function.</span>
</span><span id="__span-0-510"><a id="__codelineno-0-510" name="__codelineno-0-510"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-511"><a id="__codelineno-0-511" name="__codelineno-0-511"></a>
</span><span id="__span-0-512"><a id="__codelineno-0-512" name="__codelineno-0-512"></a><span class="sd">    Example:</span>
</span><span id="__span-0-513"><a id="__codelineno-0-513" name="__codelineno-0-513"></a><span class="sd">    -------</span>
</span><span id="__span-0-514"><a id="__codelineno-0-514" name="__codelineno-0-514"></a><span class="sd">    &gt;&gt;&gt; def preprocessing_fn(inputs):</span>
</span><span id="__span-0-515"><a id="__codelineno-0-515" name="__codelineno-0-515"></a><span class="sd">    ...   return {</span>
</span><span id="__span-0-516"><a id="__codelineno-0-516" name="__codelineno-0-516"></a><span class="sd">    ...      'scaled': tft.scale_to_0_1_per_key(inputs['x'], inputs['s'])</span>
</span><span id="__span-0-517"><a id="__codelineno-0-517" name="__codelineno-0-517"></a><span class="sd">    ...   }</span>
</span><span id="__span-0-518"><a id="__codelineno-0-518" name="__codelineno-0-518"></a><span class="sd">    &gt;&gt;&gt; raw_data = [dict(x=1, s='a'), dict(x=0, s='b'), dict(x=3, s='a')]</span>
</span><span id="__span-0-519"><a id="__codelineno-0-519" name="__codelineno-0-519"></a><span class="sd">    &gt;&gt;&gt; feature_spec = dict(</span>
</span><span id="__span-0-520"><a id="__codelineno-0-520" name="__codelineno-0-520"></a><span class="sd">    ...     x=tf.io.FixedLenFeature([], tf.float32),</span>
</span><span id="__span-0-521"><a id="__codelineno-0-521" name="__codelineno-0-521"></a><span class="sd">    ...     s=tf.io.FixedLenFeature([], tf.string))</span>
</span><span id="__span-0-522"><a id="__codelineno-0-522" name="__codelineno-0-522"></a><span class="sd">    &gt;&gt;&gt; raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec)</span>
</span><span id="__span-0-523"><a id="__codelineno-0-523" name="__codelineno-0-523"></a><span class="sd">    &gt;&gt;&gt; with tft_beam.Context(temp_dir=tempfile.mkdtemp()):</span>
</span><span id="__span-0-524"><a id="__codelineno-0-524" name="__codelineno-0-524"></a><span class="sd">    ...   transformed_dataset, transform_fn = (</span>
</span><span id="__span-0-525"><a id="__codelineno-0-525" name="__codelineno-0-525"></a><span class="sd">    ...       (raw_data, raw_data_metadata)</span>
</span><span id="__span-0-526"><a id="__codelineno-0-526" name="__codelineno-0-526"></a><span class="sd">    ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))</span>
</span><span id="__span-0-527"><a id="__codelineno-0-527" name="__codelineno-0-527"></a><span class="sd">    &gt;&gt;&gt; transformed_data, transformed_metadata = transformed_dataset</span>
</span><span id="__span-0-528"><a id="__codelineno-0-528" name="__codelineno-0-528"></a><span class="sd">    &gt;&gt;&gt; transformed_data</span>
</span><span id="__span-0-529"><a id="__codelineno-0-529" name="__codelineno-0-529"></a><span class="sd">    [{'scaled': 0.0}, {'scaled': 0.5}, {'scaled': 1.0}]</span>
</span><span id="__span-0-530"><a id="__codelineno-0-530" name="__codelineno-0-530"></a>
</span><span id="__span-0-531"><a id="__codelineno-0-531" name="__codelineno-0-531"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-532"><a id="__codelineno-0-532" name="__codelineno-0-532"></a><span class="sd">    -------</span>
</span><span id="__span-0-533"><a id="__codelineno-0-533" name="__codelineno-0-533"></a><span class="sd">      A `Tensor`, `SparseTensor`, or `RaggedTensor` containing the input column scaled to [0, 1],</span>
</span><span id="__span-0-534"><a id="__codelineno-0-534" name="__codelineno-0-534"></a><span class="sd">      per key. If the analysis dataset is empty, contains a single distinct value</span>
</span><span id="__span-0-535"><a id="__codelineno-0-535" name="__codelineno-0-535"></a><span class="sd">      or the computed key vocabulary doesn't have an entry for `key`, then `x` is</span>
</span><span id="__span-0-536"><a id="__codelineno-0-536" name="__codelineno-0-536"></a><span class="sd">      scaled using a sigmoid function.</span>
</span><span id="__span-0-537"><a id="__codelineno-0-537" name="__codelineno-0-537"></a><span class="sd">    """</span>
</span><span id="__span-0-538"><a id="__codelineno-0-538" name="__codelineno-0-538"></a>    <span class="c1"># pyformat: enable</span>
</span><span id="__span-0-539"><a id="__codelineno-0-539" name="__codelineno-0-539"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"scale_to_0_1_per_key"</span><span class="p">):</span>
</span><span id="__span-0-540"><a id="__codelineno-0-540" name="__codelineno-0-540"></a>        <span class="k">if</span> <span class="n">key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-541"><a id="__codelineno-0-541" name="__codelineno-0-541"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"key is None, call `tft.scale_to_0_1` instead"</span><span class="p">)</span>
</span><span id="__span-0-542"><a id="__codelineno-0-542" name="__codelineno-0-542"></a>        <span class="k">return</span> <span class="n">_scale_by_min_max_internal</span><span class="p">(</span>
</span><span id="__span-0-543"><a id="__codelineno-0-543" name="__codelineno-0-543"></a>            <span class="n">x</span><span class="p">,</span>
</span><span id="__span-0-544"><a id="__codelineno-0-544" name="__codelineno-0-544"></a>            <span class="n">key</span><span class="o">=</span><span class="n">key</span><span class="p">,</span>
</span><span id="__span-0-545"><a id="__codelineno-0-545" name="__codelineno-0-545"></a>            <span class="n">output_min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-546"><a id="__codelineno-0-546" name="__codelineno-0-546"></a>            <span class="n">output_max</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-547"><a id="__codelineno-0-547" name="__codelineno-0-547"></a>            <span class="n">elementwise</span><span class="o">=</span><span class="n">elementwise</span><span class="p">,</span>
</span><span id="__span-0-548"><a id="__codelineno-0-548" name="__codelineno-0-548"></a>            <span class="n">key_vocabulary_filename</span><span class="o">=</span><span class="n">key_vocabulary_filename</span><span class="p">,</span>
</span><span id="__span-0-549"><a id="__codelineno-0-549" name="__codelineno-0-549"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.scale_to_gaussian" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">scale_to_gaussian</span>


<a href="#tensorflow_transform.scale_to_gaussian" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">scale_to_gaussian</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">elementwise</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">output_dtype</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><span title="tensorflow.DType">DType</span></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Returns an (approximately) normal column with mean to 0 and variance 1.</p>
<p>We transform the column to values that are approximately distributed
according to a standard normal distribution.
The transformation is obtained by applying the moments method to estimate
the parameters of a Tukey HH distribution and applying the inverse of the
estimated function to the column values.
The method is partially described in</p>
<p>Georg M. Georgm "The Lambert Way to Gaussianize Heavy-Tailed Data with the
Inverse of Tukey's h Transformation as a Special Case," The Scientific World
Journal, Vol. 2015, Hindawi Publishing Corporation.</p>
<p>We use the L-moments instead of conventional moments to be able to deal with
long-tailed distributions. The expressions of the L-moments for the Tukey HH
distribution is in</p>
<p>Todd C. Headrick, and Mohan D. Pant. "Characterizing Tukey H and
HH-Distributions through L-Moments and the L-Correlation," ISRN Applied
Mathematics, vol. 2012, 2012. doi:10.5402/2012/980153</p>
<p>Note that the transformation to Gaussian is applied only if the column has
long-tails. If this is not the case, for instance if values are uniformly
distributed, the values are only normalized using the z score. This applies
also to the cases where only one of the tails is long; the other tail is only
rescaled but not non linearly transformed.
Also, if the analysis set is empty, the transformation is set to to leave the
input vaules unchanged.</p>
        <hr>
<p>x: A numeric <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.
  elementwise: If true, scales each element of the tensor independently;
    otherwise uses the parameters of the whole tensor.
  name: (Optional) A name for this operation.
  output_dtype: (Optional) If not None, casts the output tensor to this type.</p>
        <hr>
<p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> containing the input column
  transformed to be approximately standard distributed (i.e. a Gaussian with
  mean 0 and variance 1). If <code>x</code> is floating point, the mean will have the
  same type as <code>x</code>. If <code>x</code> is integral, the output is cast to tf.float32.</p>
<p>Note that TFLearn generally permits only tf.int64 and tf.float32, so casting
  this scaler's output may be necessary.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-73"><a id="__codelineno-0-73" name="__codelineno-0-73"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-74"><a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="k">def</span><span class="w"> </span><span class="nf">scale_to_gaussian</span><span class="p">(</span>
</span><span id="__span-0-75"><a id="__codelineno-0-75" name="__codelineno-0-75"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">,</span>
</span><span id="__span-0-76"><a id="__codelineno-0-76" name="__codelineno-0-76"></a>    <span class="n">elementwise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-77"><a id="__codelineno-0-77" name="__codelineno-0-77"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-78"><a id="__codelineno-0-78" name="__codelineno-0-78"></a>    <span class="n">output_dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">DType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-79"><a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">:</span>
</span><span id="__span-0-80"><a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="w">    </span><span class="sd">"""Returns an (approximately) normal column with mean to 0 and variance 1.</span>
</span><span id="__span-0-81"><a id="__codelineno-0-81" name="__codelineno-0-81"></a>
</span><span id="__span-0-82"><a id="__codelineno-0-82" name="__codelineno-0-82"></a><span class="sd">    We transform the column to values that are approximately distributed</span>
</span><span id="__span-0-83"><a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="sd">    according to a standard normal distribution.</span>
</span><span id="__span-0-84"><a id="__codelineno-0-84" name="__codelineno-0-84"></a><span class="sd">    The transformation is obtained by applying the moments method to estimate</span>
</span><span id="__span-0-85"><a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="sd">    the parameters of a Tukey HH distribution and applying the inverse of the</span>
</span><span id="__span-0-86"><a id="__codelineno-0-86" name="__codelineno-0-86"></a><span class="sd">    estimated function to the column values.</span>
</span><span id="__span-0-87"><a id="__codelineno-0-87" name="__codelineno-0-87"></a><span class="sd">    The method is partially described in</span>
</span><span id="__span-0-88"><a id="__codelineno-0-88" name="__codelineno-0-88"></a>
</span><span id="__span-0-89"><a id="__codelineno-0-89" name="__codelineno-0-89"></a><span class="sd">    Georg M. Georgm "The Lambert Way to Gaussianize Heavy-Tailed Data with the</span>
</span><span id="__span-0-90"><a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="sd">    Inverse of Tukey's h Transformation as a Special Case," The Scientific World</span>
</span><span id="__span-0-91"><a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">    Journal, Vol. 2015, Hindawi Publishing Corporation.</span>
</span><span id="__span-0-92"><a id="__codelineno-0-92" name="__codelineno-0-92"></a>
</span><span id="__span-0-93"><a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">    We use the L-moments instead of conventional moments to be able to deal with</span>
</span><span id="__span-0-94"><a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">    long-tailed distributions. The expressions of the L-moments for the Tukey HH</span>
</span><span id="__span-0-95"><a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">    distribution is in</span>
</span><span id="__span-0-96"><a id="__codelineno-0-96" name="__codelineno-0-96"></a>
</span><span id="__span-0-97"><a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">    Todd C. Headrick, and Mohan D. Pant. "Characterizing Tukey H and</span>
</span><span id="__span-0-98"><a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="sd">    HH-Distributions through L-Moments and the L-Correlation," ISRN Applied</span>
</span><span id="__span-0-99"><a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">    Mathematics, vol. 2012, 2012. doi:10.5402/2012/980153</span>
</span><span id="__span-0-100"><a id="__codelineno-0-100" name="__codelineno-0-100"></a>
</span><span id="__span-0-101"><a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">    Note that the transformation to Gaussian is applied only if the column has</span>
</span><span id="__span-0-102"><a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">    long-tails. If this is not the case, for instance if values are uniformly</span>
</span><span id="__span-0-103"><a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="sd">    distributed, the values are only normalized using the z score. This applies</span>
</span><span id="__span-0-104"><a id="__codelineno-0-104" name="__codelineno-0-104"></a><span class="sd">    also to the cases where only one of the tails is long; the other tail is only</span>
</span><span id="__span-0-105"><a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">    rescaled but not non linearly transformed.</span>
</span><span id="__span-0-106"><a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="sd">    Also, if the analysis set is empty, the transformation is set to to leave the</span>
</span><span id="__span-0-107"><a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="sd">    input vaules unchanged.</span>
</span><span id="__span-0-108"><a id="__codelineno-0-108" name="__codelineno-0-108"></a>
</span><span id="__span-0-109"><a id="__codelineno-0-109" name="__codelineno-0-109"></a><span class="sd">    Args:</span>
</span><span id="__span-0-110"><a id="__codelineno-0-110" name="__codelineno-0-110"></a><span class="sd">    ----</span>
</span><span id="__span-0-111"><a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="sd">      x: A numeric `Tensor`, `SparseTensor`, or `RaggedTensor`.</span>
</span><span id="__span-0-112"><a id="__codelineno-0-112" name="__codelineno-0-112"></a><span class="sd">      elementwise: If true, scales each element of the tensor independently;</span>
</span><span id="__span-0-113"><a id="__codelineno-0-113" name="__codelineno-0-113"></a><span class="sd">        otherwise uses the parameters of the whole tensor.</span>
</span><span id="__span-0-114"><a id="__codelineno-0-114" name="__codelineno-0-114"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-115"><a id="__codelineno-0-115" name="__codelineno-0-115"></a><span class="sd">      output_dtype: (Optional) If not None, casts the output tensor to this type.</span>
</span><span id="__span-0-116"><a id="__codelineno-0-116" name="__codelineno-0-116"></a>
</span><span id="__span-0-117"><a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-118"><a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="sd">    -------</span>
</span><span id="__span-0-119"><a id="__codelineno-0-119" name="__codelineno-0-119"></a><span class="sd">      A `Tensor`, `SparseTensor`, or `RaggedTensor` containing the input column</span>
</span><span id="__span-0-120"><a id="__codelineno-0-120" name="__codelineno-0-120"></a><span class="sd">      transformed to be approximately standard distributed (i.e. a Gaussian with</span>
</span><span id="__span-0-121"><a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="sd">      mean 0 and variance 1). If `x` is floating point, the mean will have the</span>
</span><span id="__span-0-122"><a id="__codelineno-0-122" name="__codelineno-0-122"></a><span class="sd">      same type as `x`. If `x` is integral, the output is cast to tf.float32.</span>
</span><span id="__span-0-123"><a id="__codelineno-0-123" name="__codelineno-0-123"></a>
</span><span id="__span-0-124"><a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="sd">      Note that TFLearn generally permits only tf.int64 and tf.float32, so casting</span>
</span><span id="__span-0-125"><a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">      this scaler's output may be necessary.</span>
</span><span id="__span-0-126"><a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="sd">    """</span>
</span><span id="__span-0-127"><a id="__codelineno-0-127" name="__codelineno-0-127"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"scale_to_gaussian"</span><span class="p">):</span>
</span><span id="__span-0-128"><a id="__codelineno-0-128" name="__codelineno-0-128"></a>        <span class="k">return</span> <span class="n">_scale_to_gaussian_internal</span><span class="p">(</span>
</span><span id="__span-0-129"><a id="__codelineno-0-129" name="__codelineno-0-129"></a>            <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">elementwise</span><span class="o">=</span><span class="n">elementwise</span><span class="p">,</span> <span class="n">output_dtype</span><span class="o">=</span><span class="n">output_dtype</span>
</span><span id="__span-0-130"><a id="__codelineno-0-130" name="__codelineno-0-130"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.scale_to_z_score" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">scale_to_z_score</span>


<a href="#tensorflow_transform.scale_to_z_score" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">scale_to_z_score</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">elementwise</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">output_dtype</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><span title="tensorflow.DType">DType</span></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Returns a standardized column with mean 0 and variance 1.</p>
<p>Scaling to z-score subtracts out the mean and divides by standard deviation.
Note that the standard deviation computed here is based on the biased variance
(0 delta degrees of freedom), as computed by analyzers.var.</p>
        <hr>
<p>x: A numeric <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.
  elementwise: If true, scales each element of the tensor independently;
    otherwise uses the mean and variance of the whole tensor.
  name: (Optional) A name for this operation.
  output_dtype: (Optional) If not None, casts the output tensor to this type.</p>
        <hr>
<p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> containing the input column
  scaled to mean 0
  and variance 1 (standard deviation 1), given by: (x - mean(x)) / std_dev(x).
  If <code>x</code> is floating point, the mean will have the same type as <code>x</code>. If <code>x</code> is
  integral, the output is cast to tf.float32. If the analysis dataset is empty
  or contains a single distinct value, then the input is returned without
  scaling.</p>
<p>Note that TFLearn generally permits only tf.int64 and tf.float32, so casting
  this scaler's output may be necessary.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-552">552</a></span>
<span class="normal"><a href="#__codelineno-0-553">553</a></span>
<span class="normal"><a href="#__codelineno-0-554">554</a></span>
<span class="normal"><a href="#__codelineno-0-555">555</a></span>
<span class="normal"><a href="#__codelineno-0-556">556</a></span>
<span class="normal"><a href="#__codelineno-0-557">557</a></span>
<span class="normal"><a href="#__codelineno-0-558">558</a></span>
<span class="normal"><a href="#__codelineno-0-559">559</a></span>
<span class="normal"><a href="#__codelineno-0-560">560</a></span>
<span class="normal"><a href="#__codelineno-0-561">561</a></span>
<span class="normal"><a href="#__codelineno-0-562">562</a></span>
<span class="normal"><a href="#__codelineno-0-563">563</a></span>
<span class="normal"><a href="#__codelineno-0-564">564</a></span>
<span class="normal"><a href="#__codelineno-0-565">565</a></span>
<span class="normal"><a href="#__codelineno-0-566">566</a></span>
<span class="normal"><a href="#__codelineno-0-567">567</a></span>
<span class="normal"><a href="#__codelineno-0-568">568</a></span>
<span class="normal"><a href="#__codelineno-0-569">569</a></span>
<span class="normal"><a href="#__codelineno-0-570">570</a></span>
<span class="normal"><a href="#__codelineno-0-571">571</a></span>
<span class="normal"><a href="#__codelineno-0-572">572</a></span>
<span class="normal"><a href="#__codelineno-0-573">573</a></span>
<span class="normal"><a href="#__codelineno-0-574">574</a></span>
<span class="normal"><a href="#__codelineno-0-575">575</a></span>
<span class="normal"><a href="#__codelineno-0-576">576</a></span>
<span class="normal"><a href="#__codelineno-0-577">577</a></span>
<span class="normal"><a href="#__codelineno-0-578">578</a></span>
<span class="normal"><a href="#__codelineno-0-579">579</a></span>
<span class="normal"><a href="#__codelineno-0-580">580</a></span>
<span class="normal"><a href="#__codelineno-0-581">581</a></span>
<span class="normal"><a href="#__codelineno-0-582">582</a></span>
<span class="normal"><a href="#__codelineno-0-583">583</a></span>
<span class="normal"><a href="#__codelineno-0-584">584</a></span>
<span class="normal"><a href="#__codelineno-0-585">585</a></span>
<span class="normal"><a href="#__codelineno-0-586">586</a></span>
<span class="normal"><a href="#__codelineno-0-587">587</a></span>
<span class="normal"><a href="#__codelineno-0-588">588</a></span>
<span class="normal"><a href="#__codelineno-0-589">589</a></span>
<span class="normal"><a href="#__codelineno-0-590">590</a></span>
<span class="normal"><a href="#__codelineno-0-591">591</a></span>
<span class="normal"><a href="#__codelineno-0-592">592</a></span>
<span class="normal"><a href="#__codelineno-0-593">593</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-552"><a id="__codelineno-0-552" name="__codelineno-0-552"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-553"><a id="__codelineno-0-553" name="__codelineno-0-553"></a><span class="k">def</span><span class="w"> </span><span class="nf">scale_to_z_score</span><span class="p">(</span>
</span><span id="__span-0-554"><a id="__codelineno-0-554" name="__codelineno-0-554"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">,</span>
</span><span id="__span-0-555"><a id="__codelineno-0-555" name="__codelineno-0-555"></a>    <span class="n">elementwise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-556"><a id="__codelineno-0-556" name="__codelineno-0-556"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-557"><a id="__codelineno-0-557" name="__codelineno-0-557"></a>    <span class="n">output_dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">DType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-558"><a id="__codelineno-0-558" name="__codelineno-0-558"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">:</span>
</span><span id="__span-0-559"><a id="__codelineno-0-559" name="__codelineno-0-559"></a><span class="w">    </span><span class="sd">"""Returns a standardized column with mean 0 and variance 1.</span>
</span><span id="__span-0-560"><a id="__codelineno-0-560" name="__codelineno-0-560"></a>
</span><span id="__span-0-561"><a id="__codelineno-0-561" name="__codelineno-0-561"></a><span class="sd">    Scaling to z-score subtracts out the mean and divides by standard deviation.</span>
</span><span id="__span-0-562"><a id="__codelineno-0-562" name="__codelineno-0-562"></a><span class="sd">    Note that the standard deviation computed here is based on the biased variance</span>
</span><span id="__span-0-563"><a id="__codelineno-0-563" name="__codelineno-0-563"></a><span class="sd">    (0 delta degrees of freedom), as computed by analyzers.var.</span>
</span><span id="__span-0-564"><a id="__codelineno-0-564" name="__codelineno-0-564"></a>
</span><span id="__span-0-565"><a id="__codelineno-0-565" name="__codelineno-0-565"></a><span class="sd">    Args:</span>
</span><span id="__span-0-566"><a id="__codelineno-0-566" name="__codelineno-0-566"></a><span class="sd">    ----</span>
</span><span id="__span-0-567"><a id="__codelineno-0-567" name="__codelineno-0-567"></a><span class="sd">      x: A numeric `Tensor`, `SparseTensor`, or `RaggedTensor`.</span>
</span><span id="__span-0-568"><a id="__codelineno-0-568" name="__codelineno-0-568"></a><span class="sd">      elementwise: If true, scales each element of the tensor independently;</span>
</span><span id="__span-0-569"><a id="__codelineno-0-569" name="__codelineno-0-569"></a><span class="sd">        otherwise uses the mean and variance of the whole tensor.</span>
</span><span id="__span-0-570"><a id="__codelineno-0-570" name="__codelineno-0-570"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-571"><a id="__codelineno-0-571" name="__codelineno-0-571"></a><span class="sd">      output_dtype: (Optional) If not None, casts the output tensor to this type.</span>
</span><span id="__span-0-572"><a id="__codelineno-0-572" name="__codelineno-0-572"></a>
</span><span id="__span-0-573"><a id="__codelineno-0-573" name="__codelineno-0-573"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-574"><a id="__codelineno-0-574" name="__codelineno-0-574"></a><span class="sd">    -------</span>
</span><span id="__span-0-575"><a id="__codelineno-0-575" name="__codelineno-0-575"></a><span class="sd">      A `Tensor`, `SparseTensor`, or `RaggedTensor` containing the input column</span>
</span><span id="__span-0-576"><a id="__codelineno-0-576" name="__codelineno-0-576"></a><span class="sd">      scaled to mean 0</span>
</span><span id="__span-0-577"><a id="__codelineno-0-577" name="__codelineno-0-577"></a><span class="sd">      and variance 1 (standard deviation 1), given by: (x - mean(x)) / std_dev(x).</span>
</span><span id="__span-0-578"><a id="__codelineno-0-578" name="__codelineno-0-578"></a><span class="sd">      If `x` is floating point, the mean will have the same type as `x`. If `x` is</span>
</span><span id="__span-0-579"><a id="__codelineno-0-579" name="__codelineno-0-579"></a><span class="sd">      integral, the output is cast to tf.float32. If the analysis dataset is empty</span>
</span><span id="__span-0-580"><a id="__codelineno-0-580" name="__codelineno-0-580"></a><span class="sd">      or contains a single distinct value, then the input is returned without</span>
</span><span id="__span-0-581"><a id="__codelineno-0-581" name="__codelineno-0-581"></a><span class="sd">      scaling.</span>
</span><span id="__span-0-582"><a id="__codelineno-0-582" name="__codelineno-0-582"></a>
</span><span id="__span-0-583"><a id="__codelineno-0-583" name="__codelineno-0-583"></a><span class="sd">      Note that TFLearn generally permits only tf.int64 and tf.float32, so casting</span>
</span><span id="__span-0-584"><a id="__codelineno-0-584" name="__codelineno-0-584"></a><span class="sd">      this scaler's output may be necessary.</span>
</span><span id="__span-0-585"><a id="__codelineno-0-585" name="__codelineno-0-585"></a><span class="sd">    """</span>
</span><span id="__span-0-586"><a id="__codelineno-0-586" name="__codelineno-0-586"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"scale_to_z_score"</span><span class="p">):</span>
</span><span id="__span-0-587"><a id="__codelineno-0-587" name="__codelineno-0-587"></a>        <span class="k">return</span> <span class="n">_scale_to_z_score_internal</span><span class="p">(</span>
</span><span id="__span-0-588"><a id="__codelineno-0-588" name="__codelineno-0-588"></a>            <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
</span><span id="__span-0-589"><a id="__codelineno-0-589" name="__codelineno-0-589"></a>            <span class="n">key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-590"><a id="__codelineno-0-590" name="__codelineno-0-590"></a>            <span class="n">elementwise</span><span class="o">=</span><span class="n">elementwise</span><span class="p">,</span>
</span><span id="__span-0-591"><a id="__codelineno-0-591" name="__codelineno-0-591"></a>            <span class="n">key_vocabulary_filename</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-592"><a id="__codelineno-0-592" name="__codelineno-0-592"></a>            <span class="n">output_dtype</span><span class="o">=</span><span class="n">output_dtype</span><span class="p">,</span>
</span><span id="__span-0-593"><a id="__codelineno-0-593" name="__codelineno-0-593"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.scale_to_z_score_per_key" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">scale_to_z_score_per_key</span>


<a href="#tensorflow_transform.scale_to_z_score_per_key" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">scale_to_z_score_per_key</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">key</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">elementwise</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">key_vocabulary_filename</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">output_dtype</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><span title="tensorflow.DType">DType</span></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow_transform.common_types.ConsistentTensorType">ConsistentTensorType</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Returns a standardized column with mean 0 and variance 1, grouped per key.</p>
<p>Scaling to z-score subtracts out the mean and divides by standard deviation.
Note that the standard deviation computed here is based on the biased variance
(0 delta degrees of freedom), as computed by analyzers.var.</p>
        <hr>
<p>x: A numeric <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.
  key: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of dtype tf.string. Must
    meet one of the following conditions:
    0. key is None,
    1. Both x and key are dense,
    2. Both x and key are sparse and <code>key</code> must exactly match <code>x</code> in
    everything except values,
    3. The axis=1 index of each x matches its index of dense key.
  elementwise: If true, scales each element of the tensor independently;
    otherwise uses the mean and variance of the whole tensor. Currently, not
    supported for per-key operations.
  key_vocabulary_filename: (Optional) The file name for the per-key file. If
    None, this combiner will assume the keys fit in memory and will not store
    the analyzer result in a file. If '', a file name will be chosen based on
    the current TensorFlow scope. If not '', it should be unique within a
    given preprocessing function.
  name: (Optional) A name for this operation.
  output_dtype: (Optional) If not None, casts the output tensor to this type.</p>
        <hr>
<p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> containing the input column
  scaled to mean 0
  and variance 1 (standard deviation 1), grouped per key if a key is provided.</p>
<p>That is, for all keys k: (x - mean(x)) / std_dev(x) for all x with key k.
  If <code>x</code> is floating point, the mean will have the same type as <code>x</code>. If <code>x</code> is
  integral, the output is cast to tf.float32. If the analysis dataset is
  empty, contains a single distinct value or the computed key vocabulary
  doesn't have an entry for <code>key</code>, then the input is returned without scaling.</p>
<p>Note that TFLearn generally permits only tf.int64 and tf.float32, so casting
  this scaler's output may be necessary.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-596">596</a></span>
<span class="normal"><a href="#__codelineno-0-597">597</a></span>
<span class="normal"><a href="#__codelineno-0-598">598</a></span>
<span class="normal"><a href="#__codelineno-0-599">599</a></span>
<span class="normal"><a href="#__codelineno-0-600">600</a></span>
<span class="normal"><a href="#__codelineno-0-601">601</a></span>
<span class="normal"><a href="#__codelineno-0-602">602</a></span>
<span class="normal"><a href="#__codelineno-0-603">603</a></span>
<span class="normal"><a href="#__codelineno-0-604">604</a></span>
<span class="normal"><a href="#__codelineno-0-605">605</a></span>
<span class="normal"><a href="#__codelineno-0-606">606</a></span>
<span class="normal"><a href="#__codelineno-0-607">607</a></span>
<span class="normal"><a href="#__codelineno-0-608">608</a></span>
<span class="normal"><a href="#__codelineno-0-609">609</a></span>
<span class="normal"><a href="#__codelineno-0-610">610</a></span>
<span class="normal"><a href="#__codelineno-0-611">611</a></span>
<span class="normal"><a href="#__codelineno-0-612">612</a></span>
<span class="normal"><a href="#__codelineno-0-613">613</a></span>
<span class="normal"><a href="#__codelineno-0-614">614</a></span>
<span class="normal"><a href="#__codelineno-0-615">615</a></span>
<span class="normal"><a href="#__codelineno-0-616">616</a></span>
<span class="normal"><a href="#__codelineno-0-617">617</a></span>
<span class="normal"><a href="#__codelineno-0-618">618</a></span>
<span class="normal"><a href="#__codelineno-0-619">619</a></span>
<span class="normal"><a href="#__codelineno-0-620">620</a></span>
<span class="normal"><a href="#__codelineno-0-621">621</a></span>
<span class="normal"><a href="#__codelineno-0-622">622</a></span>
<span class="normal"><a href="#__codelineno-0-623">623</a></span>
<span class="normal"><a href="#__codelineno-0-624">624</a></span>
<span class="normal"><a href="#__codelineno-0-625">625</a></span>
<span class="normal"><a href="#__codelineno-0-626">626</a></span>
<span class="normal"><a href="#__codelineno-0-627">627</a></span>
<span class="normal"><a href="#__codelineno-0-628">628</a></span>
<span class="normal"><a href="#__codelineno-0-629">629</a></span>
<span class="normal"><a href="#__codelineno-0-630">630</a></span>
<span class="normal"><a href="#__codelineno-0-631">631</a></span>
<span class="normal"><a href="#__codelineno-0-632">632</a></span>
<span class="normal"><a href="#__codelineno-0-633">633</a></span>
<span class="normal"><a href="#__codelineno-0-634">634</a></span>
<span class="normal"><a href="#__codelineno-0-635">635</a></span>
<span class="normal"><a href="#__codelineno-0-636">636</a></span>
<span class="normal"><a href="#__codelineno-0-637">637</a></span>
<span class="normal"><a href="#__codelineno-0-638">638</a></span>
<span class="normal"><a href="#__codelineno-0-639">639</a></span>
<span class="normal"><a href="#__codelineno-0-640">640</a></span>
<span class="normal"><a href="#__codelineno-0-641">641</a></span>
<span class="normal"><a href="#__codelineno-0-642">642</a></span>
<span class="normal"><a href="#__codelineno-0-643">643</a></span>
<span class="normal"><a href="#__codelineno-0-644">644</a></span>
<span class="normal"><a href="#__codelineno-0-645">645</a></span>
<span class="normal"><a href="#__codelineno-0-646">646</a></span>
<span class="normal"><a href="#__codelineno-0-647">647</a></span>
<span class="normal"><a href="#__codelineno-0-648">648</a></span>
<span class="normal"><a href="#__codelineno-0-649">649</a></span>
<span class="normal"><a href="#__codelineno-0-650">650</a></span>
<span class="normal"><a href="#__codelineno-0-651">651</a></span>
<span class="normal"><a href="#__codelineno-0-652">652</a></span>
<span class="normal"><a href="#__codelineno-0-653">653</a></span>
<span class="normal"><a href="#__codelineno-0-654">654</a></span>
<span class="normal"><a href="#__codelineno-0-655">655</a></span>
<span class="normal"><a href="#__codelineno-0-656">656</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-596"><a id="__codelineno-0-596" name="__codelineno-0-596"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-597"><a id="__codelineno-0-597" name="__codelineno-0-597"></a><span class="k">def</span><span class="w"> </span><span class="nf">scale_to_z_score_per_key</span><span class="p">(</span>
</span><span id="__span-0-598"><a id="__codelineno-0-598" name="__codelineno-0-598"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">,</span>
</span><span id="__span-0-599"><a id="__codelineno-0-599" name="__codelineno-0-599"></a>    <span class="n">key</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span>
</span><span id="__span-0-600"><a id="__codelineno-0-600" name="__codelineno-0-600"></a>    <span class="n">elementwise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-601"><a id="__codelineno-0-601" name="__codelineno-0-601"></a>    <span class="n">key_vocabulary_filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-602"><a id="__codelineno-0-602" name="__codelineno-0-602"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-603"><a id="__codelineno-0-603" name="__codelineno-0-603"></a>    <span class="n">output_dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">DType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-604"><a id="__codelineno-0-604" name="__codelineno-0-604"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">common_types</span><span class="o">.</span><span class="n">ConsistentTensorType</span><span class="p">:</span>
</span><span id="__span-0-605"><a id="__codelineno-0-605" name="__codelineno-0-605"></a><span class="w">    </span><span class="sd">"""Returns a standardized column with mean 0 and variance 1, grouped per key.</span>
</span><span id="__span-0-606"><a id="__codelineno-0-606" name="__codelineno-0-606"></a>
</span><span id="__span-0-607"><a id="__codelineno-0-607" name="__codelineno-0-607"></a><span class="sd">    Scaling to z-score subtracts out the mean and divides by standard deviation.</span>
</span><span id="__span-0-608"><a id="__codelineno-0-608" name="__codelineno-0-608"></a><span class="sd">    Note that the standard deviation computed here is based on the biased variance</span>
</span><span id="__span-0-609"><a id="__codelineno-0-609" name="__codelineno-0-609"></a><span class="sd">    (0 delta degrees of freedom), as computed by analyzers.var.</span>
</span><span id="__span-0-610"><a id="__codelineno-0-610" name="__codelineno-0-610"></a>
</span><span id="__span-0-611"><a id="__codelineno-0-611" name="__codelineno-0-611"></a><span class="sd">    Args:</span>
</span><span id="__span-0-612"><a id="__codelineno-0-612" name="__codelineno-0-612"></a><span class="sd">    ----</span>
</span><span id="__span-0-613"><a id="__codelineno-0-613" name="__codelineno-0-613"></a><span class="sd">      x: A numeric `Tensor`, `SparseTensor`, or `RaggedTensor`.</span>
</span><span id="__span-0-614"><a id="__codelineno-0-614" name="__codelineno-0-614"></a><span class="sd">      key: A `Tensor`, `SparseTensor`, or `RaggedTensor` of dtype tf.string. Must</span>
</span><span id="__span-0-615"><a id="__codelineno-0-615" name="__codelineno-0-615"></a><span class="sd">        meet one of the following conditions:</span>
</span><span id="__span-0-616"><a id="__codelineno-0-616" name="__codelineno-0-616"></a><span class="sd">        0. key is None,</span>
</span><span id="__span-0-617"><a id="__codelineno-0-617" name="__codelineno-0-617"></a><span class="sd">        1. Both x and key are dense,</span>
</span><span id="__span-0-618"><a id="__codelineno-0-618" name="__codelineno-0-618"></a><span class="sd">        2. Both x and key are sparse and `key` must exactly match `x` in</span>
</span><span id="__span-0-619"><a id="__codelineno-0-619" name="__codelineno-0-619"></a><span class="sd">        everything except values,</span>
</span><span id="__span-0-620"><a id="__codelineno-0-620" name="__codelineno-0-620"></a><span class="sd">        3. The axis=1 index of each x matches its index of dense key.</span>
</span><span id="__span-0-621"><a id="__codelineno-0-621" name="__codelineno-0-621"></a><span class="sd">      elementwise: If true, scales each element of the tensor independently;</span>
</span><span id="__span-0-622"><a id="__codelineno-0-622" name="__codelineno-0-622"></a><span class="sd">        otherwise uses the mean and variance of the whole tensor. Currently, not</span>
</span><span id="__span-0-623"><a id="__codelineno-0-623" name="__codelineno-0-623"></a><span class="sd">        supported for per-key operations.</span>
</span><span id="__span-0-624"><a id="__codelineno-0-624" name="__codelineno-0-624"></a><span class="sd">      key_vocabulary_filename: (Optional) The file name for the per-key file. If</span>
</span><span id="__span-0-625"><a id="__codelineno-0-625" name="__codelineno-0-625"></a><span class="sd">        None, this combiner will assume the keys fit in memory and will not store</span>
</span><span id="__span-0-626"><a id="__codelineno-0-626" name="__codelineno-0-626"></a><span class="sd">        the analyzer result in a file. If '', a file name will be chosen based on</span>
</span><span id="__span-0-627"><a id="__codelineno-0-627" name="__codelineno-0-627"></a><span class="sd">        the current TensorFlow scope. If not '', it should be unique within a</span>
</span><span id="__span-0-628"><a id="__codelineno-0-628" name="__codelineno-0-628"></a><span class="sd">        given preprocessing function.</span>
</span><span id="__span-0-629"><a id="__codelineno-0-629" name="__codelineno-0-629"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-630"><a id="__codelineno-0-630" name="__codelineno-0-630"></a><span class="sd">      output_dtype: (Optional) If not None, casts the output tensor to this type.</span>
</span><span id="__span-0-631"><a id="__codelineno-0-631" name="__codelineno-0-631"></a>
</span><span id="__span-0-632"><a id="__codelineno-0-632" name="__codelineno-0-632"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-633"><a id="__codelineno-0-633" name="__codelineno-0-633"></a><span class="sd">    -------</span>
</span><span id="__span-0-634"><a id="__codelineno-0-634" name="__codelineno-0-634"></a><span class="sd">      A `Tensor`, `SparseTensor`, or `RaggedTensor` containing the input column</span>
</span><span id="__span-0-635"><a id="__codelineno-0-635" name="__codelineno-0-635"></a><span class="sd">      scaled to mean 0</span>
</span><span id="__span-0-636"><a id="__codelineno-0-636" name="__codelineno-0-636"></a><span class="sd">      and variance 1 (standard deviation 1), grouped per key if a key is provided.</span>
</span><span id="__span-0-637"><a id="__codelineno-0-637" name="__codelineno-0-637"></a>
</span><span id="__span-0-638"><a id="__codelineno-0-638" name="__codelineno-0-638"></a><span class="sd">      That is, for all keys k: (x - mean(x)) / std_dev(x) for all x with key k.</span>
</span><span id="__span-0-639"><a id="__codelineno-0-639" name="__codelineno-0-639"></a><span class="sd">      If `x` is floating point, the mean will have the same type as `x`. If `x` is</span>
</span><span id="__span-0-640"><a id="__codelineno-0-640" name="__codelineno-0-640"></a><span class="sd">      integral, the output is cast to tf.float32. If the analysis dataset is</span>
</span><span id="__span-0-641"><a id="__codelineno-0-641" name="__codelineno-0-641"></a><span class="sd">      empty, contains a single distinct value or the computed key vocabulary</span>
</span><span id="__span-0-642"><a id="__codelineno-0-642" name="__codelineno-0-642"></a><span class="sd">      doesn't have an entry for `key`, then the input is returned without scaling.</span>
</span><span id="__span-0-643"><a id="__codelineno-0-643" name="__codelineno-0-643"></a>
</span><span id="__span-0-644"><a id="__codelineno-0-644" name="__codelineno-0-644"></a><span class="sd">      Note that TFLearn generally permits only tf.int64 and tf.float32, so casting</span>
</span><span id="__span-0-645"><a id="__codelineno-0-645" name="__codelineno-0-645"></a><span class="sd">      this scaler's output may be necessary.</span>
</span><span id="__span-0-646"><a id="__codelineno-0-646" name="__codelineno-0-646"></a><span class="sd">    """</span>
</span><span id="__span-0-647"><a id="__codelineno-0-647" name="__codelineno-0-647"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"scale_to_z_score_per_key"</span><span class="p">):</span>
</span><span id="__span-0-648"><a id="__codelineno-0-648" name="__codelineno-0-648"></a>        <span class="k">if</span> <span class="n">key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-649"><a id="__codelineno-0-649" name="__codelineno-0-649"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"key is None, call `tft.scale_to_z_score` instead"</span><span class="p">)</span>
</span><span id="__span-0-650"><a id="__codelineno-0-650" name="__codelineno-0-650"></a>        <span class="k">return</span> <span class="n">_scale_to_z_score_internal</span><span class="p">(</span>
</span><span id="__span-0-651"><a id="__codelineno-0-651" name="__codelineno-0-651"></a>            <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
</span><span id="__span-0-652"><a id="__codelineno-0-652" name="__codelineno-0-652"></a>            <span class="n">key</span><span class="o">=</span><span class="n">key</span><span class="p">,</span>
</span><span id="__span-0-653"><a id="__codelineno-0-653" name="__codelineno-0-653"></a>            <span class="n">elementwise</span><span class="o">=</span><span class="n">elementwise</span><span class="p">,</span>
</span><span id="__span-0-654"><a id="__codelineno-0-654" name="__codelineno-0-654"></a>            <span class="n">key_vocabulary_filename</span><span class="o">=</span><span class="n">key_vocabulary_filename</span><span class="p">,</span>
</span><span id="__span-0-655"><a id="__codelineno-0-655" name="__codelineno-0-655"></a>            <span class="n">output_dtype</span><span class="o">=</span><span class="n">output_dtype</span><span class="p">,</span>
</span><span id="__span-0-656"><a id="__codelineno-0-656" name="__codelineno-0-656"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.segment_indices" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">segment_indices</span>


<a href="#tensorflow_transform.segment_indices" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">segment_indices</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">segment_ids</span><span class="p">:</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Returns a <code>Tensor</code> of indices within each segment.</p>
<p>segment_ids should be a sequence of non-decreasing non-negative integers that
define a set of segments, e.g. [0, 0, 1, 2, 2, 2] defines 3 segments of length
2, 1 and 3.  The return value is a <code>Tensor</code> containing the indices within each
segment.</p>
<h6 id="tensorflow_transform.segment_indices--example">Example:<a class="headerlink" href="#tensorflow_transform.segment_indices--example" title="Permanent link">Â¶</a></h6>
<blockquote>
<blockquote>
<blockquote>
<p>result = tft.segment_indices(tf.constant([0, 0, 1, 2, 2, 2]))
print(result)
tf.Tensor([0 1 0 0 1 2], shape=(6,), dtype=int32)</p>
</blockquote>
</blockquote>
</blockquote>
        <hr>
<p>segment_ids: A 1-d <code>Tensor</code> containing an non-decreasing sequence of
    non-negative integers with type <code>tf.int32</code> or <code>tf.int64</code>.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>A <code>Tensor</code> containing the indices within each segment.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1373">1373</a></span>
<span class="normal"><a href="#__codelineno-0-1374">1374</a></span>
<span class="normal"><a href="#__codelineno-0-1375">1375</a></span>
<span class="normal"><a href="#__codelineno-0-1376">1376</a></span>
<span class="normal"><a href="#__codelineno-0-1377">1377</a></span>
<span class="normal"><a href="#__codelineno-0-1378">1378</a></span>
<span class="normal"><a href="#__codelineno-0-1379">1379</a></span>
<span class="normal"><a href="#__codelineno-0-1380">1380</a></span>
<span class="normal"><a href="#__codelineno-0-1381">1381</a></span>
<span class="normal"><a href="#__codelineno-0-1382">1382</a></span>
<span class="normal"><a href="#__codelineno-0-1383">1383</a></span>
<span class="normal"><a href="#__codelineno-0-1384">1384</a></span>
<span class="normal"><a href="#__codelineno-0-1385">1385</a></span>
<span class="normal"><a href="#__codelineno-0-1386">1386</a></span>
<span class="normal"><a href="#__codelineno-0-1387">1387</a></span>
<span class="normal"><a href="#__codelineno-0-1388">1388</a></span>
<span class="normal"><a href="#__codelineno-0-1389">1389</a></span>
<span class="normal"><a href="#__codelineno-0-1390">1390</a></span>
<span class="normal"><a href="#__codelineno-0-1391">1391</a></span>
<span class="normal"><a href="#__codelineno-0-1392">1392</a></span>
<span class="normal"><a href="#__codelineno-0-1393">1393</a></span>
<span class="normal"><a href="#__codelineno-0-1394">1394</a></span>
<span class="normal"><a href="#__codelineno-0-1395">1395</a></span>
<span class="normal"><a href="#__codelineno-0-1396">1396</a></span>
<span class="normal"><a href="#__codelineno-0-1397">1397</a></span>
<span class="normal"><a href="#__codelineno-0-1398">1398</a></span>
<span class="normal"><a href="#__codelineno-0-1399">1399</a></span>
<span class="normal"><a href="#__codelineno-0-1400">1400</a></span>
<span class="normal"><a href="#__codelineno-0-1401">1401</a></span>
<span class="normal"><a href="#__codelineno-0-1402">1402</a></span>
<span class="normal"><a href="#__codelineno-0-1403">1403</a></span>
<span class="normal"><a href="#__codelineno-0-1404">1404</a></span>
<span class="normal"><a href="#__codelineno-0-1405">1405</a></span>
<span class="normal"><a href="#__codelineno-0-1406">1406</a></span>
<span class="normal"><a href="#__codelineno-0-1407">1407</a></span>
<span class="normal"><a href="#__codelineno-0-1408">1408</a></span>
<span class="normal"><a href="#__codelineno-0-1409">1409</a></span>
<span class="normal"><a href="#__codelineno-0-1410">1410</a></span>
<span class="normal"><a href="#__codelineno-0-1411">1411</a></span>
<span class="normal"><a href="#__codelineno-0-1412">1412</a></span>
<span class="normal"><a href="#__codelineno-0-1413">1413</a></span>
<span class="normal"><a href="#__codelineno-0-1414">1414</a></span>
<span class="normal"><a href="#__codelineno-0-1415">1415</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1373"><a id="__codelineno-0-1373" name="__codelineno-0-1373"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-1374"><a id="__codelineno-0-1374" name="__codelineno-0-1374"></a><span class="k">def</span><span class="w"> </span><span class="nf">segment_indices</span><span class="p">(</span><span class="n">segment_ids</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-1375"><a id="__codelineno-0-1375" name="__codelineno-0-1375"></a><span class="w">    </span><span class="sd">"""Returns a `Tensor` of indices within each segment.</span>
</span><span id="__span-0-1376"><a id="__codelineno-0-1376" name="__codelineno-0-1376"></a>
</span><span id="__span-0-1377"><a id="__codelineno-0-1377" name="__codelineno-0-1377"></a><span class="sd">    segment_ids should be a sequence of non-decreasing non-negative integers that</span>
</span><span id="__span-0-1378"><a id="__codelineno-0-1378" name="__codelineno-0-1378"></a><span class="sd">    define a set of segments, e.g. [0, 0, 1, 2, 2, 2] defines 3 segments of length</span>
</span><span id="__span-0-1379"><a id="__codelineno-0-1379" name="__codelineno-0-1379"></a><span class="sd">    2, 1 and 3.  The return value is a `Tensor` containing the indices within each</span>
</span><span id="__span-0-1380"><a id="__codelineno-0-1380" name="__codelineno-0-1380"></a><span class="sd">    segment.</span>
</span><span id="__span-0-1381"><a id="__codelineno-0-1381" name="__codelineno-0-1381"></a>
</span><span id="__span-0-1382"><a id="__codelineno-0-1382" name="__codelineno-0-1382"></a><span class="sd">    Example:</span>
</span><span id="__span-0-1383"><a id="__codelineno-0-1383" name="__codelineno-0-1383"></a><span class="sd">    -------</span>
</span><span id="__span-0-1384"><a id="__codelineno-0-1384" name="__codelineno-0-1384"></a><span class="sd">    &gt;&gt;&gt; result = tft.segment_indices(tf.constant([0, 0, 1, 2, 2, 2]))</span>
</span><span id="__span-0-1385"><a id="__codelineno-0-1385" name="__codelineno-0-1385"></a><span class="sd">    &gt;&gt;&gt; print(result)</span>
</span><span id="__span-0-1386"><a id="__codelineno-0-1386" name="__codelineno-0-1386"></a><span class="sd">    tf.Tensor([0 1 0 0 1 2], shape=(6,), dtype=int32)</span>
</span><span id="__span-0-1387"><a id="__codelineno-0-1387" name="__codelineno-0-1387"></a>
</span><span id="__span-0-1388"><a id="__codelineno-0-1388" name="__codelineno-0-1388"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1389"><a id="__codelineno-0-1389" name="__codelineno-0-1389"></a><span class="sd">    ----</span>
</span><span id="__span-0-1390"><a id="__codelineno-0-1390" name="__codelineno-0-1390"></a><span class="sd">      segment_ids: A 1-d `Tensor` containing an non-decreasing sequence of</span>
</span><span id="__span-0-1391"><a id="__codelineno-0-1391" name="__codelineno-0-1391"></a><span class="sd">        non-negative integers with type `tf.int32` or `tf.int64`.</span>
</span><span id="__span-0-1392"><a id="__codelineno-0-1392" name="__codelineno-0-1392"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-1393"><a id="__codelineno-0-1393" name="__codelineno-0-1393"></a>
</span><span id="__span-0-1394"><a id="__codelineno-0-1394" name="__codelineno-0-1394"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1395"><a id="__codelineno-0-1395" name="__codelineno-0-1395"></a><span class="sd">    -------</span>
</span><span id="__span-0-1396"><a id="__codelineno-0-1396" name="__codelineno-0-1396"></a><span class="sd">      A `Tensor` containing the indices within each segment.</span>
</span><span id="__span-0-1397"><a id="__codelineno-0-1397" name="__codelineno-0-1397"></a><span class="sd">    """</span>
</span><span id="__span-0-1398"><a id="__codelineno-0-1398" name="__codelineno-0-1398"></a>    <span class="n">ndims</span> <span class="o">=</span> <span class="n">segment_ids</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">ndims</span>
</span><span id="__span-0-1399"><a id="__codelineno-0-1399" name="__codelineno-0-1399"></a>    <span class="k">if</span> <span class="n">ndims</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">ndims</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-1400"><a id="__codelineno-0-1400" name="__codelineno-0-1400"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="__span-0-1401"><a id="__codelineno-0-1401" name="__codelineno-0-1401"></a>            <span class="s2">"segment_indices requires a 1-dimensional input. "</span>
</span><span id="__span-0-1402"><a id="__codelineno-0-1402" name="__codelineno-0-1402"></a>            <span class="s2">"segment_indices has </span><span class="si">{}</span><span class="s2"> dimensions."</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ndims</span><span class="p">)</span>
</span><span id="__span-0-1403"><a id="__codelineno-0-1403" name="__codelineno-0-1403"></a>        <span class="p">)</span>
</span><span id="__span-0-1404"><a id="__codelineno-0-1404" name="__codelineno-0-1404"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"segment_indices"</span><span class="p">):</span>
</span><span id="__span-0-1405"><a id="__codelineno-0-1405" name="__codelineno-0-1405"></a>        <span class="c1"># TODO(KesterTong): This is a fundamental operation for segments, write a C++</span>
</span><span id="__span-0-1406"><a id="__codelineno-0-1406" name="__codelineno-0-1406"></a>        <span class="c1"># op to do this.</span>
</span><span id="__span-0-1407"><a id="__codelineno-0-1407" name="__codelineno-0-1407"></a>        <span class="c1"># TODO(KesterTong): Add a check that segment_ids are increasing.</span>
</span><span id="__span-0-1408"><a id="__codelineno-0-1408" name="__codelineno-0-1408"></a>        <span class="n">segment_lengths</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">segment_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">segment_ids</span><span class="p">),</span> <span class="n">segment_ids</span><span class="p">)</span>
</span><span id="__span-0-1409"><a id="__codelineno-0-1409" name="__codelineno-0-1409"></a>        <span class="n">segment_starts</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span>
</span><span id="__span-0-1410"><a id="__codelineno-0-1410" name="__codelineno-0-1410"></a>            <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">segment_lengths</span><span class="p">)],</span> <span class="mi">0</span><span class="p">),</span> <span class="n">segment_ids</span>
</span><span id="__span-0-1411"><a id="__codelineno-0-1411" name="__codelineno-0-1411"></a>        <span class="p">)</span>
</span><span id="__span-0-1412"><a id="__codelineno-0-1412" name="__codelineno-0-1412"></a>        <span class="k">return</span> <span class="p">(</span>
</span><span id="__span-0-1413"><a id="__codelineno-0-1413" name="__codelineno-0-1413"></a>            <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">segment_ids</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</span><span id="__span-0-1414"><a id="__codelineno-0-1414" name="__codelineno-0-1414"></a>            <span class="o">-</span> <span class="n">segment_starts</span>
</span><span id="__span-0-1415"><a id="__codelineno-0-1415" name="__codelineno-0-1415"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.size" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">size</span>


<a href="#tensorflow_transform.size" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">size</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">reduce_instance_dims</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes the total size of instances in a <code>Tensor</code> over the whole dataset.</p>
        <hr>
<p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.
  reduce_instance_dims: By default collapses the batch and instance dimensions
    to arrive at a single scalar output. If False, only collapses the batch
    dimension and outputs a vector of the same shape as the input.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>A <code>Tensor</code> of type int64.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/analyzers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-803">803</a></span>
<span class="normal"><a href="#__codelineno-0-804">804</a></span>
<span class="normal"><a href="#__codelineno-0-805">805</a></span>
<span class="normal"><a href="#__codelineno-0-806">806</a></span>
<span class="normal"><a href="#__codelineno-0-807">807</a></span>
<span class="normal"><a href="#__codelineno-0-808">808</a></span>
<span class="normal"><a href="#__codelineno-0-809">809</a></span>
<span class="normal"><a href="#__codelineno-0-810">810</a></span>
<span class="normal"><a href="#__codelineno-0-811">811</a></span>
<span class="normal"><a href="#__codelineno-0-812">812</a></span>
<span class="normal"><a href="#__codelineno-0-813">813</a></span>
<span class="normal"><a href="#__codelineno-0-814">814</a></span>
<span class="normal"><a href="#__codelineno-0-815">815</a></span>
<span class="normal"><a href="#__codelineno-0-816">816</a></span>
<span class="normal"><a href="#__codelineno-0-817">817</a></span>
<span class="normal"><a href="#__codelineno-0-818">818</a></span>
<span class="normal"><a href="#__codelineno-0-819">819</a></span>
<span class="normal"><a href="#__codelineno-0-820">820</a></span>
<span class="normal"><a href="#__codelineno-0-821">821</a></span>
<span class="normal"><a href="#__codelineno-0-822">822</a></span>
<span class="normal"><a href="#__codelineno-0-823">823</a></span>
<span class="normal"><a href="#__codelineno-0-824">824</a></span>
<span class="normal"><a href="#__codelineno-0-825">825</a></span>
<span class="normal"><a href="#__codelineno-0-826">826</a></span>
<span class="normal"><a href="#__codelineno-0-827">827</a></span>
<span class="normal"><a href="#__codelineno-0-828">828</a></span>
<span class="normal"><a href="#__codelineno-0-829">829</a></span>
<span class="normal"><a href="#__codelineno-0-830">830</a></span>
<span class="normal"><a href="#__codelineno-0-831">831</a></span>
<span class="normal"><a href="#__codelineno-0-832">832</a></span>
<span class="normal"><a href="#__codelineno-0-833">833</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-803"><a id="__codelineno-0-803" name="__codelineno-0-803"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">ANALYZER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-804"><a id="__codelineno-0-804" name="__codelineno-0-804"></a><span class="k">def</span><span class="w"> </span><span class="nf">size</span><span class="p">(</span>
</span><span id="__span-0-805"><a id="__codelineno-0-805" name="__codelineno-0-805"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span>
</span><span id="__span-0-806"><a id="__codelineno-0-806" name="__codelineno-0-806"></a>    <span class="n">reduce_instance_dims</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-807"><a id="__codelineno-0-807" name="__codelineno-0-807"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-808"><a id="__codelineno-0-808" name="__codelineno-0-808"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-809"><a id="__codelineno-0-809" name="__codelineno-0-809"></a><span class="w">    </span><span class="sd">"""Computes the total size of instances in a `Tensor` over the whole dataset.</span>
</span><span id="__span-0-810"><a id="__codelineno-0-810" name="__codelineno-0-810"></a>
</span><span id="__span-0-811"><a id="__codelineno-0-811" name="__codelineno-0-811"></a><span class="sd">    Args:</span>
</span><span id="__span-0-812"><a id="__codelineno-0-812" name="__codelineno-0-812"></a><span class="sd">    ----</span>
</span><span id="__span-0-813"><a id="__codelineno-0-813" name="__codelineno-0-813"></a><span class="sd">      x: A `Tensor`, `SparseTensor`, or `RaggedTensor`.</span>
</span><span id="__span-0-814"><a id="__codelineno-0-814" name="__codelineno-0-814"></a><span class="sd">      reduce_instance_dims: By default collapses the batch and instance dimensions</span>
</span><span id="__span-0-815"><a id="__codelineno-0-815" name="__codelineno-0-815"></a><span class="sd">        to arrive at a single scalar output. If False, only collapses the batch</span>
</span><span id="__span-0-816"><a id="__codelineno-0-816" name="__codelineno-0-816"></a><span class="sd">        dimension and outputs a vector of the same shape as the input.</span>
</span><span id="__span-0-817"><a id="__codelineno-0-817" name="__codelineno-0-817"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-818"><a id="__codelineno-0-818" name="__codelineno-0-818"></a>
</span><span id="__span-0-819"><a id="__codelineno-0-819" name="__codelineno-0-819"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-820"><a id="__codelineno-0-820" name="__codelineno-0-820"></a><span class="sd">    -------</span>
</span><span id="__span-0-821"><a id="__codelineno-0-821" name="__codelineno-0-821"></a><span class="sd">      A `Tensor` of type int64.</span>
</span><span id="__span-0-822"><a id="__codelineno-0-822" name="__codelineno-0-822"></a><span class="sd">    """</span>
</span><span id="__span-0-823"><a id="__codelineno-0-823" name="__codelineno-0-823"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"size"</span><span class="p">):</span>
</span><span id="__span-0-824"><a id="__codelineno-0-824" name="__codelineno-0-824"></a>        <span class="c1"># Note: Calling `sum` defined in this module, not the builtin.</span>
</span><span id="__span-0-825"><a id="__codelineno-0-825" name="__codelineno-0-825"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">):</span>
</span><span id="__span-0-826"><a id="__codelineno-0-826" name="__codelineno-0-826"></a>            <span class="n">ones_like_x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">(</span>
</span><span id="__span-0-827"><a id="__codelineno-0-827" name="__codelineno-0-827"></a>                <span class="n">indices</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span>
</span><span id="__span-0-828"><a id="__codelineno-0-828" name="__codelineno-0-828"></a>                <span class="n">values</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
</span><span id="__span-0-829"><a id="__codelineno-0-829" name="__codelineno-0-829"></a>                <span class="n">dense_shape</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">,</span>
</span><span id="__span-0-830"><a id="__codelineno-0-830" name="__codelineno-0-830"></a>            <span class="p">)</span>
</span><span id="__span-0-831"><a id="__codelineno-0-831" name="__codelineno-0-831"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-832"><a id="__codelineno-0-832" name="__codelineno-0-832"></a>            <span class="n">ones_like_x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span><span id="__span-0-833"><a id="__codelineno-0-833" name="__codelineno-0-833"></a>        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ones_like_x</span><span class="p">,</span> <span class="n">reduce_instance_dims</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.sparse_tensor_left_align" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">sparse_tensor_left_align</span>


<a href="#tensorflow_transform.sparse_tensor_left_align" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">sparse_tensor_left_align</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">sparse_tensor</span><span class="p">:</span> <span class="n"><span title="tensorflow.SparseTensor">SparseTensor</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow.SparseTensor">SparseTensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Re-arranges a <code>tf.SparseTensor</code> and returns a left-aligned version of it.</p>
<p>This mapper can be useful when returning a sparse tensor that may not be
left-aligned from a preprocessing_fn.</p>
        <hr>
<p>sparse_tensor: A 2D <code>tf.SparseTensor</code>.</p>
        <hr>
<p>ValueError if <code>sparse_tensor</code> is not 2D.</p>
        <hr>
<p>A left-aligned version of sparse_tensor as a <code>tf.SparseTensor</code>.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-223"><a id="__codelineno-0-223" name="__codelineno-0-223"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-224"><a id="__codelineno-0-224" name="__codelineno-0-224"></a><span class="k">def</span><span class="w"> </span><span class="nf">sparse_tensor_left_align</span><span class="p">(</span><span class="n">sparse_tensor</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">:</span>
</span><span id="__span-0-225"><a id="__codelineno-0-225" name="__codelineno-0-225"></a><span class="w">    </span><span class="sd">"""Re-arranges a `tf.SparseTensor` and returns a left-aligned version of it.</span>
</span><span id="__span-0-226"><a id="__codelineno-0-226" name="__codelineno-0-226"></a>
</span><span id="__span-0-227"><a id="__codelineno-0-227" name="__codelineno-0-227"></a><span class="sd">    This mapper can be useful when returning a sparse tensor that may not be</span>
</span><span id="__span-0-228"><a id="__codelineno-0-228" name="__codelineno-0-228"></a><span class="sd">    left-aligned from a preprocessing_fn.</span>
</span><span id="__span-0-229"><a id="__codelineno-0-229" name="__codelineno-0-229"></a>
</span><span id="__span-0-230"><a id="__codelineno-0-230" name="__codelineno-0-230"></a><span class="sd">    Args:</span>
</span><span id="__span-0-231"><a id="__codelineno-0-231" name="__codelineno-0-231"></a><span class="sd">    ----</span>
</span><span id="__span-0-232"><a id="__codelineno-0-232" name="__codelineno-0-232"></a><span class="sd">      sparse_tensor: A 2D `tf.SparseTensor`.</span>
</span><span id="__span-0-233"><a id="__codelineno-0-233" name="__codelineno-0-233"></a>
</span><span id="__span-0-234"><a id="__codelineno-0-234" name="__codelineno-0-234"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-235"><a id="__codelineno-0-235" name="__codelineno-0-235"></a><span class="sd">    ------</span>
</span><span id="__span-0-236"><a id="__codelineno-0-236" name="__codelineno-0-236"></a><span class="sd">      ValueError if `sparse_tensor` is not 2D.</span>
</span><span id="__span-0-237"><a id="__codelineno-0-237" name="__codelineno-0-237"></a>
</span><span id="__span-0-238"><a id="__codelineno-0-238" name="__codelineno-0-238"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-239"><a id="__codelineno-0-239" name="__codelineno-0-239"></a><span class="sd">    -------</span>
</span><span id="__span-0-240"><a id="__codelineno-0-240" name="__codelineno-0-240"></a><span class="sd">      A left-aligned version of sparse_tensor as a `tf.SparseTensor`.</span>
</span><span id="__span-0-241"><a id="__codelineno-0-241" name="__codelineno-0-241"></a><span class="sd">    """</span>
</span><span id="__span-0-242"><a id="__codelineno-0-242" name="__codelineno-0-242"></a>    <span class="k">if</span> <span class="n">sparse_tensor</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">ndims</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="__span-0-243"><a id="__codelineno-0-243" name="__codelineno-0-243"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"sparse_tensor_left_align requires a 2D input"</span><span class="p">)</span>
</span><span id="__span-0-244"><a id="__codelineno-0-244" name="__codelineno-0-244"></a>    <span class="n">reordered_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">reorder</span><span class="p">(</span><span class="n">sparse_tensor</span><span class="p">)</span>
</span><span id="__span-0-245"><a id="__codelineno-0-245" name="__codelineno-0-245"></a>    <span class="n">transposed_indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">reordered_tensor</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>
</span><span id="__span-0-246"><a id="__codelineno-0-246" name="__codelineno-0-246"></a>    <span class="n">row_indices</span> <span class="o">=</span> <span class="n">transposed_indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="__span-0-247"><a id="__codelineno-0-247" name="__codelineno-0-247"></a>    <span class="n">row_counts</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unique_with_counts</span><span class="p">(</span><span class="n">row_indices</span><span class="p">,</span> <span class="n">out_idx</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span><span class="o">.</span><span class="n">count</span>
</span><span id="__span-0-248"><a id="__codelineno-0-248" name="__codelineno-0-248"></a>    <span class="n">column_indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ragged</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">row_counts</span><span class="p">)</span><span class="o">.</span><span class="n">flat_values</span>
</span><span id="__span-0-249"><a id="__codelineno-0-249" name="__codelineno-0-249"></a>    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">(</span>
</span><span id="__span-0-250"><a id="__codelineno-0-250" name="__codelineno-0-250"></a>        <span class="n">indices</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">row_indices</span><span class="p">,</span> <span class="n">column_indices</span><span class="p">])),</span>
</span><span id="__span-0-251"><a id="__codelineno-0-251" name="__codelineno-0-251"></a>        <span class="n">values</span><span class="o">=</span><span class="n">reordered_tensor</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
</span><span id="__span-0-252"><a id="__codelineno-0-252" name="__codelineno-0-252"></a>        <span class="n">dense_shape</span><span class="o">=</span><span class="n">reordered_tensor</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">,</span>
</span><span id="__span-0-253"><a id="__codelineno-0-253" name="__codelineno-0-253"></a>    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.sparse_tensor_to_dense_with_shape" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">sparse_tensor_to_dense_with_shape</span>


<a href="#tensorflow_transform.sparse_tensor_to_dense_with_shape" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">sparse_tensor_to_dense_with_shape</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow.SparseTensor">SparseTensor</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">shape</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Union (typing.Union)" href="#tensorflow_transform.Union">Union</a></span><span class="p">[</span><span class="n"><span title="tensorflow.TensorShape">TensorShape</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" title="            Iterable


  
      module-attribute
   (typing.Iterable)" href="#tensorflow_transform.Iterable">Iterable</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">]],</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">default_value</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Union (typing.Union)" href="#tensorflow_transform.Union">Union</a></span><span class="p">[</span><span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Converts a <code>SparseTensor</code> into a dense tensor and sets its shape.</p>
        <hr>
<p>x: A <code>SparseTensor</code>.
  shape: The desired shape of the densified <code>Tensor</code>.
  default_value: (Optional) Value to set for indices not specified. Defaults
    to zero.</p>
        <hr>
<p>A <code>Tensor</code> with the desired shape.</p>
        <hr>
<p>ValueError: If input is not a <code>SparseTensor</code>.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-185"><a id="__codelineno-0-185" name="__codelineno-0-185"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-186"><a id="__codelineno-0-186" name="__codelineno-0-186"></a><span class="k">def</span><span class="w"> </span><span class="nf">sparse_tensor_to_dense_with_shape</span><span class="p">(</span>
</span><span id="__span-0-187"><a id="__codelineno-0-187" name="__codelineno-0-187"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">,</span>
</span><span id="__span-0-188"><a id="__codelineno-0-188" name="__codelineno-0-188"></a>    <span class="n">shape</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
</span><span id="__span-0-189"><a id="__codelineno-0-189" name="__codelineno-0-189"></a>    <span class="n">default_value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-190"><a id="__codelineno-0-190" name="__codelineno-0-190"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-191"><a id="__codelineno-0-191" name="__codelineno-0-191"></a><span class="w">    </span><span class="sd">"""Converts a `SparseTensor` into a dense tensor and sets its shape.</span>
</span><span id="__span-0-192"><a id="__codelineno-0-192" name="__codelineno-0-192"></a>
</span><span id="__span-0-193"><a id="__codelineno-0-193" name="__codelineno-0-193"></a><span class="sd">    Args:</span>
</span><span id="__span-0-194"><a id="__codelineno-0-194" name="__codelineno-0-194"></a><span class="sd">    ----</span>
</span><span id="__span-0-195"><a id="__codelineno-0-195" name="__codelineno-0-195"></a><span class="sd">      x: A `SparseTensor`.</span>
</span><span id="__span-0-196"><a id="__codelineno-0-196" name="__codelineno-0-196"></a><span class="sd">      shape: The desired shape of the densified `Tensor`.</span>
</span><span id="__span-0-197"><a id="__codelineno-0-197" name="__codelineno-0-197"></a><span class="sd">      default_value: (Optional) Value to set for indices not specified. Defaults</span>
</span><span id="__span-0-198"><a id="__codelineno-0-198" name="__codelineno-0-198"></a><span class="sd">        to zero.</span>
</span><span id="__span-0-199"><a id="__codelineno-0-199" name="__codelineno-0-199"></a>
</span><span id="__span-0-200"><a id="__codelineno-0-200" name="__codelineno-0-200"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-201"><a id="__codelineno-0-201" name="__codelineno-0-201"></a><span class="sd">    -------</span>
</span><span id="__span-0-202"><a id="__codelineno-0-202" name="__codelineno-0-202"></a><span class="sd">      A `Tensor` with the desired shape.</span>
</span><span id="__span-0-203"><a id="__codelineno-0-203" name="__codelineno-0-203"></a>
</span><span id="__span-0-204"><a id="__codelineno-0-204" name="__codelineno-0-204"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-205"><a id="__codelineno-0-205" name="__codelineno-0-205"></a><span class="sd">    ------</span>
</span><span id="__span-0-206"><a id="__codelineno-0-206" name="__codelineno-0-206"></a><span class="sd">      ValueError: If input is not a `SparseTensor`.</span>
</span><span id="__span-0-207"><a id="__codelineno-0-207" name="__codelineno-0-207"></a><span class="sd">    """</span>
</span><span id="__span-0-208"><a id="__codelineno-0-208" name="__codelineno-0-208"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">):</span>
</span><span id="__span-0-209"><a id="__codelineno-0-209" name="__codelineno-0-209"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"input must be a SparseTensor"</span><span class="p">)</span>
</span><span id="__span-0-210"><a id="__codelineno-0-210" name="__codelineno-0-210"></a>    <span class="n">new_dense_shape</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-0-211"><a id="__codelineno-0-211" name="__codelineno-0-211"></a>        <span class="n">x</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">size</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">size</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
</span><span id="__span-0-212"><a id="__codelineno-0-212" name="__codelineno-0-212"></a>    <span class="p">]</span>
</span><span id="__span-0-213"><a id="__codelineno-0-213" name="__codelineno-0-213"></a>    <span class="n">dense</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">raw_ops</span><span class="o">.</span><span class="n">SparseToDense</span><span class="p">(</span>
</span><span id="__span-0-214"><a id="__codelineno-0-214" name="__codelineno-0-214"></a>        <span class="n">sparse_indices</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span>
</span><span id="__span-0-215"><a id="__codelineno-0-215" name="__codelineno-0-215"></a>        <span class="n">output_shape</span><span class="o">=</span><span class="n">new_dense_shape</span><span class="p">,</span>
</span><span id="__span-0-216"><a id="__codelineno-0-216" name="__codelineno-0-216"></a>        <span class="n">sparse_values</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
</span><span id="__span-0-217"><a id="__codelineno-0-217" name="__codelineno-0-217"></a>        <span class="n">default_value</span><span class="o">=</span><span class="n">default_value</span><span class="p">,</span>
</span><span id="__span-0-218"><a id="__codelineno-0-218" name="__codelineno-0-218"></a>    <span class="p">)</span>
</span><span id="__span-0-219"><a id="__codelineno-0-219" name="__codelineno-0-219"></a>    <span class="n">dense</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
</span><span id="__span-0-220"><a id="__codelineno-0-220" name="__codelineno-0-220"></a>    <span class="k">return</span> <span class="n">dense</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.sum" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">sum</span>


<a href="#tensorflow_transform.sum" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">sum</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">reduce_instance_dims</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes the sum of the values of a <code>Tensor</code> over the whole dataset.</p>
        <hr>
<p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>. Its type must be floating
      point (float{16|32|64}),integral (int{8|16|32|64}), or unsigned
      integral (uint{8|16}).
  reduce_instance_dims: By default collapses the batch and instance dimensions
      to arrive at a single scalar output. If False, only collapses the batch
      dimension and outputs a vector of the same shape as the input.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>A <code>Tensor</code> containing the sum. If <code>x</code> is float32 or float64, the sum will
  have the same type as <code>x</code>. If <code>x</code> is float16, the output is cast to float32.
  If <code>x</code> is integral, the output is cast to [u]int64. If <code>x</code> is sparse and
  reduce_inst_dims is False will return 0 in place where column has no values
  across batches.</p>
        <hr>
<p>TypeError: If the type of <code>x</code> is not supported.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/analyzers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-672">672</a></span>
<span class="normal"><a href="#__codelineno-0-673">673</a></span>
<span class="normal"><a href="#__codelineno-0-674">674</a></span>
<span class="normal"><a href="#__codelineno-0-675">675</a></span>
<span class="normal"><a href="#__codelineno-0-676">676</a></span>
<span class="normal"><a href="#__codelineno-0-677">677</a></span>
<span class="normal"><a href="#__codelineno-0-678">678</a></span>
<span class="normal"><a href="#__codelineno-0-679">679</a></span>
<span class="normal"><a href="#__codelineno-0-680">680</a></span>
<span class="normal"><a href="#__codelineno-0-681">681</a></span>
<span class="normal"><a href="#__codelineno-0-682">682</a></span>
<span class="normal"><a href="#__codelineno-0-683">683</a></span>
<span class="normal"><a href="#__codelineno-0-684">684</a></span>
<span class="normal"><a href="#__codelineno-0-685">685</a></span>
<span class="normal"><a href="#__codelineno-0-686">686</a></span>
<span class="normal"><a href="#__codelineno-0-687">687</a></span>
<span class="normal"><a href="#__codelineno-0-688">688</a></span>
<span class="normal"><a href="#__codelineno-0-689">689</a></span>
<span class="normal"><a href="#__codelineno-0-690">690</a></span>
<span class="normal"><a href="#__codelineno-0-691">691</a></span>
<span class="normal"><a href="#__codelineno-0-692">692</a></span>
<span class="normal"><a href="#__codelineno-0-693">693</a></span>
<span class="normal"><a href="#__codelineno-0-694">694</a></span>
<span class="normal"><a href="#__codelineno-0-695">695</a></span>
<span class="normal"><a href="#__codelineno-0-696">696</a></span>
<span class="normal"><a href="#__codelineno-0-697">697</a></span>
<span class="normal"><a href="#__codelineno-0-698">698</a></span>
<span class="normal"><a href="#__codelineno-0-699">699</a></span>
<span class="normal"><a href="#__codelineno-0-700">700</a></span>
<span class="normal"><a href="#__codelineno-0-701">701</a></span>
<span class="normal"><a href="#__codelineno-0-702">702</a></span>
<span class="normal"><a href="#__codelineno-0-703">703</a></span>
<span class="normal"><a href="#__codelineno-0-704">704</a></span>
<span class="normal"><a href="#__codelineno-0-705">705</a></span>
<span class="normal"><a href="#__codelineno-0-706">706</a></span>
<span class="normal"><a href="#__codelineno-0-707">707</a></span>
<span class="normal"><a href="#__codelineno-0-708">708</a></span>
<span class="normal"><a href="#__codelineno-0-709">709</a></span>
<span class="normal"><a href="#__codelineno-0-710">710</a></span>
<span class="normal"><a href="#__codelineno-0-711">711</a></span>
<span class="normal"><a href="#__codelineno-0-712">712</a></span>
<span class="normal"><a href="#__codelineno-0-713">713</a></span>
<span class="normal"><a href="#__codelineno-0-714">714</a></span>
<span class="normal"><a href="#__codelineno-0-715">715</a></span>
<span class="normal"><a href="#__codelineno-0-716">716</a></span>
<span class="normal"><a href="#__codelineno-0-717">717</a></span>
<span class="normal"><a href="#__codelineno-0-718">718</a></span>
<span class="normal"><a href="#__codelineno-0-719">719</a></span>
<span class="normal"><a href="#__codelineno-0-720">720</a></span>
<span class="normal"><a href="#__codelineno-0-721">721</a></span>
<span class="normal"><a href="#__codelineno-0-722">722</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-672"><a id="__codelineno-0-672" name="__codelineno-0-672"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">ANALYZER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-673"><a id="__codelineno-0-673" name="__codelineno-0-673"></a><span class="k">def</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span>  <span class="c1"># pylint: disable=redefined-builtin</span>
</span><span id="__span-0-674"><a id="__codelineno-0-674" name="__codelineno-0-674"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span>
</span><span id="__span-0-675"><a id="__codelineno-0-675" name="__codelineno-0-675"></a>    <span class="n">reduce_instance_dims</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-676"><a id="__codelineno-0-676" name="__codelineno-0-676"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-677"><a id="__codelineno-0-677" name="__codelineno-0-677"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-678"><a id="__codelineno-0-678" name="__codelineno-0-678"></a><span class="w">    </span><span class="sd">"""Computes the sum of the values of a `Tensor` over the whole dataset.</span>
</span><span id="__span-0-679"><a id="__codelineno-0-679" name="__codelineno-0-679"></a>
</span><span id="__span-0-680"><a id="__codelineno-0-680" name="__codelineno-0-680"></a><span class="sd">    Args:</span>
</span><span id="__span-0-681"><a id="__codelineno-0-681" name="__codelineno-0-681"></a><span class="sd">    ----</span>
</span><span id="__span-0-682"><a id="__codelineno-0-682" name="__codelineno-0-682"></a><span class="sd">      x: A `Tensor`, `SparseTensor`, or `RaggedTensor`. Its type must be floating</span>
</span><span id="__span-0-683"><a id="__codelineno-0-683" name="__codelineno-0-683"></a><span class="sd">          point (float{16|32|64}),integral (int{8|16|32|64}), or unsigned</span>
</span><span id="__span-0-684"><a id="__codelineno-0-684" name="__codelineno-0-684"></a><span class="sd">          integral (uint{8|16}).</span>
</span><span id="__span-0-685"><a id="__codelineno-0-685" name="__codelineno-0-685"></a><span class="sd">      reduce_instance_dims: By default collapses the batch and instance dimensions</span>
</span><span id="__span-0-686"><a id="__codelineno-0-686" name="__codelineno-0-686"></a><span class="sd">          to arrive at a single scalar output. If False, only collapses the batch</span>
</span><span id="__span-0-687"><a id="__codelineno-0-687" name="__codelineno-0-687"></a><span class="sd">          dimension and outputs a vector of the same shape as the input.</span>
</span><span id="__span-0-688"><a id="__codelineno-0-688" name="__codelineno-0-688"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-689"><a id="__codelineno-0-689" name="__codelineno-0-689"></a>
</span><span id="__span-0-690"><a id="__codelineno-0-690" name="__codelineno-0-690"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-691"><a id="__codelineno-0-691" name="__codelineno-0-691"></a><span class="sd">    -------</span>
</span><span id="__span-0-692"><a id="__codelineno-0-692" name="__codelineno-0-692"></a><span class="sd">      A `Tensor` containing the sum. If `x` is float32 or float64, the sum will</span>
</span><span id="__span-0-693"><a id="__codelineno-0-693" name="__codelineno-0-693"></a><span class="sd">      have the same type as `x`. If `x` is float16, the output is cast to float32.</span>
</span><span id="__span-0-694"><a id="__codelineno-0-694" name="__codelineno-0-694"></a><span class="sd">      If `x` is integral, the output is cast to [u]int64. If `x` is sparse and</span>
</span><span id="__span-0-695"><a id="__codelineno-0-695" name="__codelineno-0-695"></a><span class="sd">      reduce_inst_dims is False will return 0 in place where column has no values</span>
</span><span id="__span-0-696"><a id="__codelineno-0-696" name="__codelineno-0-696"></a><span class="sd">      across batches.</span>
</span><span id="__span-0-697"><a id="__codelineno-0-697" name="__codelineno-0-697"></a>
</span><span id="__span-0-698"><a id="__codelineno-0-698" name="__codelineno-0-698"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-699"><a id="__codelineno-0-699" name="__codelineno-0-699"></a><span class="sd">    ------</span>
</span><span id="__span-0-700"><a id="__codelineno-0-700" name="__codelineno-0-700"></a><span class="sd">      TypeError: If the type of `x` is not supported.</span>
</span><span id="__span-0-701"><a id="__codelineno-0-701" name="__codelineno-0-701"></a><span class="sd">    """</span>
</span><span id="__span-0-702"><a id="__codelineno-0-702" name="__codelineno-0-702"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"sum"</span><span class="p">):</span>
</span><span id="__span-0-703"><a id="__codelineno-0-703" name="__codelineno-0-703"></a>        <span class="k">if</span> <span class="n">reduce_instance_dims</span><span class="p">:</span>
</span><span id="__span-0-704"><a id="__codelineno-0-704" name="__codelineno-0-704"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">input_tensor</span><span class="o">=</span><span class="n">tf_utils</span><span class="o">.</span><span class="n">get_values</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span><span id="__span-0-705"><a id="__codelineno-0-705" name="__codelineno-0-705"></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">):</span>
</span><span id="__span-0-706"><a id="__codelineno-0-706" name="__codelineno-0-706"></a>            <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">uint8</span> <span class="ow">or</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">uint16</span><span class="p">:</span>
</span><span id="__span-0-707"><a id="__codelineno-0-707" name="__codelineno-0-707"></a>                <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span><span id="__span-0-708"><a id="__codelineno-0-708" name="__codelineno-0-708"></a>            <span class="k">elif</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">uint32</span> <span class="ow">or</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">uint64</span><span class="p">:</span>
</span><span id="__span-0-709"><a id="__codelineno-0-709" name="__codelineno-0-709"></a>                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">"Data type </span><span class="si">%r</span><span class="s2"> is not supported"</span> <span class="o">%</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-710"><a id="__codelineno-0-710" name="__codelineno-0-710"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-711"><a id="__codelineno-0-711" name="__codelineno-0-711"></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">):</span>
</span><span id="__span-0-712"><a id="__codelineno-0-712" name="__codelineno-0-712"></a>            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Elementwise sum does not support RaggedTensors."</span><span class="p">)</span>
</span><span id="__span-0-713"><a id="__codelineno-0-713" name="__codelineno-0-713"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-714"><a id="__codelineno-0-714" name="__codelineno-0-714"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">input_tensor</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-715"><a id="__codelineno-0-715" name="__codelineno-0-715"></a>        <span class="n">output_dtype</span><span class="p">,</span> <span class="n">sum_fn</span> <span class="o">=</span> <span class="n">_sum_combine_fn_and_dtype</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-716"><a id="__codelineno-0-716" name="__codelineno-0-716"></a>        <span class="k">return</span> <span class="n">_numeric_combine</span><span class="p">(</span>
</span><span id="__span-0-717"><a id="__codelineno-0-717" name="__codelineno-0-717"></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">],</span>
</span><span id="__span-0-718"><a id="__codelineno-0-718" name="__codelineno-0-718"></a>            <span class="n">fn</span><span class="o">=</span><span class="n">sum_fn</span><span class="p">,</span>
</span><span id="__span-0-719"><a id="__codelineno-0-719" name="__codelineno-0-719"></a>            <span class="n">default_accumulator_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-720"><a id="__codelineno-0-720" name="__codelineno-0-720"></a>            <span class="n">reduce_instance_dims</span><span class="o">=</span><span class="n">reduce_instance_dims</span><span class="p">,</span>
</span><span id="__span-0-721"><a id="__codelineno-0-721" name="__codelineno-0-721"></a>            <span class="n">output_dtypes</span><span class="o">=</span><span class="p">[</span><span class="n">output_dtype</span><span class="p">],</span>
</span><span id="__span-0-722"><a id="__codelineno-0-722" name="__codelineno-0-722"></a>        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.tfidf" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">tfidf</span>


<a href="#tensorflow_transform.tfidf" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">tfidf</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow.SparseTensor">SparseTensor</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">vocab_size</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">smooth</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="            Tuple


  
      module-attribute
   (typing.Tuple)" href="#tensorflow_transform.Tuple">Tuple</a></span><span class="p">[</span><span class="n"><span title="tensorflow.SparseTensor">SparseTensor</span></span><span class="p">,</span> <span class="n"><span title="tensorflow.SparseTensor">SparseTensor</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Maps the terms in x to their term frequency * inverse document frequency.</p>
<p>The term frequency of a term in a document is calculated as
(count of term in document) / (document size)</p>
<p>The inverse document frequency of a term is, by default, calculated as
1 + log((corpus size + 1) / (count of documents containing term + 1)).</p>
<p>Example usage:</p>
<blockquote>
<blockquote>
<blockquote>
<p>def preprocessing_fn(inputs):
...   integerized = tft.compute_and_apply_vocabulary(inputs['x'])
...   vocab_size = tft.get_num_buckets_for_transformed_feature(integerized)
...   vocab_index, tfidf_weight = tft.tfidf(integerized, vocab_size)
...   return {
...      'index': vocab_index,
...      'tf_idf': tfidf_weight,
...      'integerized': integerized,
...   }
raw_data = [dict(x=["I", "like", "pie", "pie", "pie"]),
...             dict(x=["yum", "yum", "pie"])]
feature_spec = dict(x=tf.io.VarLenFeature(tf.string))
raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec)
with tft_beam.Context(temp_dir=tempfile.mkdtemp()):
...   transformed_dataset, transform_fn = (
...       (raw_data, raw_data_metadata)
...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))
transformed_data, transformed_metadata = transformed_dataset
transformed_data
[{'index': array([0, 2, 3]), 'integerized': array([3, 2, 0, 0, 0]),
  'tf_idf': array([0.6, 0.28109303, 0.28109303], dtype=float32)},
 {'index': array([0, 1]), 'integerized': array([1, 1, 0]),
  'tf_idf': array([0.33333334, 0.9369768 ], dtype=float32)}]</p>
</blockquote>
</blockquote>
</blockquote>
<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>example strings: [["I", "like", "pie", "pie", "pie"], ["yum", "yum", "pie]]
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>in: SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4],
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>                          [1, 0], [1, 1], [1, 2]],
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>                 values=[1, 2, 0, 0, 0, 3, 3, 0])
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>out: SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [1, 0], [1, 1]],
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>                  values=[1, 2, 0, 3, 0])
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>     SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [1, 0], [1, 1]],
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>                  values=[(1/5)*(log(3/2)+1), (1/5)*(log(3/2)+1), (3/5),
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>                          (2/3)*(log(3/2)+1), (1/3)]
</span></code></pre></div>
<p>NOTE: the first doc's duplicate "pie" strings have been combined to
  one output, as have the second doc's duplicate "yum" strings.</p>
        <hr>
<p>x: A 2D <code>SparseTensor</code> representing int64 values (most likely that are the
      result of calling <code>compute_and_apply_vocabulary</code> on a tokenized string).
  vocab_size: An int - the count of vocab used to turn the string into int64s
      including any OOV buckets.
  smooth: A bool indicating if the inverse document frequency should be
      smoothed. If True, which is the default, then the idf is calculated as
      1 + log((corpus size + 1) / (document frequency of term + 1)).
      Otherwise, the idf is
      1 +log((corpus size) / (document frequency of term)), which could
      result in a division by zero error.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>Two <code>SparseTensor</code>s with indices [index_in_batch, index_in_bag_of_words].
  The first has values vocab_index, which is taken from input <code>x</code>.
  The second has values tfidf_weight.</p>
        <hr>
<p>ValueError if <code>x</code> does not have 2 dimensions.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-731">731</a></span>
<span class="normal"><a href="#__codelineno-0-732">732</a></span>
<span class="normal"><a href="#__codelineno-0-733">733</a></span>
<span class="normal"><a href="#__codelineno-0-734">734</a></span>
<span class="normal"><a href="#__codelineno-0-735">735</a></span>
<span class="normal"><a href="#__codelineno-0-736">736</a></span>
<span class="normal"><a href="#__codelineno-0-737">737</a></span>
<span class="normal"><a href="#__codelineno-0-738">738</a></span>
<span class="normal"><a href="#__codelineno-0-739">739</a></span>
<span class="normal"><a href="#__codelineno-0-740">740</a></span>
<span class="normal"><a href="#__codelineno-0-741">741</a></span>
<span class="normal"><a href="#__codelineno-0-742">742</a></span>
<span class="normal"><a href="#__codelineno-0-743">743</a></span>
<span class="normal"><a href="#__codelineno-0-744">744</a></span>
<span class="normal"><a href="#__codelineno-0-745">745</a></span>
<span class="normal"><a href="#__codelineno-0-746">746</a></span>
<span class="normal"><a href="#__codelineno-0-747">747</a></span>
<span class="normal"><a href="#__codelineno-0-748">748</a></span>
<span class="normal"><a href="#__codelineno-0-749">749</a></span>
<span class="normal"><a href="#__codelineno-0-750">750</a></span>
<span class="normal"><a href="#__codelineno-0-751">751</a></span>
<span class="normal"><a href="#__codelineno-0-752">752</a></span>
<span class="normal"><a href="#__codelineno-0-753">753</a></span>
<span class="normal"><a href="#__codelineno-0-754">754</a></span>
<span class="normal"><a href="#__codelineno-0-755">755</a></span>
<span class="normal"><a href="#__codelineno-0-756">756</a></span>
<span class="normal"><a href="#__codelineno-0-757">757</a></span>
<span class="normal"><a href="#__codelineno-0-758">758</a></span>
<span class="normal"><a href="#__codelineno-0-759">759</a></span>
<span class="normal"><a href="#__codelineno-0-760">760</a></span>
<span class="normal"><a href="#__codelineno-0-761">761</a></span>
<span class="normal"><a href="#__codelineno-0-762">762</a></span>
<span class="normal"><a href="#__codelineno-0-763">763</a></span>
<span class="normal"><a href="#__codelineno-0-764">764</a></span>
<span class="normal"><a href="#__codelineno-0-765">765</a></span>
<span class="normal"><a href="#__codelineno-0-766">766</a></span>
<span class="normal"><a href="#__codelineno-0-767">767</a></span>
<span class="normal"><a href="#__codelineno-0-768">768</a></span>
<span class="normal"><a href="#__codelineno-0-769">769</a></span>
<span class="normal"><a href="#__codelineno-0-770">770</a></span>
<span class="normal"><a href="#__codelineno-0-771">771</a></span>
<span class="normal"><a href="#__codelineno-0-772">772</a></span>
<span class="normal"><a href="#__codelineno-0-773">773</a></span>
<span class="normal"><a href="#__codelineno-0-774">774</a></span>
<span class="normal"><a href="#__codelineno-0-775">775</a></span>
<span class="normal"><a href="#__codelineno-0-776">776</a></span>
<span class="normal"><a href="#__codelineno-0-777">777</a></span>
<span class="normal"><a href="#__codelineno-0-778">778</a></span>
<span class="normal"><a href="#__codelineno-0-779">779</a></span>
<span class="normal"><a href="#__codelineno-0-780">780</a></span>
<span class="normal"><a href="#__codelineno-0-781">781</a></span>
<span class="normal"><a href="#__codelineno-0-782">782</a></span>
<span class="normal"><a href="#__codelineno-0-783">783</a></span>
<span class="normal"><a href="#__codelineno-0-784">784</a></span>
<span class="normal"><a href="#__codelineno-0-785">785</a></span>
<span class="normal"><a href="#__codelineno-0-786">786</a></span>
<span class="normal"><a href="#__codelineno-0-787">787</a></span>
<span class="normal"><a href="#__codelineno-0-788">788</a></span>
<span class="normal"><a href="#__codelineno-0-789">789</a></span>
<span class="normal"><a href="#__codelineno-0-790">790</a></span>
<span class="normal"><a href="#__codelineno-0-791">791</a></span>
<span class="normal"><a href="#__codelineno-0-792">792</a></span>
<span class="normal"><a href="#__codelineno-0-793">793</a></span>
<span class="normal"><a href="#__codelineno-0-794">794</a></span>
<span class="normal"><a href="#__codelineno-0-795">795</a></span>
<span class="normal"><a href="#__codelineno-0-796">796</a></span>
<span class="normal"><a href="#__codelineno-0-797">797</a></span>
<span class="normal"><a href="#__codelineno-0-798">798</a></span>
<span class="normal"><a href="#__codelineno-0-799">799</a></span>
<span class="normal"><a href="#__codelineno-0-800">800</a></span>
<span class="normal"><a href="#__codelineno-0-801">801</a></span>
<span class="normal"><a href="#__codelineno-0-802">802</a></span>
<span class="normal"><a href="#__codelineno-0-803">803</a></span>
<span class="normal"><a href="#__codelineno-0-804">804</a></span>
<span class="normal"><a href="#__codelineno-0-805">805</a></span>
<span class="normal"><a href="#__codelineno-0-806">806</a></span>
<span class="normal"><a href="#__codelineno-0-807">807</a></span>
<span class="normal"><a href="#__codelineno-0-808">808</a></span>
<span class="normal"><a href="#__codelineno-0-809">809</a></span>
<span class="normal"><a href="#__codelineno-0-810">810</a></span>
<span class="normal"><a href="#__codelineno-0-811">811</a></span>
<span class="normal"><a href="#__codelineno-0-812">812</a></span>
<span class="normal"><a href="#__codelineno-0-813">813</a></span>
<span class="normal"><a href="#__codelineno-0-814">814</a></span>
<span class="normal"><a href="#__codelineno-0-815">815</a></span>
<span class="normal"><a href="#__codelineno-0-816">816</a></span>
<span class="normal"><a href="#__codelineno-0-817">817</a></span>
<span class="normal"><a href="#__codelineno-0-818">818</a></span>
<span class="normal"><a href="#__codelineno-0-819">819</a></span>
<span class="normal"><a href="#__codelineno-0-820">820</a></span>
<span class="normal"><a href="#__codelineno-0-821">821</a></span>
<span class="normal"><a href="#__codelineno-0-822">822</a></span>
<span class="normal"><a href="#__codelineno-0-823">823</a></span>
<span class="normal"><a href="#__codelineno-0-824">824</a></span>
<span class="normal"><a href="#__codelineno-0-825">825</a></span>
<span class="normal"><a href="#__codelineno-0-826">826</a></span>
<span class="normal"><a href="#__codelineno-0-827">827</a></span>
<span class="normal"><a href="#__codelineno-0-828">828</a></span>
<span class="normal"><a href="#__codelineno-0-829">829</a></span>
<span class="normal"><a href="#__codelineno-0-830">830</a></span>
<span class="normal"><a href="#__codelineno-0-831">831</a></span>
<span class="normal"><a href="#__codelineno-0-832">832</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-731"><a id="__codelineno-0-731" name="__codelineno-0-731"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-732"><a id="__codelineno-0-732" name="__codelineno-0-732"></a><span class="k">def</span><span class="w"> </span><span class="nf">tfidf</span><span class="p">(</span>
</span><span id="__span-0-733"><a id="__codelineno-0-733" name="__codelineno-0-733"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">smooth</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-734"><a id="__codelineno-0-734" name="__codelineno-0-734"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">]:</span>
</span><span id="__span-0-735"><a id="__codelineno-0-735" name="__codelineno-0-735"></a>    <span class="c1"># pyformat: disable</span>
</span><span id="__span-0-736"><a id="__codelineno-0-736" name="__codelineno-0-736"></a><span class="w">    </span><span class="sd">"""Maps the terms in x to their term frequency * inverse document frequency.</span>
</span><span id="__span-0-737"><a id="__codelineno-0-737" name="__codelineno-0-737"></a>
</span><span id="__span-0-738"><a id="__codelineno-0-738" name="__codelineno-0-738"></a><span class="sd">    The term frequency of a term in a document is calculated as</span>
</span><span id="__span-0-739"><a id="__codelineno-0-739" name="__codelineno-0-739"></a><span class="sd">    (count of term in document) / (document size)</span>
</span><span id="__span-0-740"><a id="__codelineno-0-740" name="__codelineno-0-740"></a>
</span><span id="__span-0-741"><a id="__codelineno-0-741" name="__codelineno-0-741"></a><span class="sd">    The inverse document frequency of a term is, by default, calculated as</span>
</span><span id="__span-0-742"><a id="__codelineno-0-742" name="__codelineno-0-742"></a><span class="sd">    1 + log((corpus size + 1) / (count of documents containing term + 1)).</span>
</span><span id="__span-0-743"><a id="__codelineno-0-743" name="__codelineno-0-743"></a>
</span><span id="__span-0-744"><a id="__codelineno-0-744" name="__codelineno-0-744"></a>
</span><span id="__span-0-745"><a id="__codelineno-0-745" name="__codelineno-0-745"></a><span class="sd">    Example usage:</span>
</span><span id="__span-0-746"><a id="__codelineno-0-746" name="__codelineno-0-746"></a>
</span><span id="__span-0-747"><a id="__codelineno-0-747" name="__codelineno-0-747"></a><span class="sd">    &gt;&gt;&gt; def preprocessing_fn(inputs):</span>
</span><span id="__span-0-748"><a id="__codelineno-0-748" name="__codelineno-0-748"></a><span class="sd">    ...   integerized = tft.compute_and_apply_vocabulary(inputs['x'])</span>
</span><span id="__span-0-749"><a id="__codelineno-0-749" name="__codelineno-0-749"></a><span class="sd">    ...   vocab_size = tft.get_num_buckets_for_transformed_feature(integerized)</span>
</span><span id="__span-0-750"><a id="__codelineno-0-750" name="__codelineno-0-750"></a><span class="sd">    ...   vocab_index, tfidf_weight = tft.tfidf(integerized, vocab_size)</span>
</span><span id="__span-0-751"><a id="__codelineno-0-751" name="__codelineno-0-751"></a><span class="sd">    ...   return {</span>
</span><span id="__span-0-752"><a id="__codelineno-0-752" name="__codelineno-0-752"></a><span class="sd">    ...      'index': vocab_index,</span>
</span><span id="__span-0-753"><a id="__codelineno-0-753" name="__codelineno-0-753"></a><span class="sd">    ...      'tf_idf': tfidf_weight,</span>
</span><span id="__span-0-754"><a id="__codelineno-0-754" name="__codelineno-0-754"></a><span class="sd">    ...      'integerized': integerized,</span>
</span><span id="__span-0-755"><a id="__codelineno-0-755" name="__codelineno-0-755"></a><span class="sd">    ...   }</span>
</span><span id="__span-0-756"><a id="__codelineno-0-756" name="__codelineno-0-756"></a><span class="sd">    &gt;&gt;&gt; raw_data = [dict(x=["I", "like", "pie", "pie", "pie"]),</span>
</span><span id="__span-0-757"><a id="__codelineno-0-757" name="__codelineno-0-757"></a><span class="sd">    ...             dict(x=["yum", "yum", "pie"])]</span>
</span><span id="__span-0-758"><a id="__codelineno-0-758" name="__codelineno-0-758"></a><span class="sd">    &gt;&gt;&gt; feature_spec = dict(x=tf.io.VarLenFeature(tf.string))</span>
</span><span id="__span-0-759"><a id="__codelineno-0-759" name="__codelineno-0-759"></a><span class="sd">    &gt;&gt;&gt; raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec)</span>
</span><span id="__span-0-760"><a id="__codelineno-0-760" name="__codelineno-0-760"></a><span class="sd">    &gt;&gt;&gt; with tft_beam.Context(temp_dir=tempfile.mkdtemp()):</span>
</span><span id="__span-0-761"><a id="__codelineno-0-761" name="__codelineno-0-761"></a><span class="sd">    ...   transformed_dataset, transform_fn = (</span>
</span><span id="__span-0-762"><a id="__codelineno-0-762" name="__codelineno-0-762"></a><span class="sd">    ...       (raw_data, raw_data_metadata)</span>
</span><span id="__span-0-763"><a id="__codelineno-0-763" name="__codelineno-0-763"></a><span class="sd">    ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))</span>
</span><span id="__span-0-764"><a id="__codelineno-0-764" name="__codelineno-0-764"></a><span class="sd">    &gt;&gt;&gt; transformed_data, transformed_metadata = transformed_dataset</span>
</span><span id="__span-0-765"><a id="__codelineno-0-765" name="__codelineno-0-765"></a><span class="sd">    &gt;&gt;&gt; transformed_data</span>
</span><span id="__span-0-766"><a id="__codelineno-0-766" name="__codelineno-0-766"></a><span class="sd">    [{'index': array([0, 2, 3]), 'integerized': array([3, 2, 0, 0, 0]),</span>
</span><span id="__span-0-767"><a id="__codelineno-0-767" name="__codelineno-0-767"></a><span class="sd">      'tf_idf': array([0.6, 0.28109303, 0.28109303], dtype=float32)},</span>
</span><span id="__span-0-768"><a id="__codelineno-0-768" name="__codelineno-0-768"></a><span class="sd">     {'index': array([0, 1]), 'integerized': array([1, 1, 0]),</span>
</span><span id="__span-0-769"><a id="__codelineno-0-769" name="__codelineno-0-769"></a><span class="sd">      'tf_idf': array([0.33333334, 0.9369768 ], dtype=float32)}]</span>
</span><span id="__span-0-770"><a id="__codelineno-0-770" name="__codelineno-0-770"></a>
</span><span id="__span-0-771"><a id="__codelineno-0-771" name="__codelineno-0-771"></a><span class="sd">      ```</span>
</span><span id="__span-0-772"><a id="__codelineno-0-772" name="__codelineno-0-772"></a><span class="sd">      example strings: [["I", "like", "pie", "pie", "pie"], ["yum", "yum", "pie]]</span>
</span><span id="__span-0-773"><a id="__codelineno-0-773" name="__codelineno-0-773"></a><span class="sd">      in: SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4],</span>
</span><span id="__span-0-774"><a id="__codelineno-0-774" name="__codelineno-0-774"></a><span class="sd">                                [1, 0], [1, 1], [1, 2]],</span>
</span><span id="__span-0-775"><a id="__codelineno-0-775" name="__codelineno-0-775"></a><span class="sd">                       values=[1, 2, 0, 0, 0, 3, 3, 0])</span>
</span><span id="__span-0-776"><a id="__codelineno-0-776" name="__codelineno-0-776"></a><span class="sd">      out: SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [1, 0], [1, 1]],</span>
</span><span id="__span-0-777"><a id="__codelineno-0-777" name="__codelineno-0-777"></a><span class="sd">                        values=[1, 2, 0, 3, 0])</span>
</span><span id="__span-0-778"><a id="__codelineno-0-778" name="__codelineno-0-778"></a><span class="sd">           SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [1, 0], [1, 1]],</span>
</span><span id="__span-0-779"><a id="__codelineno-0-779" name="__codelineno-0-779"></a><span class="sd">                        values=[(1/5)*(log(3/2)+1), (1/5)*(log(3/2)+1), (3/5),</span>
</span><span id="__span-0-780"><a id="__codelineno-0-780" name="__codelineno-0-780"></a><span class="sd">                                (2/3)*(log(3/2)+1), (1/3)]</span>
</span><span id="__span-0-781"><a id="__codelineno-0-781" name="__codelineno-0-781"></a><span class="sd">      ```</span>
</span><span id="__span-0-782"><a id="__codelineno-0-782" name="__codelineno-0-782"></a>
</span><span id="__span-0-783"><a id="__codelineno-0-783" name="__codelineno-0-783"></a><span class="sd">      NOTE: the first doc's duplicate "pie" strings have been combined to</span>
</span><span id="__span-0-784"><a id="__codelineno-0-784" name="__codelineno-0-784"></a><span class="sd">      one output, as have the second doc's duplicate "yum" strings.</span>
</span><span id="__span-0-785"><a id="__codelineno-0-785" name="__codelineno-0-785"></a>
</span><span id="__span-0-786"><a id="__codelineno-0-786" name="__codelineno-0-786"></a><span class="sd">    Args:</span>
</span><span id="__span-0-787"><a id="__codelineno-0-787" name="__codelineno-0-787"></a><span class="sd">    ----</span>
</span><span id="__span-0-788"><a id="__codelineno-0-788" name="__codelineno-0-788"></a><span class="sd">      x: A 2D `SparseTensor` representing int64 values (most likely that are the</span>
</span><span id="__span-0-789"><a id="__codelineno-0-789" name="__codelineno-0-789"></a><span class="sd">          result of calling `compute_and_apply_vocabulary` on a tokenized string).</span>
</span><span id="__span-0-790"><a id="__codelineno-0-790" name="__codelineno-0-790"></a><span class="sd">      vocab_size: An int - the count of vocab used to turn the string into int64s</span>
</span><span id="__span-0-791"><a id="__codelineno-0-791" name="__codelineno-0-791"></a><span class="sd">          including any OOV buckets.</span>
</span><span id="__span-0-792"><a id="__codelineno-0-792" name="__codelineno-0-792"></a><span class="sd">      smooth: A bool indicating if the inverse document frequency should be</span>
</span><span id="__span-0-793"><a id="__codelineno-0-793" name="__codelineno-0-793"></a><span class="sd">          smoothed. If True, which is the default, then the idf is calculated as</span>
</span><span id="__span-0-794"><a id="__codelineno-0-794" name="__codelineno-0-794"></a><span class="sd">          1 + log((corpus size + 1) / (document frequency of term + 1)).</span>
</span><span id="__span-0-795"><a id="__codelineno-0-795" name="__codelineno-0-795"></a><span class="sd">          Otherwise, the idf is</span>
</span><span id="__span-0-796"><a id="__codelineno-0-796" name="__codelineno-0-796"></a><span class="sd">          1 +log((corpus size) / (document frequency of term)), which could</span>
</span><span id="__span-0-797"><a id="__codelineno-0-797" name="__codelineno-0-797"></a><span class="sd">          result in a division by zero error.</span>
</span><span id="__span-0-798"><a id="__codelineno-0-798" name="__codelineno-0-798"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-799"><a id="__codelineno-0-799" name="__codelineno-0-799"></a>
</span><span id="__span-0-800"><a id="__codelineno-0-800" name="__codelineno-0-800"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-801"><a id="__codelineno-0-801" name="__codelineno-0-801"></a><span class="sd">    -------</span>
</span><span id="__span-0-802"><a id="__codelineno-0-802" name="__codelineno-0-802"></a><span class="sd">      Two `SparseTensor`s with indices [index_in_batch, index_in_bag_of_words].</span>
</span><span id="__span-0-803"><a id="__codelineno-0-803" name="__codelineno-0-803"></a><span class="sd">      The first has values vocab_index, which is taken from input `x`.</span>
</span><span id="__span-0-804"><a id="__codelineno-0-804" name="__codelineno-0-804"></a><span class="sd">      The second has values tfidf_weight.</span>
</span><span id="__span-0-805"><a id="__codelineno-0-805" name="__codelineno-0-805"></a>
</span><span id="__span-0-806"><a id="__codelineno-0-806" name="__codelineno-0-806"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-807"><a id="__codelineno-0-807" name="__codelineno-0-807"></a><span class="sd">    ------</span>
</span><span id="__span-0-808"><a id="__codelineno-0-808" name="__codelineno-0-808"></a><span class="sd">      ValueError if `x` does not have 2 dimensions.</span>
</span><span id="__span-0-809"><a id="__codelineno-0-809" name="__codelineno-0-809"></a><span class="sd">    """</span>
</span><span id="__span-0-810"><a id="__codelineno-0-810" name="__codelineno-0-810"></a>    <span class="c1"># pyformat: enable</span>
</span><span id="__span-0-811"><a id="__codelineno-0-811" name="__codelineno-0-811"></a>    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">ndims</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="__span-0-812"><a id="__codelineno-0-812" name="__codelineno-0-812"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="__span-0-813"><a id="__codelineno-0-813" name="__codelineno-0-813"></a>            <span class="s2">"tft.tfidf requires a 2D SparseTensor input. "</span>
</span><span id="__span-0-814"><a id="__codelineno-0-814" name="__codelineno-0-814"></a>            <span class="s2">"Input had </span><span class="si">{}</span><span class="s2"> dimensions."</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">ndims</span><span class="p">)</span>
</span><span id="__span-0-815"><a id="__codelineno-0-815" name="__codelineno-0-815"></a>        <span class="p">)</span>
</span><span id="__span-0-816"><a id="__codelineno-0-816" name="__codelineno-0-816"></a>
</span><span id="__span-0-817"><a id="__codelineno-0-817" name="__codelineno-0-817"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"tfidf"</span><span class="p">):</span>
</span><span id="__span-0-818"><a id="__codelineno-0-818" name="__codelineno-0-818"></a>        <span class="n">cleaned_input</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">to_vocab_range</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
</span><span id="__span-0-819"><a id="__codelineno-0-819" name="__codelineno-0-819"></a>
</span><span id="__span-0-820"><a id="__codelineno-0-820" name="__codelineno-0-820"></a>        <span class="n">term_frequencies</span> <span class="o">=</span> <span class="n">_to_term_frequency</span><span class="p">(</span><span class="n">cleaned_input</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
</span><span id="__span-0-821"><a id="__codelineno-0-821" name="__codelineno-0-821"></a>
</span><span id="__span-0-822"><a id="__codelineno-0-822" name="__codelineno-0-822"></a>        <span class="n">count_docs_with_term_column</span> <span class="o">=</span> <span class="n">_count_docs_with_term</span><span class="p">(</span><span class="n">term_frequencies</span><span class="p">)</span>
</span><span id="__span-0-823"><a id="__codelineno-0-823" name="__codelineno-0-823"></a>        <span class="c1"># Expand dims to get around the min_tensor_rank checks</span>
</span><span id="__span-0-824"><a id="__codelineno-0-824" name="__codelineno-0-824"></a>        <span class="n">sizes</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">cleaned_input</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-825"><a id="__codelineno-0-825" name="__codelineno-0-825"></a>        <span class="c1"># [batch, vocab] - tfidf</span>
</span><span id="__span-0-826"><a id="__codelineno-0-826" name="__codelineno-0-826"></a>        <span class="n">tfidfs</span> <span class="o">=</span> <span class="n">_to_tfidf</span><span class="p">(</span>
</span><span id="__span-0-827"><a id="__codelineno-0-827" name="__codelineno-0-827"></a>            <span class="n">term_frequencies</span><span class="p">,</span>
</span><span id="__span-0-828"><a id="__codelineno-0-828" name="__codelineno-0-828"></a>            <span class="n">analyzers</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">count_docs_with_term_column</span><span class="p">,</span> <span class="n">reduce_instance_dims</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
</span><span id="__span-0-829"><a id="__codelineno-0-829" name="__codelineno-0-829"></a>            <span class="n">analyzers</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sizes</span><span class="p">),</span>
</span><span id="__span-0-830"><a id="__codelineno-0-830" name="__codelineno-0-830"></a>            <span class="n">smooth</span><span class="p">,</span>
</span><span id="__span-0-831"><a id="__codelineno-0-831" name="__codelineno-0-831"></a>        <span class="p">)</span>
</span><span id="__span-0-832"><a id="__codelineno-0-832" name="__codelineno-0-832"></a>        <span class="k">return</span> <span class="n">_split_tfidfs_to_outputs</span><span class="p">(</span><span class="n">tfidfs</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.tukey_h_params" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">tukey_h_params</span>


<a href="#tensorflow_transform.tukey_h_params" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">tukey_h_params</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">reduce_instance_dims</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">output_dtype</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><span title="tensorflow.DType">DType</span></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="            Tuple


  
      module-attribute
   (typing.Tuple)" href="#tensorflow_transform.Tuple">Tuple</a></span><span class="p">[</span><span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes the h parameters of the values of a <code>Tensor</code> over the dataset.</p>
<p>This computes the parameters (hl, hr) of the samples, assuming a Tukey HH
distribution, i.e. (x - tukey_location) / tukey_scale is a Tukey HH
distribution with parameters hl (left parameter) and hr (right parameter).
See the following publication for the definition of the Tukey HH distribution:</p>
<p>Todd C. Headrick, and Mohan D. Pant. "Characterizing Tukey h and
hh-Distributions through L-Moments and the L-Correlation," ISRN Applied
Mathematics, vol. 2012, 2012. doi:10.5402/2012/980153</p>
        <hr>
<p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>. Its type must be floating
      point (float{16|32|64}), or integral ([u]int{8|16|32|64}).
  reduce_instance_dims: By default collapses the batch and instance dimensions
      to arrive at a single scalar output. If False, only collapses the batch
      dimension and outputs a vector of the same shape as the input.
  output_dtype: (Optional) If not None, casts the output tensor to this type.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>The tuple (hl, hr) containing two <code>Tensor</code> instances with the hl and hr
  parameters. If <code>x</code> is floating point, each parameter will have the same type
  as <code>x</code>. If <code>x</code> is integral, the output is cast to float32.</p>
        <hr>
<p>TypeError: If the type of <code>x</code> is not supported.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/analyzers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1087">1087</a></span>
<span class="normal"><a href="#__codelineno-0-1088">1088</a></span>
<span class="normal"><a href="#__codelineno-0-1089">1089</a></span>
<span class="normal"><a href="#__codelineno-0-1090">1090</a></span>
<span class="normal"><a href="#__codelineno-0-1091">1091</a></span>
<span class="normal"><a href="#__codelineno-0-1092">1092</a></span>
<span class="normal"><a href="#__codelineno-0-1093">1093</a></span>
<span class="normal"><a href="#__codelineno-0-1094">1094</a></span>
<span class="normal"><a href="#__codelineno-0-1095">1095</a></span>
<span class="normal"><a href="#__codelineno-0-1096">1096</a></span>
<span class="normal"><a href="#__codelineno-0-1097">1097</a></span>
<span class="normal"><a href="#__codelineno-0-1098">1098</a></span>
<span class="normal"><a href="#__codelineno-0-1099">1099</a></span>
<span class="normal"><a href="#__codelineno-0-1100">1100</a></span>
<span class="normal"><a href="#__codelineno-0-1101">1101</a></span>
<span class="normal"><a href="#__codelineno-0-1102">1102</a></span>
<span class="normal"><a href="#__codelineno-0-1103">1103</a></span>
<span class="normal"><a href="#__codelineno-0-1104">1104</a></span>
<span class="normal"><a href="#__codelineno-0-1105">1105</a></span>
<span class="normal"><a href="#__codelineno-0-1106">1106</a></span>
<span class="normal"><a href="#__codelineno-0-1107">1107</a></span>
<span class="normal"><a href="#__codelineno-0-1108">1108</a></span>
<span class="normal"><a href="#__codelineno-0-1109">1109</a></span>
<span class="normal"><a href="#__codelineno-0-1110">1110</a></span>
<span class="normal"><a href="#__codelineno-0-1111">1111</a></span>
<span class="normal"><a href="#__codelineno-0-1112">1112</a></span>
<span class="normal"><a href="#__codelineno-0-1113">1113</a></span>
<span class="normal"><a href="#__codelineno-0-1114">1114</a></span>
<span class="normal"><a href="#__codelineno-0-1115">1115</a></span>
<span class="normal"><a href="#__codelineno-0-1116">1116</a></span>
<span class="normal"><a href="#__codelineno-0-1117">1117</a></span>
<span class="normal"><a href="#__codelineno-0-1118">1118</a></span>
<span class="normal"><a href="#__codelineno-0-1119">1119</a></span>
<span class="normal"><a href="#__codelineno-0-1120">1120</a></span>
<span class="normal"><a href="#__codelineno-0-1121">1121</a></span>
<span class="normal"><a href="#__codelineno-0-1122">1122</a></span>
<span class="normal"><a href="#__codelineno-0-1123">1123</a></span>
<span class="normal"><a href="#__codelineno-0-1124">1124</a></span>
<span class="normal"><a href="#__codelineno-0-1125">1125</a></span>
<span class="normal"><a href="#__codelineno-0-1126">1126</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1087"><a id="__codelineno-0-1087" name="__codelineno-0-1087"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">ANALYZER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-1088"><a id="__codelineno-0-1088" name="__codelineno-0-1088"></a><span class="k">def</span><span class="w"> </span><span class="nf">tukey_h_params</span><span class="p">(</span>
</span><span id="__span-0-1089"><a id="__codelineno-0-1089" name="__codelineno-0-1089"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span>
</span><span id="__span-0-1090"><a id="__codelineno-0-1090" name="__codelineno-0-1090"></a>    <span class="n">reduce_instance_dims</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-1091"><a id="__codelineno-0-1091" name="__codelineno-0-1091"></a>    <span class="n">output_dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">DType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1092"><a id="__codelineno-0-1092" name="__codelineno-0-1092"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1093"><a id="__codelineno-0-1093" name="__codelineno-0-1093"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span id="__span-0-1094"><a id="__codelineno-0-1094" name="__codelineno-0-1094"></a><span class="w">    </span><span class="sd">"""Computes the h parameters of the values of a `Tensor` over the dataset.</span>
</span><span id="__span-0-1095"><a id="__codelineno-0-1095" name="__codelineno-0-1095"></a>
</span><span id="__span-0-1096"><a id="__codelineno-0-1096" name="__codelineno-0-1096"></a><span class="sd">    This computes the parameters (hl, hr) of the samples, assuming a Tukey HH</span>
</span><span id="__span-0-1097"><a id="__codelineno-0-1097" name="__codelineno-0-1097"></a><span class="sd">    distribution, i.e. (x - tukey_location) / tukey_scale is a Tukey HH</span>
</span><span id="__span-0-1098"><a id="__codelineno-0-1098" name="__codelineno-0-1098"></a><span class="sd">    distribution with parameters hl (left parameter) and hr (right parameter).</span>
</span><span id="__span-0-1099"><a id="__codelineno-0-1099" name="__codelineno-0-1099"></a><span class="sd">    See the following publication for the definition of the Tukey HH distribution:</span>
</span><span id="__span-0-1100"><a id="__codelineno-0-1100" name="__codelineno-0-1100"></a>
</span><span id="__span-0-1101"><a id="__codelineno-0-1101" name="__codelineno-0-1101"></a><span class="sd">    Todd C. Headrick, and Mohan D. Pant. "Characterizing Tukey h and</span>
</span><span id="__span-0-1102"><a id="__codelineno-0-1102" name="__codelineno-0-1102"></a><span class="sd">    hh-Distributions through L-Moments and the L-Correlation," ISRN Applied</span>
</span><span id="__span-0-1103"><a id="__codelineno-0-1103" name="__codelineno-0-1103"></a><span class="sd">    Mathematics, vol. 2012, 2012. doi:10.5402/2012/980153</span>
</span><span id="__span-0-1104"><a id="__codelineno-0-1104" name="__codelineno-0-1104"></a>
</span><span id="__span-0-1105"><a id="__codelineno-0-1105" name="__codelineno-0-1105"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1106"><a id="__codelineno-0-1106" name="__codelineno-0-1106"></a><span class="sd">    ----</span>
</span><span id="__span-0-1107"><a id="__codelineno-0-1107" name="__codelineno-0-1107"></a><span class="sd">      x: A `Tensor`, `SparseTensor`, or `RaggedTensor`. Its type must be floating</span>
</span><span id="__span-0-1108"><a id="__codelineno-0-1108" name="__codelineno-0-1108"></a><span class="sd">          point (float{16|32|64}), or integral ([u]int{8|16|32|64}).</span>
</span><span id="__span-0-1109"><a id="__codelineno-0-1109" name="__codelineno-0-1109"></a><span class="sd">      reduce_instance_dims: By default collapses the batch and instance dimensions</span>
</span><span id="__span-0-1110"><a id="__codelineno-0-1110" name="__codelineno-0-1110"></a><span class="sd">          to arrive at a single scalar output. If False, only collapses the batch</span>
</span><span id="__span-0-1111"><a id="__codelineno-0-1111" name="__codelineno-0-1111"></a><span class="sd">          dimension and outputs a vector of the same shape as the input.</span>
</span><span id="__span-0-1112"><a id="__codelineno-0-1112" name="__codelineno-0-1112"></a><span class="sd">      output_dtype: (Optional) If not None, casts the output tensor to this type.</span>
</span><span id="__span-0-1113"><a id="__codelineno-0-1113" name="__codelineno-0-1113"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-1114"><a id="__codelineno-0-1114" name="__codelineno-0-1114"></a>
</span><span id="__span-0-1115"><a id="__codelineno-0-1115" name="__codelineno-0-1115"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1116"><a id="__codelineno-0-1116" name="__codelineno-0-1116"></a><span class="sd">    -------</span>
</span><span id="__span-0-1117"><a id="__codelineno-0-1117" name="__codelineno-0-1117"></a><span class="sd">      The tuple (hl, hr) containing two `Tensor` instances with the hl and hr</span>
</span><span id="__span-0-1118"><a id="__codelineno-0-1118" name="__codelineno-0-1118"></a><span class="sd">      parameters. If `x` is floating point, each parameter will have the same type</span>
</span><span id="__span-0-1119"><a id="__codelineno-0-1119" name="__codelineno-0-1119"></a><span class="sd">      as `x`. If `x` is integral, the output is cast to float32.</span>
</span><span id="__span-0-1120"><a id="__codelineno-0-1120" name="__codelineno-0-1120"></a>
</span><span id="__span-0-1121"><a id="__codelineno-0-1121" name="__codelineno-0-1121"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-1122"><a id="__codelineno-0-1122" name="__codelineno-0-1122"></a><span class="sd">    ------</span>
</span><span id="__span-0-1123"><a id="__codelineno-0-1123" name="__codelineno-0-1123"></a><span class="sd">      TypeError: If the type of `x` is not supported.</span>
</span><span id="__span-0-1124"><a id="__codelineno-0-1124" name="__codelineno-0-1124"></a><span class="sd">    """</span>
</span><span id="__span-0-1125"><a id="__codelineno-0-1125" name="__codelineno-0-1125"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"tukey_h_params"</span><span class="p">):</span>
</span><span id="__span-0-1126"><a id="__codelineno-0-1126" name="__codelineno-0-1126"></a>        <span class="k">return</span> <span class="n">_tukey_parameters</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">reduce_instance_dims</span><span class="p">,</span> <span class="n">output_dtype</span><span class="p">)[</span><span class="mi">2</span><span class="p">:]</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.tukey_location" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">tukey_location</span>


<a href="#tensorflow_transform.tukey_location" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">tukey_location</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">reduce_instance_dims</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">output_dtype</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><span title="tensorflow.DType">DType</span></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes the location of the values of a <code>Tensor</code> over the whole dataset.</p>
<p>This computes the location of x, assuming a Tukey HH distribution, i.e.
(x - tukey_location) / tukey_scale is a Tukey HH distribution with parameters
tukey_h_params. See the following publication for the definition of the Tukey
HH distribution:</p>
<p>Todd C. Headrick, and Mohan D. Pant. "Characterizing Tukey h and
hh-Distributions through L-Moments and the L-Correlation," ISRN Applied
Mathematics, vol. 2012, 2012. doi:10.5402/2012/980153</p>
        <hr>
<p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>. Its type must be floating
      point (float{16|32|64}), or integral ([u]int{8|16|32|64}).
  reduce_instance_dims: By default collapses the batch and instance dimensions
      to arrive at a single scalar output. If False, only collapses the batch
      dimension and outputs a vector of the same shape as the input.
  output_dtype: (Optional) If not None, casts the output tensor to this type.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>A <code>Tensor</code> containing the location. If <code>x</code> is floating point, the location
  will have the same type as <code>x</code>. If <code>x</code> is integral, the output is cast to
  float32.</p>
        <hr>
<p>TypeError: If the type of <code>x</code> is not supported.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/analyzers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1002">1002</a></span>
<span class="normal"><a href="#__codelineno-0-1003">1003</a></span>
<span class="normal"><a href="#__codelineno-0-1004">1004</a></span>
<span class="normal"><a href="#__codelineno-0-1005">1005</a></span>
<span class="normal"><a href="#__codelineno-0-1006">1006</a></span>
<span class="normal"><a href="#__codelineno-0-1007">1007</a></span>
<span class="normal"><a href="#__codelineno-0-1008">1008</a></span>
<span class="normal"><a href="#__codelineno-0-1009">1009</a></span>
<span class="normal"><a href="#__codelineno-0-1010">1010</a></span>
<span class="normal"><a href="#__codelineno-0-1011">1011</a></span>
<span class="normal"><a href="#__codelineno-0-1012">1012</a></span>
<span class="normal"><a href="#__codelineno-0-1013">1013</a></span>
<span class="normal"><a href="#__codelineno-0-1014">1014</a></span>
<span class="normal"><a href="#__codelineno-0-1015">1015</a></span>
<span class="normal"><a href="#__codelineno-0-1016">1016</a></span>
<span class="normal"><a href="#__codelineno-0-1017">1017</a></span>
<span class="normal"><a href="#__codelineno-0-1018">1018</a></span>
<span class="normal"><a href="#__codelineno-0-1019">1019</a></span>
<span class="normal"><a href="#__codelineno-0-1020">1020</a></span>
<span class="normal"><a href="#__codelineno-0-1021">1021</a></span>
<span class="normal"><a href="#__codelineno-0-1022">1022</a></span>
<span class="normal"><a href="#__codelineno-0-1023">1023</a></span>
<span class="normal"><a href="#__codelineno-0-1024">1024</a></span>
<span class="normal"><a href="#__codelineno-0-1025">1025</a></span>
<span class="normal"><a href="#__codelineno-0-1026">1026</a></span>
<span class="normal"><a href="#__codelineno-0-1027">1027</a></span>
<span class="normal"><a href="#__codelineno-0-1028">1028</a></span>
<span class="normal"><a href="#__codelineno-0-1029">1029</a></span>
<span class="normal"><a href="#__codelineno-0-1030">1030</a></span>
<span class="normal"><a href="#__codelineno-0-1031">1031</a></span>
<span class="normal"><a href="#__codelineno-0-1032">1032</a></span>
<span class="normal"><a href="#__codelineno-0-1033">1033</a></span>
<span class="normal"><a href="#__codelineno-0-1034">1034</a></span>
<span class="normal"><a href="#__codelineno-0-1035">1035</a></span>
<span class="normal"><a href="#__codelineno-0-1036">1036</a></span>
<span class="normal"><a href="#__codelineno-0-1037">1037</a></span>
<span class="normal"><a href="#__codelineno-0-1038">1038</a></span>
<span class="normal"><a href="#__codelineno-0-1039">1039</a></span>
<span class="normal"><a href="#__codelineno-0-1040">1040</a></span>
<span class="normal"><a href="#__codelineno-0-1041">1041</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1002"><a id="__codelineno-0-1002" name="__codelineno-0-1002"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">ANALYZER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-1003"><a id="__codelineno-0-1003" name="__codelineno-0-1003"></a><span class="k">def</span><span class="w"> </span><span class="nf">tukey_location</span><span class="p">(</span>
</span><span id="__span-0-1004"><a id="__codelineno-0-1004" name="__codelineno-0-1004"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span>
</span><span id="__span-0-1005"><a id="__codelineno-0-1005" name="__codelineno-0-1005"></a>    <span class="n">reduce_instance_dims</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-1006"><a id="__codelineno-0-1006" name="__codelineno-0-1006"></a>    <span class="n">output_dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">DType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1007"><a id="__codelineno-0-1007" name="__codelineno-0-1007"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1008"><a id="__codelineno-0-1008" name="__codelineno-0-1008"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-1009"><a id="__codelineno-0-1009" name="__codelineno-0-1009"></a><span class="w">    </span><span class="sd">"""Computes the location of the values of a `Tensor` over the whole dataset.</span>
</span><span id="__span-0-1010"><a id="__codelineno-0-1010" name="__codelineno-0-1010"></a>
</span><span id="__span-0-1011"><a id="__codelineno-0-1011" name="__codelineno-0-1011"></a><span class="sd">    This computes the location of x, assuming a Tukey HH distribution, i.e.</span>
</span><span id="__span-0-1012"><a id="__codelineno-0-1012" name="__codelineno-0-1012"></a><span class="sd">    (x - tukey_location) / tukey_scale is a Tukey HH distribution with parameters</span>
</span><span id="__span-0-1013"><a id="__codelineno-0-1013" name="__codelineno-0-1013"></a><span class="sd">    tukey_h_params. See the following publication for the definition of the Tukey</span>
</span><span id="__span-0-1014"><a id="__codelineno-0-1014" name="__codelineno-0-1014"></a><span class="sd">    HH distribution:</span>
</span><span id="__span-0-1015"><a id="__codelineno-0-1015" name="__codelineno-0-1015"></a>
</span><span id="__span-0-1016"><a id="__codelineno-0-1016" name="__codelineno-0-1016"></a><span class="sd">    Todd C. Headrick, and Mohan D. Pant. "Characterizing Tukey h and</span>
</span><span id="__span-0-1017"><a id="__codelineno-0-1017" name="__codelineno-0-1017"></a><span class="sd">    hh-Distributions through L-Moments and the L-Correlation," ISRN Applied</span>
</span><span id="__span-0-1018"><a id="__codelineno-0-1018" name="__codelineno-0-1018"></a><span class="sd">    Mathematics, vol. 2012, 2012. doi:10.5402/2012/980153</span>
</span><span id="__span-0-1019"><a id="__codelineno-0-1019" name="__codelineno-0-1019"></a>
</span><span id="__span-0-1020"><a id="__codelineno-0-1020" name="__codelineno-0-1020"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1021"><a id="__codelineno-0-1021" name="__codelineno-0-1021"></a><span class="sd">    ----</span>
</span><span id="__span-0-1022"><a id="__codelineno-0-1022" name="__codelineno-0-1022"></a><span class="sd">      x: A `Tensor`, `SparseTensor`, or `RaggedTensor`. Its type must be floating</span>
</span><span id="__span-0-1023"><a id="__codelineno-0-1023" name="__codelineno-0-1023"></a><span class="sd">          point (float{16|32|64}), or integral ([u]int{8|16|32|64}).</span>
</span><span id="__span-0-1024"><a id="__codelineno-0-1024" name="__codelineno-0-1024"></a><span class="sd">      reduce_instance_dims: By default collapses the batch and instance dimensions</span>
</span><span id="__span-0-1025"><a id="__codelineno-0-1025" name="__codelineno-0-1025"></a><span class="sd">          to arrive at a single scalar output. If False, only collapses the batch</span>
</span><span id="__span-0-1026"><a id="__codelineno-0-1026" name="__codelineno-0-1026"></a><span class="sd">          dimension and outputs a vector of the same shape as the input.</span>
</span><span id="__span-0-1027"><a id="__codelineno-0-1027" name="__codelineno-0-1027"></a><span class="sd">      output_dtype: (Optional) If not None, casts the output tensor to this type.</span>
</span><span id="__span-0-1028"><a id="__codelineno-0-1028" name="__codelineno-0-1028"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-1029"><a id="__codelineno-0-1029" name="__codelineno-0-1029"></a>
</span><span id="__span-0-1030"><a id="__codelineno-0-1030" name="__codelineno-0-1030"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1031"><a id="__codelineno-0-1031" name="__codelineno-0-1031"></a><span class="sd">    -------</span>
</span><span id="__span-0-1032"><a id="__codelineno-0-1032" name="__codelineno-0-1032"></a><span class="sd">      A `Tensor` containing the location. If `x` is floating point, the location</span>
</span><span id="__span-0-1033"><a id="__codelineno-0-1033" name="__codelineno-0-1033"></a><span class="sd">      will have the same type as `x`. If `x` is integral, the output is cast to</span>
</span><span id="__span-0-1034"><a id="__codelineno-0-1034" name="__codelineno-0-1034"></a><span class="sd">      float32.</span>
</span><span id="__span-0-1035"><a id="__codelineno-0-1035" name="__codelineno-0-1035"></a>
</span><span id="__span-0-1036"><a id="__codelineno-0-1036" name="__codelineno-0-1036"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-1037"><a id="__codelineno-0-1037" name="__codelineno-0-1037"></a><span class="sd">    ------</span>
</span><span id="__span-0-1038"><a id="__codelineno-0-1038" name="__codelineno-0-1038"></a><span class="sd">      TypeError: If the type of `x` is not supported.</span>
</span><span id="__span-0-1039"><a id="__codelineno-0-1039" name="__codelineno-0-1039"></a><span class="sd">    """</span>
</span><span id="__span-0-1040"><a id="__codelineno-0-1040" name="__codelineno-0-1040"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"tukey_location"</span><span class="p">):</span>
</span><span id="__span-0-1041"><a id="__codelineno-0-1041" name="__codelineno-0-1041"></a>        <span class="k">return</span> <span class="n">_tukey_parameters</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">reduce_instance_dims</span><span class="p">,</span> <span class="n">output_dtype</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.tukey_scale" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">tukey_scale</span>


<a href="#tensorflow_transform.tukey_scale" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">tukey_scale</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">reduce_instance_dims</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">output_dtype</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><span title="tensorflow.DType">DType</span></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes the scale of the values of a <code>Tensor</code> over the whole dataset.</p>
<p>This computes the scale of x, assuming a Tukey HH distribution, i.e.
(x - tukey_location) / tukey_scale is a Tukey HH distribution with parameters
tukey_h_params. See the following publication for the definition of the Tukey
HH distribution:</p>
<p>Todd C. Headrick, and Mohan D. Pant. "Characterizing Tukey h and
hh-Distributions through L-Moments and the L-Correlation," ISRN Applied
Mathematics, vol. 2012, 2012. doi:10.5402/2012/980153</p>
        <hr>
<p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>. Its type must be floating
      point (float{16|32|64}), or integral ([u]int{8|16|32|64}).
  reduce_instance_dims: By default collapses the batch and instance dimensions
      to arrive at a single scalar output. If False, only collapses the batch
      dimension and outputs a vector of the same shape as the input.
  output_dtype: (Optional) If not None, casts the output tensor to this type.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>A <code>Tensor</code> containing the scale. If <code>x</code> is floating point, the location
  will have the same type as <code>x</code>. If <code>x</code> is integral, the output is cast to
  float32.</p>
        <hr>
<p>TypeError: If the type of <code>x</code> is not supported.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/analyzers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1044">1044</a></span>
<span class="normal"><a href="#__codelineno-0-1045">1045</a></span>
<span class="normal"><a href="#__codelineno-0-1046">1046</a></span>
<span class="normal"><a href="#__codelineno-0-1047">1047</a></span>
<span class="normal"><a href="#__codelineno-0-1048">1048</a></span>
<span class="normal"><a href="#__codelineno-0-1049">1049</a></span>
<span class="normal"><a href="#__codelineno-0-1050">1050</a></span>
<span class="normal"><a href="#__codelineno-0-1051">1051</a></span>
<span class="normal"><a href="#__codelineno-0-1052">1052</a></span>
<span class="normal"><a href="#__codelineno-0-1053">1053</a></span>
<span class="normal"><a href="#__codelineno-0-1054">1054</a></span>
<span class="normal"><a href="#__codelineno-0-1055">1055</a></span>
<span class="normal"><a href="#__codelineno-0-1056">1056</a></span>
<span class="normal"><a href="#__codelineno-0-1057">1057</a></span>
<span class="normal"><a href="#__codelineno-0-1058">1058</a></span>
<span class="normal"><a href="#__codelineno-0-1059">1059</a></span>
<span class="normal"><a href="#__codelineno-0-1060">1060</a></span>
<span class="normal"><a href="#__codelineno-0-1061">1061</a></span>
<span class="normal"><a href="#__codelineno-0-1062">1062</a></span>
<span class="normal"><a href="#__codelineno-0-1063">1063</a></span>
<span class="normal"><a href="#__codelineno-0-1064">1064</a></span>
<span class="normal"><a href="#__codelineno-0-1065">1065</a></span>
<span class="normal"><a href="#__codelineno-0-1066">1066</a></span>
<span class="normal"><a href="#__codelineno-0-1067">1067</a></span>
<span class="normal"><a href="#__codelineno-0-1068">1068</a></span>
<span class="normal"><a href="#__codelineno-0-1069">1069</a></span>
<span class="normal"><a href="#__codelineno-0-1070">1070</a></span>
<span class="normal"><a href="#__codelineno-0-1071">1071</a></span>
<span class="normal"><a href="#__codelineno-0-1072">1072</a></span>
<span class="normal"><a href="#__codelineno-0-1073">1073</a></span>
<span class="normal"><a href="#__codelineno-0-1074">1074</a></span>
<span class="normal"><a href="#__codelineno-0-1075">1075</a></span>
<span class="normal"><a href="#__codelineno-0-1076">1076</a></span>
<span class="normal"><a href="#__codelineno-0-1077">1077</a></span>
<span class="normal"><a href="#__codelineno-0-1078">1078</a></span>
<span class="normal"><a href="#__codelineno-0-1079">1079</a></span>
<span class="normal"><a href="#__codelineno-0-1080">1080</a></span>
<span class="normal"><a href="#__codelineno-0-1081">1081</a></span>
<span class="normal"><a href="#__codelineno-0-1082">1082</a></span>
<span class="normal"><a href="#__codelineno-0-1083">1083</a></span>
<span class="normal"><a href="#__codelineno-0-1084">1084</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1044"><a id="__codelineno-0-1044" name="__codelineno-0-1044"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">ANALYZER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-1045"><a id="__codelineno-0-1045" name="__codelineno-0-1045"></a><span class="k">def</span><span class="w"> </span><span class="nf">tukey_scale</span><span class="p">(</span>
</span><span id="__span-0-1046"><a id="__codelineno-0-1046" name="__codelineno-0-1046"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span>
</span><span id="__span-0-1047"><a id="__codelineno-0-1047" name="__codelineno-0-1047"></a>    <span class="n">reduce_instance_dims</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-1048"><a id="__codelineno-0-1048" name="__codelineno-0-1048"></a>    <span class="n">output_dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">DType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1049"><a id="__codelineno-0-1049" name="__codelineno-0-1049"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1050"><a id="__codelineno-0-1050" name="__codelineno-0-1050"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-1051"><a id="__codelineno-0-1051" name="__codelineno-0-1051"></a><span class="w">    </span><span class="sd">"""Computes the scale of the values of a `Tensor` over the whole dataset.</span>
</span><span id="__span-0-1052"><a id="__codelineno-0-1052" name="__codelineno-0-1052"></a>
</span><span id="__span-0-1053"><a id="__codelineno-0-1053" name="__codelineno-0-1053"></a><span class="sd">    This computes the scale of x, assuming a Tukey HH distribution, i.e.</span>
</span><span id="__span-0-1054"><a id="__codelineno-0-1054" name="__codelineno-0-1054"></a><span class="sd">    (x - tukey_location) / tukey_scale is a Tukey HH distribution with parameters</span>
</span><span id="__span-0-1055"><a id="__codelineno-0-1055" name="__codelineno-0-1055"></a><span class="sd">    tukey_h_params. See the following publication for the definition of the Tukey</span>
</span><span id="__span-0-1056"><a id="__codelineno-0-1056" name="__codelineno-0-1056"></a><span class="sd">    HH distribution:</span>
</span><span id="__span-0-1057"><a id="__codelineno-0-1057" name="__codelineno-0-1057"></a>
</span><span id="__span-0-1058"><a id="__codelineno-0-1058" name="__codelineno-0-1058"></a><span class="sd">    Todd C. Headrick, and Mohan D. Pant. "Characterizing Tukey h and</span>
</span><span id="__span-0-1059"><a id="__codelineno-0-1059" name="__codelineno-0-1059"></a><span class="sd">    hh-Distributions through L-Moments and the L-Correlation," ISRN Applied</span>
</span><span id="__span-0-1060"><a id="__codelineno-0-1060" name="__codelineno-0-1060"></a><span class="sd">    Mathematics, vol. 2012, 2012. doi:10.5402/2012/980153</span>
</span><span id="__span-0-1061"><a id="__codelineno-0-1061" name="__codelineno-0-1061"></a>
</span><span id="__span-0-1062"><a id="__codelineno-0-1062" name="__codelineno-0-1062"></a>
</span><span id="__span-0-1063"><a id="__codelineno-0-1063" name="__codelineno-0-1063"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1064"><a id="__codelineno-0-1064" name="__codelineno-0-1064"></a><span class="sd">    ----</span>
</span><span id="__span-0-1065"><a id="__codelineno-0-1065" name="__codelineno-0-1065"></a><span class="sd">      x: A `Tensor`, `SparseTensor`, or `RaggedTensor`. Its type must be floating</span>
</span><span id="__span-0-1066"><a id="__codelineno-0-1066" name="__codelineno-0-1066"></a><span class="sd">          point (float{16|32|64}), or integral ([u]int{8|16|32|64}).</span>
</span><span id="__span-0-1067"><a id="__codelineno-0-1067" name="__codelineno-0-1067"></a><span class="sd">      reduce_instance_dims: By default collapses the batch and instance dimensions</span>
</span><span id="__span-0-1068"><a id="__codelineno-0-1068" name="__codelineno-0-1068"></a><span class="sd">          to arrive at a single scalar output. If False, only collapses the batch</span>
</span><span id="__span-0-1069"><a id="__codelineno-0-1069" name="__codelineno-0-1069"></a><span class="sd">          dimension and outputs a vector of the same shape as the input.</span>
</span><span id="__span-0-1070"><a id="__codelineno-0-1070" name="__codelineno-0-1070"></a><span class="sd">      output_dtype: (Optional) If not None, casts the output tensor to this type.</span>
</span><span id="__span-0-1071"><a id="__codelineno-0-1071" name="__codelineno-0-1071"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-1072"><a id="__codelineno-0-1072" name="__codelineno-0-1072"></a>
</span><span id="__span-0-1073"><a id="__codelineno-0-1073" name="__codelineno-0-1073"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1074"><a id="__codelineno-0-1074" name="__codelineno-0-1074"></a><span class="sd">    -------</span>
</span><span id="__span-0-1075"><a id="__codelineno-0-1075" name="__codelineno-0-1075"></a><span class="sd">      A `Tensor` containing the scale. If `x` is floating point, the location</span>
</span><span id="__span-0-1076"><a id="__codelineno-0-1076" name="__codelineno-0-1076"></a><span class="sd">      will have the same type as `x`. If `x` is integral, the output is cast to</span>
</span><span id="__span-0-1077"><a id="__codelineno-0-1077" name="__codelineno-0-1077"></a><span class="sd">      float32.</span>
</span><span id="__span-0-1078"><a id="__codelineno-0-1078" name="__codelineno-0-1078"></a>
</span><span id="__span-0-1079"><a id="__codelineno-0-1079" name="__codelineno-0-1079"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-1080"><a id="__codelineno-0-1080" name="__codelineno-0-1080"></a><span class="sd">    ------</span>
</span><span id="__span-0-1081"><a id="__codelineno-0-1081" name="__codelineno-0-1081"></a><span class="sd">      TypeError: If the type of `x` is not supported.</span>
</span><span id="__span-0-1082"><a id="__codelineno-0-1082" name="__codelineno-0-1082"></a><span class="sd">    """</span>
</span><span id="__span-0-1083"><a id="__codelineno-0-1083" name="__codelineno-0-1083"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"tukey_scale"</span><span class="p">):</span>
</span><span id="__span-0-1084"><a id="__codelineno-0-1084" name="__codelineno-0-1084"></a>        <span class="k">return</span> <span class="n">_tukey_parameters</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">reduce_instance_dims</span><span class="p">,</span> <span class="n">output_dtype</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.var" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">var</span>


<a href="#tensorflow_transform.var" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">var</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">reduce_instance_dims</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">output_dtype</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><span title="tensorflow.DType">DType</span></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes the variance of the values of a <code>Tensor</code> over the whole dataset.</p>
<p>Uses the biased variance (0 delta degrees of freedom), as given by
(x - mean(x))**2 / length(x).</p>
        <hr>
<p>x: <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>. Its type must be floating
      point (float{16|32|64}), or integral ([u]int{8|16|32|64}).
  reduce_instance_dims: By default collapses the batch and instance dimensions
      to arrive at a single scalar output. If False, only collapses the batch
      dimension and outputs a vector of the same shape as the input.
  name: (Optional) A name for this operation.
  output_dtype: (Optional) If not None, casts the output tensor to this type.</p>
        <hr>
<p>A <code>Tensor</code> containing the variance. If <code>x</code> is floating point, the variance
  will have the same type as <code>x</code>. If <code>x</code> is integral, the output is cast to
  float32. NaNs and infinite input values are ignored.</p>
        <hr>
<p>TypeError: If the type of <code>x</code> is not supported.</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/analyzers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-924">924</a></span>
<span class="normal"><a href="#__codelineno-0-925">925</a></span>
<span class="normal"><a href="#__codelineno-0-926">926</a></span>
<span class="normal"><a href="#__codelineno-0-927">927</a></span>
<span class="normal"><a href="#__codelineno-0-928">928</a></span>
<span class="normal"><a href="#__codelineno-0-929">929</a></span>
<span class="normal"><a href="#__codelineno-0-930">930</a></span>
<span class="normal"><a href="#__codelineno-0-931">931</a></span>
<span class="normal"><a href="#__codelineno-0-932">932</a></span>
<span class="normal"><a href="#__codelineno-0-933">933</a></span>
<span class="normal"><a href="#__codelineno-0-934">934</a></span>
<span class="normal"><a href="#__codelineno-0-935">935</a></span>
<span class="normal"><a href="#__codelineno-0-936">936</a></span>
<span class="normal"><a href="#__codelineno-0-937">937</a></span>
<span class="normal"><a href="#__codelineno-0-938">938</a></span>
<span class="normal"><a href="#__codelineno-0-939">939</a></span>
<span class="normal"><a href="#__codelineno-0-940">940</a></span>
<span class="normal"><a href="#__codelineno-0-941">941</a></span>
<span class="normal"><a href="#__codelineno-0-942">942</a></span>
<span class="normal"><a href="#__codelineno-0-943">943</a></span>
<span class="normal"><a href="#__codelineno-0-944">944</a></span>
<span class="normal"><a href="#__codelineno-0-945">945</a></span>
<span class="normal"><a href="#__codelineno-0-946">946</a></span>
<span class="normal"><a href="#__codelineno-0-947">947</a></span>
<span class="normal"><a href="#__codelineno-0-948">948</a></span>
<span class="normal"><a href="#__codelineno-0-949">949</a></span>
<span class="normal"><a href="#__codelineno-0-950">950</a></span>
<span class="normal"><a href="#__codelineno-0-951">951</a></span>
<span class="normal"><a href="#__codelineno-0-952">952</a></span>
<span class="normal"><a href="#__codelineno-0-953">953</a></span>
<span class="normal"><a href="#__codelineno-0-954">954</a></span>
<span class="normal"><a href="#__codelineno-0-955">955</a></span>
<span class="normal"><a href="#__codelineno-0-956">956</a></span>
<span class="normal"><a href="#__codelineno-0-957">957</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-924"><a id="__codelineno-0-924" name="__codelineno-0-924"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">ANALYZER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-925"><a id="__codelineno-0-925" name="__codelineno-0-925"></a><span class="k">def</span><span class="w"> </span><span class="nf">var</span><span class="p">(</span>
</span><span id="__span-0-926"><a id="__codelineno-0-926" name="__codelineno-0-926"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span>
</span><span id="__span-0-927"><a id="__codelineno-0-927" name="__codelineno-0-927"></a>    <span class="n">reduce_instance_dims</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-928"><a id="__codelineno-0-928" name="__codelineno-0-928"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-929"><a id="__codelineno-0-929" name="__codelineno-0-929"></a>    <span class="n">output_dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">DType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-930"><a id="__codelineno-0-930" name="__codelineno-0-930"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-931"><a id="__codelineno-0-931" name="__codelineno-0-931"></a><span class="w">    </span><span class="sd">"""Computes the variance of the values of a `Tensor` over the whole dataset.</span>
</span><span id="__span-0-932"><a id="__codelineno-0-932" name="__codelineno-0-932"></a>
</span><span id="__span-0-933"><a id="__codelineno-0-933" name="__codelineno-0-933"></a><span class="sd">    Uses the biased variance (0 delta degrees of freedom), as given by</span>
</span><span id="__span-0-934"><a id="__codelineno-0-934" name="__codelineno-0-934"></a><span class="sd">    (x - mean(x))**2 / length(x).</span>
</span><span id="__span-0-935"><a id="__codelineno-0-935" name="__codelineno-0-935"></a>
</span><span id="__span-0-936"><a id="__codelineno-0-936" name="__codelineno-0-936"></a><span class="sd">    Args:</span>
</span><span id="__span-0-937"><a id="__codelineno-0-937" name="__codelineno-0-937"></a><span class="sd">    ----</span>
</span><span id="__span-0-938"><a id="__codelineno-0-938" name="__codelineno-0-938"></a><span class="sd">      x: `Tensor`, `SparseTensor`, or `RaggedTensor`. Its type must be floating</span>
</span><span id="__span-0-939"><a id="__codelineno-0-939" name="__codelineno-0-939"></a><span class="sd">          point (float{16|32|64}), or integral ([u]int{8|16|32|64}).</span>
</span><span id="__span-0-940"><a id="__codelineno-0-940" name="__codelineno-0-940"></a><span class="sd">      reduce_instance_dims: By default collapses the batch and instance dimensions</span>
</span><span id="__span-0-941"><a id="__codelineno-0-941" name="__codelineno-0-941"></a><span class="sd">          to arrive at a single scalar output. If False, only collapses the batch</span>
</span><span id="__span-0-942"><a id="__codelineno-0-942" name="__codelineno-0-942"></a><span class="sd">          dimension and outputs a vector of the same shape as the input.</span>
</span><span id="__span-0-943"><a id="__codelineno-0-943" name="__codelineno-0-943"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-944"><a id="__codelineno-0-944" name="__codelineno-0-944"></a><span class="sd">      output_dtype: (Optional) If not None, casts the output tensor to this type.</span>
</span><span id="__span-0-945"><a id="__codelineno-0-945" name="__codelineno-0-945"></a>
</span><span id="__span-0-946"><a id="__codelineno-0-946" name="__codelineno-0-946"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-947"><a id="__codelineno-0-947" name="__codelineno-0-947"></a><span class="sd">    -------</span>
</span><span id="__span-0-948"><a id="__codelineno-0-948" name="__codelineno-0-948"></a><span class="sd">      A `Tensor` containing the variance. If `x` is floating point, the variance</span>
</span><span id="__span-0-949"><a id="__codelineno-0-949" name="__codelineno-0-949"></a><span class="sd">      will have the same type as `x`. If `x` is integral, the output is cast to</span>
</span><span id="__span-0-950"><a id="__codelineno-0-950" name="__codelineno-0-950"></a><span class="sd">      float32. NaNs and infinite input values are ignored.</span>
</span><span id="__span-0-951"><a id="__codelineno-0-951" name="__codelineno-0-951"></a>
</span><span id="__span-0-952"><a id="__codelineno-0-952" name="__codelineno-0-952"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-953"><a id="__codelineno-0-953" name="__codelineno-0-953"></a><span class="sd">    ------</span>
</span><span id="__span-0-954"><a id="__codelineno-0-954" name="__codelineno-0-954"></a><span class="sd">      TypeError: If the type of `x` is not supported.</span>
</span><span id="__span-0-955"><a id="__codelineno-0-955" name="__codelineno-0-955"></a><span class="sd">    """</span>
</span><span id="__span-0-956"><a id="__codelineno-0-956" name="__codelineno-0-956"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"var"</span><span class="p">):</span>
</span><span id="__span-0-957"><a id="__codelineno-0-957" name="__codelineno-0-957"></a>        <span class="k">return</span> <span class="n">_mean_and_var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">reduce_instance_dims</span><span class="p">,</span> <span class="n">output_dtype</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.vocabulary" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">vocabulary</span>


<a href="#tensorflow_transform.vocabulary" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">vocabulary</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.TensorType">TensorType</span></span><span class="p">,</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">top_k</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">frequency_threshold</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">vocab_filename</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">store_frequency</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">reserved_tokens</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>        <span class="n"><a class="autorefs autorefs-internal" title="            Union (typing.Union)" href="#tensorflow_transform.Union">Union</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="            Sequence


  
      module-attribute
   (typing.Sequence)" href="../tft-experimental/#tensorflow_transform.experimental.Sequence">Sequence</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">],</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">]</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="n">weights</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="n">labels</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="            Union (typing.Union)" href="#tensorflow_transform.Union">Union</a></span><span class="p">[</span><span class="n"><span title="tensorflow.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><span title="tensorflow.SparseTensor">SparseTensor</span></span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="n">use_adjusted_mutual_info</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="n">min_diff_from_avg</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="n">coverage_top_k</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-16"><a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="n">coverage_frequency_threshold</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-17"><a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="n">key_fn</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="            Callable


  
      module-attribute
   (typing.Callable)" href="#tensorflow_transform.Callable">Callable</a></span><span class="p">[[</span><span class="n"><a class="autorefs autorefs-internal" title="            Any (typing.Any)" href="#tensorflow_transform.Any">Any</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-internal" title="            Any (typing.Any)" href="#tensorflow_transform.Any">Any</a></span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-18"><a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="n">fingerprint_shuffle</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-19"><a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>    <span class="n">file_format</span><span class="p">:</span> <span class="n"><span title="tensorflow_transform.common_types.VocabularyFileFormatType">VocabularyFileFormatType</span></span> <span class="o">=</span> <span class="n"><span title="tensorflow_transform.analyzers.DEFAULT_VOCABULARY_FILE_FORMAT">DEFAULT_VOCABULARY_FILE_FORMAT</span></span><span class="p">,</span>
</span><span id="__span-0-20"><a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-21"><a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow_transform.common_types.TemporaryAnalyzerOutputType">TemporaryAnalyzerOutputType</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes the unique values of <code>x</code> over the whole dataset.</p>
<p>Computes The unique values taken by <code>x</code>, which can be a <code>Tensor</code>,
<code>SparseTensor</code>, or <code>RaggedTensor</code> of any size.  The unique values will be
aggregated over all dimensions of <code>x</code> and all instances.</p>
<p>In case <code>file_format</code> is 'text' and one of the tokens contains the '\n' or
'\r' characters or is empty it will be discarded.</p>
<p>If an integer <code>Tensor</code> is provided, its semantic type should be categorical
not a continuous/numeric, since computing a vocabulary over a continuous
feature is not appropriate.</p>
<p>The unique values are sorted by decreasing frequency and then reverse
lexicographical order (e.g. [('a', 5), ('c', 3), ('b', 3)]). This is true even
if <code>x</code> is numerical dtype (e.g. [('3', 5), ('2', 3), ('111', 3)]).</p>
<p>For large datasets it is highly recommended to either set frequency_threshold
or top_k to control the size of the output, and also the run time of this
operation.</p>
<p>When labels are provided, we filter the vocabulary based on the relationship
between the token's presence in a record and the label for that record, using
(possibly adjusted) Mutual Information. Note: If labels are provided, the x
input must be a unique set of per record, as the semantics of the mutual
information calculation depend on a multi-hot representation of the input.
Having unique input tokens per row is advisable but not required for a
frequency-based vocabulary.</p>
<p>WARNING: The following is experimental and is still being actively worked on.</p>
<p>Supply <code>key_fn</code> if you would like to generate a vocabulary with coverage over
specific keys.</p>
<p>A "coverage vocabulary" is the union of two vocabulary "arms". The "standard
arm" of the vocabulary is equivalent to the one generated by the same function
call with no coverage arguments. Adding coverage only appends additional
entries to the end of the standard vocabulary.</p>
<p>The "coverage arm" of the vocabulary is determined by taking the
<code>coverage_top_k</code> most frequent unique terms per key. A term's key is obtained
by applying <code>key_fn</code> to the term. Use <code>coverage_frequency_threshold</code> to lower
bound the frequency of entries in the coverage arm of the vocabulary.</p>
<p>Note this is currently implemented for the case where the key is contained
within each vocabulary entry (b/117796748).</p>
        <hr>
<p>x: A categorical/discrete input <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>
    with dtype tf.string or tf.int[8|16|32|64]. The inputs should generally be
    unique per row (i.e. a bag of words/ngrams representation).
  top_k: Limit the generated vocabulary to the first <code>top_k</code> elements. If set
    to None, the full vocabulary is generated.
  frequency_threshold: Limit the generated vocabulary only to elements whose
    absolute frequency is &gt;= to the supplied threshold. If set to None, the
    full vocabulary is generated.  Absolute frequency means the number of
    occurrences of the element in the dataset, as opposed to the proportion of
    instances that contain that element.
  vocab_filename: The file name for the vocabulary file. If None, a file name
    will be chosen based on the current scope. If not None, should be unique
    within a given preprocessing function. NOTE To make your pipelines
    resilient to implementation details please set <code>vocab_filename</code> when you
    are using the vocab_filename on a downstream component.
  store_frequency: If True, frequency of the words is stored in the vocabulary
    file. In the case labels are provided, the mutual information is stored in
    the file instead. Each line in the file will be of the form 'frequency
    word'. NOTE: if this is True then the computed vocabulary cannot be used
    with <code>tft.apply_vocabulary</code> directly, since frequencies are added to the
    beginning of each row of the vocabulary, which the mapper will not ignore.
  reserved_tokens: (Optional) A list of tokens that should appear in the
    vocabulary regardless of their appearance in the input. These tokens would
    maintain their order, and have a reserved spot at the beginning of the
    vocabulary. Note: this field has no affect on cache.
  weights: (Optional) Weights <code>Tensor</code> for the vocabulary. It must have the
    same shape as x.
  labels: (Optional) Labels dense <code>Tensor</code> for the vocabulary. If provided,
    the vocabulary is calculated based on mutual information with the label,
    rather than frequency. The labels must have the same batch dimension as x.
    If x is sparse, labels should be a 1D tensor reflecting row-wise labels.
    If x is dense, labels can either be a 1D tensor of row-wise labels, or a
    dense tensor of the identical shape as x (i.e. element-wise labels).
    Labels should be a discrete integerized tensor (If the label is numeric,
    it should first be bucketized; If the label is a string, an integer
    vocabulary should first be applied). Note: <code>CompositeTensor</code> labels are
    not yet supported (b/134931826). WARNING: When labels are provided, the
    frequency_threshold argument functions as a mutual information threshold,
    which is a float. TODO(b/116308354): Fix confusing naming.
  use_adjusted_mutual_info: If true, and labels are provided, calculate
    vocabulary using adjusted rather than raw mutual information.
  min_diff_from_avg: MI (or AMI) of a feature x label will be adjusted to zero
    whenever the difference between count and the expected (average) count is
    lower than min_diff_from_average. This can be thought of as a regularizing
    parameter that pushes small MI/AMI values to zero. If None, a default
    parameter will be selected based on the size of the dataset (see
    calculate_recommended_min_diff_from_avg).
  coverage_top_k: (Optional), (Experimental) The minimum number of elements
    per key to be included in the vocabulary.
  coverage_frequency_threshold: (Optional), (Experimental) Limit the coverage
    arm of the vocabulary only to elements whose absolute frequency is &gt;= this
    threshold for a given key.
  key_fn: (Optional), (Experimental) A fn that takes in a single entry of <code>x</code>
    and returns the corresponding key for coverage calculation. If this is
    <code>None</code>, no coverage arm is added to the vocabulary.
  fingerprint_shuffle: (Optional), (Experimental) Whether to sort the
    vocabularies by fingerprint instead of counts. This is useful for load
    balancing on the training parameter servers. Shuffle only happens while
    writing the files, so all the filters above (top_k, frequency_threshold,
    etc) will still take effect.
  file_format: (Optional) A str. The format of the resulting vocabulary file.
    Accepted formats are: 'tfrecord_gzip', 'text'. 'tfrecord_gzip' requires
    tensorflow&gt;=2.4. The default value is 'text'.
  name: (Optional) A name for this operation.</p>
        <hr>
<p>The path name for the vocabulary file containing the unique values of <code>x</code>.</p>
        <hr>
<p>ValueError: If <code>top_k</code> or <code>frequency_threshold</code> is negative.
    If <code>coverage_top_k</code> or <code>coverage_frequency_threshold</code> is negative.
    If either <code>coverage_top_k</code> or <code>coverage_frequency_threshold</code> is specified
      and <code>key_fn</code> is not.
    If <code>key_fn</code> is specified and neither <code>coverage_top_k</code>, nor</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/analyzers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1915">1915</a></span>
<span class="normal"><a href="#__codelineno-0-1916">1916</a></span>
<span class="normal"><a href="#__codelineno-0-1917">1917</a></span>
<span class="normal"><a href="#__codelineno-0-1918">1918</a></span>
<span class="normal"><a href="#__codelineno-0-1919">1919</a></span>
<span class="normal"><a href="#__codelineno-0-1920">1920</a></span>
<span class="normal"><a href="#__codelineno-0-1921">1921</a></span>
<span class="normal"><a href="#__codelineno-0-1922">1922</a></span>
<span class="normal"><a href="#__codelineno-0-1923">1923</a></span>
<span class="normal"><a href="#__codelineno-0-1924">1924</a></span>
<span class="normal"><a href="#__codelineno-0-1925">1925</a></span>
<span class="normal"><a href="#__codelineno-0-1926">1926</a></span>
<span class="normal"><a href="#__codelineno-0-1927">1927</a></span>
<span class="normal"><a href="#__codelineno-0-1928">1928</a></span>
<span class="normal"><a href="#__codelineno-0-1929">1929</a></span>
<span class="normal"><a href="#__codelineno-0-1930">1930</a></span>
<span class="normal"><a href="#__codelineno-0-1931">1931</a></span>
<span class="normal"><a href="#__codelineno-0-1932">1932</a></span>
<span class="normal"><a href="#__codelineno-0-1933">1933</a></span>
<span class="normal"><a href="#__codelineno-0-1934">1934</a></span>
<span class="normal"><a href="#__codelineno-0-1935">1935</a></span>
<span class="normal"><a href="#__codelineno-0-1936">1936</a></span>
<span class="normal"><a href="#__codelineno-0-1937">1937</a></span>
<span class="normal"><a href="#__codelineno-0-1938">1938</a></span>
<span class="normal"><a href="#__codelineno-0-1939">1939</a></span>
<span class="normal"><a href="#__codelineno-0-1940">1940</a></span>
<span class="normal"><a href="#__codelineno-0-1941">1941</a></span>
<span class="normal"><a href="#__codelineno-0-1942">1942</a></span>
<span class="normal"><a href="#__codelineno-0-1943">1943</a></span>
<span class="normal"><a href="#__codelineno-0-1944">1944</a></span>
<span class="normal"><a href="#__codelineno-0-1945">1945</a></span>
<span class="normal"><a href="#__codelineno-0-1946">1946</a></span>
<span class="normal"><a href="#__codelineno-0-1947">1947</a></span>
<span class="normal"><a href="#__codelineno-0-1948">1948</a></span>
<span class="normal"><a href="#__codelineno-0-1949">1949</a></span>
<span class="normal"><a href="#__codelineno-0-1950">1950</a></span>
<span class="normal"><a href="#__codelineno-0-1951">1951</a></span>
<span class="normal"><a href="#__codelineno-0-1952">1952</a></span>
<span class="normal"><a href="#__codelineno-0-1953">1953</a></span>
<span class="normal"><a href="#__codelineno-0-1954">1954</a></span>
<span class="normal"><a href="#__codelineno-0-1955">1955</a></span>
<span class="normal"><a href="#__codelineno-0-1956">1956</a></span>
<span class="normal"><a href="#__codelineno-0-1957">1957</a></span>
<span class="normal"><a href="#__codelineno-0-1958">1958</a></span>
<span class="normal"><a href="#__codelineno-0-1959">1959</a></span>
<span class="normal"><a href="#__codelineno-0-1960">1960</a></span>
<span class="normal"><a href="#__codelineno-0-1961">1961</a></span>
<span class="normal"><a href="#__codelineno-0-1962">1962</a></span>
<span class="normal"><a href="#__codelineno-0-1963">1963</a></span>
<span class="normal"><a href="#__codelineno-0-1964">1964</a></span>
<span class="normal"><a href="#__codelineno-0-1965">1965</a></span>
<span class="normal"><a href="#__codelineno-0-1966">1966</a></span>
<span class="normal"><a href="#__codelineno-0-1967">1967</a></span>
<span class="normal"><a href="#__codelineno-0-1968">1968</a></span>
<span class="normal"><a href="#__codelineno-0-1969">1969</a></span>
<span class="normal"><a href="#__codelineno-0-1970">1970</a></span>
<span class="normal"><a href="#__codelineno-0-1971">1971</a></span>
<span class="normal"><a href="#__codelineno-0-1972">1972</a></span>
<span class="normal"><a href="#__codelineno-0-1973">1973</a></span>
<span class="normal"><a href="#__codelineno-0-1974">1974</a></span>
<span class="normal"><a href="#__codelineno-0-1975">1975</a></span>
<span class="normal"><a href="#__codelineno-0-1976">1976</a></span>
<span class="normal"><a href="#__codelineno-0-1977">1977</a></span>
<span class="normal"><a href="#__codelineno-0-1978">1978</a></span>
<span class="normal"><a href="#__codelineno-0-1979">1979</a></span>
<span class="normal"><a href="#__codelineno-0-1980">1980</a></span>
<span class="normal"><a href="#__codelineno-0-1981">1981</a></span>
<span class="normal"><a href="#__codelineno-0-1982">1982</a></span>
<span class="normal"><a href="#__codelineno-0-1983">1983</a></span>
<span class="normal"><a href="#__codelineno-0-1984">1984</a></span>
<span class="normal"><a href="#__codelineno-0-1985">1985</a></span>
<span class="normal"><a href="#__codelineno-0-1986">1986</a></span>
<span class="normal"><a href="#__codelineno-0-1987">1987</a></span>
<span class="normal"><a href="#__codelineno-0-1988">1988</a></span>
<span class="normal"><a href="#__codelineno-0-1989">1989</a></span>
<span class="normal"><a href="#__codelineno-0-1990">1990</a></span>
<span class="normal"><a href="#__codelineno-0-1991">1991</a></span>
<span class="normal"><a href="#__codelineno-0-1992">1992</a></span>
<span class="normal"><a href="#__codelineno-0-1993">1993</a></span>
<span class="normal"><a href="#__codelineno-0-1994">1994</a></span>
<span class="normal"><a href="#__codelineno-0-1995">1995</a></span>
<span class="normal"><a href="#__codelineno-0-1996">1996</a></span>
<span class="normal"><a href="#__codelineno-0-1997">1997</a></span>
<span class="normal"><a href="#__codelineno-0-1998">1998</a></span>
<span class="normal"><a href="#__codelineno-0-1999">1999</a></span>
<span class="normal"><a href="#__codelineno-0-2000">2000</a></span>
<span class="normal"><a href="#__codelineno-0-2001">2001</a></span>
<span class="normal"><a href="#__codelineno-0-2002">2002</a></span>
<span class="normal"><a href="#__codelineno-0-2003">2003</a></span>
<span class="normal"><a href="#__codelineno-0-2004">2004</a></span>
<span class="normal"><a href="#__codelineno-0-2005">2005</a></span>
<span class="normal"><a href="#__codelineno-0-2006">2006</a></span>
<span class="normal"><a href="#__codelineno-0-2007">2007</a></span>
<span class="normal"><a href="#__codelineno-0-2008">2008</a></span>
<span class="normal"><a href="#__codelineno-0-2009">2009</a></span>
<span class="normal"><a href="#__codelineno-0-2010">2010</a></span>
<span class="normal"><a href="#__codelineno-0-2011">2011</a></span>
<span class="normal"><a href="#__codelineno-0-2012">2012</a></span>
<span class="normal"><a href="#__codelineno-0-2013">2013</a></span>
<span class="normal"><a href="#__codelineno-0-2014">2014</a></span>
<span class="normal"><a href="#__codelineno-0-2015">2015</a></span>
<span class="normal"><a href="#__codelineno-0-2016">2016</a></span>
<span class="normal"><a href="#__codelineno-0-2017">2017</a></span>
<span class="normal"><a href="#__codelineno-0-2018">2018</a></span>
<span class="normal"><a href="#__codelineno-0-2019">2019</a></span>
<span class="normal"><a href="#__codelineno-0-2020">2020</a></span>
<span class="normal"><a href="#__codelineno-0-2021">2021</a></span>
<span class="normal"><a href="#__codelineno-0-2022">2022</a></span>
<span class="normal"><a href="#__codelineno-0-2023">2023</a></span>
<span class="normal"><a href="#__codelineno-0-2024">2024</a></span>
<span class="normal"><a href="#__codelineno-0-2025">2025</a></span>
<span class="normal"><a href="#__codelineno-0-2026">2026</a></span>
<span class="normal"><a href="#__codelineno-0-2027">2027</a></span>
<span class="normal"><a href="#__codelineno-0-2028">2028</a></span>
<span class="normal"><a href="#__codelineno-0-2029">2029</a></span>
<span class="normal"><a href="#__codelineno-0-2030">2030</a></span>
<span class="normal"><a href="#__codelineno-0-2031">2031</a></span>
<span class="normal"><a href="#__codelineno-0-2032">2032</a></span>
<span class="normal"><a href="#__codelineno-0-2033">2033</a></span>
<span class="normal"><a href="#__codelineno-0-2034">2034</a></span>
<span class="normal"><a href="#__codelineno-0-2035">2035</a></span>
<span class="normal"><a href="#__codelineno-0-2036">2036</a></span>
<span class="normal"><a href="#__codelineno-0-2037">2037</a></span>
<span class="normal"><a href="#__codelineno-0-2038">2038</a></span>
<span class="normal"><a href="#__codelineno-0-2039">2039</a></span>
<span class="normal"><a href="#__codelineno-0-2040">2040</a></span>
<span class="normal"><a href="#__codelineno-0-2041">2041</a></span>
<span class="normal"><a href="#__codelineno-0-2042">2042</a></span>
<span class="normal"><a href="#__codelineno-0-2043">2043</a></span>
<span class="normal"><a href="#__codelineno-0-2044">2044</a></span>
<span class="normal"><a href="#__codelineno-0-2045">2045</a></span>
<span class="normal"><a href="#__codelineno-0-2046">2046</a></span>
<span class="normal"><a href="#__codelineno-0-2047">2047</a></span>
<span class="normal"><a href="#__codelineno-0-2048">2048</a></span>
<span class="normal"><a href="#__codelineno-0-2049">2049</a></span>
<span class="normal"><a href="#__codelineno-0-2050">2050</a></span>
<span class="normal"><a href="#__codelineno-0-2051">2051</a></span>
<span class="normal"><a href="#__codelineno-0-2052">2052</a></span>
<span class="normal"><a href="#__codelineno-0-2053">2053</a></span>
<span class="normal"><a href="#__codelineno-0-2054">2054</a></span>
<span class="normal"><a href="#__codelineno-0-2055">2055</a></span>
<span class="normal"><a href="#__codelineno-0-2056">2056</a></span>
<span class="normal"><a href="#__codelineno-0-2057">2057</a></span>
<span class="normal"><a href="#__codelineno-0-2058">2058</a></span>
<span class="normal"><a href="#__codelineno-0-2059">2059</a></span>
<span class="normal"><a href="#__codelineno-0-2060">2060</a></span>
<span class="normal"><a href="#__codelineno-0-2061">2061</a></span>
<span class="normal"><a href="#__codelineno-0-2062">2062</a></span>
<span class="normal"><a href="#__codelineno-0-2063">2063</a></span>
<span class="normal"><a href="#__codelineno-0-2064">2064</a></span>
<span class="normal"><a href="#__codelineno-0-2065">2065</a></span>
<span class="normal"><a href="#__codelineno-0-2066">2066</a></span>
<span class="normal"><a href="#__codelineno-0-2067">2067</a></span>
<span class="normal"><a href="#__codelineno-0-2068">2068</a></span>
<span class="normal"><a href="#__codelineno-0-2069">2069</a></span>
<span class="normal"><a href="#__codelineno-0-2070">2070</a></span>
<span class="normal"><a href="#__codelineno-0-2071">2071</a></span>
<span class="normal"><a href="#__codelineno-0-2072">2072</a></span>
<span class="normal"><a href="#__codelineno-0-2073">2073</a></span>
<span class="normal"><a href="#__codelineno-0-2074">2074</a></span>
<span class="normal"><a href="#__codelineno-0-2075">2075</a></span>
<span class="normal"><a href="#__codelineno-0-2076">2076</a></span>
<span class="normal"><a href="#__codelineno-0-2077">2077</a></span>
<span class="normal"><a href="#__codelineno-0-2078">2078</a></span>
<span class="normal"><a href="#__codelineno-0-2079">2079</a></span>
<span class="normal"><a href="#__codelineno-0-2080">2080</a></span>
<span class="normal"><a href="#__codelineno-0-2081">2081</a></span>
<span class="normal"><a href="#__codelineno-0-2082">2082</a></span>
<span class="normal"><a href="#__codelineno-0-2083">2083</a></span>
<span class="normal"><a href="#__codelineno-0-2084">2084</a></span>
<span class="normal"><a href="#__codelineno-0-2085">2085</a></span>
<span class="normal"><a href="#__codelineno-0-2086">2086</a></span>
<span class="normal"><a href="#__codelineno-0-2087">2087</a></span>
<span class="normal"><a href="#__codelineno-0-2088">2088</a></span>
<span class="normal"><a href="#__codelineno-0-2089">2089</a></span>
<span class="normal"><a href="#__codelineno-0-2090">2090</a></span>
<span class="normal"><a href="#__codelineno-0-2091">2091</a></span>
<span class="normal"><a href="#__codelineno-0-2092">2092</a></span>
<span class="normal"><a href="#__codelineno-0-2093">2093</a></span>
<span class="normal"><a href="#__codelineno-0-2094">2094</a></span>
<span class="normal"><a href="#__codelineno-0-2095">2095</a></span>
<span class="normal"><a href="#__codelineno-0-2096">2096</a></span>
<span class="normal"><a href="#__codelineno-0-2097">2097</a></span>
<span class="normal"><a href="#__codelineno-0-2098">2098</a></span>
<span class="normal"><a href="#__codelineno-0-2099">2099</a></span>
<span class="normal"><a href="#__codelineno-0-2100">2100</a></span>
<span class="normal"><a href="#__codelineno-0-2101">2101</a></span>
<span class="normal"><a href="#__codelineno-0-2102">2102</a></span>
<span class="normal"><a href="#__codelineno-0-2103">2103</a></span>
<span class="normal"><a href="#__codelineno-0-2104">2104</a></span>
<span class="normal"><a href="#__codelineno-0-2105">2105</a></span>
<span class="normal"><a href="#__codelineno-0-2106">2106</a></span>
<span class="normal"><a href="#__codelineno-0-2107">2107</a></span>
<span class="normal"><a href="#__codelineno-0-2108">2108</a></span>
<span class="normal"><a href="#__codelineno-0-2109">2109</a></span>
<span class="normal"><a href="#__codelineno-0-2110">2110</a></span>
<span class="normal"><a href="#__codelineno-0-2111">2111</a></span>
<span class="normal"><a href="#__codelineno-0-2112">2112</a></span>
<span class="normal"><a href="#__codelineno-0-2113">2113</a></span>
<span class="normal"><a href="#__codelineno-0-2114">2114</a></span>
<span class="normal"><a href="#__codelineno-0-2115">2115</a></span>
<span class="normal"><a href="#__codelineno-0-2116">2116</a></span>
<span class="normal"><a href="#__codelineno-0-2117">2117</a></span>
<span class="normal"><a href="#__codelineno-0-2118">2118</a></span>
<span class="normal"><a href="#__codelineno-0-2119">2119</a></span>
<span class="normal"><a href="#__codelineno-0-2120">2120</a></span>
<span class="normal"><a href="#__codelineno-0-2121">2121</a></span>
<span class="normal"><a href="#__codelineno-0-2122">2122</a></span>
<span class="normal"><a href="#__codelineno-0-2123">2123</a></span>
<span class="normal"><a href="#__codelineno-0-2124">2124</a></span>
<span class="normal"><a href="#__codelineno-0-2125">2125</a></span>
<span class="normal"><a href="#__codelineno-0-2126">2126</a></span>
<span class="normal"><a href="#__codelineno-0-2127">2127</a></span>
<span class="normal"><a href="#__codelineno-0-2128">2128</a></span>
<span class="normal"><a href="#__codelineno-0-2129">2129</a></span>
<span class="normal"><a href="#__codelineno-0-2130">2130</a></span>
<span class="normal"><a href="#__codelineno-0-2131">2131</a></span>
<span class="normal"><a href="#__codelineno-0-2132">2132</a></span>
<span class="normal"><a href="#__codelineno-0-2133">2133</a></span>
<span class="normal"><a href="#__codelineno-0-2134">2134</a></span>
<span class="normal"><a href="#__codelineno-0-2135">2135</a></span>
<span class="normal"><a href="#__codelineno-0-2136">2136</a></span>
<span class="normal"><a href="#__codelineno-0-2137">2137</a></span>
<span class="normal"><a href="#__codelineno-0-2138">2138</a></span>
<span class="normal"><a href="#__codelineno-0-2139">2139</a></span>
<span class="normal"><a href="#__codelineno-0-2140">2140</a></span>
<span class="normal"><a href="#__codelineno-0-2141">2141</a></span>
<span class="normal"><a href="#__codelineno-0-2142">2142</a></span>
<span class="normal"><a href="#__codelineno-0-2143">2143</a></span>
<span class="normal"><a href="#__codelineno-0-2144">2144</a></span>
<span class="normal"><a href="#__codelineno-0-2145">2145</a></span>
<span class="normal"><a href="#__codelineno-0-2146">2146</a></span>
<span class="normal"><a href="#__codelineno-0-2147">2147</a></span>
<span class="normal"><a href="#__codelineno-0-2148">2148</a></span>
<span class="normal"><a href="#__codelineno-0-2149">2149</a></span>
<span class="normal"><a href="#__codelineno-0-2150">2150</a></span>
<span class="normal"><a href="#__codelineno-0-2151">2151</a></span>
<span class="normal"><a href="#__codelineno-0-2152">2152</a></span>
<span class="normal"><a href="#__codelineno-0-2153">2153</a></span>
<span class="normal"><a href="#__codelineno-0-2154">2154</a></span>
<span class="normal"><a href="#__codelineno-0-2155">2155</a></span>
<span class="normal"><a href="#__codelineno-0-2156">2156</a></span>
<span class="normal"><a href="#__codelineno-0-2157">2157</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1915"><a id="__codelineno-0-1915" name="__codelineno-0-1915"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">ANALYZER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-1916"><a id="__codelineno-0-1916" name="__codelineno-0-1916"></a><span class="k">def</span><span class="w"> </span><span class="nf">vocabulary</span><span class="p">(</span>
</span><span id="__span-0-1917"><a id="__codelineno-0-1917" name="__codelineno-0-1917"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span>
</span><span id="__span-0-1918"><a id="__codelineno-0-1918" name="__codelineno-0-1918"></a>    <span class="o">*</span><span class="p">,</span>  <span class="c1"># Force passing optional parameters by keys.</span>
</span><span id="__span-0-1919"><a id="__codelineno-0-1919" name="__codelineno-0-1919"></a>    <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1920"><a id="__codelineno-0-1920" name="__codelineno-0-1920"></a>    <span class="n">frequency_threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1921"><a id="__codelineno-0-1921" name="__codelineno-0-1921"></a>    <span class="n">vocab_filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1922"><a id="__codelineno-0-1922" name="__codelineno-0-1922"></a>    <span class="n">store_frequency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-1923"><a id="__codelineno-0-1923" name="__codelineno-0-1923"></a>    <span class="n">reserved_tokens</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1924"><a id="__codelineno-0-1924" name="__codelineno-0-1924"></a>    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1925"><a id="__codelineno-0-1925" name="__codelineno-0-1925"></a>    <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1926"><a id="__codelineno-0-1926" name="__codelineno-0-1926"></a>    <span class="n">use_adjusted_mutual_info</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-1927"><a id="__codelineno-0-1927" name="__codelineno-0-1927"></a>    <span class="n">min_diff_from_avg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1928"><a id="__codelineno-0-1928" name="__codelineno-0-1928"></a>    <span class="n">coverage_top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1929"><a id="__codelineno-0-1929" name="__codelineno-0-1929"></a>    <span class="n">coverage_frequency_threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1930"><a id="__codelineno-0-1930" name="__codelineno-0-1930"></a>    <span class="n">key_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1931"><a id="__codelineno-0-1931" name="__codelineno-0-1931"></a>    <span class="n">fingerprint_shuffle</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-1932"><a id="__codelineno-0-1932" name="__codelineno-0-1932"></a>    <span class="n">file_format</span><span class="p">:</span> <span class="n">common_types</span><span class="o">.</span><span class="n">VocabularyFileFormatType</span> <span class="o">=</span> <span class="n">DEFAULT_VOCABULARY_FILE_FORMAT</span><span class="p">,</span>
</span><span id="__span-0-1933"><a id="__codelineno-0-1933" name="__codelineno-0-1933"></a>    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-1934"><a id="__codelineno-0-1934" name="__codelineno-0-1934"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">common_types</span><span class="o">.</span><span class="n">TemporaryAnalyzerOutputType</span><span class="p">:</span>
</span><span id="__span-0-1935"><a id="__codelineno-0-1935" name="__codelineno-0-1935"></a><span class="w">    </span><span class="sa">r</span><span class="sd">"""Computes the unique values of `x` over the whole dataset.</span>
</span><span id="__span-0-1936"><a id="__codelineno-0-1936" name="__codelineno-0-1936"></a>
</span><span id="__span-0-1937"><a id="__codelineno-0-1937" name="__codelineno-0-1937"></a><span class="sd">    Computes The unique values taken by `x`, which can be a `Tensor`,</span>
</span><span id="__span-0-1938"><a id="__codelineno-0-1938" name="__codelineno-0-1938"></a><span class="sd">    `SparseTensor`, or `RaggedTensor` of any size.  The unique values will be</span>
</span><span id="__span-0-1939"><a id="__codelineno-0-1939" name="__codelineno-0-1939"></a><span class="sd">    aggregated over all dimensions of `x` and all instances.</span>
</span><span id="__span-0-1940"><a id="__codelineno-0-1940" name="__codelineno-0-1940"></a>
</span><span id="__span-0-1941"><a id="__codelineno-0-1941" name="__codelineno-0-1941"></a><span class="sd">    In case `file_format` is 'text' and one of the tokens contains the '\n' or</span>
</span><span id="__span-0-1942"><a id="__codelineno-0-1942" name="__codelineno-0-1942"></a><span class="sd">    '\r' characters or is empty it will be discarded.</span>
</span><span id="__span-0-1943"><a id="__codelineno-0-1943" name="__codelineno-0-1943"></a>
</span><span id="__span-0-1944"><a id="__codelineno-0-1944" name="__codelineno-0-1944"></a><span class="sd">    If an integer `Tensor` is provided, its semantic type should be categorical</span>
</span><span id="__span-0-1945"><a id="__codelineno-0-1945" name="__codelineno-0-1945"></a><span class="sd">    not a continuous/numeric, since computing a vocabulary over a continuous</span>
</span><span id="__span-0-1946"><a id="__codelineno-0-1946" name="__codelineno-0-1946"></a><span class="sd">    feature is not appropriate.</span>
</span><span id="__span-0-1947"><a id="__codelineno-0-1947" name="__codelineno-0-1947"></a>
</span><span id="__span-0-1948"><a id="__codelineno-0-1948" name="__codelineno-0-1948"></a><span class="sd">    The unique values are sorted by decreasing frequency and then reverse</span>
</span><span id="__span-0-1949"><a id="__codelineno-0-1949" name="__codelineno-0-1949"></a><span class="sd">    lexicographical order (e.g. [('a', 5), ('c', 3), ('b', 3)]). This is true even</span>
</span><span id="__span-0-1950"><a id="__codelineno-0-1950" name="__codelineno-0-1950"></a><span class="sd">    if `x` is numerical dtype (e.g. [('3', 5), ('2', 3), ('111', 3)]).</span>
</span><span id="__span-0-1951"><a id="__codelineno-0-1951" name="__codelineno-0-1951"></a>
</span><span id="__span-0-1952"><a id="__codelineno-0-1952" name="__codelineno-0-1952"></a><span class="sd">    For large datasets it is highly recommended to either set frequency_threshold</span>
</span><span id="__span-0-1953"><a id="__codelineno-0-1953" name="__codelineno-0-1953"></a><span class="sd">    or top_k to control the size of the output, and also the run time of this</span>
</span><span id="__span-0-1954"><a id="__codelineno-0-1954" name="__codelineno-0-1954"></a><span class="sd">    operation.</span>
</span><span id="__span-0-1955"><a id="__codelineno-0-1955" name="__codelineno-0-1955"></a>
</span><span id="__span-0-1956"><a id="__codelineno-0-1956" name="__codelineno-0-1956"></a><span class="sd">    When labels are provided, we filter the vocabulary based on the relationship</span>
</span><span id="__span-0-1957"><a id="__codelineno-0-1957" name="__codelineno-0-1957"></a><span class="sd">    between the token's presence in a record and the label for that record, using</span>
</span><span id="__span-0-1958"><a id="__codelineno-0-1958" name="__codelineno-0-1958"></a><span class="sd">    (possibly adjusted) Mutual Information. Note: If labels are provided, the x</span>
</span><span id="__span-0-1959"><a id="__codelineno-0-1959" name="__codelineno-0-1959"></a><span class="sd">    input must be a unique set of per record, as the semantics of the mutual</span>
</span><span id="__span-0-1960"><a id="__codelineno-0-1960" name="__codelineno-0-1960"></a><span class="sd">    information calculation depend on a multi-hot representation of the input.</span>
</span><span id="__span-0-1961"><a id="__codelineno-0-1961" name="__codelineno-0-1961"></a><span class="sd">    Having unique input tokens per row is advisable but not required for a</span>
</span><span id="__span-0-1962"><a id="__codelineno-0-1962" name="__codelineno-0-1962"></a><span class="sd">    frequency-based vocabulary.</span>
</span><span id="__span-0-1963"><a id="__codelineno-0-1963" name="__codelineno-0-1963"></a>
</span><span id="__span-0-1964"><a id="__codelineno-0-1964" name="__codelineno-0-1964"></a><span class="sd">    WARNING: The following is experimental and is still being actively worked on.</span>
</span><span id="__span-0-1965"><a id="__codelineno-0-1965" name="__codelineno-0-1965"></a>
</span><span id="__span-0-1966"><a id="__codelineno-0-1966" name="__codelineno-0-1966"></a><span class="sd">    Supply `key_fn` if you would like to generate a vocabulary with coverage over</span>
</span><span id="__span-0-1967"><a id="__codelineno-0-1967" name="__codelineno-0-1967"></a><span class="sd">    specific keys.</span>
</span><span id="__span-0-1968"><a id="__codelineno-0-1968" name="__codelineno-0-1968"></a>
</span><span id="__span-0-1969"><a id="__codelineno-0-1969" name="__codelineno-0-1969"></a><span class="sd">    A "coverage vocabulary" is the union of two vocabulary "arms". The "standard</span>
</span><span id="__span-0-1970"><a id="__codelineno-0-1970" name="__codelineno-0-1970"></a><span class="sd">    arm" of the vocabulary is equivalent to the one generated by the same function</span>
</span><span id="__span-0-1971"><a id="__codelineno-0-1971" name="__codelineno-0-1971"></a><span class="sd">    call with no coverage arguments. Adding coverage only appends additional</span>
</span><span id="__span-0-1972"><a id="__codelineno-0-1972" name="__codelineno-0-1972"></a><span class="sd">    entries to the end of the standard vocabulary.</span>
</span><span id="__span-0-1973"><a id="__codelineno-0-1973" name="__codelineno-0-1973"></a>
</span><span id="__span-0-1974"><a id="__codelineno-0-1974" name="__codelineno-0-1974"></a><span class="sd">    The "coverage arm" of the vocabulary is determined by taking the</span>
</span><span id="__span-0-1975"><a id="__codelineno-0-1975" name="__codelineno-0-1975"></a><span class="sd">    `coverage_top_k` most frequent unique terms per key. A term's key is obtained</span>
</span><span id="__span-0-1976"><a id="__codelineno-0-1976" name="__codelineno-0-1976"></a><span class="sd">    by applying `key_fn` to the term. Use `coverage_frequency_threshold` to lower</span>
</span><span id="__span-0-1977"><a id="__codelineno-0-1977" name="__codelineno-0-1977"></a><span class="sd">    bound the frequency of entries in the coverage arm of the vocabulary.</span>
</span><span id="__span-0-1978"><a id="__codelineno-0-1978" name="__codelineno-0-1978"></a>
</span><span id="__span-0-1979"><a id="__codelineno-0-1979" name="__codelineno-0-1979"></a><span class="sd">    Note this is currently implemented for the case where the key is contained</span>
</span><span id="__span-0-1980"><a id="__codelineno-0-1980" name="__codelineno-0-1980"></a><span class="sd">    within each vocabulary entry (b/117796748).</span>
</span><span id="__span-0-1981"><a id="__codelineno-0-1981" name="__codelineno-0-1981"></a>
</span><span id="__span-0-1982"><a id="__codelineno-0-1982" name="__codelineno-0-1982"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1983"><a id="__codelineno-0-1983" name="__codelineno-0-1983"></a><span class="sd">    ----</span>
</span><span id="__span-0-1984"><a id="__codelineno-0-1984" name="__codelineno-0-1984"></a><span class="sd">      x: A categorical/discrete input `Tensor`, `SparseTensor`, or `RaggedTensor`</span>
</span><span id="__span-0-1985"><a id="__codelineno-0-1985" name="__codelineno-0-1985"></a><span class="sd">        with dtype tf.string or tf.int[8|16|32|64]. The inputs should generally be</span>
</span><span id="__span-0-1986"><a id="__codelineno-0-1986" name="__codelineno-0-1986"></a><span class="sd">        unique per row (i.e. a bag of words/ngrams representation).</span>
</span><span id="__span-0-1987"><a id="__codelineno-0-1987" name="__codelineno-0-1987"></a><span class="sd">      top_k: Limit the generated vocabulary to the first `top_k` elements. If set</span>
</span><span id="__span-0-1988"><a id="__codelineno-0-1988" name="__codelineno-0-1988"></a><span class="sd">        to None, the full vocabulary is generated.</span>
</span><span id="__span-0-1989"><a id="__codelineno-0-1989" name="__codelineno-0-1989"></a><span class="sd">      frequency_threshold: Limit the generated vocabulary only to elements whose</span>
</span><span id="__span-0-1990"><a id="__codelineno-0-1990" name="__codelineno-0-1990"></a><span class="sd">        absolute frequency is &gt;= to the supplied threshold. If set to None, the</span>
</span><span id="__span-0-1991"><a id="__codelineno-0-1991" name="__codelineno-0-1991"></a><span class="sd">        full vocabulary is generated.  Absolute frequency means the number of</span>
</span><span id="__span-0-1992"><a id="__codelineno-0-1992" name="__codelineno-0-1992"></a><span class="sd">        occurrences of the element in the dataset, as opposed to the proportion of</span>
</span><span id="__span-0-1993"><a id="__codelineno-0-1993" name="__codelineno-0-1993"></a><span class="sd">        instances that contain that element.</span>
</span><span id="__span-0-1994"><a id="__codelineno-0-1994" name="__codelineno-0-1994"></a><span class="sd">      vocab_filename: The file name for the vocabulary file. If None, a file name</span>
</span><span id="__span-0-1995"><a id="__codelineno-0-1995" name="__codelineno-0-1995"></a><span class="sd">        will be chosen based on the current scope. If not None, should be unique</span>
</span><span id="__span-0-1996"><a id="__codelineno-0-1996" name="__codelineno-0-1996"></a><span class="sd">        within a given preprocessing function. NOTE To make your pipelines</span>
</span><span id="__span-0-1997"><a id="__codelineno-0-1997" name="__codelineno-0-1997"></a><span class="sd">        resilient to implementation details please set `vocab_filename` when you</span>
</span><span id="__span-0-1998"><a id="__codelineno-0-1998" name="__codelineno-0-1998"></a><span class="sd">        are using the vocab_filename on a downstream component.</span>
</span><span id="__span-0-1999"><a id="__codelineno-0-1999" name="__codelineno-0-1999"></a><span class="sd">      store_frequency: If True, frequency of the words is stored in the vocabulary</span>
</span><span id="__span-0-2000"><a id="__codelineno-0-2000" name="__codelineno-0-2000"></a><span class="sd">        file. In the case labels are provided, the mutual information is stored in</span>
</span><span id="__span-0-2001"><a id="__codelineno-0-2001" name="__codelineno-0-2001"></a><span class="sd">        the file instead. Each line in the file will be of the form 'frequency</span>
</span><span id="__span-0-2002"><a id="__codelineno-0-2002" name="__codelineno-0-2002"></a><span class="sd">        word'. NOTE: if this is True then the computed vocabulary cannot be used</span>
</span><span id="__span-0-2003"><a id="__codelineno-0-2003" name="__codelineno-0-2003"></a><span class="sd">        with `tft.apply_vocabulary` directly, since frequencies are added to the</span>
</span><span id="__span-0-2004"><a id="__codelineno-0-2004" name="__codelineno-0-2004"></a><span class="sd">        beginning of each row of the vocabulary, which the mapper will not ignore.</span>
</span><span id="__span-0-2005"><a id="__codelineno-0-2005" name="__codelineno-0-2005"></a><span class="sd">      reserved_tokens: (Optional) A list of tokens that should appear in the</span>
</span><span id="__span-0-2006"><a id="__codelineno-0-2006" name="__codelineno-0-2006"></a><span class="sd">        vocabulary regardless of their appearance in the input. These tokens would</span>
</span><span id="__span-0-2007"><a id="__codelineno-0-2007" name="__codelineno-0-2007"></a><span class="sd">        maintain their order, and have a reserved spot at the beginning of the</span>
</span><span id="__span-0-2008"><a id="__codelineno-0-2008" name="__codelineno-0-2008"></a><span class="sd">        vocabulary. Note: this field has no affect on cache.</span>
</span><span id="__span-0-2009"><a id="__codelineno-0-2009" name="__codelineno-0-2009"></a><span class="sd">      weights: (Optional) Weights `Tensor` for the vocabulary. It must have the</span>
</span><span id="__span-0-2010"><a id="__codelineno-0-2010" name="__codelineno-0-2010"></a><span class="sd">        same shape as x.</span>
</span><span id="__span-0-2011"><a id="__codelineno-0-2011" name="__codelineno-0-2011"></a><span class="sd">      labels: (Optional) Labels dense `Tensor` for the vocabulary. If provided,</span>
</span><span id="__span-0-2012"><a id="__codelineno-0-2012" name="__codelineno-0-2012"></a><span class="sd">        the vocabulary is calculated based on mutual information with the label,</span>
</span><span id="__span-0-2013"><a id="__codelineno-0-2013" name="__codelineno-0-2013"></a><span class="sd">        rather than frequency. The labels must have the same batch dimension as x.</span>
</span><span id="__span-0-2014"><a id="__codelineno-0-2014" name="__codelineno-0-2014"></a><span class="sd">        If x is sparse, labels should be a 1D tensor reflecting row-wise labels.</span>
</span><span id="__span-0-2015"><a id="__codelineno-0-2015" name="__codelineno-0-2015"></a><span class="sd">        If x is dense, labels can either be a 1D tensor of row-wise labels, or a</span>
</span><span id="__span-0-2016"><a id="__codelineno-0-2016" name="__codelineno-0-2016"></a><span class="sd">        dense tensor of the identical shape as x (i.e. element-wise labels).</span>
</span><span id="__span-0-2017"><a id="__codelineno-0-2017" name="__codelineno-0-2017"></a><span class="sd">        Labels should be a discrete integerized tensor (If the label is numeric,</span>
</span><span id="__span-0-2018"><a id="__codelineno-0-2018" name="__codelineno-0-2018"></a><span class="sd">        it should first be bucketized; If the label is a string, an integer</span>
</span><span id="__span-0-2019"><a id="__codelineno-0-2019" name="__codelineno-0-2019"></a><span class="sd">        vocabulary should first be applied). Note: `CompositeTensor` labels are</span>
</span><span id="__span-0-2020"><a id="__codelineno-0-2020" name="__codelineno-0-2020"></a><span class="sd">        not yet supported (b/134931826). WARNING: When labels are provided, the</span>
</span><span id="__span-0-2021"><a id="__codelineno-0-2021" name="__codelineno-0-2021"></a><span class="sd">        frequency_threshold argument functions as a mutual information threshold,</span>
</span><span id="__span-0-2022"><a id="__codelineno-0-2022" name="__codelineno-0-2022"></a><span class="sd">        which is a float. TODO(b/116308354): Fix confusing naming.</span>
</span><span id="__span-0-2023"><a id="__codelineno-0-2023" name="__codelineno-0-2023"></a><span class="sd">      use_adjusted_mutual_info: If true, and labels are provided, calculate</span>
</span><span id="__span-0-2024"><a id="__codelineno-0-2024" name="__codelineno-0-2024"></a><span class="sd">        vocabulary using adjusted rather than raw mutual information.</span>
</span><span id="__span-0-2025"><a id="__codelineno-0-2025" name="__codelineno-0-2025"></a><span class="sd">      min_diff_from_avg: MI (or AMI) of a feature x label will be adjusted to zero</span>
</span><span id="__span-0-2026"><a id="__codelineno-0-2026" name="__codelineno-0-2026"></a><span class="sd">        whenever the difference between count and the expected (average) count is</span>
</span><span id="__span-0-2027"><a id="__codelineno-0-2027" name="__codelineno-0-2027"></a><span class="sd">        lower than min_diff_from_average. This can be thought of as a regularizing</span>
</span><span id="__span-0-2028"><a id="__codelineno-0-2028" name="__codelineno-0-2028"></a><span class="sd">        parameter that pushes small MI/AMI values to zero. If None, a default</span>
</span><span id="__span-0-2029"><a id="__codelineno-0-2029" name="__codelineno-0-2029"></a><span class="sd">        parameter will be selected based on the size of the dataset (see</span>
</span><span id="__span-0-2030"><a id="__codelineno-0-2030" name="__codelineno-0-2030"></a><span class="sd">        calculate_recommended_min_diff_from_avg).</span>
</span><span id="__span-0-2031"><a id="__codelineno-0-2031" name="__codelineno-0-2031"></a><span class="sd">      coverage_top_k: (Optional), (Experimental) The minimum number of elements</span>
</span><span id="__span-0-2032"><a id="__codelineno-0-2032" name="__codelineno-0-2032"></a><span class="sd">        per key to be included in the vocabulary.</span>
</span><span id="__span-0-2033"><a id="__codelineno-0-2033" name="__codelineno-0-2033"></a><span class="sd">      coverage_frequency_threshold: (Optional), (Experimental) Limit the coverage</span>
</span><span id="__span-0-2034"><a id="__codelineno-0-2034" name="__codelineno-0-2034"></a><span class="sd">        arm of the vocabulary only to elements whose absolute frequency is &gt;= this</span>
</span><span id="__span-0-2035"><a id="__codelineno-0-2035" name="__codelineno-0-2035"></a><span class="sd">        threshold for a given key.</span>
</span><span id="__span-0-2036"><a id="__codelineno-0-2036" name="__codelineno-0-2036"></a><span class="sd">      key_fn: (Optional), (Experimental) A fn that takes in a single entry of `x`</span>
</span><span id="__span-0-2037"><a id="__codelineno-0-2037" name="__codelineno-0-2037"></a><span class="sd">        and returns the corresponding key for coverage calculation. If this is</span>
</span><span id="__span-0-2038"><a id="__codelineno-0-2038" name="__codelineno-0-2038"></a><span class="sd">        `None`, no coverage arm is added to the vocabulary.</span>
</span><span id="__span-0-2039"><a id="__codelineno-0-2039" name="__codelineno-0-2039"></a><span class="sd">      fingerprint_shuffle: (Optional), (Experimental) Whether to sort the</span>
</span><span id="__span-0-2040"><a id="__codelineno-0-2040" name="__codelineno-0-2040"></a><span class="sd">        vocabularies by fingerprint instead of counts. This is useful for load</span>
</span><span id="__span-0-2041"><a id="__codelineno-0-2041" name="__codelineno-0-2041"></a><span class="sd">        balancing on the training parameter servers. Shuffle only happens while</span>
</span><span id="__span-0-2042"><a id="__codelineno-0-2042" name="__codelineno-0-2042"></a><span class="sd">        writing the files, so all the filters above (top_k, frequency_threshold,</span>
</span><span id="__span-0-2043"><a id="__codelineno-0-2043" name="__codelineno-0-2043"></a><span class="sd">        etc) will still take effect.</span>
</span><span id="__span-0-2044"><a id="__codelineno-0-2044" name="__codelineno-0-2044"></a><span class="sd">      file_format: (Optional) A str. The format of the resulting vocabulary file.</span>
</span><span id="__span-0-2045"><a id="__codelineno-0-2045" name="__codelineno-0-2045"></a><span class="sd">        Accepted formats are: 'tfrecord_gzip', 'text'. 'tfrecord_gzip' requires</span>
</span><span id="__span-0-2046"><a id="__codelineno-0-2046" name="__codelineno-0-2046"></a><span class="sd">        tensorflow&gt;=2.4. The default value is 'text'.</span>
</span><span id="__span-0-2047"><a id="__codelineno-0-2047" name="__codelineno-0-2047"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-2048"><a id="__codelineno-0-2048" name="__codelineno-0-2048"></a>
</span><span id="__span-0-2049"><a id="__codelineno-0-2049" name="__codelineno-0-2049"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-2050"><a id="__codelineno-0-2050" name="__codelineno-0-2050"></a><span class="sd">    -------</span>
</span><span id="__span-0-2051"><a id="__codelineno-0-2051" name="__codelineno-0-2051"></a><span class="sd">      The path name for the vocabulary file containing the unique values of `x`.</span>
</span><span id="__span-0-2052"><a id="__codelineno-0-2052" name="__codelineno-0-2052"></a>
</span><span id="__span-0-2053"><a id="__codelineno-0-2053" name="__codelineno-0-2053"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-2054"><a id="__codelineno-0-2054" name="__codelineno-0-2054"></a><span class="sd">    ------</span>
</span><span id="__span-0-2055"><a id="__codelineno-0-2055" name="__codelineno-0-2055"></a><span class="sd">      ValueError: If `top_k` or `frequency_threshold` is negative.</span>
</span><span id="__span-0-2056"><a id="__codelineno-0-2056" name="__codelineno-0-2056"></a><span class="sd">        If `coverage_top_k` or `coverage_frequency_threshold` is negative.</span>
</span><span id="__span-0-2057"><a id="__codelineno-0-2057" name="__codelineno-0-2057"></a><span class="sd">        If either `coverage_top_k` or `coverage_frequency_threshold` is specified</span>
</span><span id="__span-0-2058"><a id="__codelineno-0-2058" name="__codelineno-0-2058"></a><span class="sd">          and `key_fn` is not.</span>
</span><span id="__span-0-2059"><a id="__codelineno-0-2059" name="__codelineno-0-2059"></a><span class="sd">        If `key_fn` is specified and neither `coverage_top_k`, nor</span>
</span><span id="__span-0-2060"><a id="__codelineno-0-2060" name="__codelineno-0-2060"></a><span class="sd">    """</span>
</span><span id="__span-0-2061"><a id="__codelineno-0-2061" name="__codelineno-0-2061"></a>    <span class="n">top_k</span><span class="p">,</span> <span class="n">frequency_threshold</span> <span class="o">=</span> <span class="n">_get_top_k_and_frequency_threshold</span><span class="p">(</span>
</span><span id="__span-0-2062"><a id="__codelineno-0-2062" name="__codelineno-0-2062"></a>        <span class="n">top_k</span><span class="p">,</span> <span class="n">frequency_threshold</span>
</span><span id="__span-0-2063"><a id="__codelineno-0-2063" name="__codelineno-0-2063"></a>    <span class="p">)</span>
</span><span id="__span-0-2064"><a id="__codelineno-0-2064" name="__codelineno-0-2064"></a>
</span><span id="__span-0-2065"><a id="__codelineno-0-2065" name="__codelineno-0-2065"></a>    <span class="k">if</span> <span class="p">(</span><span class="n">coverage_top_k</span> <span class="ow">or</span> <span class="n">coverage_frequency_threshold</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">key_fn</span><span class="p">:</span>
</span><span id="__span-0-2066"><a id="__codelineno-0-2066" name="__codelineno-0-2066"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="__span-0-2067"><a id="__codelineno-0-2067" name="__codelineno-0-2067"></a>            <span class="s2">"You must specify `key_fn` if you specify `coverage_top_k"</span>
</span><span id="__span-0-2068"><a id="__codelineno-0-2068" name="__codelineno-0-2068"></a>            <span class="s2">" or `coverage_frequency_threshold` in `vocabulary`."</span>
</span><span id="__span-0-2069"><a id="__codelineno-0-2069" name="__codelineno-0-2069"></a>        <span class="p">)</span>
</span><span id="__span-0-2070"><a id="__codelineno-0-2070" name="__codelineno-0-2070"></a>
</span><span id="__span-0-2071"><a id="__codelineno-0-2071" name="__codelineno-0-2071"></a>    <span class="k">if</span> <span class="n">key_fn</span> <span class="ow">and</span> <span class="ow">not</span> <span class="p">(</span><span class="n">coverage_top_k</span> <span class="ow">or</span> <span class="n">coverage_frequency_threshold</span><span class="p">):</span>
</span><span id="__span-0-2072"><a id="__codelineno-0-2072" name="__codelineno-0-2072"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="__span-0-2073"><a id="__codelineno-0-2073" name="__codelineno-0-2073"></a>            <span class="s2">"You must specify `coverage_top_k`  or "</span>
</span><span id="__span-0-2074"><a id="__codelineno-0-2074" name="__codelineno-0-2074"></a>            <span class="s2">"`coverage_frequency_threshold` if you specify `key_fn` in"</span>
</span><span id="__span-0-2075"><a id="__codelineno-0-2075" name="__codelineno-0-2075"></a>            <span class="s2">" `vocabulary`."</span>
</span><span id="__span-0-2076"><a id="__codelineno-0-2076" name="__codelineno-0-2076"></a>        <span class="p">)</span>
</span><span id="__span-0-2077"><a id="__codelineno-0-2077" name="__codelineno-0-2077"></a>
</span><span id="__span-0-2078"><a id="__codelineno-0-2078" name="__codelineno-0-2078"></a>    <span class="k">if</span> <span class="n">file_format</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ALLOWED_VOCABULARY_FILE_FORMATS</span><span class="p">:</span>
</span><span id="__span-0-2079"><a id="__codelineno-0-2079" name="__codelineno-0-2079"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="__span-0-2080"><a id="__codelineno-0-2080" name="__codelineno-0-2080"></a>            <span class="s1">'"</span><span class="si">{}</span><span class="s1">" is not an accepted file_format. It should be one of: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
</span><span id="__span-0-2081"><a id="__codelineno-0-2081" name="__codelineno-0-2081"></a>                <span class="n">file_format</span><span class="p">,</span> <span class="n">ALLOWED_VOCABULARY_FILE_FORMATS</span>
</span><span id="__span-0-2082"><a id="__codelineno-0-2082" name="__codelineno-0-2082"></a>            <span class="p">)</span>
</span><span id="__span-0-2083"><a id="__codelineno-0-2083" name="__codelineno-0-2083"></a>        <span class="p">)</span>
</span><span id="__span-0-2084"><a id="__codelineno-0-2084" name="__codelineno-0-2084"></a>
</span><span id="__span-0-2085"><a id="__codelineno-0-2085" name="__codelineno-0-2085"></a>    <span class="n">coverage_top_k</span><span class="p">,</span> <span class="n">coverage_frequency_threshold</span> <span class="o">=</span> <span class="n">_get_top_k_and_frequency_threshold</span><span class="p">(</span>
</span><span id="__span-0-2086"><a id="__codelineno-0-2086" name="__codelineno-0-2086"></a>        <span class="n">coverage_top_k</span><span class="p">,</span> <span class="n">coverage_frequency_threshold</span>
</span><span id="__span-0-2087"><a id="__codelineno-0-2087" name="__codelineno-0-2087"></a>    <span class="p">)</span>
</span><span id="__span-0-2088"><a id="__codelineno-0-2088" name="__codelineno-0-2088"></a>
</span><span id="__span-0-2089"><a id="__codelineno-0-2089" name="__codelineno-0-2089"></a>    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">tf</span><span class="o">.</span><span class="n">string</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_integer</span><span class="p">:</span>
</span><span id="__span-0-2090"><a id="__codelineno-0-2090" name="__codelineno-0-2090"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"expected tf.string or integer but got </span><span class="si">%r</span><span class="s2">"</span> <span class="o">%</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-2091"><a id="__codelineno-0-2091" name="__codelineno-0-2091"></a>
</span><span id="__span-0-2092"><a id="__codelineno-0-2092" name="__codelineno-0-2092"></a>    <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">labels</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_integer</span><span class="p">:</span>
</span><span id="__span-0-2093"><a id="__codelineno-0-2093" name="__codelineno-0-2093"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"expected integer labels but got </span><span class="si">%r</span><span class="s2">"</span> <span class="o">%</span> <span class="n">labels</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-2094"><a id="__codelineno-0-2094" name="__codelineno-0-2094"></a>
</span><span id="__span-0-2095"><a id="__codelineno-0-2095" name="__codelineno-0-2095"></a>    <span class="k">if</span> <span class="p">(</span>
</span><span id="__span-0-2096"><a id="__codelineno-0-2096" name="__codelineno-0-2096"></a>        <span class="n">frequency_threshold</span> <span class="ow">is</span> <span class="kc">None</span>
</span><span id="__span-0-2097"><a id="__codelineno-0-2097" name="__codelineno-0-2097"></a>        <span class="ow">and</span> <span class="n">labels</span> <span class="ow">is</span> <span class="kc">None</span>
</span><span id="__span-0-2098"><a id="__codelineno-0-2098" name="__codelineno-0-2098"></a>        <span class="ow">and</span> <span class="n">key_fn</span> <span class="ow">is</span> <span class="kc">None</span>
</span><span id="__span-0-2099"><a id="__codelineno-0-2099" name="__codelineno-0-2099"></a>        <span class="ow">and</span> <span class="ow">not</span> <span class="n">fingerprint_shuffle</span>
</span><span id="__span-0-2100"><a id="__codelineno-0-2100" name="__codelineno-0-2100"></a>        <span class="ow">and</span> <span class="n">top_k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="__span-0-2101"><a id="__codelineno-0-2101" name="__codelineno-0-2101"></a>        <span class="ow">and</span> <span class="n">top_k</span> <span class="o">&lt;=</span> <span class="n">LARGE_VOCAB_TOP_K</span>
</span><span id="__span-0-2102"><a id="__codelineno-0-2102" name="__codelineno-0-2102"></a>    <span class="p">):</span>
</span><span id="__span-0-2103"><a id="__codelineno-0-2103" name="__codelineno-0-2103"></a>        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
</span><span id="__span-0-2104"><a id="__codelineno-0-2104" name="__codelineno-0-2104"></a>            <span class="s2">"If the number of unique tokens is smaller than the provided "</span>
</span><span id="__span-0-2105"><a id="__codelineno-0-2105" name="__codelineno-0-2105"></a>            <span class="s2">"top_k or approximation error is acceptable, consider using "</span>
</span><span id="__span-0-2106"><a id="__codelineno-0-2106" name="__codelineno-0-2106"></a>            <span class="s2">"tft.experimental.approximate_vocabulary for a potentially "</span>
</span><span id="__span-0-2107"><a id="__codelineno-0-2107" name="__codelineno-0-2107"></a>            <span class="s2">"more efficient implementation."</span>
</span><span id="__span-0-2108"><a id="__codelineno-0-2108" name="__codelineno-0-2108"></a>        <span class="p">)</span>
</span><span id="__span-0-2109"><a id="__codelineno-0-2109" name="__codelineno-0-2109"></a>
</span><span id="__span-0-2110"><a id="__codelineno-0-2110" name="__codelineno-0-2110"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"vocabulary"</span><span class="p">):</span>
</span><span id="__span-0-2111"><a id="__codelineno-0-2111" name="__codelineno-0-2111"></a>        <span class="n">vocabulary_key</span> <span class="o">=</span> <span class="n">vocab_filename</span>
</span><span id="__span-0-2112"><a id="__codelineno-0-2112" name="__codelineno-0-2112"></a>        <span class="n">vocab_filename</span> <span class="o">=</span> <span class="n">_get_vocab_filename</span><span class="p">(</span><span class="n">vocab_filename</span><span class="p">,</span> <span class="n">store_frequency</span><span class="p">)</span>
</span><span id="__span-0-2113"><a id="__codelineno-0-2113" name="__codelineno-0-2113"></a>        <span class="n">informativeness_threshold</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"-inf"</span><span class="p">)</span>
</span><span id="__span-0-2114"><a id="__codelineno-0-2114" name="__codelineno-0-2114"></a>        <span class="n">coverage_informativeness_threshold</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"-inf"</span><span class="p">)</span>
</span><span id="__span-0-2115"><a id="__codelineno-0-2115" name="__codelineno-0-2115"></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-2116"><a id="__codelineno-0-2116" name="__codelineno-0-2116"></a>            <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-2117"><a id="__codelineno-0-2117" name="__codelineno-0-2117"></a>                <span class="n">vocab_ordering_type</span> <span class="o">=</span> <span class="n">_VocabOrderingType</span><span class="o">.</span><span class="n">WEIGHTED_MUTUAL_INFORMATION</span>
</span><span id="__span-0-2118"><a id="__codelineno-0-2118" name="__codelineno-0-2118"></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-2119"><a id="__codelineno-0-2119" name="__codelineno-0-2119"></a>                <span class="n">vocab_ordering_type</span> <span class="o">=</span> <span class="n">_VocabOrderingType</span><span class="o">.</span><span class="n">MUTUAL_INFORMATION</span>
</span><span id="__span-0-2120"><a id="__codelineno-0-2120" name="__codelineno-0-2120"></a>            <span class="c1"># Correct for the overloaded `frequency_threshold` API.</span>
</span><span id="__span-0-2121"><a id="__codelineno-0-2121" name="__codelineno-0-2121"></a>            <span class="k">if</span> <span class="n">frequency_threshold</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-2122"><a id="__codelineno-0-2122" name="__codelineno-0-2122"></a>                <span class="n">informativeness_threshold</span> <span class="o">=</span> <span class="n">frequency_threshold</span>
</span><span id="__span-0-2123"><a id="__codelineno-0-2123" name="__codelineno-0-2123"></a>            <span class="n">frequency_threshold</span> <span class="o">=</span> <span class="mf">0.0</span>
</span><span id="__span-0-2124"><a id="__codelineno-0-2124" name="__codelineno-0-2124"></a>            <span class="k">if</span> <span class="n">coverage_frequency_threshold</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-2125"><a id="__codelineno-0-2125" name="__codelineno-0-2125"></a>                <span class="n">coverage_informativeness_threshold</span> <span class="o">=</span> <span class="n">coverage_frequency_threshold</span>
</span><span id="__span-0-2126"><a id="__codelineno-0-2126" name="__codelineno-0-2126"></a>            <span class="n">coverage_frequency_threshold</span> <span class="o">=</span> <span class="mf">0.0</span>
</span><span id="__span-0-2127"><a id="__codelineno-0-2127" name="__codelineno-0-2127"></a>        <span class="k">elif</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-2128"><a id="__codelineno-0-2128" name="__codelineno-0-2128"></a>            <span class="n">vocab_ordering_type</span> <span class="o">=</span> <span class="n">_VocabOrderingType</span><span class="o">.</span><span class="n">WEIGHTED_FREQUENCY</span>
</span><span id="__span-0-2129"><a id="__codelineno-0-2129" name="__codelineno-0-2129"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-2130"><a id="__codelineno-0-2130" name="__codelineno-0-2130"></a>            <span class="n">vocab_ordering_type</span> <span class="o">=</span> <span class="n">_VocabOrderingType</span><span class="o">.</span><span class="n">FREQUENCY</span>
</span><span id="__span-0-2131"><a id="__codelineno-0-2131" name="__codelineno-0-2131"></a>        <span class="n">analyzer_inputs</span> <span class="o">=</span> <span class="n">_get_vocabulary_analyzer_inputs</span><span class="p">(</span>
</span><span id="__span-0-2132"><a id="__codelineno-0-2132" name="__codelineno-0-2132"></a>            <span class="n">vocab_ordering_type</span><span class="o">=</span><span class="n">vocab_ordering_type</span><span class="p">,</span>
</span><span id="__span-0-2133"><a id="__codelineno-0-2133" name="__codelineno-0-2133"></a>            <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
</span><span id="__span-0-2134"><a id="__codelineno-0-2134" name="__codelineno-0-2134"></a>            <span class="n">file_format</span><span class="o">=</span><span class="n">file_format</span><span class="p">,</span>
</span><span id="__span-0-2135"><a id="__codelineno-0-2135" name="__codelineno-0-2135"></a>            <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
</span><span id="__span-0-2136"><a id="__codelineno-0-2136" name="__codelineno-0-2136"></a>            <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
</span><span id="__span-0-2137"><a id="__codelineno-0-2137" name="__codelineno-0-2137"></a>        <span class="p">)</span>
</span><span id="__span-0-2138"><a id="__codelineno-0-2138" name="__codelineno-0-2138"></a>        <span class="k">return</span> <span class="n">_vocabulary_analyzer_nodes</span><span class="p">(</span>
</span><span id="__span-0-2139"><a id="__codelineno-0-2139" name="__codelineno-0-2139"></a>            <span class="n">analyzer_inputs</span><span class="o">=</span><span class="n">analyzer_inputs</span><span class="p">,</span>
</span><span id="__span-0-2140"><a id="__codelineno-0-2140" name="__codelineno-0-2140"></a>            <span class="n">input_dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
</span><span id="__span-0-2141"><a id="__codelineno-0-2141" name="__codelineno-0-2141"></a>            <span class="n">vocab_ordering_type</span><span class="o">=</span><span class="n">vocab_ordering_type</span><span class="p">,</span>
</span><span id="__span-0-2142"><a id="__codelineno-0-2142" name="__codelineno-0-2142"></a>            <span class="n">vocab_filename</span><span class="o">=</span><span class="n">vocab_filename</span><span class="p">,</span>
</span><span id="__span-0-2143"><a id="__codelineno-0-2143" name="__codelineno-0-2143"></a>            <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span>
</span><span id="__span-0-2144"><a id="__codelineno-0-2144" name="__codelineno-0-2144"></a>            <span class="n">frequency_threshold</span><span class="o">=</span><span class="n">frequency_threshold</span> <span class="ow">or</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-2145"><a id="__codelineno-0-2145" name="__codelineno-0-2145"></a>            <span class="n">informativeness_threshold</span><span class="o">=</span><span class="n">informativeness_threshold</span><span class="p">,</span>
</span><span id="__span-0-2146"><a id="__codelineno-0-2146" name="__codelineno-0-2146"></a>            <span class="n">use_adjusted_mutual_info</span><span class="o">=</span><span class="n">use_adjusted_mutual_info</span><span class="p">,</span>
</span><span id="__span-0-2147"><a id="__codelineno-0-2147" name="__codelineno-0-2147"></a>            <span class="n">min_diff_from_avg</span><span class="o">=</span><span class="n">min_diff_from_avg</span><span class="p">,</span>
</span><span id="__span-0-2148"><a id="__codelineno-0-2148" name="__codelineno-0-2148"></a>            <span class="n">fingerprint_shuffle</span><span class="o">=</span><span class="n">fingerprint_shuffle</span><span class="p">,</span>
</span><span id="__span-0-2149"><a id="__codelineno-0-2149" name="__codelineno-0-2149"></a>            <span class="n">store_frequency</span><span class="o">=</span><span class="n">store_frequency</span><span class="p">,</span>
</span><span id="__span-0-2150"><a id="__codelineno-0-2150" name="__codelineno-0-2150"></a>            <span class="n">key_fn</span><span class="o">=</span><span class="n">key_fn</span><span class="p">,</span>
</span><span id="__span-0-2151"><a id="__codelineno-0-2151" name="__codelineno-0-2151"></a>            <span class="n">coverage_top_k</span><span class="o">=</span><span class="n">coverage_top_k</span><span class="p">,</span>
</span><span id="__span-0-2152"><a id="__codelineno-0-2152" name="__codelineno-0-2152"></a>            <span class="n">coverage_frequency_threshold</span><span class="o">=</span><span class="n">coverage_frequency_threshold</span> <span class="ow">or</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-2153"><a id="__codelineno-0-2153" name="__codelineno-0-2153"></a>            <span class="n">coverage_informativeness_threshold</span><span class="o">=</span><span class="n">coverage_informativeness_threshold</span><span class="p">,</span>
</span><span id="__span-0-2154"><a id="__codelineno-0-2154" name="__codelineno-0-2154"></a>            <span class="n">file_format</span><span class="o">=</span><span class="n">file_format</span><span class="p">,</span>
</span><span id="__span-0-2155"><a id="__codelineno-0-2155" name="__codelineno-0-2155"></a>            <span class="n">vocabulary_key</span><span class="o">=</span><span class="n">vocabulary_key</span><span class="p">,</span>
</span><span id="__span-0-2156"><a id="__codelineno-0-2156" name="__codelineno-0-2156"></a>            <span class="n">reserved_tokens</span><span class="o">=</span><span class="n">reserved_tokens</span><span class="p">,</span>
</span><span id="__span-0-2157"><a id="__codelineno-0-2157" name="__codelineno-0-2157"></a>        <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="tensorflow_transform.word_count" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">word_count</span>


<a href="#tensorflow_transform.word_count" class="headerlink" title="Permanent link">Â¶</a></h4>
<div class="language-python doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">word_count</span><span class="p">(</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">tokens</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Union (typing.Union)" href="#tensorflow_transform.Union">Union</a></span><span class="p">[</span><span class="n"><span title="tensorflow.SparseTensor">SparseTensor</span></span><span class="p">,</span> <span class="n"><span title="tensorflow.RaggedTensor">RaggedTensor</span></span><span class="p">],</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="            Optional (typing.Optional)" href="#tensorflow_transform.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="tensorflow.Tensor">Tensor</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Find the token count of each document/row.</p>
<p><code>tokens</code> is either a <code>RaggedTensor</code> or <code>SparseTensor</code>, representing tokenized
strings. This function simply returns size of each row, so the dtype is not
constrained to string.</p>
<h6 id="tensorflow_transform.word_count--example">Example:<a class="headerlink" href="#tensorflow_transform.word_count--example" title="Permanent link">Â¶</a></h6>
<blockquote>
<blockquote>
<blockquote>
<p>sparse = tf.SparseTensor(indices=[[0, 0], [0, 1], [2, 2]],
...                          values=['a', 'b', 'c'], dense_shape=(4, 4))
tft.word_count(sparse)
<tf.tensor: shape="(4,)," dtype="int64," numpy="array([2," 0, 1, 0])></tf.tensor:></p>
</blockquote>
</blockquote>
</blockquote>
        <hr>
<p>tokens: either
    (1) a <code>SparseTensor</code>, or
    (2) a <code>RaggedTensor</code> with ragged rank of 1, non-ragged rank of 1
    of dtype <code>tf.string</code> containing tokens to be counted
  name: (Optional) A name for this operation.</p>
        <hr>
<p>A one-dimensional <code>Tensor</code> the token counts of each row.</p>
        <hr>
<p>ValueError: if tokens is neither sparse nor ragged</p>


            <details class="quote">
              <summary>Source code in <code>tensorflow_transform/mappers.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1786">1786</a></span>
<span class="normal"><a href="#__codelineno-0-1787">1787</a></span>
<span class="normal"><a href="#__codelineno-0-1788">1788</a></span>
<span class="normal"><a href="#__codelineno-0-1789">1789</a></span>
<span class="normal"><a href="#__codelineno-0-1790">1790</a></span>
<span class="normal"><a href="#__codelineno-0-1791">1791</a></span>
<span class="normal"><a href="#__codelineno-0-1792">1792</a></span>
<span class="normal"><a href="#__codelineno-0-1793">1793</a></span>
<span class="normal"><a href="#__codelineno-0-1794">1794</a></span>
<span class="normal"><a href="#__codelineno-0-1795">1795</a></span>
<span class="normal"><a href="#__codelineno-0-1796">1796</a></span>
<span class="normal"><a href="#__codelineno-0-1797">1797</a></span>
<span class="normal"><a href="#__codelineno-0-1798">1798</a></span>
<span class="normal"><a href="#__codelineno-0-1799">1799</a></span>
<span class="normal"><a href="#__codelineno-0-1800">1800</a></span>
<span class="normal"><a href="#__codelineno-0-1801">1801</a></span>
<span class="normal"><a href="#__codelineno-0-1802">1802</a></span>
<span class="normal"><a href="#__codelineno-0-1803">1803</a></span>
<span class="normal"><a href="#__codelineno-0-1804">1804</a></span>
<span class="normal"><a href="#__codelineno-0-1805">1805</a></span>
<span class="normal"><a href="#__codelineno-0-1806">1806</a></span>
<span class="normal"><a href="#__codelineno-0-1807">1807</a></span>
<span class="normal"><a href="#__codelineno-0-1808">1808</a></span>
<span class="normal"><a href="#__codelineno-0-1809">1809</a></span>
<span class="normal"><a href="#__codelineno-0-1810">1810</a></span>
<span class="normal"><a href="#__codelineno-0-1811">1811</a></span>
<span class="normal"><a href="#__codelineno-0-1812">1812</a></span>
<span class="normal"><a href="#__codelineno-0-1813">1813</a></span>
<span class="normal"><a href="#__codelineno-0-1814">1814</a></span>
<span class="normal"><a href="#__codelineno-0-1815">1815</a></span>
<span class="normal"><a href="#__codelineno-0-1816">1816</a></span>
<span class="normal"><a href="#__codelineno-0-1817">1817</a></span>
<span class="normal"><a href="#__codelineno-0-1818">1818</a></span>
<span class="normal"><a href="#__codelineno-0-1819">1819</a></span>
<span class="normal"><a href="#__codelineno-0-1820">1820</a></span>
<span class="normal"><a href="#__codelineno-0-1821">1821</a></span>
<span class="normal"><a href="#__codelineno-0-1822">1822</a></span>
<span class="normal"><a href="#__codelineno-0-1823">1823</a></span>
<span class="normal"><a href="#__codelineno-0-1824">1824</a></span>
<span class="normal"><a href="#__codelineno-0-1825">1825</a></span>
<span class="normal"><a href="#__codelineno-0-1826">1826</a></span>
<span class="normal"><a href="#__codelineno-0-1827">1827</a></span>
<span class="normal"><a href="#__codelineno-0-1828">1828</a></span>
<span class="normal"><a href="#__codelineno-0-1829">1829</a></span>
<span class="normal"><a href="#__codelineno-0-1830">1830</a></span>
<span class="normal"><a href="#__codelineno-0-1831">1831</a></span>
<span class="normal"><a href="#__codelineno-0-1832">1832</a></span>
<span class="normal"><a href="#__codelineno-0-1833">1833</a></span>
<span class="normal"><a href="#__codelineno-0-1834">1834</a></span>
<span class="normal"><a href="#__codelineno-0-1835">1835</a></span>
<span class="normal"><a href="#__codelineno-0-1836">1836</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1786"><a id="__codelineno-0-1786" name="__codelineno-0-1786"></a><span class="nd">@common</span><span class="o">.</span><span class="n">log_api_use</span><span class="p">(</span><span class="n">common</span><span class="o">.</span><span class="n">MAPPER_COLLECTION</span><span class="p">)</span>
</span><span id="__span-0-1787"><a id="__codelineno-0-1787" name="__codelineno-0-1787"></a><span class="k">def</span><span class="w"> </span><span class="nf">word_count</span><span class="p">(</span>
</span><span id="__span-0-1788"><a id="__codelineno-0-1788" name="__codelineno-0-1788"></a>    <span class="n">tokens</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">],</span> <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-1789"><a id="__codelineno-0-1789" name="__codelineno-0-1789"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-1790"><a id="__codelineno-0-1790" name="__codelineno-0-1790"></a>    <span class="c1"># pyformat: disable</span>
</span><span id="__span-0-1791"><a id="__codelineno-0-1791" name="__codelineno-0-1791"></a><span class="w">    </span><span class="sd">"""Find the token count of each document/row.</span>
</span><span id="__span-0-1792"><a id="__codelineno-0-1792" name="__codelineno-0-1792"></a>
</span><span id="__span-0-1793"><a id="__codelineno-0-1793" name="__codelineno-0-1793"></a><span class="sd">    `tokens` is either a `RaggedTensor` or `SparseTensor`, representing tokenized</span>
</span><span id="__span-0-1794"><a id="__codelineno-0-1794" name="__codelineno-0-1794"></a><span class="sd">    strings. This function simply returns size of each row, so the dtype is not</span>
</span><span id="__span-0-1795"><a id="__codelineno-0-1795" name="__codelineno-0-1795"></a><span class="sd">    constrained to string.</span>
</span><span id="__span-0-1796"><a id="__codelineno-0-1796" name="__codelineno-0-1796"></a>
</span><span id="__span-0-1797"><a id="__codelineno-0-1797" name="__codelineno-0-1797"></a><span class="sd">    Example:</span>
</span><span id="__span-0-1798"><a id="__codelineno-0-1798" name="__codelineno-0-1798"></a><span class="sd">    -------</span>
</span><span id="__span-0-1799"><a id="__codelineno-0-1799" name="__codelineno-0-1799"></a><span class="sd">    &gt;&gt;&gt; sparse = tf.SparseTensor(indices=[[0, 0], [0, 1], [2, 2]],</span>
</span><span id="__span-0-1800"><a id="__codelineno-0-1800" name="__codelineno-0-1800"></a><span class="sd">    ...                          values=['a', 'b', 'c'], dense_shape=(4, 4))</span>
</span><span id="__span-0-1801"><a id="__codelineno-0-1801" name="__codelineno-0-1801"></a><span class="sd">    &gt;&gt;&gt; tft.word_count(sparse)</span>
</span><span id="__span-0-1802"><a id="__codelineno-0-1802" name="__codelineno-0-1802"></a><span class="sd">    &lt;tf.Tensor: shape=(4,), dtype=int64, numpy=array([2, 0, 1, 0])&gt;</span>
</span><span id="__span-0-1803"><a id="__codelineno-0-1803" name="__codelineno-0-1803"></a>
</span><span id="__span-0-1804"><a id="__codelineno-0-1804" name="__codelineno-0-1804"></a><span class="sd">    Args:</span>
</span><span id="__span-0-1805"><a id="__codelineno-0-1805" name="__codelineno-0-1805"></a><span class="sd">    ----</span>
</span><span id="__span-0-1806"><a id="__codelineno-0-1806" name="__codelineno-0-1806"></a><span class="sd">      tokens: either</span>
</span><span id="__span-0-1807"><a id="__codelineno-0-1807" name="__codelineno-0-1807"></a><span class="sd">        (1) a `SparseTensor`, or</span>
</span><span id="__span-0-1808"><a id="__codelineno-0-1808" name="__codelineno-0-1808"></a><span class="sd">        (2) a `RaggedTensor` with ragged rank of 1, non-ragged rank of 1</span>
</span><span id="__span-0-1809"><a id="__codelineno-0-1809" name="__codelineno-0-1809"></a><span class="sd">        of dtype `tf.string` containing tokens to be counted</span>
</span><span id="__span-0-1810"><a id="__codelineno-0-1810" name="__codelineno-0-1810"></a><span class="sd">      name: (Optional) A name for this operation.</span>
</span><span id="__span-0-1811"><a id="__codelineno-0-1811" name="__codelineno-0-1811"></a>
</span><span id="__span-0-1812"><a id="__codelineno-0-1812" name="__codelineno-0-1812"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-1813"><a id="__codelineno-0-1813" name="__codelineno-0-1813"></a><span class="sd">    -------</span>
</span><span id="__span-0-1814"><a id="__codelineno-0-1814" name="__codelineno-0-1814"></a><span class="sd">      A one-dimensional `Tensor` the token counts of each row.</span>
</span><span id="__span-0-1815"><a id="__codelineno-0-1815" name="__codelineno-0-1815"></a>
</span><span id="__span-0-1816"><a id="__codelineno-0-1816" name="__codelineno-0-1816"></a><span class="sd">    Raises:</span>
</span><span id="__span-0-1817"><a id="__codelineno-0-1817" name="__codelineno-0-1817"></a><span class="sd">    ------</span>
</span><span id="__span-0-1818"><a id="__codelineno-0-1818" name="__codelineno-0-1818"></a><span class="sd">      ValueError: if tokens is neither sparse nor ragged</span>
</span><span id="__span-0-1819"><a id="__codelineno-0-1819" name="__codelineno-0-1819"></a><span class="sd">    """</span>
</span><span id="__span-0-1820"><a id="__codelineno-0-1820" name="__codelineno-0-1820"></a>    <span class="c1"># pyformat: enable</span>
</span><span id="__span-0-1821"><a id="__codelineno-0-1821" name="__codelineno-0-1821"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">"word_count"</span><span class="p">):</span>
</span><span id="__span-0-1822"><a id="__codelineno-0-1822" name="__codelineno-0-1822"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">RaggedTensor</span><span class="p">):</span>
</span><span id="__span-0-1823"><a id="__codelineno-0-1823" name="__codelineno-0-1823"></a>            <span class="k">return</span> <span class="n">tokens</span><span class="o">.</span><span class="n">row_lengths</span><span class="p">()</span>
</span><span id="__span-0-1824"><a id="__codelineno-0-1824" name="__codelineno-0-1824"></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">):</span>
</span><span id="__span-0-1825"><a id="__codelineno-0-1825" name="__codelineno-0-1825"></a>            <span class="n">result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
</span><span id="__span-0-1826"><a id="__codelineno-0-1826" name="__codelineno-0-1826"></a>                <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">(</span>
</span><span id="__span-0-1827"><a id="__codelineno-0-1827" name="__codelineno-0-1827"></a>                    <span class="n">indices</span><span class="o">=</span><span class="n">tokens</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span>
</span><span id="__span-0-1828"><a id="__codelineno-0-1828" name="__codelineno-0-1828"></a>                    <span class="n">values</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">tokens</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
</span><span id="__span-0-1829"><a id="__codelineno-0-1829" name="__codelineno-0-1829"></a>                    <span class="n">dense_shape</span><span class="o">=</span><span class="n">tokens</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">,</span>
</span><span id="__span-0-1830"><a id="__codelineno-0-1830" name="__codelineno-0-1830"></a>                <span class="p">),</span>
</span><span id="__span-0-1831"><a id="__codelineno-0-1831" name="__codelineno-0-1831"></a>                <span class="n">axis</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">tokens</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">ndims</span><span class="p">)),</span>
</span><span id="__span-0-1832"><a id="__codelineno-0-1832" name="__codelineno-0-1832"></a>            <span class="p">)</span>
</span><span id="__span-0-1833"><a id="__codelineno-0-1833" name="__codelineno-0-1833"></a>            <span class="n">result</span><span class="o">.</span><span class="n">set_shape</span><span class="p">([</span><span class="n">tokens</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
</span><span id="__span-0-1834"><a id="__codelineno-0-1834" name="__codelineno-0-1834"></a>            <span class="k">return</span> <span class="n">result</span>
</span><span id="__span-0-1835"><a id="__codelineno-0-1835" name="__codelineno-0-1835"></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-1836"><a id="__codelineno-0-1836" name="__codelineno-0-1836"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Invalid token tensor"</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": ["content.code.copy", "content.code.select", "content.action.edit"], "search": "../../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.50899def.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>