{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Transform library for non-TFX users","text":"<p>Transform is available as a standalone library.</p> <ul> <li>Getting Started with TensorFlow     Transform</li> <li>TensorFlow Transform API     Reference</li> </ul> <p>The <code>tft</code> module documentation is the only module that is relevant to TFX users. The <code>tft_beam</code> module is relevant only when using Transform as a standalone library. Typically, a TFX user constructs a <code>preprocessing_fn</code>, and the rest of the Transform library calls are made by the Transform component.</p> <p>You can also use the Apache Beam <code>MLTransform</code> class to preprocess data for training and inference. The <code>MLTransform</code> class wraps multiple TFX data processing transforms in one class. For more information, see Preprocess data with MLTransform in the Apache Beam documentation.</p>"},{"location":"build_tft_beam_docs/","title":"Build tft beam docs","text":"In\u00a0[\u00a0]: Copied! <pre>#\n# Copyright 2017 Google Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr\"\"\"Generate docs for `tft.beam`.\n\nThis requires a local installation of `tft` and `tensoirflow_docs`\n\n```\n$ pip install tensorflow_transform git+https://github.com/tensorflow/docs\n```\n\n```\npython build_tft_beam_docs.py --output_dir=/tmp/tft_beam_api/\n```\n\n\"\"\"\n</pre> # # Copyright 2017 Google Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. r\"\"\"Generate docs for `tft.beam`.  This requires a local installation of `tft` and `tensoirflow_docs`  ``` $ pip install tensorflow_transform git+https://github.com/tensorflow/docs ```  ``` python build_tft_beam_docs.py --output_dir=/tmp/tft_beam_api/ ```  \"\"\" In\u00a0[\u00a0]: Copied! <pre>from absl import app, flags\nfrom tensorflow_docs.api_generator import doc_controls, generate_lib, public_api\n</pre> from absl import app, flags from tensorflow_docs.api_generator import doc_controls, generate_lib, public_api In\u00a0[\u00a0]: Copied! <pre>import tensorflow_transform.beam as tft_beam\n</pre> import tensorflow_transform.beam as tft_beam In\u00a0[\u00a0]: Copied! <pre>flags.DEFINE_string(\n    \"output_dir\", \"/tmp/tft_beam_api/\", \"The path to output the files to\"\n)\n</pre> flags.DEFINE_string(     \"output_dir\", \"/tmp/tft_beam_api/\", \"The path to output the files to\" ) In\u00a0[\u00a0]: Copied! <pre>flags.DEFINE_string(\n    \"code_url_prefix\",\n    \"https://github.com/tensorflow/transform/tree/master/tensorflow_transform\",\n    \"The url prefix for links to code.\",\n)\n</pre> flags.DEFINE_string(     \"code_url_prefix\",     \"https://github.com/tensorflow/transform/tree/master/tensorflow_transform\",     \"The url prefix for links to code.\", ) In\u00a0[\u00a0]: Copied! <pre>flags.DEFINE_bool(\n    \"search_hints\", True, \"Include metadata search hints in the generated files\"\n)\n</pre> flags.DEFINE_bool(     \"search_hints\", True, \"Include metadata search hints in the generated files\" ) In\u00a0[\u00a0]: Copied! <pre>flags.DEFINE_string(\n    \"site_path\", \"tfx/transform/api_docs/python\", \"Path prefix in the _toc.yaml\"\n)\n</pre> flags.DEFINE_string(     \"site_path\", \"tfx/transform/api_docs/python\", \"Path prefix in the _toc.yaml\" ) In\u00a0[\u00a0]: Copied! <pre>FLAGS = flags.FLAGS\n</pre> FLAGS = flags.FLAGS In\u00a0[\u00a0]: Copied! <pre>def main(args):\n    if args[1:]:\n        raise ValueError(\"Unrecognized Command line args\", args[1:])\n\n    doc_controls.do_not_generate_docs(tft_beam.analyzer_impls)\n\n    doc_generator = generate_lib.DocGenerator(\n        root_title=\"TFT-Beam\",\n        py_modules=[(\"tft_beam\", tft_beam)],\n        code_url_prefix=FLAGS.code_url_prefix + \"/beam\",\n        search_hints=FLAGS.search_hints,\n        site_path=FLAGS.site_path,\n        callbacks=[\n            public_api.explicit_package_contents_filter,\n            public_api.local_definitions_filter,\n        ],\n    )\n\n    doc_generator.build(FLAGS.output_dir)\n</pre> def main(args):     if args[1:]:         raise ValueError(\"Unrecognized Command line args\", args[1:])      doc_controls.do_not_generate_docs(tft_beam.analyzer_impls)      doc_generator = generate_lib.DocGenerator(         root_title=\"TFT-Beam\",         py_modules=[(\"tft_beam\", tft_beam)],         code_url_prefix=FLAGS.code_url_prefix + \"/beam\",         search_hints=FLAGS.search_hints,         site_path=FLAGS.site_path,         callbacks=[             public_api.explicit_package_contents_filter,             public_api.local_definitions_filter,         ],     )      doc_generator.build(FLAGS.output_dir) In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    app.run(main)\n</pre> if __name__ == \"__main__\":     app.run(main)"},{"location":"build_tft_docs/","title":"Build tft docs","text":"In\u00a0[\u00a0]: Copied! <pre>#\n# Copyright 2017 Google Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr\"\"\"Generate docs for `tft`.\n\nThis requires a local installation of `tft` and `tensoirflow_docs`\n\n```\n$ pip install tensorflow_transform git+https://github.com/tensorflow/docs\n```\n\n```\npython build_tft_docs.py --output_dir=/tmp/tft-api\n```\n\n\"\"\"\n</pre> # # Copyright 2017 Google Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # #     http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. r\"\"\"Generate docs for `tft`.  This requires a local installation of `tft` and `tensoirflow_docs`  ``` $ pip install tensorflow_transform git+https://github.com/tensorflow/docs ```  ``` python build_tft_docs.py --output_dir=/tmp/tft-api ```  \"\"\" In\u00a0[\u00a0]: Copied! <pre>from absl import app, flags\nfrom tensorflow_docs.api_generator import generate_lib, public_api\n</pre> from absl import app, flags from tensorflow_docs.api_generator import generate_lib, public_api In\u00a0[\u00a0]: Copied! <pre>import tensorflow_transform as transform\n</pre> import tensorflow_transform as transform In\u00a0[\u00a0]: Copied! <pre>flags.DEFINE_string(\"output_dir\", \"/tmp/tft_api/\", \"The path to output the files to\")\n</pre> flags.DEFINE_string(\"output_dir\", \"/tmp/tft_api/\", \"The path to output the files to\") In\u00a0[\u00a0]: Copied! <pre>flags.DEFINE_string(\n    \"code_url_prefix\",\n    \"https://github.com/tensorflow/transform/tree/master/tensorflow_transform\",\n    \"The url prefix for links to code.\",\n)\n</pre> flags.DEFINE_string(     \"code_url_prefix\",     \"https://github.com/tensorflow/transform/tree/master/tensorflow_transform\",     \"The url prefix for links to code.\", ) In\u00a0[\u00a0]: Copied! <pre>flags.DEFINE_bool(\n    \"search_hints\", True, \"Include metadata search hints in the generated files\"\n)\n</pre> flags.DEFINE_bool(     \"search_hints\", True, \"Include metadata search hints in the generated files\" ) In\u00a0[\u00a0]: Copied! <pre>flags.DEFINE_string(\n    \"site_path\", \"tfx/transform/api_docs/python\", \"Path prefix in the _toc.yaml\"\n)\n</pre> flags.DEFINE_string(     \"site_path\", \"tfx/transform/api_docs/python\", \"Path prefix in the _toc.yaml\" ) In\u00a0[\u00a0]: Copied! <pre>FLAGS = flags.FLAGS\n</pre> FLAGS = flags.FLAGS In\u00a0[\u00a0]: Copied! <pre>def main(args):\n    if args[1:]:\n        raise ValueError(\"Unrecognized Command line args\", args[1:])\n\n    doc_generator = generate_lib.DocGenerator(\n        root_title=\"TF-Transform\",\n        py_modules=[(\"tft\", transform)],\n        code_url_prefix=FLAGS.code_url_prefix,\n        search_hints=FLAGS.search_hints,\n        site_path=FLAGS.site_path,\n        callbacks=[public_api.explicit_package_contents_filter],\n    )\n\n    doc_generator.build(FLAGS.output_dir)\n</pre> def main(args):     if args[1:]:         raise ValueError(\"Unrecognized Command line args\", args[1:])      doc_generator = generate_lib.DocGenerator(         root_title=\"TF-Transform\",         py_modules=[(\"tft\", transform)],         code_url_prefix=FLAGS.code_url_prefix,         search_hints=FLAGS.search_hints,         site_path=FLAGS.site_path,         callbacks=[public_api.explicit_package_contents_filter],     )      doc_generator.build(FLAGS.output_dir) In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    app.run(main)\n</pre> if __name__ == \"__main__\":     app.run(main)"},{"location":"common_transformations/","title":"Common Transformations","text":"<ul> <li>Common Transformations<ul> <li>Using String/Categorical data</li> <li>Mean imputation for missing data</li> </ul> </li> </ul> <p>In this document we describe how to do common transformations with tf.transform.</p> <p>We assume you have already constructed the beam pipeline along the lines of the examples, and only describe what needs to be added to <code>preprocessing_fn</code> and possibly model.</p>"},{"location":"common_transformations/#using-stringcategorical-data","title":"Using String/Categorical data","text":"<p>The following <code>preprocessing_fn</code> will compute a vocabulary over the values of feature <code>x</code> with tokens in descending frequency order, convert feature <code>x</code> values to their index in the vocabulary, and finally perform a one-hot encoding for the output.</p> <p>This is common for example in use cases where the label feature is a categorical string. The resulting one-hot encoding is ready for training.</p> <p>Note: this example produces <code>x_out</code> as a potentially large dense tensor. This is fine as long as the transformed data doesn't get materialized, and this is the format expected in training. Otherwise, a more efficient representation would be a <code>tf.SparseTensor</code>, in which case only a single index and value (1) is used to represent each instance.</p> <pre><code>def preprocessing_fn(inputs):\n  integerized = tft.compute_and_apply_vocabulary(\n      inputs['x'],\n      num_oov_buckets=1,\n      vocab_filename='x_vocab')\n  one_hot_encoded = tf.one_hot(\n      integerized,\n      depth=tf.cast(tft.experimental.get_vocabulary_size_by_name('x_vocab') + 1,\n                    tf.int32),\n      on_value=1.0,\n      off_value=0.0)\n  return {\n    'x_out': one_hot_encoded,\n  }\n</code></pre>"},{"location":"common_transformations/#mean-imputation-for-missing-data","title":"Mean imputation for missing data","text":"<p>In this example, feature <code>x</code> is an optional feature, represented as a <code>tf.SparseTensor</code> in the <code>preprocessing_fn</code>. In order to convert it to a dense tensor, we compute its mean, and set the mean to be the default value when it is missing from an instance.</p> <p>The resulting dense tensor will have the shape <code>[None, 1]</code>, <code>None</code> represents the batch dimension, and for the second dimension it will be the number of values that <code>x</code> can have per instance. In this case it's 1.</p> <pre><code>def preprocessing_fn(inputs):\n  return {\n      'x_out': tft.sparse_tensor_to_dense_with_shape(\n          inputs['x'], default_value=tft.mean(x), shape=[None, 1])\n  }\n</code></pre>"},{"location":"get_started/","title":"Get Started","text":"<p>This guide introduces the basic concepts of <code>tf.Transform</code> and how to use them. It will:</p> <ul> <li>Define a preprocessing function, a logical description of the pipeline that transforms the raw data into the data used to train a machine learning model.</li> <li>Show the Apache Beam implementation used to transform data by converting the preprocessing function into a Beam pipeline.</li> <li>Show additional usage examples.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>!pip install -U tensorflow_transform\n</pre> !pip install -U tensorflow_transform In\u00a0[\u00a0]: Copied! <pre>!pip install pyarrow\n</pre> !pip install pyarrow In\u00a0[\u00a0]: Copied! <pre>import pkg_resources\nimport importlib\nimportlib.reload(pkg_resources)\n</pre> import pkg_resources import importlib importlib.reload(pkg_resources) In\u00a0[\u00a0]: Copied! <pre>import os\nimport tempfile\n\nimport tensorflow as tf\nimport tensorflow_transform as tft\nimport tensorflow_transform.beam as tft_beam\n\nfrom tensorflow_transform.tf_metadata import dataset_metadata\nfrom tensorflow_transform.tf_metadata import schema_utils\n\nfrom tfx_bsl.public import tfxio\n</pre> import os import tempfile  import tensorflow as tf import tensorflow_transform as tft import tensorflow_transform.beam as tft_beam  from tensorflow_transform.tf_metadata import dataset_metadata from tensorflow_transform.tf_metadata import schema_utils  from tfx_bsl.public import tfxio In\u00a0[\u00a0]: Copied! <pre>def preprocessing_fn(inputs):\n  x = inputs['x']\n  y = inputs['y']\n  s = inputs['s']\n  x_centered = x - tft.mean(x)\n  y_normalized = tft.scale_to_0_1(y)\n  s_integerized = tft.compute_and_apply_vocabulary(s)\n  x_centered_times_y_normalized = x_centered * y_normalized\n  return {\n      'x_centered': x_centered,\n      'y_normalized': y_normalized,\n      'x_centered_times_y_normalized': x_centered_times_y_normalized,\n      's_integerized': s_integerized\n  }\n</pre> def preprocessing_fn(inputs):   x = inputs['x']   y = inputs['y']   s = inputs['s']   x_centered = x - tft.mean(x)   y_normalized = tft.scale_to_0_1(y)   s_integerized = tft.compute_and_apply_vocabulary(s)   x_centered_times_y_normalized = x_centered * y_normalized   return {       'x_centered': x_centered,       'y_normalized': y_normalized,       'x_centered_times_y_normalized': x_centered_times_y_normalized,       's_integerized': s_integerized   } <p>Here, <code>x</code>, <code>y</code> and <code>s</code> are <code>Tensor</code>s that represent input features. The first new tensor that is created, <code>x_centered</code>, is built by applying <code>tft.mean</code> to <code>x</code> and subtracting this from <code>x</code>. <code>tft.mean(x)</code> returns a tensor representing the mean of the tensor <code>x</code>. <code>x_centered</code> is the tensor <code>x</code> with the mean subtracted.</p> <p>The second new tensor, <code>y_normalized</code>, is created in a similar manner but using the convenience method <code>tft.scale_to_0_1</code>. This method does something similar to computing <code>x_centered</code>, namely computing a maximum and minimum and using these to scale <code>y</code>.</p> <p>The tensor <code>s_integerized</code> shows an example of string manipulation. In this case, we take a string and map it to an integer. This uses the convenience function <code>tft.compute_and_apply_vocabulary</code>. This function uses an analyzer to compute the unique values taken by the input strings, and then uses TensorFlow operations to convert the input strings to indices in the table of unique values.</p> <p>The final column shows that it is possible to use TensorFlow operations to create new features by combining tensors.</p> <p>The preprocessing function defines a pipeline of operations on a dataset. In order to apply the pipeline, we rely on a concrete implementation of the <code>tf.Transform</code> API. The Apache Beam implementation provides <code>PTransform</code> which applies a user's preprocessing function to data. The typical workflow of a <code>tf.Transform</code> user will construct a preprocessing function, then incorporate this into a larger Beam pipeline, creating the data for training.</p> In\u00a0[\u00a0]: Copied! <pre>raw_data = [\n    {'x': 1, 'y': 1, 's': 'hello'},\n    {'x': 2, 'y': 2, 's': 'world'},\n    {'x': 3, 'y': 3, 's': 'hello'}\n]\n\nraw_data_metadata = dataset_metadata.DatasetMetadata(\n    schema_utils.schema_from_feature_spec({\n        'y': tf.io.FixedLenFeature([], tf.float32),\n        'x': tf.io.FixedLenFeature([], tf.float32),\n        's': tf.io.FixedLenFeature([], tf.string),\n    }))\n\nwith tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n  transformed_dataset, transform_fn = (\n      (raw_data, raw_data_metadata) |\n      tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\n</pre> raw_data = [     {'x': 1, 'y': 1, 's': 'hello'},     {'x': 2, 'y': 2, 's': 'world'},     {'x': 3, 'y': 3, 's': 'hello'} ]  raw_data_metadata = dataset_metadata.DatasetMetadata(     schema_utils.schema_from_feature_spec({         'y': tf.io.FixedLenFeature([], tf.float32),         'x': tf.io.FixedLenFeature([], tf.float32),         's': tf.io.FixedLenFeature([], tf.string),     }))  with tft_beam.Context(temp_dir=tempfile.mkdtemp()):   transformed_dataset, transform_fn = (       (raw_data, raw_data_metadata) |       tft_beam.AnalyzeAndTransformDataset(preprocessing_fn)) In\u00a0[\u00a0]: Copied! <pre>transformed_data, transformed_metadata = transformed_dataset\n</pre> transformed_data, transformed_metadata = transformed_dataset <p>The <code>transformed_data</code> content is shown below and contains the transformed columns in the same format as the raw data. In particular, the values of <code>s_integerized</code> are <code>[0, 1, 0]</code>\u2014these values depend on how the words <code>hello</code> and <code>world</code> were mapped to integers, which is deterministic. For the column <code>x_centered</code>, we subtracted the mean so the values of the column <code>x</code>, which were <code>[1.0, 2.0, 3.0]</code>, became <code>[-1.0, 0.0, 1.0]</code>. Similarly, the rest of the columns match their expected values.</p> In\u00a0[\u00a0]: Copied! <pre>transformed_data\n</pre> transformed_data <p>Both <code>raw_data</code> and <code>transformed_data</code> are datasets. The next two sections show how the Beam implementation represents datasets and how to read and write data to disk. The other return value, <code>transform_fn</code>, represents the transformation applied to the data, covered in detail below.</p> <p>The <code>tft_beam.AnalyzeAndTransformDataset</code> class is the composition of the two fundamental transforms provided by the implementation <code>tft_beam.AnalyzeDataset</code> and <code>tft_beam.TransformDataset</code>. So the following two code snippets are equivalent:</p> In\u00a0[\u00a0]: Copied! <pre>my_data = (raw_data, raw_data_metadata)\n</pre> my_data = (raw_data, raw_data_metadata) In\u00a0[\u00a0]: Copied! <pre>with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n  transformed_data, transform_fn = (\n      my_data | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\n</pre> with tft_beam.Context(temp_dir=tempfile.mkdtemp()):   transformed_data, transform_fn = (       my_data | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn)) In\u00a0[\u00a0]: Copied! <pre>with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n  transform_fn = my_data | tft_beam.AnalyzeDataset(preprocessing_fn)\n  transformed_data = (my_data, transform_fn) | tft_beam.TransformDataset()\n</pre> with tft_beam.Context(temp_dir=tempfile.mkdtemp()):   transform_fn = my_data | tft_beam.AnalyzeDataset(preprocessing_fn)   transformed_data = (my_data, transform_fn) | tft_beam.TransformDataset() <p><code>transform_fn</code> is a pure function that represents an operation that is applied to each row of the dataset. In particular, the analyzer values are already computed and treated as constants. In the example, the <code>transform_fn</code> contains as constants the mean of column <code>x</code>, the min and max of column <code>y</code>, and the vocabulary used to map the strings to integers.</p> <p>An important feature of <code>tf.Transform</code> is that <code>transform_fn</code> represents a map over rows\u2014it is a pure function applied to each row separately. All of the computation for aggregating rows is done in <code>AnalyzeDataset</code>. Furthermore, the <code>transform_fn</code> is represented as a TensorFlow <code>Graph</code> which can be embedded into the serving graph.</p> <p><code>AnalyzeAndTransformDataset</code> is provided for optimizations in this special case. This is the same pattern used in scikit-learn, providing the <code>fit</code>, <code>transform</code>, and <code>fit_transform</code> methods.</p> <ul> <li>If <code>raw_data_metadata</code> is a <code>dataset_metadata.DatasetMetadata</code> (see below, \"The 'instance dict' format\" section), then <code>raw_data</code> is expected to be in the \"instance dict\" format.</li> <li>If <code>raw_data_metadata</code> is a <code>tfxio.TensorAdapterConfig</code> (see below, \"The TFXIO format\" section), then <code>raw_data</code> is expected to be in the TFXIO format.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>import tensorflow_transform as tft\n\nraw_data_metadata = tft.DatasetMetadata.from_feature_spec({\n        's': tf.io.FixedLenFeature([], tf.string),\n        'y': tf.io.FixedLenFeature([], tf.float32),\n        'x': tf.io.FixedLenFeature([], tf.float32),\n    })\n</pre> import tensorflow_transform as tft  raw_data_metadata = tft.DatasetMetadata.from_feature_spec({         's': tf.io.FixedLenFeature([], tf.string),         'y': tf.io.FixedLenFeature([], tf.float32),         'x': tf.io.FixedLenFeature([], tf.float32),     }) <p>The <code>Schema</code> proto contains the information needed to parse the data from its on-disk or in-memory format, into tensors. It is typically constructed by calling <code>schema_utils.schema_from_feature_spec</code> with a dict mapping feature keys to <code>tf.io.FixedLenFeature</code>, <code>tf.io.VarLenFeature</code>, and <code>tf.io.SparseFeature</code> values. See the documentation for <code>tf.parse_example</code> for more details.</p> <p>Above we use <code>tf.io.FixedLenFeature</code> to indicate that each feature contains a fixed number of values, in this case a single scalar value. Because <code>tf.Transform</code> batches instances, the actual <code>Tensor</code> representing the feature will have shape <code>(None,)</code> where the unknown dimension is the batch dimension.</p> In\u00a0[\u00a0]: Copied! <pre>import pyarrow as pa\n\nraw_data = [\n    pa.record_batch(\n    data=[\n        pa.array([[1], [2], [3]], pa.list_(pa.float32())),\n        pa.array([[1], [2], [3]], pa.list_(pa.float32())),\n        pa.array([['hello'], ['world'], ['hello']], pa.list_(pa.binary())),\n    ],\n    names=['x', 'y', 's'])\n]\n</pre> import pyarrow as pa  raw_data = [     pa.record_batch(     data=[         pa.array([[1], [2], [3]], pa.list_(pa.float32())),         pa.array([[1], [2], [3]], pa.list_(pa.float32())),         pa.array([['hello'], ['world'], ['hello']], pa.list_(pa.binary())),     ],     names=['x', 'y', 's']) ] <p>Similar to the <code>dataset_metadata.DatasetMetadata</code> instance that accompanies the \"instance dict\" format, a <code>tfxio.TensorAdapterConfig</code> is must accompany the <code>RecordBatch</code>es. It consists of the Arrow schema of the <code>RecordBatch</code>es, and <code>tfxio.TensorRepresentations</code> to uniquely determine how columns in <code>RecordBatch</code>es can be interpreted as TensorFlow Tensors (including but not limited to <code>tf.Tensor</code>, <code>tf.SparseTensor</code>).</p> <p><code>tfxio.TensorRepresentations</code> is type alias for a <code>Dict[str, tensorflow_metadata.proto.v0.schema_pb2.TensorRepresentation]</code> which establishes the relationship between a Tensor that a <code>preprocessing_fn</code> accepts and columns in the <code>RecordBatch</code>es. For example:</p> In\u00a0[\u00a0]: Copied! <pre>from google.protobuf import text_format\nfrom tensorflow_metadata.proto.v0 import schema_pb2\n\ntensor_representation = {\n    'x': text_format.Parse(\n        \"\"\"dense_tensor { column_name: \"col1\" shape { dim { size: 2 } } }\"\"\",\n        schema_pb2.TensorRepresentation())\n}\n</pre> from google.protobuf import text_format from tensorflow_metadata.proto.v0 import schema_pb2  tensor_representation = {     'x': text_format.Parse(         \"\"\"dense_tensor { column_name: \"col1\" shape { dim { size: 2 } } }\"\"\",         schema_pb2.TensorRepresentation()) } <p>Means that <code>inputs['x']</code> in <code>preprocessing_fn</code> should be a dense <code>tf.Tensor</code>, whose values come from a column of name <code>'col1'</code> in the input <code>RecordBatch</code>es, and its (batched) shape should be <code>[batch_size, 2]</code>.</p> <p>A <code>schema_pb2.TensorRepresentation</code> is a Protobuf defined in TensorFlow Metadata.</p> In\u00a0[\u00a0]: Copied! <pre>!wget https://storage.googleapis.com/artifacts.tfx-oss-public.appspot.com/datasets/census/adult.data\n</pre> !wget https://storage.googleapis.com/artifacts.tfx-oss-public.appspot.com/datasets/census/adult.data In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\n\ntrain_data_file = \"adult.data\"\n</pre> import pandas as pd  train_data_file = \"adult.data\" <p>There's some configuration code hidden in the cell below.</p> In\u00a0[\u00a0]: Copied! <pre>#@title\nORDERED_CSV_COLUMNS = [\n    'age', 'workclass', 'fnlwgt', 'education', 'education-num',\n    'marital-status', 'occupation', 'relationship', 'race', 'sex',\n    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'label'\n]\n\nCATEGORICAL_FEATURE_KEYS = [\n    'workclass',\n    'education',\n    'marital-status',\n    'occupation',\n    'relationship',\n    'race',\n    'sex',\n    'native-country',\n]\n\nNUMERIC_FEATURE_KEYS = [\n    'age',\n    'capital-gain',\n    'capital-loss',\n    'hours-per-week',\n    'education-num',\n]\n\nLABEL_KEY = 'label'\n\nRAW_DATA_FEATURE_SPEC = dict(\n    [(name, tf.io.FixedLenFeature([], tf.string))\n     for name in CATEGORICAL_FEATURE_KEYS] +\n    [(name, tf.io.FixedLenFeature([], tf.float32))\n     for name in NUMERIC_FEATURE_KEYS] +\n    [(LABEL_KEY, tf.io.FixedLenFeature([], tf.string))]\n)\n\nSCHEMA = tft.tf_metadata.dataset_metadata.DatasetMetadata(\n    tft.tf_metadata.schema_utils.schema_from_feature_spec(RAW_DATA_FEATURE_SPEC)).schema\n</pre> #@title ORDERED_CSV_COLUMNS = [     'age', 'workclass', 'fnlwgt', 'education', 'education-num',     'marital-status', 'occupation', 'relationship', 'race', 'sex',     'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'label' ]  CATEGORICAL_FEATURE_KEYS = [     'workclass',     'education',     'marital-status',     'occupation',     'relationship',     'race',     'sex',     'native-country', ]  NUMERIC_FEATURE_KEYS = [     'age',     'capital-gain',     'capital-loss',     'hours-per-week',     'education-num', ]  LABEL_KEY = 'label'  RAW_DATA_FEATURE_SPEC = dict(     [(name, tf.io.FixedLenFeature([], tf.string))      for name in CATEGORICAL_FEATURE_KEYS] +     [(name, tf.io.FixedLenFeature([], tf.float32))      for name in NUMERIC_FEATURE_KEYS] +     [(LABEL_KEY, tf.io.FixedLenFeature([], tf.string))] )  SCHEMA = tft.tf_metadata.dataset_metadata.DatasetMetadata(     tft.tf_metadata.schema_utils.schema_from_feature_spec(RAW_DATA_FEATURE_SPEC)).schema In\u00a0[\u00a0]: Copied! <pre>pd.read_csv(train_data_file, names = ORDERED_CSV_COLUMNS).head()\n</pre> pd.read_csv(train_data_file, names = ORDERED_CSV_COLUMNS).head() <p>The columns of the dataset are either categorical or numeric. This dataset describes a classification problem: predicting the last column where the individual earns more or less than 50K per year. However, from the perspective of <code>tf.Transform</code>, this label is just another categorical column.</p> <p>We use a Pre-canned <code>tfxio.BeamRecordCsvTFXIO</code> to translate the CSV lines into <code>RecordBatches</code>. <code>TFXIO</code> requires two important piece of information:</p> <ul> <li>a TensorFlow Metadata Schema,<code>tfmd.proto.v0.shema_pb2</code>, that contains type and shape information about each CSV column. <code>schema_pb2.TensorRepresentation</code>s are an optional part of the Schema; if not provided (which is the case in this example), they will be inferred from the type and shape information. One can get the Schema either by using a helper function we provide to translate from TF parsing specs (shown in this example), or by running TensorFlow Data Validation.</li> <li>a list of column names, in the order they appear in the CSV file. Note that those names must match the feature names in the Schema.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>!pip install -U -q tfx_bsl\n</pre> !pip install -U -q tfx_bsl In\u00a0[\u00a0]: Copied! <pre>from tfx_bsl.public import tfxio\nfrom tfx_bsl.coders.example_coder import RecordBatchToExamples\n\nimport apache_beam as beam\n</pre> from tfx_bsl.public import tfxio from tfx_bsl.coders.example_coder import RecordBatchToExamples  import apache_beam as beam In\u00a0[\u00a0]: Copied! <pre>pipeline = beam.Pipeline()\n\ncsv_tfxio = tfxio.BeamRecordCsvTFXIO(\n    physical_format='text', column_names=ORDERED_CSV_COLUMNS, schema=SCHEMA)\n\nraw_data = (\n    pipeline\n    | 'ReadTrainData' &gt;&gt; beam.io.ReadFromText(\n        train_data_file, coder=beam.coders.BytesCoder())\n    | 'FixCommasTrainData' &gt;&gt; beam.Map(\n        lambda line: line.replace(b', ', b','))\n    | 'DecodeTrainData' &gt;&gt; csv_tfxio.BeamSource())\n</pre> pipeline = beam.Pipeline()  csv_tfxio = tfxio.BeamRecordCsvTFXIO(     physical_format='text', column_names=ORDERED_CSV_COLUMNS, schema=SCHEMA)  raw_data = (     pipeline     | 'ReadTrainData' &gt;&gt; beam.io.ReadFromText(         train_data_file, coder=beam.coders.BytesCoder())     | 'FixCommasTrainData' &gt;&gt; beam.Map(         lambda line: line.replace(b', ', b','))     | 'DecodeTrainData' &gt;&gt; csv_tfxio.BeamSource()) In\u00a0[\u00a0]: Copied! <pre>raw_data\n</pre> raw_data <p>Note that we had to do some additional fix-ups after the CSV lines are read in. Otherwise, we could rely on the <code>tfxio.CsvTFXIO</code> to handle both reading the files and translating to <code>RecordBatch</code>es:</p> In\u00a0[\u00a0]: Copied! <pre>csv_tfxio = tfxio.CsvTFXIO(train_data_file,\n                           telemetry_descriptors=[], #???\n                           column_names=ORDERED_CSV_COLUMNS,\n                           schema=SCHEMA)\n\np2 = beam.Pipeline()\nraw_data_2 = p2 | 'TFXIORead' &gt;&gt; csv_tfxio.BeamSource()\n</pre> csv_tfxio = tfxio.CsvTFXIO(train_data_file,                            telemetry_descriptors=[], #???                            column_names=ORDERED_CSV_COLUMNS,                            schema=SCHEMA)  p2 = beam.Pipeline() raw_data_2 = p2 | 'TFXIORead' &gt;&gt; csv_tfxio.BeamSource() <p>Preprocessing for this dataset is similar to the previous example, except the preprocessing function is programmatically generated instead of manually specifying each column. In the preprocessing function below, <code>NUMERICAL_COLUMNS</code> and <code>CATEGORICAL_COLUMNS</code> are lists that contain the names of the numeric and categorical columns:</p> In\u00a0[\u00a0]: Copied! <pre>NUM_OOV_BUCKETS = 1\n\ndef preprocessing_fn(inputs):\n  \"\"\"Preprocess input columns into transformed columns.\"\"\"\n  # Since we are modifying some features and leaving others unchanged, we\n  # start by setting `outputs` to a copy of `inputs.\n  outputs = inputs.copy()\n\n  # Scale numeric columns to have range [0, 1].\n  for key in NUMERIC_FEATURE_KEYS:\n    outputs[key] = tft.scale_to_0_1(outputs[key])\n\n  # For all categorical columns except the label column, we generate a\n  # vocabulary but do not modify the feature.  This vocabulary is instead\n  # used in the trainer, by means of a feature column, to convert the feature\n  # from a string to an integer id.\n  for key in CATEGORICAL_FEATURE_KEYS:\n    outputs[key] = tft.compute_and_apply_vocabulary(\n        tf.strings.strip(inputs[key]),\n        num_oov_buckets=NUM_OOV_BUCKETS,\n        vocab_filename=key)\n\n  # For the label column we provide the mapping from string to index.\n  with tf.init_scope():\n    # `init_scope` - Only initialize the table once.\n    initializer = tf.lookup.KeyValueTensorInitializer(\n        keys=['&gt;50K', '&lt;=50K'],\n        values=tf.cast(tf.range(2), tf.int64),\n        key_dtype=tf.string,\n        value_dtype=tf.int64)\n    table = tf.lookup.StaticHashTable(initializer, default_value=-1)\n\n  outputs[LABEL_KEY] = table.lookup(outputs[LABEL_KEY])\n\n  return outputs\n</pre> NUM_OOV_BUCKETS = 1  def preprocessing_fn(inputs):   \"\"\"Preprocess input columns into transformed columns.\"\"\"   # Since we are modifying some features and leaving others unchanged, we   # start by setting `outputs` to a copy of `inputs.   outputs = inputs.copy()    # Scale numeric columns to have range [0, 1].   for key in NUMERIC_FEATURE_KEYS:     outputs[key] = tft.scale_to_0_1(outputs[key])    # For all categorical columns except the label column, we generate a   # vocabulary but do not modify the feature.  This vocabulary is instead   # used in the trainer, by means of a feature column, to convert the feature   # from a string to an integer id.   for key in CATEGORICAL_FEATURE_KEYS:     outputs[key] = tft.compute_and_apply_vocabulary(         tf.strings.strip(inputs[key]),         num_oov_buckets=NUM_OOV_BUCKETS,         vocab_filename=key)    # For the label column we provide the mapping from string to index.   with tf.init_scope():     # `init_scope` - Only initialize the table once.     initializer = tf.lookup.KeyValueTensorInitializer(         keys=['&gt;50K', '&lt;=50K'],         values=tf.cast(tf.range(2), tf.int64),         key_dtype=tf.string,         value_dtype=tf.int64)     table = tf.lookup.StaticHashTable(initializer, default_value=-1)    outputs[LABEL_KEY] = table.lookup(outputs[LABEL_KEY])    return outputs <p>One difference from the previous example is the label column manually specifies the mapping from the string to an index. So <code>'&gt;50'</code> is mapped to <code>0</code> and <code>'&lt;=50K'</code> is mapped to <code>1</code> because it's useful to know which index in the trained model corresponds to which label.</p> <p>The <code>record_batches</code> variable represents a <code>PCollection</code> of <code>pyarrow.RecordBatch</code>es. The <code>tensor_adapter_config</code> is given by <code>csv_tfxio</code>, which is inferred from <code>SCHEMA</code> (and ultimately, in this example, from the TF parsing specs).</p> <p>The final stage is to write the transformed data to disk and has a similar form to reading the raw data. The schema used to do this is part of the output of <code>tft_beam.AnalyzeAndTransformDataset</code> which infers a schema for the output data. The code to write to disk is shown below. The schema is a part of the metadata but uses the two interchangeably in the <code>tf.Transform</code> API (i.e. pass the metadata to the <code>tft.coders.ExampleProtoCoder</code>). Be aware that this writes to a different format. Instead of <code>textio.WriteToText</code>, use Beam's built-in support for the <code>TFRecord</code> format and use a coder to encode the data as <code>Example</code> protos. This is a better format to use for training, as shown in the next section. <code>transformed_eval_data_base</code> provides the base filename for the individual shards that are written.</p> In\u00a0[\u00a0]: Copied! <pre>raw_dataset = (raw_data, csv_tfxio.TensorAdapterConfig())\n</pre> raw_dataset = (raw_data, csv_tfxio.TensorAdapterConfig()) In\u00a0[\u00a0]: Copied! <pre>working_dir = tempfile.mkdtemp()\nwith tft_beam.Context(temp_dir=working_dir):\n  transformed_dataset, transform_fn = (\n      raw_dataset | tft_beam.AnalyzeAndTransformDataset(\n          preprocessing_fn, output_record_batches=True))\n</pre> working_dir = tempfile.mkdtemp() with tft_beam.Context(temp_dir=working_dir):   transformed_dataset, transform_fn = (       raw_dataset | tft_beam.AnalyzeAndTransformDataset(           preprocessing_fn, output_record_batches=True)) In\u00a0[\u00a0]: Copied! <pre>output_dir = tempfile.mkdtemp()\n</pre> output_dir = tempfile.mkdtemp() In\u00a0[\u00a0]: Copied! <pre>transformed_data, _ = transformed_dataset\n\n_ = (\n    transformed_data\n    | 'EncodeTrainData' &gt;&gt;\n    beam.FlatMapTuple(lambda batch, _: RecordBatchToExamples(batch))\n    | 'WriteTrainData' &gt;&gt; beam.io.WriteToTFRecord(\n        os.path.join(output_dir , 'transformed.tfrecord')))\n</pre> transformed_data, _ = transformed_dataset  _ = (     transformed_data     | 'EncodeTrainData' &gt;&gt;     beam.FlatMapTuple(lambda batch, _: RecordBatchToExamples(batch))     | 'WriteTrainData' &gt;&gt; beam.io.WriteToTFRecord(         os.path.join(output_dir , 'transformed.tfrecord'))) <p>In addition to the training data, <code>transform_fn</code> is also written out with the metadata:</p> In\u00a0[\u00a0]: Copied! <pre>_ = (\n    transform_fn\n    | 'WriteTransformFn' &gt;&gt; tft_beam.WriteTransformFn(output_dir))\n</pre> _ = (     transform_fn     | 'WriteTransformFn' &gt;&gt; tft_beam.WriteTransformFn(output_dir)) <p>Run the entire Beam pipeline with <code>pipeline.run().wait_until_finish()</code>. Up until this point, the Beam pipeline represents a deferred, distributed computation. It provides instructions for what will be done, but the instructions have not been executed. This final call executes the specified pipeline.</p> In\u00a0[\u00a0]: Copied! <pre>result = pipeline.run().wait_until_finish()\n</pre> result = pipeline.run().wait_until_finish() <p>After running the pipeline the output directory contains two artifacts.</p> <ul> <li>The transformed data, and the metadata describing it.</li> <li>The <code>tf.saved_model</code> containing the resulting <code>preprocessing_fn</code></li> </ul> In\u00a0[\u00a0]: Copied! <pre>!ls {output_dir}\n</pre> !ls {output_dir} <p>To see how to use these artifacts refer to the Advanced preprocessing tutorial.</p>"},{"location":"get_started/#get-started-with-tensorflow-transform","title":"Get Started with TensorFlow Transform\u00b6","text":""},{"location":"get_started/#setup","title":"Setup\u00b6","text":""},{"location":"get_started/#define-a-preprocessing-function","title":"Define a preprocessing function\u00b6","text":"<p>The preprocessing function is the most important concept of <code>tf.Transform</code>. The preprocessing function is a logical description of a transformation of the dataset. The preprocessing function accepts and returns a dictionary of tensors, where a tensor means <code>Tensor</code> or <code>SparseTensor</code>. There are two kinds of functions used to define the preprocessing function:</p> <ol> <li>Any function that accepts and returns tensors. These add TensorFlow operations to the graph that transform raw data into transformed data.</li> <li>Any of the analyzers provided by <code>tf.Transform</code>. Analyzers also accept and return tensors, but unlike TensorFlow functions, they do not add operations to the graph. Instead, analyzers cause <code>tf.Transform</code> to compute a full-pass operation outside of TensorFlow. They use the input tensor values over the entire dataset to generate a constant tensor that is returned as the output. For example, <code>tft.min</code> computes the minimum of a tensor over the dataset. <code>tf.Transform</code> provides a fixed set of analyzers, but this will be extended in future versions.</li> </ol>"},{"location":"get_started/#preprocessing-function-example","title":"Preprocessing function example\u00b6","text":"<p>By combining analyzers and regular TensorFlow functions, users can create flexible pipelines for transforming data. The following preprocessing function transforms each of the three features in different ways, and combines two of the features:</p>"},{"location":"get_started/#batching","title":"Batching\u00b6","text":"<p>Batching is an important part of TensorFlow. Since one of the goals of <code>tf.Transform</code> is to provide a TensorFlow graph for preprocessing that can be incorporated into the serving graph (and, optionally, the training graph), batching is also an important concept in <code>tf.Transform</code>.</p> <p>While not obvious in the example above, the user defined preprocessing function is passed tensors representing batches and not individual instances, as happens during training and serving with TensorFlow. On the other hand, analyzers perform a computation over the entire dataset that returns a single value and not a batch of values. <code>x</code> is a <code>Tensor</code> with a shape of <code>(batch_size,)</code>, while <code>tft.mean(x)</code> is a <code>Tensor</code> with a shape of <code>()</code>. The subtraction <code>x - tft.mean(x)</code> broadcasts where the value of <code>tft.mean(x)</code> is subtracted from every element of the batch represented by <code>x</code>.</p>"},{"location":"get_started/#apache-beam-implementation","title":"Apache Beam Implementation\u00b6","text":"<p>While the preprocessing function is intended as a logical description of a preprocessing pipeline implemented on multiple data processing frameworks, <code>tf.Transform</code> provides a canonical implementation used on Apache Beam. This implementation demonstrates the functionality required from an implementation. There is no formal API for this functionality, so each implementation can use an API that is idiomatic for its particular data processing framework.</p> <p>The Apache Beam implementation provides two <code>PTransform</code>s used to process data for a preprocessing function. The following shows the usage for the composite <code>PTransform</code> - <code>tft_beam.AnalyzeAndTransformDataset</code>:</p>"},{"location":"get_started/#data-formats-and-schema","title":"Data Formats and Schema\u00b6","text":"<p>TFT Beam implementation accepts two different input data formats. The \"instance dict\" format (as seen in the example above and simple.ipynb &amp; simple_example.py) is an intuitive format and is suitable for small datasets while the TFXIO (Apache Arrow) format provides improved performance and is suitble for large datasets.</p> <p>The \"metadata\" accompanying the <code>PCollection</code> tells the Beam implementation the format of the <code>PCollection</code>.</p> <pre><code>(raw_data, raw_data_metadata) | tft.AnalyzeDataset(...)\n</code></pre>"},{"location":"get_started/#the-instance-dict-format","title":"The \"instance dict\" format\u00b6","text":"<p>The previous code examples used this format. The metadata contains the schema that defines the layout of the data and how it is read from and written to various formats. Even this in-memory format is not self-describing and requires the schema in order to be interpreted as tensors.</p> <p>Again, here is the definition of the schema for the example data:</p>"},{"location":"get_started/#the-tfxio-format","title":"The TFXIO format\u00b6","text":"<p>With this format, the data is expected to be contained in a <code>pyarrow.RecordBatch</code>. For tabular data, our Apache Beam implementation accepts Arrow <code>RecordBatch</code>es that consist of columns of the following types:</p> <ul> <li><p><code>pa.list_(&lt;primitive&gt;)</code>, where <code>&lt;primitive&gt;</code> is <code>pa.int64()</code>, <code>pa.float32()</code> <code>pa.binary()</code> or <code>pa.large_binary()</code>.</p> </li> <li><p><code>pa.large_list(&lt;primitive&gt;)</code></p> </li> </ul> <p>The toy input dataset we used above, when represented as a <code>RecordBatch</code>, looks like the following:</p>"},{"location":"get_started/#compatibility-with-tensorflow","title":"Compatibility with TensorFlow\u00b6","text":"<p><code>tf.Transform</code> provides support for exporting the <code>transform_fn</code> as a SavedModel, see the simple tutorial for an example. The default behavior before the <code>0.30</code> release exported a TF 1.x SavedModel. Starting with the <code>0.30</code> release, the default behavior is to export a TF 2.x SavedModel unless TF 2.x behaviors are explicitly disabled (by calling <code>tf.compat.v1.disable_v2_behavior()</code>).</p> <p>If using TF 1.x concepts such as <code>tf.estimator</code> and <code>tf.Sessions</code>, you can retain the previous behavior by passing <code>force_tf_compat_v1=True</code> to <code>tft_beam.Context</code> if using <code>tf.Transform</code> as a standalone library or to the Transform component in TFX.</p> <p>When exporting the <code>transform_fn</code> as a TF 2.x SavedModel, the <code>preprocessing_fn</code> is expected to be traceable using <code>tf.function</code>. Additionally, if running your pipeline remotely (for example with the <code>DataflowRunner</code>), ensure that the <code>preprocessing_fn</code> and any dependencies are packaged properly as described here.</p> <p>Known issues with using <code>tf.Transform</code> to export a TF 2.x SavedModel are documented here.</p>"},{"location":"get_started/#input-and-output-with-apache-beam","title":"Input and output with Apache Beam\u00b6","text":"<p>So far, we've seen input and output data in python lists (of <code>RecordBatch</code>es or instance dictionaries). This is a simplification that relies on Apache Beam's ability to work with lists as well as its main representation of data, the <code>PCollection</code>.</p> <p>A <code>PCollection</code> is a data representation that forms a part of a Beam pipeline. A Beam pipeline is formed by applying various <code>PTransform</code>s, including <code>AnalyzeDataset</code> and <code>TransformDataset</code>, and running the pipeline. A <code>PCollection</code> is not created in the memory of the main binary, but instead is distributed among the workers (although this section uses the in-memory execution mode).</p>"},{"location":"get_started/#pre-canned-pcollection-sources-tfxio","title":"Pre-canned <code>PCollection</code> Sources (<code>TFXIO</code>)\u00b6","text":"<p>The <code>RecordBatch</code> format that our implementation accepts is a common format that other TFX libraries accept. Therefore TFX offers convenient \"sources\" (a.k.a <code>TFXIO</code>) that read files of various formats on disk and produce <code>RecordBatch</code>es and can also give <code>tfxio.TensorAdapterConfig</code>, including inferred <code>tfxio.TensorRepresentations</code>.</p> <p>Those <code>TFXIO</code>s can be found in package <code>tfx_bsl</code> (<code>tfx_bsl.public.tfxio</code>).</p>"},{"location":"get_started/#example-census-income-dataset","title":"Example: \"Census Income\" dataset\u00b6","text":"<p>The following example requires both reading and writing data on disk and representing data as a <code>PCollection</code> (not a list), see: <code>census_example.py</code>. Below we show how to download the data and run this example. The \"Census Income\" dataset is provided by the UCI Machine Learning Repository. This dataset contains both categorical and numeric data.</p> <p>Here is some code to download and preview this data:</p>"},{"location":"install/","title":"Install","text":"<p>{% setvar github_path %}tensorflow/transform{% endsetvar %}</p>"},{"location":"install/#tensorflow-transform","title":"TensorFlow Transform","text":"<p>TensorFlow Transform is a library for preprocessing data with TensorFlow. <code>tf.Transform</code> is useful for data that requires a full-pass, such as:</p> <ul> <li>Normalize an input value by mean and standard deviation.</li> <li>Convert strings to integers by generating a vocabulary over all input values.</li> <li>Convert floats to integers by assigning them to buckets based on the observed   data distribution.</li> </ul> <p>TensorFlow has built-in support for manipulations on a single example or a batch of examples. <code>tf.Transform</code> extends these capabilities to support full-passes over the example data.</p> <p>The output of <code>tf.Transform</code> is exported as a TensorFlow graph to use for training and serving. Using the same graph for both training and serving can prevent skew since the same transformations are applied in both stages.</p> <p>For an introduction to <code>tf.Transform</code>, see the <code>tf.Transform</code> section of the TFX Dev Summit talk on TFX (link).</p>"},{"location":"install/#installation","title":"Installation","text":"<p>The <code>tensorflow-transform</code> PyPI package is the recommended way to install <code>tf.Transform</code>:</p> <pre><code>pip install tensorflow-transform\n</code></pre>"},{"location":"install/#build-tft-from-source","title":"Build TFT from source","text":"<p>To build from source follow the following steps: Create a virtual environment by running the commands</p> <pre><code>python3 -m venv &lt;virtualenv_name&gt;\nsource &lt;virtualenv_name&gt;/bin/activate\npip3 install setuptools wheel\ngit clone https://github.com/tensorflow/transform.git\ncd transform\npython3 setup.py bdist_wheel\n</code></pre> <p>This will build the TFT wheel in the dist directory. To install the wheel from dist directory run the commands</p> <pre><code>cd dist\npip3 install tensorflow_transform-&lt;version&gt;-py3-none-any.whl\n</code></pre>"},{"location":"install/#nightly-packages","title":"Nightly Packages","text":"<p>TFT also hosts nightly packages at https://pypi-nightly.tensorflow.org on Google Cloud. To install the latest nightly package, please use the following command:</p> <pre><code>pip install --extra-index-url https://pypi-nightly.tensorflow.org/simple tensorflow-transform\n</code></pre> <p>This will install the nightly packages for the major dependencies of TFT such as TensorFlow Metadata (TFMD), TFX Basic Shared Libraries (TFX-BSL).</p> <p>Note: These nightly packages are unstable and breakages are likely to happen. The fix could often take a week or more depending on the complexity involved.</p>"},{"location":"install/#notable-dependencies","title":"Notable Dependencies","text":"<p>TensorFlow is required.</p> <p>Apache Beam is required; it's the way that efficient distributed computation is supported. By default, Apache Beam runs in local mode but can also run in distributed mode using Google Cloud Dataflow and other Apache Beam runners.</p> <p>Apache Arrow is also required. TFT uses Arrow to represent data internally in order to make use of vectorized numpy functions.</p>"},{"location":"install/#compatible-versions","title":"Compatible versions","text":"<p>The following table is the <code>tf.Transform</code> package versions that are compatible with each other. This is determined by our testing framework, but other untested combinations may also work.</p> tensorflow-transform apache-beam[gcp] pyarrow tensorflow tensorflow-metadata tfx-bsl GitHub master 2.65.0 10.0.1 nightly (2.x) 1.17.1 1.17.1 1.17.0 2.65.0 10.0.1 2.17 1.17.1 1.17.1 1.16.0 2.60.0 10.0.1 2.16 1.16.1 1.16.1 1.15.0 2.47.0 10.0.0 2.15 1.15.0 1.15.1 1.14.0 2.47.0 10.0.0 2.13 1.14.0 1.14.0 1.13.0 2.41.0 6.0.0 2.12 1.13.1 1.13.0 1.12.0 2.41.0 6.0.0 2.11 1.12.0 1.12.0 1.11.0 2.41.0 6.0.0 1.15.5 / 2.10 1.11.0 1.11.0 1.10.0 2.40.0 6.0.0 1.15.5 / 2.9 1.10.0 1.10.0 1.9.0 2.38.0 5.0.0 1.15.5 / 2.9 1.9.0 1.9.0 1.8.0 2.38.0 5.0.0 1.15.5 / 2.8 1.8.0 1.8.0 1.7.0 2.36.0 5.0.0 1.15.5 / 2.8 1.7.0 1.7.0 1.6.1 2.35.0 5.0.0 1.15.5 / 2.8 1.6.0 1.6.0 1.6.0 2.35.0 5.0.0 1.15.5 / 2.7 1.6.0 1.6.0 1.5.0 2.34.0 5.0.0 1.15.2 / 2.7 1.5.0 1.5.0 1.4.1 2.33.0 4.0.1 1.15.2 / 2.6 1.4.0 1.4.0 1.4.0 2.33.0 4.0.1 1.15.2 / 2.6 1.4.0 1.4.0 1.3.0 2.31.0 2.0.0 1.15.2 / 2.6 1.2.0 1.3.0 1.2.0 2.31.0 2.0.0 1.15.2 / 2.5 1.2.0 1.2.0 1.1.1 2.29.0 2.0.0 1.15.2 / 2.5 1.1.0 1.1.1 1.1.0 2.29.0 2.0.0 1.15.2 / 2.5 1.1.0 1.1.0 1.0.0 2.29.0 2.0.0 1.15 / 2.5 1.0.0 1.0.0 0.30.0 2.28.0 2.0.0 1.15 / 2.4 0.30.0 0.30.0 0.29.0 2.28.0 2.0.0 1.15 / 2.4 0.29.0 0.29.0 0.28.0 2.28.0 2.0.0 1.15 / 2.4 0.28.0 0.28.1 0.27.0 2.27.0 2.0.0 1.15 / 2.4 0.27.0 0.27.0 0.26.0 2.25.0 0.17.0 1.15 / 2.3 0.26.0 0.26.0 0.25.0 2.25.0 0.17.0 1.15 / 2.3 0.25.0 0.25.0 0.24.1 2.24.0 0.17.0 1.15 / 2.3 0.24.0 0.24.1 0.24.0 2.23.0 0.17.0 1.15 / 2.3 0.24.0 0.24.0 0.23.0 2.23.0 0.17.0 1.15 / 2.3 0.23.0 0.23.0 0.22.0 2.20.0 0.16.0 1.15 / 2.2 0.22.0 0.22.0 0.21.2 2.17.0 0.15.0 1.15 / 2.1 0.21.0 0.21.3 0.21.0 2.17.0 0.15.0 1.15 / 2.1 0.21.0 0.21.0 0.15.0 2.16.0 0.14.0 1.15 / 2.0 0.15.0 0.15.0 0.14.0 2.14.0 0.14.0 1.14 0.14.0 n/a 0.13.0 2.11.0 n/a 1.13 0.12.1 n/a 0.12.0 2.10.0 n/a 1.12 0.12.0 n/a 0.11.0 2.8.0 n/a 1.11 0.9.0 n/a 0.9.0 2.6.0 n/a 1.9 0.9.0 n/a 0.8.0 2.5.0 n/a 1.8 n/a n/a 0.6.0 2.4.0 n/a 1.6 n/a n/a 0.5.0 2.3.0 n/a 1.5 n/a n/a 0.4.0 2.2.0 n/a 1.4 n/a n/a 0.3.1 2.1.1 n/a 1.3 n/a n/a 0.3.0 2.1.1 n/a 1.3 n/a n/a 0.1.10 2.0.0 n/a 1.0 n/a n/a"},{"location":"install/#questions","title":"Questions","text":"<p>Please direct any questions about working with <code>tf.Transform</code> to Stack Overflow using the tensorflow-transform tag.</p>"},{"location":"tf2_support/","title":"Using tf.Transform with TensorFlow 2.x","text":"<p>Starting with the <code>0.30</code> release of <code>tf.Transform</code>, the default behavior is to export a TF 2.x SavedModel unless TF 2.x behaviors are explicitly disabled. This page provides a guide for using <code>tf.Transform</code> to export the transform graph as a TensorFlow 2.x SavedModel.</p>"},{"location":"tf2_support/#new-in-tftransform-with-tf-2x","title":"New in tf.Transform with TF 2.x","text":""},{"location":"tf2_support/#loading-keras-models-within-the-preprocessing_fn","title":"Loading Keras models within the <code>preprocessing_fn</code>","text":"<p>Please use the <code>tft.make_and_track_object</code> API to load Keras models as shown in the example below.</p> <pre><code>def preprocessing_fn(inputs):\n  keras_model = tft.make_and_track_object(lambda: tf.keras.models.load_model(...), name='_unique_name')\n  ...\n  return {'keras_model_output': keras_model(inputs[...])}\n</code></pre>"},{"location":"tf2_support/#using-tf-2x-tfhub-modules","title":"Using TF 2.x tf.hub modules","text":"<p>TF 2.x hub modules work in <code>tf.Transform</code> only when the <code>preprocessing_fn</code> is traced and exported as a TF 2.x SavedModel (this is the default behavior starting with <code>tensorflow_transform 0.30</code>). Please use the <code>tft.make_and_track_object</code> API to load <code>tf.hub</code> modules as shown in the example below.</p> <pre><code>def preprocessing_fn(inputs):\n  hub_module = tft.make_and_track_object(lambda: hub.load(...))\n  ...\n  return {'hub_module_output': hub_module(inputs[...])}\n</code></pre>"},{"location":"tf2_support/#potential-migration-issues","title":"Potential migration issues","text":"<p>If migrating an existing <code>tf.Transform</code> pipeline from TF 1.x to TF 2.x, the following issues may be encountered:</p>"},{"location":"tf2_support/#runtimeerror-the-order-of-analyzers-in-your-preprocessing_fn-appears-to-be-non-deterministic","title":"RuntimeError: The order of analyzers in your <code>preprocessing_fn</code> appears to be non-deterministic.","text":"<p>In TF 2.x, the <code>preprocessing_fn</code> provided by the user is traced several times. If the order in which TFT analyzers are encountered changes with each trace, this error will be raised. This can be fixed by removing any non-determinism in the order in which TFT analyzers are invoked.</p>"},{"location":"tf2_support/#output-of-transform_raw_features-does-not-contain-expected-feature","title":"Output of <code>transform_raw_features</code> does not contain expected feature.","text":"<p>Example exceptions:</p> <pre><code>KeyError: \\&lt;feature key&gt;\n</code></pre> <p>or</p> <pre><code>\\&lt;feature key&gt; not found in features dictionary.\n</code></pre> <p><code>TFTransformOutput.transform_raw_features</code> ignores the <code>drop_unused_features</code> parameter and behaves as if it were True. Please update any usages of the output dictionary from this API to check if the key you are attempting to retrieve exists in it.</p>"},{"location":"tf2_support/#tfestimatorbaselineclassifier-sees-table-not-initialized-error","title":"tf.estimator.BaselineClassifier sees Table not initialized error.","text":"<p>Example exception:</p> <pre><code>tensorflow.python.framework.errors_impl.FailedPreconditionError: Table not initialized.\n</code></pre> <p>Support for Trainer with Estimator based executor is best-effort. While other estimators work, we have seen issues with table initialization in the BaselineClassifier. Please disable TF 2.x in <code>tf.Transform</code>.</p>"},{"location":"tf2_support/#known-issues-features-not-yet-supported","title":"Known issues / Features not yet supported","text":""},{"location":"tf2_support/#outputting-vocabularies-in-tfrecord-format-is-not-yet-supported","title":"Outputting vocabularies in TFRecord format is not yet supported.","text":"<p><code>tfrecord_gzip</code> is not yet supported as a valid value for the <code>file_format</code> parameter in <code>tft.vocabulary</code> (and other vocabulary APIs).</p>"},{"location":"tf2_support/#retaining-the-legacy-tftransform-behavior","title":"Retaining the legacy tf.Transform behavior","text":"<p>If your <code>tf.Transform</code> pipeline should not run with TF 2.x, you can retain the legacy behavior in one of the following ways:</p> <ul> <li>Disable TF2 in <code>tf.Transform</code> by calling     <code>tf.compat.v1.disable_v2_behavior()</code></li> <li>Passing <code>force_tf_compat_v1=True</code> to <code>tft_beam.Context</code> if using     <code>tf.Transform</code> as a standalone library or to the Transform component in TFX.</li> </ul>"},{"location":"tft_bestpractices/","title":"Data preprocessing for ML: options and recommendations","text":"<p>This document is the first in a two-part series that explores the topic of data engineering and feature engineering for machine learning (ML), with a focus on supervised learning tasks. This first part discusses the best practices for preprocessing data in an ML pipeline on Google Cloud. The document focuses on using TensorFlow and the open source TensorFlow Transform (<code>tf.Transform</code>) library to prepare data, train the model, and serve the model for prediction. This document highlights the challenges of preprocessing data for ML, and it describes the options and scenarios for performing data transformation on Google Cloud effectively.</p> <p>This document assumes that you're familiar with BigQuery, Dataflow, Vertex AI, and the TensorFlow Keras API.</p> <p>The second document, Data preprocessing for ML with Google Cloud, provides a step-by-step tutorial for how to implement a <code>tf.Transform</code> pipeline.</p>"},{"location":"tft_bestpractices/#introduction","title":"Introduction","text":"<p>ML helps you automatically find complex and potentially useful patterns in data. These patterns are condensed in an ML model that can then be used on new data points---a process called making predictions or performing inference.</p> <p>Building an ML model is a multistep process. Each step presents its own technical and conceptual challenges. This two-part series focuses on supervised learning tasks and the process of selecting, transforming, and augmenting the source data to create powerful predictive signals to the target variable. These operations combine domain knowledge with data science techniques. The operations are the essence of feature engineering.</p> <p>The size of training datasets for real-world ML models can easily be equal to or greater than one terabyte (TB). Therefore, you need large-scale data processing frameworks in order to process these datasets efficiently and distributedly. When you use an ML model to make predictions, you have to apply the same transformations that you used for the training data on the new data points. By applying the same transformations, you present the live dataset to the ML model the way that the model expects.</p> <p>This document discusses these challenges for different levels of granularity of feature engineering operations: instance-level, full-pass, and time-window aggregations. This document also describes the options and scenarios to perform data transformation for ML on Google Cloud.</p> <p>This document also provides an overview of TensorFlow Transform (<code>tf.Transform</code>), a library for TensorFlow that lets you define both instance-level and full-pass data transformation through data preprocessing pipelines. These pipelines are executed with Apache Beam, and they create artifacts that let you apply the same transformations during prediction as when the model is served.</p>"},{"location":"tft_bestpractices/#preprocessing-data-for-ml","title":"Preprocessing data for ML","text":"<p>This section introduces data preprocessing operations and stages of data readiness. It also discusses the types of the preprocessing operations and their granularity.</p>"},{"location":"tft_bestpractices/#data-engineering-compared-to-feature-engineering","title":"Data engineering compared to feature engineering","text":"<p>Preprocessing the data for ML involves both data engineering and feature engineering. Data engineering is the process of converting raw data into prepared data. Feature engineering then tunes the prepared data to create the features that are expected by the ML model. These terms have the following meanings:</p> Raw data (or just data) The data in its source form, without any prior preparation for ML. In this context, the data might be in its raw form (in a data lake) or in a transformed form (in a data warehouse). Transformed data that's in a data warehouse might have been converted from its original raw form to be used for analytics. However, in this context, raw data means that the data hasn't been prepared specifically for your ML task. Data is also considered raw data if it's sent from streaming systems that eventually call ML models for predictions. Prepared data The dataset in the form ready for your ML task: data sources have been parsed, joined, and put into a tabular form. Prepared data is aggregated and summarized to the right granularity---for example, each row in the dataset represents a unique customer, and each column represents summary information for the customer, like the total spent in the last six weeks. In a prepared data table, irrelevant columns have been dropped, and invalid records have been filtered out. For supervised learning tasks, the target feature is present. Engineered features The dataset with the tuned features that are expected by the model---that is, features that are created by performing certain ML-specific operations on the columns in the prepared dataset, and creating new features for your model during training and prediction, as described later in Preprocessing operations. Examples of these operations include scaling numerical columns to a value between 0 and 1, clipping values, and one-hot-encoding categorical features. <p>The following diagram, figure 1, shows the steps that are involved in preparing preprocessed data:</p> <p>Figure 1: The flow of data from raw data to prepared data to engineered features to machine learning.</p> <p>In practice, data from the same source is often at different stages of readiness. For example, a field from a table in your data warehouse might be used directly as an engineered feature. At the same time, another field in the same table might need to go through transformations before it becomes an engineered feature. Similarly, data engineering and feature engineering operations might be combined in the same data preprocessing step.</p>"},{"location":"tft_bestpractices/#preprocessing-operations","title":"Preprocessing operations","text":"<p>Data preprocessing includes several operations. Each operation is designed to help ML build better predictive models. The details of these preprocessing operations are outside the scope of this document, but some operations are briefly described in this section.</p> <p>For structured data, data preprocessing operations include the following:</p> <ul> <li>Data cleansing: removing or correcting records that have corrupted or invalid values from raw data, and removing records that are missing a large number of columns.</li> <li>Instances selection and partitioning: selecting data points from the input dataset to create training, evaluation (validation), and test sets. This process includes techniques for repeatable random sampling, minority classes oversampling, and stratified partitioning.</li> <li>Feature tuning: improving the quality of a feature for ML, which includes scaling and normalizing numeric values, imputing missing values, clipping outliers, and adjusting values that have skewed distributions.</li> <li>Feature transformation: converting a numeric feature to a categorical feature (through bucketization), and converting categorical features to a numeric representation (through one-hot encoding, learning with counts, sparse feature embeddings, etc.). Some models work only with numeric or categorical features, while others can handle mixed type features. Even when models handle both types, they can benefit from different representations (numeric and categorical) of the same feature.</li> <li>Feature extraction: reducing the number of features by creating lower-dimension, more powerful data representations using techniques such as PCA, embedding extraction, and hashing.</li> <li>Feature selection: selecting a subset of the input features for training the model, and ignoring the irrelevant or redundant ones, using filter or wrapper methods. Feature selection can also involve simply dropping features if the features are missing a large number of values.</li> <li>Feature construction: creating new features by using typical techniques, such as polynomial expansion (by using univariate mathematical functions) or feature crossing (to capture feature interactions). Features can also be constructed by using business logic from the domain of the ML use case.</li> </ul> <p>When you work with unstructured data (for example, images, audio, or text documents), deep learning replaces domain-knowledge-based feature engineering by folding it into the model architecture. A convolutional layer is an automatic feature preprocessor. Constructing the right model architecture requires some empirical knowledge of the data. In addition, some amount of preprocessing is needed, such as the following:</p> <ul> <li>For text documents: stemming and lemmatization, TF-IDF calculation, and n-gram extraction, embedding lookup.</li> <li>For images: clipping, resizing, cropping, Gaussian blur, and canary filters.</li> <li>For all types of data (including text and images): transfer learning, which treats all-but-last layers of the fully trained model as a feature engineering step.</li> </ul>"},{"location":"tft_bestpractices/#preprocessing-granularity","title":"Preprocessing granularity","text":"<p>This section discusses the granularity of types of data transformations. It shows why this perspective is critical when preparing new data points for predictions using transformations that are applied on training data.</p> <p>Preprocessing and transformation operations can be categorized as follows, based on operation granularity:</p> <ul> <li> <p>Instance-level transformations during training and prediction. These are straightforward transformations, where only values from the same instance are needed for the transformation. For example, instance-level transformations might include clipping the value of a feature to some threshold, polynomially expanding another feature, multiplying two features, or comparing two features to create a Boolean flag.</p> <p>These transformations must be applied identically during training and prediction, because the model will be trained on the transformed features, not on the raw input values. If the data isn't transformed identically, then the model behaves poorly because it is presented with data that has a distribution of values that it wasn't trained with. For more information, see the discussion of training-serving skew in the Preprocessing challenges section.</p> </li> <li> <p>Full-pass transformations during training, but instance-level transformations during prediction. In this scenario, transformations are stateful, because they use some precomputed statistics to perform the transformation. During training, you analyze the whole body of training data to compute quantities such as minimum, maximum, mean, and variance for transforming training data, evaluation data, and new data at prediction time.</p> <p>For example, to normalize a numeric feature for training, you compute its mean (\\(\\mu\\)) and its standard deviation (\\(\\sigma\\)) across the whole of the training data. This computation is called a full-pass (or analyze) operation. When you serve the model for prediction, the value of a new data point is normalized to avoid training-serving skew. Therefore, \\(\\mu\\) and \\(\\sigma\\) values that are computed during training are used to adjust the feature value, which is the following simple instance-level operation:</p> \\[ value_\\text{scaled} = \\frac{value_\\text{raw} - \\mu}{\\sigma} \\] <p>Full-pass transformations include the following:</p> <ul> <li>MinMax scaling numerical features using min and max computed from the training dataset.</li> <li>Standard scaling (z-score normalization) numerical features using \\(\\mu\\) and \\(\\sigma\\) computed on the training dataset.</li> <li>Bucketizing numerical features using quantiles.</li> <li>Imputing missing values using the median (numerical features) or the mode (categorical features).</li> <li>Converting strings (nominal values) to integers (indexes) by extracting all the distinct values (vocabulary) of an input categorical feature.</li> <li>Counting the occurrence of a term (feature value) in all the documents (instances) to calculate for TF-IDF.</li> <li>Computing the PCA of the input features to project the data into a lower dimensional space (with linearly dependent features).</li> </ul> <p>You should use only the training data to compute statistics like \\(\\mu\\), \\(\\sigma\\), min, and max. If you add the test and evaluation data for these operations, you are leaking information from the evaluation and test data to train the model. Doing so affects the reliability of the test and evaluation results. To ensure that you apply a consistent transformation to all datasets, you use the same statistics computed from the training data to transform the test and evaluation data.</p> </li> <li> <p>Historical aggregations during training and prediction. This involves creating business aggregations, derivations, and flags as input signals to the prediction task---for example, creating recency, frequency, and monetary (RFM) metrics for customers to build propensity models. These types of features can be precomputed and stored in a feature store to be used during model training, batch scoring, and online prediction serving. You can also perform additional feature engineering (for example, transformation and tuning) to these aggregations before training and prediction.</p> </li> <li> <p>Historical aggregations during training, but real-time aggregations during prediction. This approach involves creating a feature by summarizing real-time values over time. In this approach, the instances to be aggregated are defined through temporal window clauses. For example, you can use this approach if you want to train a model that estimates the taxi trip time based on the traffic metrics for the route in the last 5 minutes, in the last 10 minutes, in the last 30 minutes, and at other intervals. You can also use this approach to predict the failure of an engine part based on the moving average of temperature and vibration values computed over the last 3 minutes. Although these aggregations can be prepared offline for training, they are computed in real time from a data stream during serving.</p> <p>More precisely, when you prepare training data, if the aggregated value isn't in the raw data, the value is created during the data engineering phase. The raw data is usually stored in a database with a format of <code>(entity, timestamp, value)</code>. In the previous examples, <code>entity</code> is the route segment identifier for the taxi routes and the engine part identifier for the engine failure. You can use windowing operations to compute <code>(entity, time_index, aggregated_value_over_time_window)</code> and use the aggregation features as an input for your model training.</p> <p>When the model for real-time (online) prediction is served, the model expects features derived from the aggregated values as an input. Therefore, you can use a stream-processing technology like Apache Beam to compute the aggregations from the real-time data points streamed into your system. Stream-processing technology aggregates real-time data based on time windows as new data points arrive. You can also perform additional feature engineering (for example, transformation and tuning) to these aggregations before training and prediction.</p> </li> </ul>"},{"location":"tft_bestpractices/#ml-pipeline-on-google-cloud","title":"ML pipeline on Google Cloud","text":"<p>This section discusses the core components of a typical end-to-end pipeline to train and serve TensorFlow ML models on Google Cloud using managed services. It also discusses where you can implement different categories of the data preprocessing operations, and common challenges that you might face when you implement such transformations. The How tf.Transform works section shows how the TensorFlow Transform library helps to address these challenges.</p>"},{"location":"tft_bestpractices/#high-level-architecture","title":"High-level architecture","text":"<p>The following diagram, figure 2, shows a high-level architecture of a typical ML pipeline for training and serving TensorFlow models. The labels A, B, and C in the diagram refer to the different places in the pipeline where data preprocessing can take place. Details about these steps are provided in the following section.</p> <p>Figure 2: High-level architecture for ML training and serving on Google Cloud.</p> <p>The pipeline consists of the following steps:</p> <ol> <li>After raw data is imported, tabular data is stored in BigQuery, and other data like images, audio, and video, is stored in Cloud Storage. The second part of this series uses tabular data stored in BigQuery as an example.</li> <li>Data engineering (preparation) and feature engineering are executed at scale using Dataflow. This execution produces ML-ready training, evaluation, and test sets that are stored in Cloud Storage. Ideally, these datasets are stored as TFRecord files, which is the optimized format for TensorFlow computations.</li> <li>A TensorFlow model trainer package is submitted to Vertex AI Training, which uses the preprocessed data from the previous steps to train the model. The output of this step is a trained TensorFlow SavedModel that is exported to Cloud Storage.</li> <li>The trained TensorFlow model is deployed to Vertex AI Prediction as a service that has a REST API so that it can be used for online predictions. The same model can also be used for batch prediction jobs.</li> <li>After the model is deployed as a REST API, client apps and internal systems can invoke the API by sending requests with some data points, and receiving responses from the model with predictions.</li> <li>For orchestrating and automating this pipeline, you can use Vertex AI Pipelines as a scheduler to invoke the data preparation, model training, and model deployment steps.</li> </ol> <p>You can also use Vertex AI Feature Store to store input features to make predictions. For example, you can periodically create engineered features from the latest raw data and store them in Vertex AI Feature Store. Client apps fetch the required input features from Vertex AI Feature Store and send them to the model to receive predictions.</p>"},{"location":"tft_bestpractices/#where-to-do-preprocessing","title":"Where to do preprocessing","text":"<p>In figure 2, the labels A, B, and C show that data preprocessing operations can take place in BigQuery, Dataflow, or TensorFlow. The following sections describe how each of these options work.</p>"},{"location":"tft_bestpractices/#option-a-bigquery","title":"Option A: BigQuery","text":"<p>Typically, logic is implemented in BigQuery for the following operations:</p> <ul> <li>Sampling: randomly selecting a subset from the data.</li> <li>Filtering: removing irrelevant or invalid instances.</li> <li>Partitioning: splitting the data to produce training, evaluation, and test sets.</li> </ul> <p>BigQuery SQL scripts can be used as a source query for the Dataflow preprocessing pipeline, which is the data processing step in figure 2. For example, if a system is used in Canada, and the data warehouse has transactions from around the world, filtering to get Canada-only training data is best done in BigQuery. Feature engineering in BigQuery is simple and scalable, and supports implementing instance-level and historical aggregations feature transformations.</p> <p>However, we recommend that you use BigQuery for feature engineering only if you use your model for batch prediction (scoring), or if the features are precomputed in BigQuery, but stored in Vertex AI Feature Store to be used during online prediction. If you plan to deploy the model for online predictions, and if you don't have the engineered feature in an online feature store, you have to replicate the SQL preprocessing operations to transform the raw data points that other systems generate. In other words, you need to implement the logic twice: one time in SQL to preprocess training data in BigQuery, and a second time in the logic of the app that consumes the model to preprocess online data points for prediction.</p> <p>For example, if your client app is written in Java, you need to reimplement the logic in Java. This can introduce errors due to implementation discrepancies, as described in the training-serving skew section of Preprocessing challenges later in this document. It's also extra overhead to maintain two different implementations. Whenever you change the logic in SQL to preprocess the training data, you need to change the Java implementation accordingly to preprocess data at serving time.</p> <p>If you are using your model only for batch prediction (for example, using Vertex AI batch prediction), and if your data for scoring is sourced from BigQuery, you can implement these preprocessing operations as part of the BigQuery SQL script. In that case, you can use the same preprocessing SQL script to prepare both training and scoring data.</p> <p>Full-pass stateful transformations aren't suitable for implementation in BigQuery. If you use BigQuery for full-pass transformations, you need auxiliary tables to store quantities needed by stateful transformations, such as means and variances to scale numerical features. Further, implementation of full-pass transformations using SQL on BigQuery creates increased complexity in the SQL scripts, and creates intricate dependency between training and the scoring SQL scripts.</p>"},{"location":"tft_bestpractices/#option-b-dataflow","title":"Option B: Dataflow","text":"<p>As shown in figure 2, you can implement computationally expensive preprocessing operations in Apache Beam, and run them at scale using Dataflow. Dataflow is a fully managed autoscaling service for batch and stream data processing. When you use Dataflow, you can also use external specialized libraries for data processing, unlike BigQuery.</p> <p>Dataflow can perform instance-level transformations, and historical and real-time aggregation feature transformations. In particular, if your ML models expect an input feature like <code>total_number_of_clicks_last_90sec</code>, Apache Beam windowing functions can compute these features based on aggregating the values of time windows of real-time (streaming) events data (for example, click events). In the earlier discussion of granularity of transformations, this was referred to as \"Historical aggregations during training, but real-time aggregations during prediction.\"</p> <p>The following diagram, figure 3, shows the role of Dataflow in processing stream data for near real-time predictions.</p> <p>Figure 3: High-level architecture using stream data for prediction in Dataflow.</p> <p>As shown in figure 3, during processing, events called data points are ingested into Pub/Sub. Dataflow consumes these data points, computes features based on aggregates over time, and then calls the deployed ML model API for predictions. Predictions are then sent to an outbound Pub/Sub queue. From Pub/Sub, predictions can be consumed by downstream systems like monitoring or control, or they can be pushed back (for example, as notifications) to the original requesting client. Predictions can also be stored in a low-latency data store like Cloud Bigtable for real-time fetching. Cloud Bigtable can also be used to accumulate and store these real-time aggregations so they can be looked up when needed for prediction.</p> <p>The same Apache Beam implementation can be used to batch-process training data that comes from an offline datastore like BigQuery and stream-process real-time data for serving online predictions.</p> <p>In other typical architectures, such as the architecture shown in figure 2, the client app directly calls the deployed model API for online predictions. In that case, if preprocessing operations are implemented in Dataflow to prepare the training data, the operations aren't applied to the prediction data that goes directly to the model. Therefore, transformations like these should be integrated in the model during serving for online predictions.</p> <p>Dataflow can be used to perform full-pass transformation, by computing the required statistics at scale. However, these statistics need to be stored somewhere to be used during prediction to transform prediction data points. By using the TensorFlow Transform (<code>tf.Transform</code>) library, you can directly embed these statistics in the model instead of storing them elsewhere. This approach is explained later in How tf.Transform works.</p>"},{"location":"tft_bestpractices/#option-c-tensorflow","title":"Option C: TensorFlow","text":"<p>As shown in figure 2, you can implement data preprocessing and transformation operations in the TensorFlow model itself. As shown in the figure, the preprocessing that you implement for training the TensorFlow model becomes an integral part of the model when the model is exported and deployed for predictions. Transformations in the TensorFlow model can be accomplished in one of the following ways:</p> <ul> <li>Implementing all of the instance-level transformation logic in the <code>input_fn</code> function and in the <code>serving_fn</code> function. The <code>input_fn</code> function prepares a dataset using the <code>tf.data.Dataset</code> API for training a model. The <code>serving_fn</code> function receives and prepares the data for predictions.</li> <li>Putting the transformation code directly in your TensorFlow model by using Keras preprocessing layers or creating custom layers.</li> </ul> <p>The transformation logic code in the <code>serving_fn</code> function defines the serving interface of your SavedModel for online prediction. If you implement the same transformations that were used for preparing training data in the transformation logic code of the <code>serving_fn</code> function, it ensures that the same transformations are applied to new prediction data points when they're served.</p> <p>However, because the TensorFlow model processes each data point independently or in a small batch, you can't calculate aggregations from all data points. As a result, full-pass transformations can't be implemented in your TensorFlow model.</p>"},{"location":"tft_bestpractices/#preprocessing-challenges","title":"Preprocessing challenges","text":"<p>The following are the primary challenges of implementing data preprocessing:</p> <ul> <li> <p>Training-serving skew. Training-serving skew refers to a difference between effectiveness (predictive performance) during training and during serving. This skew can be caused by a discrepancy between how you handle data in the training and the serving pipelines. For example, if your model is trained on a logarithmically transformed feature, but it's presented with the raw feature during serving, the prediction output might not be accurate.</p> <p>If the transformations become part of the model itself, it can be straightforward to handle instance-level transformations, as described earlier in Option C: TensorFlow. In that case, the model serving interface (the <code>serving_fn</code> function) expects raw data, while the model internally transforms this data before computing the output. The transformations are the same as those that were applied on the raw training and prediction data points.</p> </li> <li> <p>Full-pass transformations. You can't implement full-pass transformations such as scaling and normalization transformations in your TensorFlow model. In full-pass transformations, some statistics (for example, <code>max</code> and <code>min</code> values to scale numeric features) must be computed on the training data beforehand, as described in Option B: Dataflow. The values then have to be stored somewhere to be used during model serving for prediction to transform the new raw data points as instance-level transformations, which avoids training-serving skew. You can use the TensorFlow Transform (<code>tf.Transform</code>) library to directly embed the statistics in your TensorFlow model. This approach is explained later in How tf.Transform works.</p> </li> <li> <p>Preparing the data up front for better training efficiency. Implementing instance-level transformations as part of the model can degrade the efficiency of the training process. This degradation occurs because the same transformations are repeatedly applied to the same training data on each epoch. Imagine that you have raw training data with 1,000 features, and you apply a mix of instance-level transformations to generate 10,000 features. If you implement these transformations as part of your model, and if you then feed the model the raw training data, these 10,000 operations are applied N times on each instance, where N is the number of epochs. In addition, if you're using accelerators (GPUs or TPUs), they sit idle while the CPU performs those transformations, which isn't an efficient use of your costly accelerators.</p> <p>Ideally, the training data is transformed before training, using the technique described under Option B: Dataflow, where the 10,000 transformation operations are applied only once on each training instance. The transformed training data is then presented to the model. No further transformations are applied, and the accelerators are busy all of the time. In addition, using Dataflow helps you to preprocess large amounts of data at scale, using a fully managed service.</p> <p>Preparing the training data up front can improve training efficiency. However, implementing the transformation logic outside of the model (the approaches described in Option A: BigQuery or Option B: Dataflow) doesn't resolve the issue of training-serving skew. Unless you store the engineered feature in the feature store to be used for both training and prediction, the transformation logic must be implemented somewhere to be applied on new data points coming for prediction, because the model interface expects transformed data. The TensorFlow Transform (<code>tf.Transform</code>) library can help you to address this issue, as described in the following section.</p> </li> </ul>"},{"location":"tft_bestpractices/#how-tftransform-works","title":"How tf.Transform works","text":"<p>The <code>tf.Transform</code> library is useful for transformations that require a full pass. The output of the <code>tf.Transform</code> library is exported as a TensorFlow graph that represents the instance-level transformation logic and the statistics computed from full-pass transformations, to be used for training and serving. Using the same graph for both training and serving can prevent skew, because the same transformations are applied in both stages. In addition, the <code>tf.Transform</code> library can run at scale in a batch processing pipeline on Dataflow to prepare the training data up front and improve training efficiency.</p> <p>The following diagram, figure 4, shows how the <code>tf.Transform</code> library preprocesses and transforms data for training and prediction. The process is described in the following sections.</p> <p>Figure 4: Behavior of <code>tf.Transform</code> for preprocessing and transforming data.</p>"},{"location":"tft_bestpractices/#transform-training-and-evaluation-data","title":"Transform training and evaluation data","text":"<p>You preprocess the raw training data using the transformation implemented in the <code>tf.Transform</code> Apache Beam APIs, and run it at scale on Dataflow. The preprocessing occurs in the following phases:</p> <ul> <li>Analyze phase: During the analyze phase, the required statistics (like means, variances, and quantiles) for stateful transformations are computed on the training data with full-pass operations. This phase produces a set of transformation artifacts, including the <code>transform_fn</code> graph. The <code>transform_fn</code> graph is a TensorFlow graph that has the transformation logic as instance-level operations. It includes the statistics computed in the analyze phase as constants.</li> <li>Transform phase: During the transform phase, the <code>transform_fn</code> graph is applied to the raw training data, where the computed statistics are used to process the data records (for example, to scale numerical columns) in an instance-level fashion.</li> </ul> <p>A two-phase approach like this addresses the preprocessing challenge of performing full-pass transformations.</p> <p>When the evaluation data is preprocessed, only instance-level operations are applied, using the logic in the <code>transform_fn</code> graph and the statistics computed from the analyze phase in the training data. In other words, you don't analyze the evaluation data in a full-pass fashion to compute new statistics, such as \\(\\mu\\) and \\(\\sigma\\), to normalize numeric features in evaluation data. Instead, you use the computed statistics from the training data to transform the evaluation data in an instance-level fashion.</p> <p>The transformed training and evaluation data are prepared at scale using Dataflow, before they are used to train the model. This batch data-preparation process addresses the preprocessing challenge of preparing the data up front to improve training efficiency. As shown in figure 4, the model internal interface expects transformed features.</p>"},{"location":"tft_bestpractices/#attach-transformations-to-the-exported-model","title":"Attach transformations to the exported model","text":"<p>As noted, the <code>transform_fn</code> graph that's produced by the <code>tf.Transform</code> pipeline is stored as an exported TensorFlow graph. The exported graph consists of the transformation logic as instance-level operations, and all of the statistics computed in the full-pass transformations as graph constants. When the trained model is exported for serving, the <code>transform_fn</code> graph is attached to the SavedModel as part of its <code>serving_fn</code> function.</p> <p>While it's serving the model for prediction, the model serving interface expects data points in the raw format (that is, before any transformations). However, the model internal interface expects the data in the transformed format.</p> <p>The <code>transform_fn</code> graph, which is now part of the model, applies all the preprocessing logic on the incoming data point. It uses the stored constants (like \\(\\mu\\) and \\(\\sigma\\) to normalize the numeric features) in the instance-level operation during prediction. Therefore, the <code>transform_fn</code> graph converts the raw data point into the transformed format. The transformed format is what is expected by the model internal interface in order to produce prediction, as shown in figure 4.</p> <p>This mechanism resolves the preprocessing challenge of the training-serving skew, because the same logic (implementation) that is used to transform the training and evaluation data is applied to transform the new data points during prediction serving.</p>"},{"location":"tft_bestpractices/#preprocessing-options-summary","title":"Preprocessing options summary","text":"<p>The following table summarizes the data preprocessing options that this document discussed. In the table, \"N/A\" stands for \"not applicable.\"</p> <p>Data preprocessing option </p> <p>Instance-level   (stateless transformations)</p> <p>Full-pass during training and instance-level during serving (stateful transformations) </p> <p>Real-time (window) aggregations during training and serving (streaming transformations) </p> <p>BigQuery \u00a0(SQL) </p> <p>Batch scoring: OK---the same transformation implementation is applied on data during training and batch scoring. Online prediction: Not recommended---you can process training data, but it results in training-serving skew because you process serving data using different tools. </p> <p>Batch scoring: Not recommended. Online prediction: Not recommended.  Although you can use statistics computed using BigQuery for instance-level batch/online transformations, it isn\\'t easy because you must maintain a stats store to be populated during training and used during prediction.</p> <p>Batch scoring: N/A---aggregates like these are computed based on real-time events. Online prediction: Not recommended---you can process training data, but it results in training-serving skew because you process serving data using different tools. </p> <p>Dataflow (Apache Beam) </p> <p>Batch scoring: OK---the same transformation implementation is applied on data during training and batch scoring. Online prediction: OK---if data at serving time comes from Pub/Sub to be consumed by Dataflow. Otherwise, results in training-serving skew. </p> <p>Batch scoring: Not recommended. Online predictions: Not recommended.  Although you can use statistics computed using Dataflow for instance-level batch/online transformations, it isn\\'t easy because you must maintain a stats store to be populated during training and used during prediction.</p> <p>Batch scoring: N/A---aggregates like these are computed based on real-time events. Online prediction: OK---the same Apache Beam transformation is applied on data during training (batch) and serving (stream). </p> <p>Dataflow (Apache Beam + TFT) </p> <p>Batch scoring: OK---the same transformation implementation is applied to data during training and batch scoring. Online prediction: Recommended---it avoids training-serving skew and prepares training data up front. </p> <p>Batch scoring: Recommended. Online prediction: Recommended.  Both uses are recommended because transformation logic and computed statistics during training are stored as a TensorFlow graph that\\'s attached to the exported model for serving.</p> <p>Batch scoring: N/A---aggregates like these are computed based on real-time events. Online prediction: OK---the same Apache Beam transformation is applied on data during training (batch) and serving (stream). </p> <p>TensorFlow (<code>input_fn</code> &amp; <code>serving_fn</code>) </p> <p>Batch scoring: Not recommended. Online prediction: Not recommended.  For training efficiency in both cases, it\\'s better to prepare the training data up front.</p> <p>Batch scoring: Not Possible. Online prediction: Not Possible. </p> <p>Batch scoring: N/A---aggregates like these are computed based on real-time events. Online prediction: Not Possible. </p> <p>* With TensorFlow, transformations like crossing, embedding, and one-hot encoding should be performed declaratively as <code>feature_columns</code> columns.</p>"},{"location":"tft_bestpractices/#whats-next","title":"What's next","text":"<ul> <li>To implement a <code>tf.Transform</code> pipeline and run it using Dataflow, read part two of this series, Data preprocessing for ML using TensorFlow Transform.</li> <li>Take the Coursera specialization on ML with TensorFlow on Google Cloud.</li> <li>Learn about best practices for ML engineering in Rules of ML.</li> <li>For more reference architectures, diagrams, and best practices, explore the TFX Cloud Solutions.</li> </ul>"},{"location":"api_docs/python/tft-beam-analyzer-cache/","title":"TensorFlow Transform <code>tft.beam.analyzer_cache</code> Module","text":""},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache","title":"tensorflow_transform.beam.analyzer_cache","text":"<p>Module which allows a pipeilne to define and utilize cached analyzers.</p>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache-attributes","title":"Attributes","text":""},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.BeamAnalysisCache","title":"BeamAnalysisCache  <code>module-attribute</code>","text":"<pre><code>BeamAnalysisCache = Mapping[DatasetKey, DatasetCache]\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache-classes","title":"Classes","text":""},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.DatasetCache","title":"DatasetCache","text":"<p>               Bases: <code>TypedNamedTuple('DatasetCache', [('cache_dict', Mapping[str, PCollection[bytes]]), ('metadata', Optional[Union[PCollection[DatasetCacheMetadata], DatasetCacheMetadata]])])</code></p> <p>Complete cache for a dataset as well as metadata.</p>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.DatasetCache-functions","title":"Functions","text":""},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.DatasetCache.get","title":"get","text":"<pre><code>get(key)\n</code></pre> Source code in <code>tensorflow_transform/beam/analyzer_cache.py</code> <pre><code>def get(self, key):\n    return self.cache_dict.get(key)\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.DatasetCache.items","title":"items","text":"<pre><code>items()\n</code></pre> Source code in <code>tensorflow_transform/beam/analyzer_cache.py</code> <pre><code>def items(self):\n    return self.cache_dict.items()\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.DatasetCache.keys","title":"keys","text":"<pre><code>keys()\n</code></pre> Source code in <code>tensorflow_transform/beam/analyzer_cache.py</code> <pre><code>def keys(self):\n    return self.cache_dict.keys()\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.DatasetCache.values","title":"values","text":"<pre><code>values()\n</code></pre> Source code in <code>tensorflow_transform/beam/analyzer_cache.py</code> <pre><code>def values(self):\n    return self.cache_dict.values()\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.DatasetCacheMetadata","title":"DatasetCacheMetadata","text":"<p>               Bases: <code>TypedNamedTuple('DatasetCacheMetadata', [('dataset_size', int)])</code></p> <p>Metadata about a cached dataset.</p>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.DatasetCacheMetadata-functions","title":"Functions","text":""},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.DatasetCacheMetadata.decode","title":"decode  <code>classmethod</code>","text":"<pre><code>decode(value: bytes) -&gt; DatasetCacheMetadata\n</code></pre> Source code in <code>tensorflow_transform/beam/analyzer_cache.py</code> <pre><code>@classmethod\ndef decode(cls, value: bytes) -&gt; \"DatasetCacheMetadata\":\n    return cls(**pickle.loads(value))\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.DatasetCacheMetadata.encode","title":"encode","text":"<pre><code>encode() -&gt; bytes\n</code></pre> Source code in <code>tensorflow_transform/beam/analyzer_cache.py</code> <pre><code>def encode(self) -&gt; bytes:\n    return pickle.dumps(self._asdict(), protocol=0)\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.DatasetKey","title":"DatasetKey","text":"<p>               Bases: <code>namedtuple('DatasetKey', ['key', 'is_cached'])</code></p> <p>A key for a dataset used for analysis.</p>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.DatasetKey-functions","title":"Functions","text":""},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.DatasetKey.is_flattened_dataset_key","title":"is_flattened_dataset_key","text":"<pre><code>is_flattened_dataset_key() -&gt; bool\n</code></pre> Source code in <code>tensorflow_transform/beam/analyzer_cache.py</code> <pre><code>def is_flattened_dataset_key(self) -&gt; bool:\n    return self.key == self._FLATTENED_DATASET_KEY\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.DatasetKey.non_cacheable","title":"non_cacheable","text":"<pre><code>non_cacheable() -&gt; DatasetKey\n</code></pre> <p>Creates a non cacheable dataset key, for which no cache will be produced.</p> Source code in <code>tensorflow_transform/beam/analyzer_cache.py</code> <pre><code>def non_cacheable(self) -&gt; \"DatasetKey\":\n    \"\"\"Creates a non cacheable dataset key, for which no cache will be produced.\"\"\"\n    return self._replace(key=f\"uncached_{self.key}\", is_cached=False)\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS","title":"ReadAnalysisCacheFromFS","text":"<pre><code>ReadAnalysisCacheFromFS(\n    cache_base_dir: str,\n    dataset_keys: Iterable[DatasetKey],\n    cache_entry_keys: Optional[Iterable[bytes]] = None,\n    source: Optional[object] = None,\n)\n</code></pre> <p>               Bases: <code>PTransform</code></p> <p>Reads cache from the FS written by WriteAnalysisCacheToFS.</p> <p>Init method.</p> <p>cache_base_dir: A string, the path that the cache should be stored in.   dataset_keys: An iterable of <code>DatasetKey</code>s.   cache_entry_keys: (Optional) An iterable of cache entry key strings. If     provided, only cache entries that exist in <code>cache_entry_keys</code> will be     read.   source: (Optional) A PTransform class that takes a path argument in its     constructor, and is used to read the cache.</p> Source code in <code>tensorflow_transform/beam/analyzer_cache.py</code> <pre><code>def __init__(\n    self,\n    cache_base_dir: str,\n    dataset_keys: Iterable[DatasetKey],\n    cache_entry_keys: Optional[Iterable[bytes]] = None,\n    source: Optional[object] = None,\n):\n    \"\"\"Init method.\n\n    Args:\n    ----\n      cache_base_dir: A string, the path that the cache should be stored in.\n      dataset_keys: An iterable of `DatasetKey`s.\n      cache_entry_keys: (Optional) An iterable of cache entry key strings. If\n        provided, only cache entries that exist in `cache_entry_keys` will be\n        read.\n      source: (Optional) A PTransform class that takes a path argument in its\n        constructor, and is used to read the cache.\n    \"\"\"\n    self._cache_base_dir = cache_base_dir\n    if not all(isinstance(d, DatasetKey) for d in dataset_keys):\n        raise ValueError(\"Expected dataset_keys to be of type DatasetKey\")\n    self._sorted_dataset_keys = sorted(dataset_keys)\n    self._filtered_cache_entry_keys = (\n        None if cache_entry_keys is None else set(cache_entry_keys)\n    )\n    # TODO(b/37788560): Possibly use Riegeli as a default file format once\n    # possible.\n    self._source = source if source is not None else beam.io.ReadFromTFRecord\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS-attributes","title":"Attributes","text":""},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.label","title":"label  <code>property</code> <code>writable</code>","text":"<pre><code>label\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.pipeline","title":"pipeline  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline = None\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.side_inputs","title":"side_inputs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>side_inputs = ()\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS-functions","title":"Functions","text":""},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.annotations","title":"annotations","text":"<pre><code>annotations() -&gt; dict[str, Union[bytes, str, Message]]\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def annotations(self) -&gt; dict[str, Union[bytes, str, message.Message]]:\n  return {\n      'python_type':  #\n      f'{self.__class__.__module__}.{self.__class__.__qualname__}'\n  }\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.default_label","title":"default_label","text":"<pre><code>default_label()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_label(self):\n  # type: () -&gt; str\n  return self.__class__.__name__\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.default_type_hints","title":"default_type_hints","text":"<pre><code>default_type_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_type_hints(self):\n  fn_type_hints = IOTypeHints.from_callable(self.expand)\n  if fn_type_hints is not None:\n    fn_type_hints = fn_type_hints.strip_pcoll()\n\n  # Prefer class decorator type hints for backwards compatibility.\n  return get_type_hints(self.__class__).with_defaults(fn_type_hints)\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.display_data","title":"display_data","text":"<pre><code>display_data()\n</code></pre> <p>Returns the display data associated to a pipeline component.</p> <p>It should be reimplemented in pipeline components that wish to have static display data.</p> RETURNS DESCRIPTION <p>Dict[str, Any]: A dictionary containing <code>key:value</code> pairs.</p> <p>The value might be an integer, float or string value; a</p> <p>class:<code>DisplayDataItem</code> for values that have more data</p> <p>(e.g. short value, label, url); or a :class:<code>HasDisplayData</code> instance</p> <p>that has more display data that should be picked up. For example::</p> <p>{   'key1': 'string_value',   'key2': 1234,   'key3': 3.14159265,   'key4': DisplayDataItem('apache.org', url='http://apache.org'),   'key5': subComponent }</p> Source code in <code>apache_beam/transforms/display.py</code> <pre><code>def display_data(self):\n  # type: () -&gt; dict\n\n  \"\"\" Returns the display data associated to a pipeline component.\n\n  It should be reimplemented in pipeline components that wish to have\n  static display data.\n\n  Returns:\n    Dict[str, Any]: A dictionary containing ``key:value`` pairs.\n    The value might be an integer, float or string value; a\n    :class:`DisplayDataItem` for values that have more data\n    (e.g. short value, label, url); or a :class:`HasDisplayData` instance\n    that has more display data that should be picked up. For example::\n\n      {\n        'key1': 'string_value',\n        'key2': 1234,\n        'key3': 3.14159265,\n        'key4': DisplayDataItem('apache.org', url='http://apache.org'),\n        'key5': subComponent\n      }\n  \"\"\"\n  return {}\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.expand","title":"expand","text":"<pre><code>expand(pipeline: Pipeline)\n</code></pre> Source code in <code>tensorflow_transform/beam/analyzer_cache.py</code> <pre><code>def expand(self, pipeline: beam.Pipeline):\n    result = {}\n\n    for dataset_key_idx, dataset_key in enumerate(self._sorted_dataset_keys):\n        dataset_cache_path = _get_dataset_cache_path(\n            self._cache_base_dir, dataset_key\n        )\n        manifest_file = _ManifestFile(dataset_cache_path)\n        manifest = manifest_file.read()\n        if not manifest:\n            continue\n        dataset_id = f\"AnalysisIndex{dataset_key_idx}\"\n        cache_dict = {}\n        for key, cache_key_idx in manifest.items():\n            if self._should_read_cache_entry_key(key):\n                cache_dict[key] = (\n                    pipeline\n                    | f\"Read[{dataset_id}]][CacheKeyIndex{cache_key_idx}]\"\n                    &gt;&gt; self._source(\n                        f\"{os.path.join(dataset_cache_path, str(cache_key_idx))}-*-of-*\"\n                    )\n                )\n        metadata = pipeline | f\"ReadMetadata[{dataset_id}]\" &gt;&gt; _ReadMetadata(\n            dataset_cache_path\n        )\n        result[dataset_key] = DatasetCache(cache_dict, metadata)\n    return result\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.from_runner_api","title":"from_runner_api  <code>classmethod</code>","text":"<pre><code>from_runner_api(proto, context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef from_runner_api(\n    cls,\n    proto,  # type: Optional[beam_runner_api_pb2.PTransform]\n    context  # type: PipelineContext\n):\n  # type: (...) -&gt; Optional[PTransform]\n  if proto is None or proto.spec is None or not proto.spec.urn:\n    return None\n  parameter_type, constructor = cls._known_urns[proto.spec.urn]\n\n  return constructor(\n      proto,\n      proto_utils.parse_Bytes(proto.spec.payload, parameter_type),\n      context)\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.get_resource_hints","title":"get_resource_hints","text":"<pre><code>get_resource_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_resource_hints(self):\n  # type: () -&gt; dict[str, bytes]\n  if '_resource_hints' not in self.__dict__:\n    # PTransform subclasses don't always call super(), so prefer lazy\n    # initialization. By default, transforms don't have any resource hints.\n    self._resource_hints = {}  # type: dict[str, bytes]\n  return self._resource_hints\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.get_type_hints","title":"get_type_hints","text":"<pre><code>get_type_hints()\n</code></pre> <p>Gets and/or initializes type hints for this object.</p> <p>If type hints have not been set, attempts to initialize type hints in this order: - Using self.default_type_hints(). - Using self.class type hints.</p> Source code in <code>apache_beam/typehints/decorators.py</code> <pre><code>def get_type_hints(self):\n  \"\"\"Gets and/or initializes type hints for this object.\n\n  If type hints have not been set, attempts to initialize type hints in this\n  order:\n  - Using self.default_type_hints().\n  - Using self.__class__ type hints.\n  \"\"\"\n  return (\n      self._get_or_create_type_hints().with_defaults(\n          self.default_type_hints()).with_defaults(\n              get_type_hints(self.__class__)))\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.get_windowing","title":"get_windowing","text":"<pre><code>get_windowing(inputs)\n</code></pre> <p>Returns the window function to be associated with transform's output.</p> <p>By default most transforms just return the windowing function associated with the input PCollection (or the first input if several).</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_windowing(self, inputs):\n  # type: (Any) -&gt; Windowing\n\n  \"\"\"Returns the window function to be associated with transform's output.\n\n  By default most transforms just return the windowing function associated\n  with the input PCollection (or the first input if several).\n  \"\"\"\n  if inputs:\n    return inputs[0].windowing\n  else:\n    from apache_beam.transforms.core import Windowing\n    from apache_beam.transforms.window import GlobalWindows\n    # TODO(robertwb): Return something compatible with every windowing?\n    return Windowing(GlobalWindows())\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.infer_output_type","title":"infer_output_type","text":"<pre><code>infer_output_type(unused_input_type)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def infer_output_type(self, unused_input_type):\n  return self.get_type_hints().simple_output_type(self.label) or typehints.Any\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.register_urn","title":"register_urn  <code>classmethod</code>","text":"<pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre> <pre><code>register_urn(urn, parameter_type, constructor=None)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef register_urn(cls, urn, parameter_type, constructor=None):\n  def register(constructor):\n    if isinstance(constructor, type):\n      constructor.from_runner_api_parameter = register(\n          constructor.from_runner_api_parameter)\n    else:\n      cls._known_urns[urn] = parameter_type, constructor\n    return constructor\n\n  if constructor:\n    # Used as a statement.\n    register(constructor)\n  else:\n    # Used as a decorator.\n    return register\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.runner_api_requires_keyed_input","title":"runner_api_requires_keyed_input","text":"<pre><code>runner_api_requires_keyed_input()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def runner_api_requires_keyed_input(self):\n  return False\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.to_runner_api","title":"to_runner_api","text":"<pre><code>to_runner_api(context, has_parts=False, **extra_kwargs)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api(self, context, has_parts=False, **extra_kwargs):\n  # type: (PipelineContext, bool, Any) -&gt; beam_runner_api_pb2.FunctionSpec\n  from apache_beam.portability.api import beam_runner_api_pb2\n  # typing: only ParDo supports extra_kwargs\n  urn, typed_param = self.to_runner_api_parameter(context, **extra_kwargs)\n  if urn == python_urns.GENERIC_COMPOSITE_TRANSFORM and not has_parts:\n    # TODO(https://github.com/apache/beam/issues/18713): Remove this fallback.\n    urn, typed_param = self.to_runner_api_pickled(context)\n  return beam_runner_api_pb2.FunctionSpec(\n      urn=urn,\n      payload=typed_param.SerializeToString() if isinstance(\n          typed_param, message.Message) else typed_param.encode('utf-8')\n      if isinstance(typed_param, str) else typed_param)\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.to_runner_api_parameter","title":"to_runner_api_parameter","text":"<pre><code>to_runner_api_parameter(unused_context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_parameter(\n    self,\n    unused_context  # type: PipelineContext\n):\n  # type: (...) -&gt; tuple[str, Optional[Union[message.Message, bytes, str]]]\n  # The payload here is just to ease debugging.\n  return (\n      python_urns.GENERIC_COMPOSITE_TRANSFORM,\n      getattr(self, '_fn_api_payload', str(self)))\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.to_runner_api_pickled","title":"to_runner_api_pickled","text":"<pre><code>to_runner_api_pickled(context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_pickled(self, context):\n  # type: (PipelineContext) -&gt; tuple[str, bytes]\n  return (\n      python_urns.PICKLED_TRANSFORM,\n      pickler.dumps(\n          self,\n          enable_best_effort_determinism=context.\n          enable_best_effort_deterministic_pickling,\n      ),\n  )\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.type_check_inputs","title":"type_check_inputs","text":"<pre><code>type_check_inputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'input')\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.type_check_inputs_or_outputs","title":"type_check_inputs_or_outputs","text":"<pre><code>type_check_inputs_or_outputs(pvalueish, input_or_output)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs_or_outputs(self, pvalueish, input_or_output):\n  type_hints = self.get_type_hints()\n  hints = getattr(type_hints, input_or_output + '_types')\n  if hints is None or not any(hints):\n    return\n  arg_hints, kwarg_hints = hints\n  if arg_hints and kwarg_hints:\n    raise TypeCheckError(\n        'PTransform cannot have both positional and keyword type hints '\n        'without overriding %s._type_check_%s()' %\n        (self.__class__, input_or_output))\n  root_hint = (\n      arg_hints[0] if len(arg_hints) == 1 else arg_hints or kwarg_hints)\n  for context, pvalue_, hint in _ZipPValues().visit(pvalueish, root_hint):\n    if isinstance(pvalue_, DoOutputsTuple):\n      continue\n    if pvalue_.element_type is None:\n      # TODO(robertwb): It's a bug that we ever get here. (typecheck)\n      continue\n    if hint and not typehints.is_consistent_with(pvalue_.element_type, hint):\n      at_context = ' %s %s' % (input_or_output, context) if context else ''\n      raise TypeCheckError(\n          '{type} type hint violation at {label}{context}: expected {hint}, '\n          'got {actual_type}'.format(\n              type=input_or_output.title(),\n              label=self.label,\n              context=at_context,\n              hint=hint,\n              actual_type=pvalue_.element_type))\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.type_check_outputs","title":"type_check_outputs","text":"<pre><code>type_check_outputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_outputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'output')\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.with_input_types","title":"with_input_types","text":"<pre><code>with_input_types(input_type_hint)\n</code></pre> <p>Annotates the input type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>input_type_hint</code> <p>An instance of an allowed built-in type, a custom class, or an instance of a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If input_type_hint is not a valid type-hint. See :obj:<code>apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_input_types(self, input_type_hint):\n  \"\"\"Annotates the input type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    input_type_hint (type): An instance of an allowed built-in type, a custom\n      class, or an instance of a\n      :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **input_type_hint** is not a valid type-hint.\n      See\n      :obj:`apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  input_type_hint = native_type_compatibility.convert_to_beam_type(\n      input_type_hint)\n  validate_composite_type_param(\n      input_type_hint, 'Type hints for a PTransform')\n  return super().with_input_types(input_type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.with_output_types","title":"with_output_types","text":"<pre><code>with_output_types(type_hint)\n</code></pre> <p>Annotates the output type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>type_hint</code> <p>An instance of an allowed built-in type, a custom class, or a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If type_hint is not a valid type-hint. See :obj:<code>~apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_output_types(self, type_hint):\n  \"\"\"Annotates the output type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    type_hint (type): An instance of an allowed built-in type, a custom class,\n      or a :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **type_hint** is not a valid type-hint. See\n      :obj:`~apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  type_hint = native_type_compatibility.convert_to_beam_type(type_hint)\n  validate_composite_type_param(type_hint, 'Type hints for a PTransform')\n  return super().with_output_types(type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.ReadAnalysisCacheFromFS.with_resource_hints","title":"with_resource_hints","text":"<pre><code>with_resource_hints(**kwargs)\n</code></pre> <p>Adds resource hints to the :class:<code>PTransform</code>.</p> <p>Resource hints allow users to express constraints on the environment where the transform should be executed.  Interpretation of the resource hints is defined by Beam Runners. Runners may ignore the unsupported hints.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>key-value pairs describing hints and their values.</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>if provided hints are unknown to the SDK. See :mod:<code>apache_beam.transforms.resources</code> for a list of known hints.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_resource_hints(self, **kwargs):  # type: (...) -&gt; PTransform\n  \"\"\"Adds resource hints to the :class:`PTransform`.\n\n  Resource hints allow users to express constraints on the environment where\n  the transform should be executed.  Interpretation of the resource hints is\n  defined by Beam Runners. Runners may ignore the unsupported hints.\n\n  Args:\n    **kwargs: key-value pairs describing hints and their values.\n\n  Raises:\n    ValueError: if provided hints are unknown to the SDK. See\n      :mod:`apache_beam.transforms.resources` for a list of known hints.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object.\n  \"\"\"\n  self.get_resource_hints().update(resources.parse_resource_hints(kwargs))\n  return self\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS","title":"WriteAnalysisCacheToFS","text":"<pre><code>WriteAnalysisCacheToFS(\n    pipeline: Pipeline,\n    cache_base_dir: str,\n    dataset_keys: Optional[Iterable[DatasetKey]] = None,\n    sink: Optional[object] = None,\n)\n</code></pre> <p>               Bases: <code>PTransform</code></p> <p>Writes a cache object that can be read by ReadAnalysisCacheFromFS.</p> <p>Given a cache collection, this writes it to the configured directory. If the configured directory already contains cache, this will merge the new cache with the old. NOTE: This merging of cache is determined at beam graph construction time, so the cache must already exist there when constructing this.</p> <p>Init method.</p> <p>pipeline: A beam Pipeline.   cache_base_dir: A str, the path that the cache should be stored in.   dataset_keys: (Optional) An iterable of strings.   sink: (Optional) A PTransform class that takes a path in its constructor,     and is used to write the cache. If not provided this uses a GZipped     TFRecord sink.</p> Source code in <code>tensorflow_transform/beam/analyzer_cache.py</code> <pre><code>def __init__(\n    self,\n    pipeline: beam.Pipeline,\n    cache_base_dir: str,\n    dataset_keys: Optional[Iterable[DatasetKey]] = None,\n    sink: Optional[object] = None,\n):\n    \"\"\"Init method.\n\n    Args:\n    ----\n      pipeline: A beam Pipeline.\n      cache_base_dir: A str, the path that the cache should be stored in.\n      dataset_keys: (Optional) An iterable of strings.\n      sink: (Optional) A PTransform class that takes a path in its constructor,\n        and is used to write the cache. If not provided this uses a GZipped\n        TFRecord sink.\n    \"\"\"\n    self.pipeline = pipeline\n    self._cache_base_dir = cache_base_dir\n    if dataset_keys is None:\n        self._sorted_dataset_keys = None\n    else:\n        self._sorted_dataset_keys = sorted(dataset_keys)\n    self._sink = sink\n    if self._sink is None:\n        # TODO(b/37788560): Possibly use Riegeli as a default file format once\n        # possible.\n        self._sink = _WriteToTFRecordGzip\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS-attributes","title":"Attributes","text":""},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.label","title":"label  <code>property</code> <code>writable</code>","text":"<pre><code>label\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.pipeline","title":"pipeline  <code>instance-attribute</code>","text":"<pre><code>pipeline = pipeline\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.side_inputs","title":"side_inputs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>side_inputs = ()\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS-functions","title":"Functions","text":""},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.annotations","title":"annotations","text":"<pre><code>annotations() -&gt; dict[str, Union[bytes, str, Message]]\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def annotations(self) -&gt; dict[str, Union[bytes, str, message.Message]]:\n  return {\n      'python_type':  #\n      f'{self.__class__.__module__}.{self.__class__.__qualname__}'\n  }\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.default_label","title":"default_label","text":"<pre><code>default_label()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_label(self):\n  # type: () -&gt; str\n  return self.__class__.__name__\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.default_type_hints","title":"default_type_hints","text":"<pre><code>default_type_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_type_hints(self):\n  fn_type_hints = IOTypeHints.from_callable(self.expand)\n  if fn_type_hints is not None:\n    fn_type_hints = fn_type_hints.strip_pcoll()\n\n  # Prefer class decorator type hints for backwards compatibility.\n  return get_type_hints(self.__class__).with_defaults(fn_type_hints)\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.display_data","title":"display_data","text":"<pre><code>display_data()\n</code></pre> <p>Returns the display data associated to a pipeline component.</p> <p>It should be reimplemented in pipeline components that wish to have static display data.</p> RETURNS DESCRIPTION <p>Dict[str, Any]: A dictionary containing <code>key:value</code> pairs.</p> <p>The value might be an integer, float or string value; a</p> <p>class:<code>DisplayDataItem</code> for values that have more data</p> <p>(e.g. short value, label, url); or a :class:<code>HasDisplayData</code> instance</p> <p>that has more display data that should be picked up. For example::</p> <p>{   'key1': 'string_value',   'key2': 1234,   'key3': 3.14159265,   'key4': DisplayDataItem('apache.org', url='http://apache.org'),   'key5': subComponent }</p> Source code in <code>apache_beam/transforms/display.py</code> <pre><code>def display_data(self):\n  # type: () -&gt; dict\n\n  \"\"\" Returns the display data associated to a pipeline component.\n\n  It should be reimplemented in pipeline components that wish to have\n  static display data.\n\n  Returns:\n    Dict[str, Any]: A dictionary containing ``key:value`` pairs.\n    The value might be an integer, float or string value; a\n    :class:`DisplayDataItem` for values that have more data\n    (e.g. short value, label, url); or a :class:`HasDisplayData` instance\n    that has more display data that should be picked up. For example::\n\n      {\n        'key1': 'string_value',\n        'key2': 1234,\n        'key3': 3.14159265,\n        'key4': DisplayDataItem('apache.org', url='http://apache.org'),\n        'key5': subComponent\n      }\n  \"\"\"\n  return {}\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.expand","title":"expand","text":"<pre><code>expand(dataset_cache_dict)\n</code></pre> Source code in <code>tensorflow_transform/beam/analyzer_cache.py</code> <pre><code>def expand(self, dataset_cache_dict):\n    if self._sorted_dataset_keys is None:\n        sorted_dataset_keys_list = sorted(dataset_cache_dict.keys())\n    else:\n        sorted_dataset_keys_list = self._sorted_dataset_keys\n        missing_keys = set(dataset_cache_dict.keys()).difference(\n            set(sorted_dataset_keys_list)\n        )\n        if missing_keys:\n            raise ValueError(\n                \"The dataset keys in the cache dictionary must be a subset of the \"\n                \"keys in dataset_keys. Missing {}.\".format(missing_keys)\n            )\n    if not all(isinstance(d, DatasetKey) for d in sorted_dataset_keys_list):\n        raise ValueError(\"Expected dataset_keys to be of type DatasetKey\")\n\n    cache_is_written = []\n    for dataset_key, cache in dataset_cache_dict.items():\n        dataset_key_idx = sorted_dataset_keys_list.index(dataset_key)\n        dataset_key_dir = _get_dataset_cache_path(self._cache_base_dir, dataset_key)\n        with _ManifestFile(dataset_key_dir) as manifest_file:\n            cache_is_written.extend(\n                self._write_cache(\n                    manifest_file, dataset_key_idx, dataset_key_dir, cache\n                )\n            )\n\n    return cache_is_written\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.from_runner_api","title":"from_runner_api  <code>classmethod</code>","text":"<pre><code>from_runner_api(proto, context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef from_runner_api(\n    cls,\n    proto,  # type: Optional[beam_runner_api_pb2.PTransform]\n    context  # type: PipelineContext\n):\n  # type: (...) -&gt; Optional[PTransform]\n  if proto is None or proto.spec is None or not proto.spec.urn:\n    return None\n  parameter_type, constructor = cls._known_urns[proto.spec.urn]\n\n  return constructor(\n      proto,\n      proto_utils.parse_Bytes(proto.spec.payload, parameter_type),\n      context)\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.get_resource_hints","title":"get_resource_hints","text":"<pre><code>get_resource_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_resource_hints(self):\n  # type: () -&gt; dict[str, bytes]\n  if '_resource_hints' not in self.__dict__:\n    # PTransform subclasses don't always call super(), so prefer lazy\n    # initialization. By default, transforms don't have any resource hints.\n    self._resource_hints = {}  # type: dict[str, bytes]\n  return self._resource_hints\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.get_type_hints","title":"get_type_hints","text":"<pre><code>get_type_hints()\n</code></pre> <p>Gets and/or initializes type hints for this object.</p> <p>If type hints have not been set, attempts to initialize type hints in this order: - Using self.default_type_hints(). - Using self.class type hints.</p> Source code in <code>apache_beam/typehints/decorators.py</code> <pre><code>def get_type_hints(self):\n  \"\"\"Gets and/or initializes type hints for this object.\n\n  If type hints have not been set, attempts to initialize type hints in this\n  order:\n  - Using self.default_type_hints().\n  - Using self.__class__ type hints.\n  \"\"\"\n  return (\n      self._get_or_create_type_hints().with_defaults(\n          self.default_type_hints()).with_defaults(\n              get_type_hints(self.__class__)))\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.get_windowing","title":"get_windowing","text":"<pre><code>get_windowing(inputs)\n</code></pre> <p>Returns the window function to be associated with transform's output.</p> <p>By default most transforms just return the windowing function associated with the input PCollection (or the first input if several).</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_windowing(self, inputs):\n  # type: (Any) -&gt; Windowing\n\n  \"\"\"Returns the window function to be associated with transform's output.\n\n  By default most transforms just return the windowing function associated\n  with the input PCollection (or the first input if several).\n  \"\"\"\n  if inputs:\n    return inputs[0].windowing\n  else:\n    from apache_beam.transforms.core import Windowing\n    from apache_beam.transforms.window import GlobalWindows\n    # TODO(robertwb): Return something compatible with every windowing?\n    return Windowing(GlobalWindows())\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.infer_output_type","title":"infer_output_type","text":"<pre><code>infer_output_type(unused_input_type)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def infer_output_type(self, unused_input_type):\n  return self.get_type_hints().simple_output_type(self.label) or typehints.Any\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.register_urn","title":"register_urn  <code>classmethod</code>","text":"<pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre> <pre><code>register_urn(urn, parameter_type, constructor=None)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef register_urn(cls, urn, parameter_type, constructor=None):\n  def register(constructor):\n    if isinstance(constructor, type):\n      constructor.from_runner_api_parameter = register(\n          constructor.from_runner_api_parameter)\n    else:\n      cls._known_urns[urn] = parameter_type, constructor\n    return constructor\n\n  if constructor:\n    # Used as a statement.\n    register(constructor)\n  else:\n    # Used as a decorator.\n    return register\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.runner_api_requires_keyed_input","title":"runner_api_requires_keyed_input","text":"<pre><code>runner_api_requires_keyed_input()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def runner_api_requires_keyed_input(self):\n  return False\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.to_runner_api","title":"to_runner_api","text":"<pre><code>to_runner_api(context, has_parts=False, **extra_kwargs)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api(self, context, has_parts=False, **extra_kwargs):\n  # type: (PipelineContext, bool, Any) -&gt; beam_runner_api_pb2.FunctionSpec\n  from apache_beam.portability.api import beam_runner_api_pb2\n  # typing: only ParDo supports extra_kwargs\n  urn, typed_param = self.to_runner_api_parameter(context, **extra_kwargs)\n  if urn == python_urns.GENERIC_COMPOSITE_TRANSFORM and not has_parts:\n    # TODO(https://github.com/apache/beam/issues/18713): Remove this fallback.\n    urn, typed_param = self.to_runner_api_pickled(context)\n  return beam_runner_api_pb2.FunctionSpec(\n      urn=urn,\n      payload=typed_param.SerializeToString() if isinstance(\n          typed_param, message.Message) else typed_param.encode('utf-8')\n      if isinstance(typed_param, str) else typed_param)\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.to_runner_api_parameter","title":"to_runner_api_parameter","text":"<pre><code>to_runner_api_parameter(unused_context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_parameter(\n    self,\n    unused_context  # type: PipelineContext\n):\n  # type: (...) -&gt; tuple[str, Optional[Union[message.Message, bytes, str]]]\n  # The payload here is just to ease debugging.\n  return (\n      python_urns.GENERIC_COMPOSITE_TRANSFORM,\n      getattr(self, '_fn_api_payload', str(self)))\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.to_runner_api_pickled","title":"to_runner_api_pickled","text":"<pre><code>to_runner_api_pickled(context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_pickled(self, context):\n  # type: (PipelineContext) -&gt; tuple[str, bytes]\n  return (\n      python_urns.PICKLED_TRANSFORM,\n      pickler.dumps(\n          self,\n          enable_best_effort_determinism=context.\n          enable_best_effort_deterministic_pickling,\n      ),\n  )\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.type_check_inputs","title":"type_check_inputs","text":"<pre><code>type_check_inputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'input')\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.type_check_inputs_or_outputs","title":"type_check_inputs_or_outputs","text":"<pre><code>type_check_inputs_or_outputs(pvalueish, input_or_output)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs_or_outputs(self, pvalueish, input_or_output):\n  type_hints = self.get_type_hints()\n  hints = getattr(type_hints, input_or_output + '_types')\n  if hints is None or not any(hints):\n    return\n  arg_hints, kwarg_hints = hints\n  if arg_hints and kwarg_hints:\n    raise TypeCheckError(\n        'PTransform cannot have both positional and keyword type hints '\n        'without overriding %s._type_check_%s()' %\n        (self.__class__, input_or_output))\n  root_hint = (\n      arg_hints[0] if len(arg_hints) == 1 else arg_hints or kwarg_hints)\n  for context, pvalue_, hint in _ZipPValues().visit(pvalueish, root_hint):\n    if isinstance(pvalue_, DoOutputsTuple):\n      continue\n    if pvalue_.element_type is None:\n      # TODO(robertwb): It's a bug that we ever get here. (typecheck)\n      continue\n    if hint and not typehints.is_consistent_with(pvalue_.element_type, hint):\n      at_context = ' %s %s' % (input_or_output, context) if context else ''\n      raise TypeCheckError(\n          '{type} type hint violation at {label}{context}: expected {hint}, '\n          'got {actual_type}'.format(\n              type=input_or_output.title(),\n              label=self.label,\n              context=at_context,\n              hint=hint,\n              actual_type=pvalue_.element_type))\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.type_check_outputs","title":"type_check_outputs","text":"<pre><code>type_check_outputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_outputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'output')\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.with_input_types","title":"with_input_types","text":"<pre><code>with_input_types(input_type_hint)\n</code></pre> <p>Annotates the input type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>input_type_hint</code> <p>An instance of an allowed built-in type, a custom class, or an instance of a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If input_type_hint is not a valid type-hint. See :obj:<code>apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_input_types(self, input_type_hint):\n  \"\"\"Annotates the input type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    input_type_hint (type): An instance of an allowed built-in type, a custom\n      class, or an instance of a\n      :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **input_type_hint** is not a valid type-hint.\n      See\n      :obj:`apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  input_type_hint = native_type_compatibility.convert_to_beam_type(\n      input_type_hint)\n  validate_composite_type_param(\n      input_type_hint, 'Type hints for a PTransform')\n  return super().with_input_types(input_type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.with_output_types","title":"with_output_types","text":"<pre><code>with_output_types(type_hint)\n</code></pre> <p>Annotates the output type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>type_hint</code> <p>An instance of an allowed built-in type, a custom class, or a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If type_hint is not a valid type-hint. See :obj:<code>~apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_output_types(self, type_hint):\n  \"\"\"Annotates the output type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    type_hint (type): An instance of an allowed built-in type, a custom class,\n      or a :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **type_hint** is not a valid type-hint. See\n      :obj:`~apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  type_hint = native_type_compatibility.convert_to_beam_type(type_hint)\n  validate_composite_type_param(type_hint, 'Type hints for a PTransform')\n  return super().with_output_types(type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.WriteAnalysisCacheToFS.with_resource_hints","title":"with_resource_hints","text":"<pre><code>with_resource_hints(**kwargs)\n</code></pre> <p>Adds resource hints to the :class:<code>PTransform</code>.</p> <p>Resource hints allow users to express constraints on the environment where the transform should be executed.  Interpretation of the resource hints is defined by Beam Runners. Runners may ignore the unsupported hints.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>key-value pairs describing hints and their values.</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>if provided hints are unknown to the SDK. See :mod:<code>apache_beam.transforms.resources</code> for a list of known hints.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_resource_hints(self, **kwargs):  # type: (...) -&gt; PTransform\n  \"\"\"Adds resource hints to the :class:`PTransform`.\n\n  Resource hints allow users to express constraints on the environment where\n  the transform should be executed.  Interpretation of the resource hints is\n  defined by Beam Runners. Runners may ignore the unsupported hints.\n\n  Args:\n    **kwargs: key-value pairs describing hints and their values.\n\n  Raises:\n    ValueError: if provided hints are unknown to the SDK. See\n      :mod:`apache_beam.transforms.resources` for a list of known hints.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object.\n  \"\"\"\n  self.get_resource_hints().update(resources.parse_resource_hints(kwargs))\n  return self\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache-functions","title":"Functions","text":""},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.make_cache_entry_key","title":"make_cache_entry_key","text":"<pre><code>make_cache_entry_key(cache_key: str) -&gt; str\n</code></pre> Source code in <code>tensorflow_transform/beam/analyzer_cache.py</code> <pre><code>def make_cache_entry_key(cache_key: str) -&gt; str:\n    return _CACHE_VERSION + tf.compat.as_bytes(cache_key)\n</code></pre>"},{"location":"api_docs/python/tft-beam-analyzer-cache/#tensorflow_transform.beam.analyzer_cache.validate_dataset_keys","title":"validate_dataset_keys","text":"<pre><code>validate_dataset_keys(dataset_keys: Iterable[DatasetKey])\n</code></pre> Source code in <code>tensorflow_transform/beam/analyzer_cache.py</code> <pre><code>def validate_dataset_keys(dataset_keys: Iterable[DatasetKey]):\n    regex = re.compile(r\"^[a-zA-Z0-9\\.\\-_]+$\")\n    for dataset_key in dataset_keys:\n        if not isinstance(dataset_key, DatasetKey):\n            raise ValueError(\"Dataset key {} must be of type DatasetKey\")\n        if not regex.match(dataset_key.key):\n            raise ValueError(\n                \"Dataset key {!r} does not match allowed pattern: {!r}\".format(\n                    dataset_key.key, regex.pattern\n                )\n            )\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/","title":"TensorFlow Transform <code>tft.beam.experimental</code> Module","text":""},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental","title":"tensorflow_transform.beam.experimental","text":"<p>Module level imports for tensorflow_transform.beam.experimental.</p>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental-classes","title":"Classes","text":""},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer","title":"PTransformAnalyzer","text":"<pre><code>PTransformAnalyzer()\n</code></pre> <p>               Bases: <code>PTransform</code></p> <p>A PTransform analyzer's base class which provides a temp dir if needed.</p> Source code in <code>tensorflow_transform/beam/experimental/analyzer_impls.py</code> <pre><code>def __init__(self):\n    self._base_temp_dir = None\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer-attributes","title":"Attributes","text":""},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.base_temp_dir","title":"base_temp_dir  <code>property</code> <code>writable</code>","text":"<pre><code>base_temp_dir\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.label","title":"label  <code>property</code> <code>writable</code>","text":"<pre><code>label\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.pipeline","title":"pipeline  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline = None\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.side_inputs","title":"side_inputs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>side_inputs = ()\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer-functions","title":"Functions","text":""},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.annotations","title":"annotations","text":"<pre><code>annotations() -&gt; dict[str, Union[bytes, str, Message]]\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def annotations(self) -&gt; dict[str, Union[bytes, str, message.Message]]:\n  return {\n      'python_type':  #\n      f'{self.__class__.__module__}.{self.__class__.__qualname__}'\n  }\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.default_label","title":"default_label","text":"<pre><code>default_label()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_label(self):\n  # type: () -&gt; str\n  return self.__class__.__name__\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.default_type_hints","title":"default_type_hints","text":"<pre><code>default_type_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_type_hints(self):\n  fn_type_hints = IOTypeHints.from_callable(self.expand)\n  if fn_type_hints is not None:\n    fn_type_hints = fn_type_hints.strip_pcoll()\n\n  # Prefer class decorator type hints for backwards compatibility.\n  return get_type_hints(self.__class__).with_defaults(fn_type_hints)\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.display_data","title":"display_data","text":"<pre><code>display_data()\n</code></pre> <p>Returns the display data associated to a pipeline component.</p> <p>It should be reimplemented in pipeline components that wish to have static display data.</p> RETURNS DESCRIPTION <p>Dict[str, Any]: A dictionary containing <code>key:value</code> pairs.</p> <p>The value might be an integer, float or string value; a</p> <p>class:<code>DisplayDataItem</code> for values that have more data</p> <p>(e.g. short value, label, url); or a :class:<code>HasDisplayData</code> instance</p> <p>that has more display data that should be picked up. For example::</p> <p>{   'key1': 'string_value',   'key2': 1234,   'key3': 3.14159265,   'key4': DisplayDataItem('apache.org', url='http://apache.org'),   'key5': subComponent }</p> Source code in <code>apache_beam/transforms/display.py</code> <pre><code>def display_data(self):\n  # type: () -&gt; dict\n\n  \"\"\" Returns the display data associated to a pipeline component.\n\n  It should be reimplemented in pipeline components that wish to have\n  static display data.\n\n  Returns:\n    Dict[str, Any]: A dictionary containing ``key:value`` pairs.\n    The value might be an integer, float or string value; a\n    :class:`DisplayDataItem` for values that have more data\n    (e.g. short value, label, url); or a :class:`HasDisplayData` instance\n    that has more display data that should be picked up. For example::\n\n      {\n        'key1': 'string_value',\n        'key2': 1234,\n        'key3': 3.14159265,\n        'key4': DisplayDataItem('apache.org', url='http://apache.org'),\n        'key5': subComponent\n      }\n  \"\"\"\n  return {}\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.expand","title":"expand","text":"<pre><code>expand(input_or_inputs: InputT) -&gt; OutputT\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def expand(self, input_or_inputs: InputT) -&gt; OutputT:\n  raise NotImplementedError\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.from_runner_api","title":"from_runner_api  <code>classmethod</code>","text":"<pre><code>from_runner_api(proto, context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef from_runner_api(\n    cls,\n    proto,  # type: Optional[beam_runner_api_pb2.PTransform]\n    context  # type: PipelineContext\n):\n  # type: (...) -&gt; Optional[PTransform]\n  if proto is None or proto.spec is None or not proto.spec.urn:\n    return None\n  parameter_type, constructor = cls._known_urns[proto.spec.urn]\n\n  return constructor(\n      proto,\n      proto_utils.parse_Bytes(proto.spec.payload, parameter_type),\n      context)\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.get_resource_hints","title":"get_resource_hints","text":"<pre><code>get_resource_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_resource_hints(self):\n  # type: () -&gt; dict[str, bytes]\n  if '_resource_hints' not in self.__dict__:\n    # PTransform subclasses don't always call super(), so prefer lazy\n    # initialization. By default, transforms don't have any resource hints.\n    self._resource_hints = {}  # type: dict[str, bytes]\n  return self._resource_hints\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.get_type_hints","title":"get_type_hints","text":"<pre><code>get_type_hints()\n</code></pre> <p>Gets and/or initializes type hints for this object.</p> <p>If type hints have not been set, attempts to initialize type hints in this order: - Using self.default_type_hints(). - Using self.class type hints.</p> Source code in <code>apache_beam/typehints/decorators.py</code> <pre><code>def get_type_hints(self):\n  \"\"\"Gets and/or initializes type hints for this object.\n\n  If type hints have not been set, attempts to initialize type hints in this\n  order:\n  - Using self.default_type_hints().\n  - Using self.__class__ type hints.\n  \"\"\"\n  return (\n      self._get_or_create_type_hints().with_defaults(\n          self.default_type_hints()).with_defaults(\n              get_type_hints(self.__class__)))\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.get_windowing","title":"get_windowing","text":"<pre><code>get_windowing(inputs)\n</code></pre> <p>Returns the window function to be associated with transform's output.</p> <p>By default most transforms just return the windowing function associated with the input PCollection (or the first input if several).</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_windowing(self, inputs):\n  # type: (Any) -&gt; Windowing\n\n  \"\"\"Returns the window function to be associated with transform's output.\n\n  By default most transforms just return the windowing function associated\n  with the input PCollection (or the first input if several).\n  \"\"\"\n  if inputs:\n    return inputs[0].windowing\n  else:\n    from apache_beam.transforms.core import Windowing\n    from apache_beam.transforms.window import GlobalWindows\n    # TODO(robertwb): Return something compatible with every windowing?\n    return Windowing(GlobalWindows())\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.infer_output_type","title":"infer_output_type","text":"<pre><code>infer_output_type(unused_input_type)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def infer_output_type(self, unused_input_type):\n  return self.get_type_hints().simple_output_type(self.label) or typehints.Any\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.register_urn","title":"register_urn  <code>classmethod</code>","text":"<pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre> <pre><code>register_urn(urn, parameter_type, constructor=None)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef register_urn(cls, urn, parameter_type, constructor=None):\n  def register(constructor):\n    if isinstance(constructor, type):\n      constructor.from_runner_api_parameter = register(\n          constructor.from_runner_api_parameter)\n    else:\n      cls._known_urns[urn] = parameter_type, constructor\n    return constructor\n\n  if constructor:\n    # Used as a statement.\n    register(constructor)\n  else:\n    # Used as a decorator.\n    return register\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.runner_api_requires_keyed_input","title":"runner_api_requires_keyed_input","text":"<pre><code>runner_api_requires_keyed_input()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def runner_api_requires_keyed_input(self):\n  return False\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.to_runner_api","title":"to_runner_api","text":"<pre><code>to_runner_api(context, has_parts=False, **extra_kwargs)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api(self, context, has_parts=False, **extra_kwargs):\n  # type: (PipelineContext, bool, Any) -&gt; beam_runner_api_pb2.FunctionSpec\n  from apache_beam.portability.api import beam_runner_api_pb2\n  # typing: only ParDo supports extra_kwargs\n  urn, typed_param = self.to_runner_api_parameter(context, **extra_kwargs)\n  if urn == python_urns.GENERIC_COMPOSITE_TRANSFORM and not has_parts:\n    # TODO(https://github.com/apache/beam/issues/18713): Remove this fallback.\n    urn, typed_param = self.to_runner_api_pickled(context)\n  return beam_runner_api_pb2.FunctionSpec(\n      urn=urn,\n      payload=typed_param.SerializeToString() if isinstance(\n          typed_param, message.Message) else typed_param.encode('utf-8')\n      if isinstance(typed_param, str) else typed_param)\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.to_runner_api_parameter","title":"to_runner_api_parameter","text":"<pre><code>to_runner_api_parameter(unused_context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_parameter(\n    self,\n    unused_context  # type: PipelineContext\n):\n  # type: (...) -&gt; tuple[str, Optional[Union[message.Message, bytes, str]]]\n  # The payload here is just to ease debugging.\n  return (\n      python_urns.GENERIC_COMPOSITE_TRANSFORM,\n      getattr(self, '_fn_api_payload', str(self)))\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.to_runner_api_pickled","title":"to_runner_api_pickled","text":"<pre><code>to_runner_api_pickled(context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_pickled(self, context):\n  # type: (PipelineContext) -&gt; tuple[str, bytes]\n  return (\n      python_urns.PICKLED_TRANSFORM,\n      pickler.dumps(\n          self,\n          enable_best_effort_determinism=context.\n          enable_best_effort_deterministic_pickling,\n      ),\n  )\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.type_check_inputs","title":"type_check_inputs","text":"<pre><code>type_check_inputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'input')\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.type_check_inputs_or_outputs","title":"type_check_inputs_or_outputs","text":"<pre><code>type_check_inputs_or_outputs(pvalueish, input_or_output)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs_or_outputs(self, pvalueish, input_or_output):\n  type_hints = self.get_type_hints()\n  hints = getattr(type_hints, input_or_output + '_types')\n  if hints is None or not any(hints):\n    return\n  arg_hints, kwarg_hints = hints\n  if arg_hints and kwarg_hints:\n    raise TypeCheckError(\n        'PTransform cannot have both positional and keyword type hints '\n        'without overriding %s._type_check_%s()' %\n        (self.__class__, input_or_output))\n  root_hint = (\n      arg_hints[0] if len(arg_hints) == 1 else arg_hints or kwarg_hints)\n  for context, pvalue_, hint in _ZipPValues().visit(pvalueish, root_hint):\n    if isinstance(pvalue_, DoOutputsTuple):\n      continue\n    if pvalue_.element_type is None:\n      # TODO(robertwb): It's a bug that we ever get here. (typecheck)\n      continue\n    if hint and not typehints.is_consistent_with(pvalue_.element_type, hint):\n      at_context = ' %s %s' % (input_or_output, context) if context else ''\n      raise TypeCheckError(\n          '{type} type hint violation at {label}{context}: expected {hint}, '\n          'got {actual_type}'.format(\n              type=input_or_output.title(),\n              label=self.label,\n              context=at_context,\n              hint=hint,\n              actual_type=pvalue_.element_type))\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.type_check_outputs","title":"type_check_outputs","text":"<pre><code>type_check_outputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_outputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'output')\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.with_input_types","title":"with_input_types","text":"<pre><code>with_input_types(input_type_hint)\n</code></pre> <p>Annotates the input type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>input_type_hint</code> <p>An instance of an allowed built-in type, a custom class, or an instance of a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If input_type_hint is not a valid type-hint. See :obj:<code>apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_input_types(self, input_type_hint):\n  \"\"\"Annotates the input type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    input_type_hint (type): An instance of an allowed built-in type, a custom\n      class, or an instance of a\n      :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **input_type_hint** is not a valid type-hint.\n      See\n      :obj:`apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  input_type_hint = native_type_compatibility.convert_to_beam_type(\n      input_type_hint)\n  validate_composite_type_param(\n      input_type_hint, 'Type hints for a PTransform')\n  return super().with_input_types(input_type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.with_output_types","title":"with_output_types","text":"<pre><code>with_output_types(type_hint)\n</code></pre> <p>Annotates the output type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>type_hint</code> <p>An instance of an allowed built-in type, a custom class, or a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If type_hint is not a valid type-hint. See :obj:<code>~apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_output_types(self, type_hint):\n  \"\"\"Annotates the output type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    type_hint (type): An instance of an allowed built-in type, a custom class,\n      or a :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **type_hint** is not a valid type-hint. See\n      :obj:`~apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  type_hint = native_type_compatibility.convert_to_beam_type(type_hint)\n  validate_composite_type_param(type_hint, 'Type hints for a PTransform')\n  return super().with_output_types(type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam-experimental/#tensorflow_transform.beam.experimental.PTransformAnalyzer.with_resource_hints","title":"with_resource_hints","text":"<pre><code>with_resource_hints(**kwargs)\n</code></pre> <p>Adds resource hints to the :class:<code>PTransform</code>.</p> <p>Resource hints allow users to express constraints on the environment where the transform should be executed.  Interpretation of the resource hints is defined by Beam Runners. Runners may ignore the unsupported hints.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>key-value pairs describing hints and their values.</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>if provided hints are unknown to the SDK. See :mod:<code>apache_beam.transforms.resources</code> for a list of known hints.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_resource_hints(self, **kwargs):  # type: (...) -&gt; PTransform\n  \"\"\"Adds resource hints to the :class:`PTransform`.\n\n  Resource hints allow users to express constraints on the environment where\n  the transform should be executed.  Interpretation of the resource hints is\n  defined by Beam Runners. Runners may ignore the unsupported hints.\n\n  Args:\n    **kwargs: key-value pairs describing hints and their values.\n\n  Raises:\n    ValueError: if provided hints are unknown to the SDK. See\n      :mod:`apache_beam.transforms.resources` for a list of known hints.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object.\n  \"\"\"\n  self.get_resource_hints().update(resources.parse_resource_hints(kwargs))\n  return self\n</code></pre>"},{"location":"api_docs/python/tft-beam/","title":"TensorFlow Transform <code>tft.beam</code> Module","text":""},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam","title":"tensorflow_transform.beam","text":"<p>Module level imports for tensorflow_transform.beam.</p>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam-classes","title":"Classes","text":""},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset","title":"AnalyzeAndTransformDataset","text":"<pre><code>AnalyzeAndTransformDataset(\n    preprocessing_fn, output_record_batches=False\n)\n</code></pre> <p>               Bases: <code>PTransform</code></p> <p>Combination of AnalyzeDataset and TransformDataset.</p> <pre><code>transformed, transform_fn = AnalyzeAndTransformDataset(\n    preprocessing_fn).expand(dataset)\n</code></pre> <p>should be equivalent to</p> <pre><code>transform_fn = AnalyzeDataset(preprocessing_fn).expand(dataset)\ntransformed = TransformDataset().expand((dataset, transform_fn))\n</code></pre> <p>but may be more efficient since it avoids multiple passes over the data.</p> <p>Init method.</p> <p>preprocessing_fn: A function that accepts and returns a dictionary from       strings to <code>Tensor</code>s, <code>SparseTensor</code>s, or <code>RaggedTensor</code>s.   output_record_batches: (Optional) A bool. If <code>True</code>,       <code>AnalyzeAndTransformDataset</code> outputs <code>pyarrow.RecordBatch</code>es;       otherwise, outputs instance dicts.</p> Source code in <code>tensorflow_transform/beam/impl.py</code> <pre><code>def __init__(self, preprocessing_fn, output_record_batches=False):\n    \"\"\"Init method.\n\n    Args:\n    ----\n      preprocessing_fn: A function that accepts and returns a dictionary from\n          strings to `Tensor`s, `SparseTensor`s, or `RaggedTensor`s.\n      output_record_batches: (Optional) A bool. If `True`,\n          `AnalyzeAndTransformDataset` outputs `pyarrow.RecordBatch`es;\n          otherwise, outputs instance dicts.\n    \"\"\"\n    self._preprocessing_fn = preprocessing_fn\n    self._output_record_batches = output_record_batches\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset-attributes","title":"Attributes","text":""},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.label","title":"label  <code>property</code> <code>writable</code>","text":"<pre><code>label\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.pipeline","title":"pipeline  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline = None\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.side_inputs","title":"side_inputs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>side_inputs = ()\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset-functions","title":"Functions","text":""},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.annotations","title":"annotations","text":"<pre><code>annotations() -&gt; dict[str, Union[bytes, str, Message]]\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def annotations(self) -&gt; dict[str, Union[bytes, str, message.Message]]:\n  return {\n      'python_type':  #\n      f'{self.__class__.__module__}.{self.__class__.__qualname__}'\n  }\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.default_label","title":"default_label","text":"<pre><code>default_label()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_label(self):\n  # type: () -&gt; str\n  return self.__class__.__name__\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.default_type_hints","title":"default_type_hints","text":"<pre><code>default_type_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_type_hints(self):\n  fn_type_hints = IOTypeHints.from_callable(self.expand)\n  if fn_type_hints is not None:\n    fn_type_hints = fn_type_hints.strip_pcoll()\n\n  # Prefer class decorator type hints for backwards compatibility.\n  return get_type_hints(self.__class__).with_defaults(fn_type_hints)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.display_data","title":"display_data","text":"<pre><code>display_data()\n</code></pre> <p>Returns the display data associated to a pipeline component.</p> <p>It should be reimplemented in pipeline components that wish to have static display data.</p> RETURNS DESCRIPTION <p>Dict[str, Any]: A dictionary containing <code>key:value</code> pairs.</p> <p>The value might be an integer, float or string value; a</p> <p>class:<code>DisplayDataItem</code> for values that have more data</p> <p>(e.g. short value, label, url); or a :class:<code>HasDisplayData</code> instance</p> <p>that has more display data that should be picked up. For example::</p> <p>{   'key1': 'string_value',   'key2': 1234,   'key3': 3.14159265,   'key4': DisplayDataItem('apache.org', url='http://apache.org'),   'key5': subComponent }</p> Source code in <code>apache_beam/transforms/display.py</code> <pre><code>def display_data(self):\n  # type: () -&gt; dict\n\n  \"\"\" Returns the display data associated to a pipeline component.\n\n  It should be reimplemented in pipeline components that wish to have\n  static display data.\n\n  Returns:\n    Dict[str, Any]: A dictionary containing ``key:value`` pairs.\n    The value might be an integer, float or string value; a\n    :class:`DisplayDataItem` for values that have more data\n    (e.g. short value, label, url); or a :class:`HasDisplayData` instance\n    that has more display data that should be picked up. For example::\n\n      {\n        'key1': 'string_value',\n        'key2': 1234,\n        'key3': 3.14159265,\n        'key4': DisplayDataItem('apache.org', url='http://apache.org'),\n        'key5': subComponent\n      }\n  \"\"\"\n  return {}\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.expand","title":"expand","text":"<pre><code>expand(dataset)\n</code></pre> <p>Transform the dataset by applying the preprocessing_fn.</p> <p>dataset: A dataset.</p> <p>A (Dataset, TransformFn) pair containing the preprocessed dataset and   the graph that maps the input to the output data.</p> Source code in <code>tensorflow_transform/beam/impl.py</code> <pre><code>def expand(self, dataset):\n    \"\"\"Transform the dataset by applying the preprocessing_fn.\n\n    Args:\n    ----\n      dataset: A dataset.\n\n    Returns:\n    -------\n      A (Dataset, TransformFn) pair containing the preprocessed dataset and\n      the graph that maps the input to the output data.\n    \"\"\"\n    # Expand is currently implemented by composing AnalyzeDataset and\n    # TransformDataset.  Future versions however could do somthing more optimal,\n    # e.g. caching the values of expensive computations done in AnalyzeDataset.\n    transform_fn = dataset | \"AnalyzeDataset\" &gt;&gt; AnalyzeDataset(\n        self._preprocessing_fn\n    )\n\n    if Context.get_use_deep_copy_optimization():\n        data, metadata = dataset\n\n        # obviates unnecessary data materialization when the input data source is\n        # safe to read more than once.\n        logging.info(\"Deep copying the dataset before applying transformation\")\n        dataset = (deep_copy.deep_copy(data), metadata)\n\n    transformed_dataset = (\n        dataset,\n        transform_fn,\n    ) | \"TransformDataset\" &gt;&gt; TransformDataset(\n        output_record_batches=self._output_record_batches\n    )\n    return transformed_dataset, transform_fn\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.from_runner_api","title":"from_runner_api  <code>classmethod</code>","text":"<pre><code>from_runner_api(proto, context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef from_runner_api(\n    cls,\n    proto,  # type: Optional[beam_runner_api_pb2.PTransform]\n    context  # type: PipelineContext\n):\n  # type: (...) -&gt; Optional[PTransform]\n  if proto is None or proto.spec is None or not proto.spec.urn:\n    return None\n  parameter_type, constructor = cls._known_urns[proto.spec.urn]\n\n  return constructor(\n      proto,\n      proto_utils.parse_Bytes(proto.spec.payload, parameter_type),\n      context)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.get_resource_hints","title":"get_resource_hints","text":"<pre><code>get_resource_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_resource_hints(self):\n  # type: () -&gt; dict[str, bytes]\n  if '_resource_hints' not in self.__dict__:\n    # PTransform subclasses don't always call super(), so prefer lazy\n    # initialization. By default, transforms don't have any resource hints.\n    self._resource_hints = {}  # type: dict[str, bytes]\n  return self._resource_hints\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.get_type_hints","title":"get_type_hints","text":"<pre><code>get_type_hints()\n</code></pre> <p>Gets and/or initializes type hints for this object.</p> <p>If type hints have not been set, attempts to initialize type hints in this order: - Using self.default_type_hints(). - Using self.class type hints.</p> Source code in <code>apache_beam/typehints/decorators.py</code> <pre><code>def get_type_hints(self):\n  \"\"\"Gets and/or initializes type hints for this object.\n\n  If type hints have not been set, attempts to initialize type hints in this\n  order:\n  - Using self.default_type_hints().\n  - Using self.__class__ type hints.\n  \"\"\"\n  return (\n      self._get_or_create_type_hints().with_defaults(\n          self.default_type_hints()).with_defaults(\n              get_type_hints(self.__class__)))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.get_windowing","title":"get_windowing","text":"<pre><code>get_windowing(inputs)\n</code></pre> <p>Returns the window function to be associated with transform's output.</p> <p>By default most transforms just return the windowing function associated with the input PCollection (or the first input if several).</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_windowing(self, inputs):\n  # type: (Any) -&gt; Windowing\n\n  \"\"\"Returns the window function to be associated with transform's output.\n\n  By default most transforms just return the windowing function associated\n  with the input PCollection (or the first input if several).\n  \"\"\"\n  if inputs:\n    return inputs[0].windowing\n  else:\n    from apache_beam.transforms.core import Windowing\n    from apache_beam.transforms.window import GlobalWindows\n    # TODO(robertwb): Return something compatible with every windowing?\n    return Windowing(GlobalWindows())\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.infer_output_type","title":"infer_output_type","text":"<pre><code>infer_output_type(unused_input_type)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def infer_output_type(self, unused_input_type):\n  return self.get_type_hints().simple_output_type(self.label) or typehints.Any\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.register_urn","title":"register_urn  <code>classmethod</code>","text":"<pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre> <pre><code>register_urn(urn, parameter_type, constructor=None)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef register_urn(cls, urn, parameter_type, constructor=None):\n  def register(constructor):\n    if isinstance(constructor, type):\n      constructor.from_runner_api_parameter = register(\n          constructor.from_runner_api_parameter)\n    else:\n      cls._known_urns[urn] = parameter_type, constructor\n    return constructor\n\n  if constructor:\n    # Used as a statement.\n    register(constructor)\n  else:\n    # Used as a decorator.\n    return register\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.runner_api_requires_keyed_input","title":"runner_api_requires_keyed_input","text":"<pre><code>runner_api_requires_keyed_input()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def runner_api_requires_keyed_input(self):\n  return False\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.to_runner_api","title":"to_runner_api","text":"<pre><code>to_runner_api(context, has_parts=False, **extra_kwargs)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api(self, context, has_parts=False, **extra_kwargs):\n  # type: (PipelineContext, bool, Any) -&gt; beam_runner_api_pb2.FunctionSpec\n  from apache_beam.portability.api import beam_runner_api_pb2\n  # typing: only ParDo supports extra_kwargs\n  urn, typed_param = self.to_runner_api_parameter(context, **extra_kwargs)\n  if urn == python_urns.GENERIC_COMPOSITE_TRANSFORM and not has_parts:\n    # TODO(https://github.com/apache/beam/issues/18713): Remove this fallback.\n    urn, typed_param = self.to_runner_api_pickled(context)\n  return beam_runner_api_pb2.FunctionSpec(\n      urn=urn,\n      payload=typed_param.SerializeToString() if isinstance(\n          typed_param, message.Message) else typed_param.encode('utf-8')\n      if isinstance(typed_param, str) else typed_param)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.to_runner_api_parameter","title":"to_runner_api_parameter","text":"<pre><code>to_runner_api_parameter(unused_context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_parameter(\n    self,\n    unused_context  # type: PipelineContext\n):\n  # type: (...) -&gt; tuple[str, Optional[Union[message.Message, bytes, str]]]\n  # The payload here is just to ease debugging.\n  return (\n      python_urns.GENERIC_COMPOSITE_TRANSFORM,\n      getattr(self, '_fn_api_payload', str(self)))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.to_runner_api_pickled","title":"to_runner_api_pickled","text":"<pre><code>to_runner_api_pickled(context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_pickled(self, context):\n  # type: (PipelineContext) -&gt; tuple[str, bytes]\n  return (\n      python_urns.PICKLED_TRANSFORM,\n      pickler.dumps(\n          self,\n          enable_best_effort_determinism=context.\n          enable_best_effort_deterministic_pickling,\n      ),\n  )\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.type_check_inputs","title":"type_check_inputs","text":"<pre><code>type_check_inputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'input')\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.type_check_inputs_or_outputs","title":"type_check_inputs_or_outputs","text":"<pre><code>type_check_inputs_or_outputs(pvalueish, input_or_output)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs_or_outputs(self, pvalueish, input_or_output):\n  type_hints = self.get_type_hints()\n  hints = getattr(type_hints, input_or_output + '_types')\n  if hints is None or not any(hints):\n    return\n  arg_hints, kwarg_hints = hints\n  if arg_hints and kwarg_hints:\n    raise TypeCheckError(\n        'PTransform cannot have both positional and keyword type hints '\n        'without overriding %s._type_check_%s()' %\n        (self.__class__, input_or_output))\n  root_hint = (\n      arg_hints[0] if len(arg_hints) == 1 else arg_hints or kwarg_hints)\n  for context, pvalue_, hint in _ZipPValues().visit(pvalueish, root_hint):\n    if isinstance(pvalue_, DoOutputsTuple):\n      continue\n    if pvalue_.element_type is None:\n      # TODO(robertwb): It's a bug that we ever get here. (typecheck)\n      continue\n    if hint and not typehints.is_consistent_with(pvalue_.element_type, hint):\n      at_context = ' %s %s' % (input_or_output, context) if context else ''\n      raise TypeCheckError(\n          '{type} type hint violation at {label}{context}: expected {hint}, '\n          'got {actual_type}'.format(\n              type=input_or_output.title(),\n              label=self.label,\n              context=at_context,\n              hint=hint,\n              actual_type=pvalue_.element_type))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.type_check_outputs","title":"type_check_outputs","text":"<pre><code>type_check_outputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_outputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'output')\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.with_input_types","title":"with_input_types","text":"<pre><code>with_input_types(input_type_hint)\n</code></pre> <p>Annotates the input type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>input_type_hint</code> <p>An instance of an allowed built-in type, a custom class, or an instance of a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If input_type_hint is not a valid type-hint. See :obj:<code>apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_input_types(self, input_type_hint):\n  \"\"\"Annotates the input type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    input_type_hint (type): An instance of an allowed built-in type, a custom\n      class, or an instance of a\n      :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **input_type_hint** is not a valid type-hint.\n      See\n      :obj:`apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  input_type_hint = native_type_compatibility.convert_to_beam_type(\n      input_type_hint)\n  validate_composite_type_param(\n      input_type_hint, 'Type hints for a PTransform')\n  return super().with_input_types(input_type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.with_output_types","title":"with_output_types","text":"<pre><code>with_output_types(type_hint)\n</code></pre> <p>Annotates the output type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>type_hint</code> <p>An instance of an allowed built-in type, a custom class, or a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If type_hint is not a valid type-hint. See :obj:<code>~apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_output_types(self, type_hint):\n  \"\"\"Annotates the output type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    type_hint (type): An instance of an allowed built-in type, a custom class,\n      or a :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **type_hint** is not a valid type-hint. See\n      :obj:`~apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  type_hint = native_type_compatibility.convert_to_beam_type(type_hint)\n  validate_composite_type_param(type_hint, 'Type hints for a PTransform')\n  return super().with_output_types(type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeAndTransformDataset.with_resource_hints","title":"with_resource_hints","text":"<pre><code>with_resource_hints(**kwargs)\n</code></pre> <p>Adds resource hints to the :class:<code>PTransform</code>.</p> <p>Resource hints allow users to express constraints on the environment where the transform should be executed.  Interpretation of the resource hints is defined by Beam Runners. Runners may ignore the unsupported hints.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>key-value pairs describing hints and their values.</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>if provided hints are unknown to the SDK. See :mod:<code>apache_beam.transforms.resources</code> for a list of known hints.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_resource_hints(self, **kwargs):  # type: (...) -&gt; PTransform\n  \"\"\"Adds resource hints to the :class:`PTransform`.\n\n  Resource hints allow users to express constraints on the environment where\n  the transform should be executed.  Interpretation of the resource hints is\n  defined by Beam Runners. Runners may ignore the unsupported hints.\n\n  Args:\n    **kwargs: key-value pairs describing hints and their values.\n\n  Raises:\n    ValueError: if provided hints are unknown to the SDK. See\n      :mod:`apache_beam.transforms.resources` for a list of known hints.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object.\n  \"\"\"\n  self.get_resource_hints().update(resources.parse_resource_hints(kwargs))\n  return self\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset","title":"AnalyzeDataset","text":"<pre><code>AnalyzeDataset(preprocessing_fn, pipeline=None)\n</code></pre> <p>               Bases: <code>_AnalyzeDatasetCommon</code></p> <p>Takes a preprocessing_fn and computes the relevant statistics.</p> <p>AnalyzeDataset accepts a preprocessing_fn in its constructor.  When its <code>expand</code> method is called on a dataset, it computes all the relevant statistics required to run the transformation described by the preprocessing_fn, and returns a TransformFn representing the application of the preprocessing_fn.</p> <p>Init method.</p> <p>preprocessing_fn: A function that accepts and returns a dictionary from     strings to <code>Tensor</code>s, <code>SparseTensor</code>s, or <code>RaggedTensor</code>s.   pipeline: (Optional) a beam Pipeline.</p> Source code in <code>tensorflow_transform/beam/impl.py</code> <pre><code>def __init__(self, preprocessing_fn, pipeline=None):\n    \"\"\"Init method.\n\n    Args:\n    ----\n      preprocessing_fn: A function that accepts and returns a dictionary from\n        strings to `Tensor`s, `SparseTensor`s, or `RaggedTensor`s.\n      pipeline: (Optional) a beam Pipeline.\n    \"\"\"\n    self._preprocessing_fn = preprocessing_fn\n    self.pipeline = pipeline\n    self._save_options = Context.get_save_options()\n    self._use_tf_compat_v1 = Context.get_use_tf_compat_v1()\n    if self._use_tf_compat_v1:\n        _warn_about_tf_compat_v1()\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset-attributes","title":"Attributes","text":""},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.label","title":"label  <code>property</code> <code>writable</code>","text":"<pre><code>label\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.pipeline","title":"pipeline  <code>instance-attribute</code>","text":"<pre><code>pipeline = pipeline\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.side_inputs","title":"side_inputs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>side_inputs = ()\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset-functions","title":"Functions","text":""},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.annotations","title":"annotations","text":"<pre><code>annotations() -&gt; dict[str, Union[bytes, str, Message]]\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def annotations(self) -&gt; dict[str, Union[bytes, str, message.Message]]:\n  return {\n      'python_type':  #\n      f'{self.__class__.__module__}.{self.__class__.__qualname__}'\n  }\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.default_label","title":"default_label","text":"<pre><code>default_label()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_label(self):\n  # type: () -&gt; str\n  return self.__class__.__name__\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.default_type_hints","title":"default_type_hints","text":"<pre><code>default_type_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_type_hints(self):\n  fn_type_hints = IOTypeHints.from_callable(self.expand)\n  if fn_type_hints is not None:\n    fn_type_hints = fn_type_hints.strip_pcoll()\n\n  # Prefer class decorator type hints for backwards compatibility.\n  return get_type_hints(self.__class__).with_defaults(fn_type_hints)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.display_data","title":"display_data","text":"<pre><code>display_data()\n</code></pre> <p>Returns the display data associated to a pipeline component.</p> <p>It should be reimplemented in pipeline components that wish to have static display data.</p> RETURNS DESCRIPTION <p>Dict[str, Any]: A dictionary containing <code>key:value</code> pairs.</p> <p>The value might be an integer, float or string value; a</p> <p>class:<code>DisplayDataItem</code> for values that have more data</p> <p>(e.g. short value, label, url); or a :class:<code>HasDisplayData</code> instance</p> <p>that has more display data that should be picked up. For example::</p> <p>{   'key1': 'string_value',   'key2': 1234,   'key3': 3.14159265,   'key4': DisplayDataItem('apache.org', url='http://apache.org'),   'key5': subComponent }</p> Source code in <code>apache_beam/transforms/display.py</code> <pre><code>def display_data(self):\n  # type: () -&gt; dict\n\n  \"\"\" Returns the display data associated to a pipeline component.\n\n  It should be reimplemented in pipeline components that wish to have\n  static display data.\n\n  Returns:\n    Dict[str, Any]: A dictionary containing ``key:value`` pairs.\n    The value might be an integer, float or string value; a\n    :class:`DisplayDataItem` for values that have more data\n    (e.g. short value, label, url); or a :class:`HasDisplayData` instance\n    that has more display data that should be picked up. For example::\n\n      {\n        'key1': 'string_value',\n        'key2': 1234,\n        'key3': 3.14159265,\n        'key4': DisplayDataItem('apache.org', url='http://apache.org'),\n        'key5': subComponent\n      }\n  \"\"\"\n  return {}\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.expand","title":"expand","text":"<pre><code>expand(dataset)\n</code></pre> <p>Analyze the dataset.</p> <p>dataset: A dataset.</p> <p>A TransformFn containing the deferred transform function.</p> <p>ValueError: If preprocessing_fn has no outputs.</p> Source code in <code>tensorflow_transform/beam/impl.py</code> <pre><code>def expand(self, dataset):\n    input_values, input_metadata = dataset\n    result, cache = super().expand((input_values, None, None, input_metadata))\n    assert not cache\n    return result\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.from_runner_api","title":"from_runner_api  <code>classmethod</code>","text":"<pre><code>from_runner_api(proto, context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef from_runner_api(\n    cls,\n    proto,  # type: Optional[beam_runner_api_pb2.PTransform]\n    context  # type: PipelineContext\n):\n  # type: (...) -&gt; Optional[PTransform]\n  if proto is None or proto.spec is None or not proto.spec.urn:\n    return None\n  parameter_type, constructor = cls._known_urns[proto.spec.urn]\n\n  return constructor(\n      proto,\n      proto_utils.parse_Bytes(proto.spec.payload, parameter_type),\n      context)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.get_resource_hints","title":"get_resource_hints","text":"<pre><code>get_resource_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_resource_hints(self):\n  # type: () -&gt; dict[str, bytes]\n  if '_resource_hints' not in self.__dict__:\n    # PTransform subclasses don't always call super(), so prefer lazy\n    # initialization. By default, transforms don't have any resource hints.\n    self._resource_hints = {}  # type: dict[str, bytes]\n  return self._resource_hints\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.get_type_hints","title":"get_type_hints","text":"<pre><code>get_type_hints()\n</code></pre> <p>Gets and/or initializes type hints for this object.</p> <p>If type hints have not been set, attempts to initialize type hints in this order: - Using self.default_type_hints(). - Using self.class type hints.</p> Source code in <code>apache_beam/typehints/decorators.py</code> <pre><code>def get_type_hints(self):\n  \"\"\"Gets and/or initializes type hints for this object.\n\n  If type hints have not been set, attempts to initialize type hints in this\n  order:\n  - Using self.default_type_hints().\n  - Using self.__class__ type hints.\n  \"\"\"\n  return (\n      self._get_or_create_type_hints().with_defaults(\n          self.default_type_hints()).with_defaults(\n              get_type_hints(self.__class__)))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.get_windowing","title":"get_windowing","text":"<pre><code>get_windowing(inputs)\n</code></pre> <p>Returns the window function to be associated with transform's output.</p> <p>By default most transforms just return the windowing function associated with the input PCollection (or the first input if several).</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_windowing(self, inputs):\n  # type: (Any) -&gt; Windowing\n\n  \"\"\"Returns the window function to be associated with transform's output.\n\n  By default most transforms just return the windowing function associated\n  with the input PCollection (or the first input if several).\n  \"\"\"\n  if inputs:\n    return inputs[0].windowing\n  else:\n    from apache_beam.transforms.core import Windowing\n    from apache_beam.transforms.window import GlobalWindows\n    # TODO(robertwb): Return something compatible with every windowing?\n    return Windowing(GlobalWindows())\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.infer_output_type","title":"infer_output_type","text":"<pre><code>infer_output_type(unused_input_type)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def infer_output_type(self, unused_input_type):\n  return self.get_type_hints().simple_output_type(self.label) or typehints.Any\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.register_urn","title":"register_urn  <code>classmethod</code>","text":"<pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre> <pre><code>register_urn(urn, parameter_type, constructor=None)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef register_urn(cls, urn, parameter_type, constructor=None):\n  def register(constructor):\n    if isinstance(constructor, type):\n      constructor.from_runner_api_parameter = register(\n          constructor.from_runner_api_parameter)\n    else:\n      cls._known_urns[urn] = parameter_type, constructor\n    return constructor\n\n  if constructor:\n    # Used as a statement.\n    register(constructor)\n  else:\n    # Used as a decorator.\n    return register\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.runner_api_requires_keyed_input","title":"runner_api_requires_keyed_input","text":"<pre><code>runner_api_requires_keyed_input()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def runner_api_requires_keyed_input(self):\n  return False\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.to_runner_api","title":"to_runner_api","text":"<pre><code>to_runner_api(context, has_parts=False, **extra_kwargs)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api(self, context, has_parts=False, **extra_kwargs):\n  # type: (PipelineContext, bool, Any) -&gt; beam_runner_api_pb2.FunctionSpec\n  from apache_beam.portability.api import beam_runner_api_pb2\n  # typing: only ParDo supports extra_kwargs\n  urn, typed_param = self.to_runner_api_parameter(context, **extra_kwargs)\n  if urn == python_urns.GENERIC_COMPOSITE_TRANSFORM and not has_parts:\n    # TODO(https://github.com/apache/beam/issues/18713): Remove this fallback.\n    urn, typed_param = self.to_runner_api_pickled(context)\n  return beam_runner_api_pb2.FunctionSpec(\n      urn=urn,\n      payload=typed_param.SerializeToString() if isinstance(\n          typed_param, message.Message) else typed_param.encode('utf-8')\n      if isinstance(typed_param, str) else typed_param)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.to_runner_api_parameter","title":"to_runner_api_parameter","text":"<pre><code>to_runner_api_parameter(unused_context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_parameter(\n    self,\n    unused_context  # type: PipelineContext\n):\n  # type: (...) -&gt; tuple[str, Optional[Union[message.Message, bytes, str]]]\n  # The payload here is just to ease debugging.\n  return (\n      python_urns.GENERIC_COMPOSITE_TRANSFORM,\n      getattr(self, '_fn_api_payload', str(self)))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.to_runner_api_pickled","title":"to_runner_api_pickled","text":"<pre><code>to_runner_api_pickled(context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_pickled(self, context):\n  # type: (PipelineContext) -&gt; tuple[str, bytes]\n  return (\n      python_urns.PICKLED_TRANSFORM,\n      pickler.dumps(\n          self,\n          enable_best_effort_determinism=context.\n          enable_best_effort_deterministic_pickling,\n      ),\n  )\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.type_check_inputs","title":"type_check_inputs","text":"<pre><code>type_check_inputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'input')\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.type_check_inputs_or_outputs","title":"type_check_inputs_or_outputs","text":"<pre><code>type_check_inputs_or_outputs(pvalueish, input_or_output)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs_or_outputs(self, pvalueish, input_or_output):\n  type_hints = self.get_type_hints()\n  hints = getattr(type_hints, input_or_output + '_types')\n  if hints is None or not any(hints):\n    return\n  arg_hints, kwarg_hints = hints\n  if arg_hints and kwarg_hints:\n    raise TypeCheckError(\n        'PTransform cannot have both positional and keyword type hints '\n        'without overriding %s._type_check_%s()' %\n        (self.__class__, input_or_output))\n  root_hint = (\n      arg_hints[0] if len(arg_hints) == 1 else arg_hints or kwarg_hints)\n  for context, pvalue_, hint in _ZipPValues().visit(pvalueish, root_hint):\n    if isinstance(pvalue_, DoOutputsTuple):\n      continue\n    if pvalue_.element_type is None:\n      # TODO(robertwb): It's a bug that we ever get here. (typecheck)\n      continue\n    if hint and not typehints.is_consistent_with(pvalue_.element_type, hint):\n      at_context = ' %s %s' % (input_or_output, context) if context else ''\n      raise TypeCheckError(\n          '{type} type hint violation at {label}{context}: expected {hint}, '\n          'got {actual_type}'.format(\n              type=input_or_output.title(),\n              label=self.label,\n              context=at_context,\n              hint=hint,\n              actual_type=pvalue_.element_type))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.type_check_outputs","title":"type_check_outputs","text":"<pre><code>type_check_outputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_outputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'output')\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.with_input_types","title":"with_input_types","text":"<pre><code>with_input_types(input_type_hint)\n</code></pre> <p>Annotates the input type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>input_type_hint</code> <p>An instance of an allowed built-in type, a custom class, or an instance of a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If input_type_hint is not a valid type-hint. See :obj:<code>apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_input_types(self, input_type_hint):\n  \"\"\"Annotates the input type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    input_type_hint (type): An instance of an allowed built-in type, a custom\n      class, or an instance of a\n      :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **input_type_hint** is not a valid type-hint.\n      See\n      :obj:`apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  input_type_hint = native_type_compatibility.convert_to_beam_type(\n      input_type_hint)\n  validate_composite_type_param(\n      input_type_hint, 'Type hints for a PTransform')\n  return super().with_input_types(input_type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.with_output_types","title":"with_output_types","text":"<pre><code>with_output_types(type_hint)\n</code></pre> <p>Annotates the output type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>type_hint</code> <p>An instance of an allowed built-in type, a custom class, or a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If type_hint is not a valid type-hint. See :obj:<code>~apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_output_types(self, type_hint):\n  \"\"\"Annotates the output type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    type_hint (type): An instance of an allowed built-in type, a custom class,\n      or a :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **type_hint** is not a valid type-hint. See\n      :obj:`~apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  type_hint = native_type_compatibility.convert_to_beam_type(type_hint)\n  validate_composite_type_param(type_hint, 'Type hints for a PTransform')\n  return super().with_output_types(type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDataset.with_resource_hints","title":"with_resource_hints","text":"<pre><code>with_resource_hints(**kwargs)\n</code></pre> <p>Adds resource hints to the :class:<code>PTransform</code>.</p> <p>Resource hints allow users to express constraints on the environment where the transform should be executed.  Interpretation of the resource hints is defined by Beam Runners. Runners may ignore the unsupported hints.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>key-value pairs describing hints and their values.</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>if provided hints are unknown to the SDK. See :mod:<code>apache_beam.transforms.resources</code> for a list of known hints.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_resource_hints(self, **kwargs):  # type: (...) -&gt; PTransform\n  \"\"\"Adds resource hints to the :class:`PTransform`.\n\n  Resource hints allow users to express constraints on the environment where\n  the transform should be executed.  Interpretation of the resource hints is\n  defined by Beam Runners. Runners may ignore the unsupported hints.\n\n  Args:\n    **kwargs: key-value pairs describing hints and their values.\n\n  Raises:\n    ValueError: if provided hints are unknown to the SDK. See\n      :mod:`apache_beam.transforms.resources` for a list of known hints.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object.\n  \"\"\"\n  self.get_resource_hints().update(resources.parse_resource_hints(kwargs))\n  return self\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache","title":"AnalyzeDatasetWithCache","text":"<pre><code>AnalyzeDatasetWithCache(preprocessing_fn, pipeline=None)\n</code></pre> <p>               Bases: <code>_AnalyzeDatasetCommon</code></p> <p>Takes a preprocessing_fn and computes the relevant statistics.</p> <p>WARNING: This is experimental.</p> <p>Operates similarly to AnalyzeDataset, by computing the required statistics except this will not re-compute statistics when they are already cached, and will write out cache for statistics that it does compute whenever possible.</p> <p>Example use:</p> <p>span_0_key = tft_beam.analyzer_cache.DatasetKey('span-0') cache_dir = tempfile.mkdtemp() output_path = os.path.join(tempfile.mkdtemp(), 'result') def preprocessing_fn(inputs): ...   x = inputs['x'] ...   return {'x_mean': tft.mean(x, name='x') + tf.zeros_like(x)} feature_spec = {'x': tf.io.FixedLenFeature([], tf.float32)} input_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec) input_data_dict_0 = {span_0_key: [{'x': x} for x in range(6)]} input_data_dict_1 = {span_0_key: [{'x': x} for x in range(6, 11)]} empty_input_cache = {} with tft_beam.Context(temp_dir=tempfile.mkdtemp()): ...   with beam.Pipeline() as p: ...     # Iteration #0: ...     transform_fn, output_cache = ( ...         (input_data_dict_0, empty_input_cache, input_metadata) ...         | tft_beam.AnalyzeDatasetWithCache(preprocessing_fn)) ...     output_cache | tft_beam.analyzer_cache.WriteAnalysisCacheToFS( ...         p, cache_dir) ... ...     # Iteration #1: ...     input_cache = p | tft_beam.analyzer_cache.ReadAnalysisCacheFromFS( ...          cache_dir, [span_0_key]) ...     transform_fn, output_cache = ( ...         (input_data_dict_1, input_cache, input_metadata) ...         | tft_beam.AnalyzeDatasetWithCache(preprocessing_fn)) ...     output_cache | tft_beam.analyzer_cache.WriteAnalysisCacheToFS( ...         p, cache_dir) ... ...     # Applying the accumulated transformation: ...     transform_data = p | beam.Create(input_data_dict_0[span_0_key]) ...     transformed_dataset = ( ...         ((transform_data, input_metadata), transform_fn) ...         | tft_beam.TransformDataset()) ...     transformed_data, transformed_metadata = transformed_dataset ...     (transformed_data ...         | beam.combiners.Sample.FixedSizeGlobally(1) ...         | beam.io.WriteToText(output_path, shard_name_template='')) with open(output_path) as f: ...   f.read()</p> <p>\"[{'x_mean': 5.0}]\\n\"</p> <p>Init method.</p> <p>preprocessing_fn: A function that accepts and returns a dictionary from     strings to <code>Tensor</code>s, <code>SparseTensor</code>s, or <code>RaggedTensor</code>s.   pipeline: (Optional) a beam Pipeline.</p> Source code in <code>tensorflow_transform/beam/impl.py</code> <pre><code>def __init__(self, preprocessing_fn, pipeline=None):\n    \"\"\"Init method.\n\n    Args:\n    ----\n      preprocessing_fn: A function that accepts and returns a dictionary from\n        strings to `Tensor`s, `SparseTensor`s, or `RaggedTensor`s.\n      pipeline: (Optional) a beam Pipeline.\n    \"\"\"\n    self._preprocessing_fn = preprocessing_fn\n    self.pipeline = pipeline\n    self._save_options = Context.get_save_options()\n    self._use_tf_compat_v1 = Context.get_use_tf_compat_v1()\n    if self._use_tf_compat_v1:\n        _warn_about_tf_compat_v1()\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache-attributes","title":"Attributes","text":""},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.label","title":"label  <code>property</code> <code>writable</code>","text":"<pre><code>label\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.pipeline","title":"pipeline  <code>instance-attribute</code>","text":"<pre><code>pipeline = pipeline\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.side_inputs","title":"side_inputs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>side_inputs = ()\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache-functions","title":"Functions","text":""},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.annotations","title":"annotations","text":"<pre><code>annotations() -&gt; dict[str, Union[bytes, str, Message]]\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def annotations(self) -&gt; dict[str, Union[bytes, str, message.Message]]:\n  return {\n      'python_type':  #\n      f'{self.__class__.__module__}.{self.__class__.__qualname__}'\n  }\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.default_label","title":"default_label","text":"<pre><code>default_label()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_label(self):\n  # type: () -&gt; str\n  return self.__class__.__name__\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.default_type_hints","title":"default_type_hints","text":"<pre><code>default_type_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_type_hints(self):\n  fn_type_hints = IOTypeHints.from_callable(self.expand)\n  if fn_type_hints is not None:\n    fn_type_hints = fn_type_hints.strip_pcoll()\n\n  # Prefer class decorator type hints for backwards compatibility.\n  return get_type_hints(self.__class__).with_defaults(fn_type_hints)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.display_data","title":"display_data","text":"<pre><code>display_data()\n</code></pre> <p>Returns the display data associated to a pipeline component.</p> <p>It should be reimplemented in pipeline components that wish to have static display data.</p> RETURNS DESCRIPTION <p>Dict[str, Any]: A dictionary containing <code>key:value</code> pairs.</p> <p>The value might be an integer, float or string value; a</p> <p>class:<code>DisplayDataItem</code> for values that have more data</p> <p>(e.g. short value, label, url); or a :class:<code>HasDisplayData</code> instance</p> <p>that has more display data that should be picked up. For example::</p> <p>{   'key1': 'string_value',   'key2': 1234,   'key3': 3.14159265,   'key4': DisplayDataItem('apache.org', url='http://apache.org'),   'key5': subComponent }</p> Source code in <code>apache_beam/transforms/display.py</code> <pre><code>def display_data(self):\n  # type: () -&gt; dict\n\n  \"\"\" Returns the display data associated to a pipeline component.\n\n  It should be reimplemented in pipeline components that wish to have\n  static display data.\n\n  Returns:\n    Dict[str, Any]: A dictionary containing ``key:value`` pairs.\n    The value might be an integer, float or string value; a\n    :class:`DisplayDataItem` for values that have more data\n    (e.g. short value, label, url); or a :class:`HasDisplayData` instance\n    that has more display data that should be picked up. For example::\n\n      {\n        'key1': 'string_value',\n        'key2': 1234,\n        'key3': 3.14159265,\n        'key4': DisplayDataItem('apache.org', url='http://apache.org'),\n        'key5': subComponent\n      }\n  \"\"\"\n  return {}\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.expand","title":"expand","text":"<pre><code>expand(dataset)\n</code></pre> <p>Analyze the dataset.</p> <p>dataset: A dataset.</p> <p>A TransformFn containing the deferred transform function.</p> <p>ValueError: If preprocessing_fn has no outputs.</p> Source code in <code>tensorflow_transform/beam/impl.py</code> <pre><code>def expand(self, dataset):\n    input_values_pcoll_dict = dataset[1] or dict()\n    analyzer_cache.validate_dataset_keys(input_values_pcoll_dict.keys())\n    return super().expand(self._make_parent_dataset(dataset))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.from_runner_api","title":"from_runner_api  <code>classmethod</code>","text":"<pre><code>from_runner_api(proto, context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef from_runner_api(\n    cls,\n    proto,  # type: Optional[beam_runner_api_pb2.PTransform]\n    context  # type: PipelineContext\n):\n  # type: (...) -&gt; Optional[PTransform]\n  if proto is None or proto.spec is None or not proto.spec.urn:\n    return None\n  parameter_type, constructor = cls._known_urns[proto.spec.urn]\n\n  return constructor(\n      proto,\n      proto_utils.parse_Bytes(proto.spec.payload, parameter_type),\n      context)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.get_resource_hints","title":"get_resource_hints","text":"<pre><code>get_resource_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_resource_hints(self):\n  # type: () -&gt; dict[str, bytes]\n  if '_resource_hints' not in self.__dict__:\n    # PTransform subclasses don't always call super(), so prefer lazy\n    # initialization. By default, transforms don't have any resource hints.\n    self._resource_hints = {}  # type: dict[str, bytes]\n  return self._resource_hints\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.get_type_hints","title":"get_type_hints","text":"<pre><code>get_type_hints()\n</code></pre> <p>Gets and/or initializes type hints for this object.</p> <p>If type hints have not been set, attempts to initialize type hints in this order: - Using self.default_type_hints(). - Using self.class type hints.</p> Source code in <code>apache_beam/typehints/decorators.py</code> <pre><code>def get_type_hints(self):\n  \"\"\"Gets and/or initializes type hints for this object.\n\n  If type hints have not been set, attempts to initialize type hints in this\n  order:\n  - Using self.default_type_hints().\n  - Using self.__class__ type hints.\n  \"\"\"\n  return (\n      self._get_or_create_type_hints().with_defaults(\n          self.default_type_hints()).with_defaults(\n              get_type_hints(self.__class__)))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.get_windowing","title":"get_windowing","text":"<pre><code>get_windowing(inputs)\n</code></pre> <p>Returns the window function to be associated with transform's output.</p> <p>By default most transforms just return the windowing function associated with the input PCollection (or the first input if several).</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_windowing(self, inputs):\n  # type: (Any) -&gt; Windowing\n\n  \"\"\"Returns the window function to be associated with transform's output.\n\n  By default most transforms just return the windowing function associated\n  with the input PCollection (or the first input if several).\n  \"\"\"\n  if inputs:\n    return inputs[0].windowing\n  else:\n    from apache_beam.transforms.core import Windowing\n    from apache_beam.transforms.window import GlobalWindows\n    # TODO(robertwb): Return something compatible with every windowing?\n    return Windowing(GlobalWindows())\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.infer_output_type","title":"infer_output_type","text":"<pre><code>infer_output_type(unused_input_type)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def infer_output_type(self, unused_input_type):\n  return self.get_type_hints().simple_output_type(self.label) or typehints.Any\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.register_urn","title":"register_urn  <code>classmethod</code>","text":"<pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre> <pre><code>register_urn(urn, parameter_type, constructor=None)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef register_urn(cls, urn, parameter_type, constructor=None):\n  def register(constructor):\n    if isinstance(constructor, type):\n      constructor.from_runner_api_parameter = register(\n          constructor.from_runner_api_parameter)\n    else:\n      cls._known_urns[urn] = parameter_type, constructor\n    return constructor\n\n  if constructor:\n    # Used as a statement.\n    register(constructor)\n  else:\n    # Used as a decorator.\n    return register\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.runner_api_requires_keyed_input","title":"runner_api_requires_keyed_input","text":"<pre><code>runner_api_requires_keyed_input()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def runner_api_requires_keyed_input(self):\n  return False\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.to_runner_api","title":"to_runner_api","text":"<pre><code>to_runner_api(context, has_parts=False, **extra_kwargs)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api(self, context, has_parts=False, **extra_kwargs):\n  # type: (PipelineContext, bool, Any) -&gt; beam_runner_api_pb2.FunctionSpec\n  from apache_beam.portability.api import beam_runner_api_pb2\n  # typing: only ParDo supports extra_kwargs\n  urn, typed_param = self.to_runner_api_parameter(context, **extra_kwargs)\n  if urn == python_urns.GENERIC_COMPOSITE_TRANSFORM and not has_parts:\n    # TODO(https://github.com/apache/beam/issues/18713): Remove this fallback.\n    urn, typed_param = self.to_runner_api_pickled(context)\n  return beam_runner_api_pb2.FunctionSpec(\n      urn=urn,\n      payload=typed_param.SerializeToString() if isinstance(\n          typed_param, message.Message) else typed_param.encode('utf-8')\n      if isinstance(typed_param, str) else typed_param)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.to_runner_api_parameter","title":"to_runner_api_parameter","text":"<pre><code>to_runner_api_parameter(unused_context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_parameter(\n    self,\n    unused_context  # type: PipelineContext\n):\n  # type: (...) -&gt; tuple[str, Optional[Union[message.Message, bytes, str]]]\n  # The payload here is just to ease debugging.\n  return (\n      python_urns.GENERIC_COMPOSITE_TRANSFORM,\n      getattr(self, '_fn_api_payload', str(self)))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.to_runner_api_pickled","title":"to_runner_api_pickled","text":"<pre><code>to_runner_api_pickled(context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_pickled(self, context):\n  # type: (PipelineContext) -&gt; tuple[str, bytes]\n  return (\n      python_urns.PICKLED_TRANSFORM,\n      pickler.dumps(\n          self,\n          enable_best_effort_determinism=context.\n          enable_best_effort_deterministic_pickling,\n      ),\n  )\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.type_check_inputs","title":"type_check_inputs","text":"<pre><code>type_check_inputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'input')\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.type_check_inputs_or_outputs","title":"type_check_inputs_or_outputs","text":"<pre><code>type_check_inputs_or_outputs(pvalueish, input_or_output)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs_or_outputs(self, pvalueish, input_or_output):\n  type_hints = self.get_type_hints()\n  hints = getattr(type_hints, input_or_output + '_types')\n  if hints is None or not any(hints):\n    return\n  arg_hints, kwarg_hints = hints\n  if arg_hints and kwarg_hints:\n    raise TypeCheckError(\n        'PTransform cannot have both positional and keyword type hints '\n        'without overriding %s._type_check_%s()' %\n        (self.__class__, input_or_output))\n  root_hint = (\n      arg_hints[0] if len(arg_hints) == 1 else arg_hints or kwarg_hints)\n  for context, pvalue_, hint in _ZipPValues().visit(pvalueish, root_hint):\n    if isinstance(pvalue_, DoOutputsTuple):\n      continue\n    if pvalue_.element_type is None:\n      # TODO(robertwb): It's a bug that we ever get here. (typecheck)\n      continue\n    if hint and not typehints.is_consistent_with(pvalue_.element_type, hint):\n      at_context = ' %s %s' % (input_or_output, context) if context else ''\n      raise TypeCheckError(\n          '{type} type hint violation at {label}{context}: expected {hint}, '\n          'got {actual_type}'.format(\n              type=input_or_output.title(),\n              label=self.label,\n              context=at_context,\n              hint=hint,\n              actual_type=pvalue_.element_type))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.type_check_outputs","title":"type_check_outputs","text":"<pre><code>type_check_outputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_outputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'output')\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.with_input_types","title":"with_input_types","text":"<pre><code>with_input_types(input_type_hint)\n</code></pre> <p>Annotates the input type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>input_type_hint</code> <p>An instance of an allowed built-in type, a custom class, or an instance of a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If input_type_hint is not a valid type-hint. See :obj:<code>apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_input_types(self, input_type_hint):\n  \"\"\"Annotates the input type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    input_type_hint (type): An instance of an allowed built-in type, a custom\n      class, or an instance of a\n      :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **input_type_hint** is not a valid type-hint.\n      See\n      :obj:`apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  input_type_hint = native_type_compatibility.convert_to_beam_type(\n      input_type_hint)\n  validate_composite_type_param(\n      input_type_hint, 'Type hints for a PTransform')\n  return super().with_input_types(input_type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.with_output_types","title":"with_output_types","text":"<pre><code>with_output_types(type_hint)\n</code></pre> <p>Annotates the output type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>type_hint</code> <p>An instance of an allowed built-in type, a custom class, or a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If type_hint is not a valid type-hint. See :obj:<code>~apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_output_types(self, type_hint):\n  \"\"\"Annotates the output type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    type_hint (type): An instance of an allowed built-in type, a custom class,\n      or a :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **type_hint** is not a valid type-hint. See\n      :obj:`~apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  type_hint = native_type_compatibility.convert_to_beam_type(type_hint)\n  validate_composite_type_param(type_hint, 'Type hints for a PTransform')\n  return super().with_output_types(type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.AnalyzeDatasetWithCache.with_resource_hints","title":"with_resource_hints","text":"<pre><code>with_resource_hints(**kwargs)\n</code></pre> <p>Adds resource hints to the :class:<code>PTransform</code>.</p> <p>Resource hints allow users to express constraints on the environment where the transform should be executed.  Interpretation of the resource hints is defined by Beam Runners. Runners may ignore the unsupported hints.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>key-value pairs describing hints and their values.</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>if provided hints are unknown to the SDK. See :mod:<code>apache_beam.transforms.resources</code> for a list of known hints.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_resource_hints(self, **kwargs):  # type: (...) -&gt; PTransform\n  \"\"\"Adds resource hints to the :class:`PTransform`.\n\n  Resource hints allow users to express constraints on the environment where\n  the transform should be executed.  Interpretation of the resource hints is\n  defined by Beam Runners. Runners may ignore the unsupported hints.\n\n  Args:\n    **kwargs: key-value pairs describing hints and their values.\n\n  Raises:\n    ValueError: if provided hints are unknown to the SDK. See\n      :mod:`apache_beam.transforms.resources` for a list of known hints.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object.\n  \"\"\"\n  self.get_resource_hints().update(resources.parse_resource_hints(kwargs))\n  return self\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.Context","title":"Context","text":"<pre><code>Context(\n    temp_dir: Optional[str] = None,\n    desired_batch_size: Optional[int] = None,\n    passthrough_keys: Optional[Iterable[str]] = None,\n    use_deep_copy_optimization: Optional[bool] = None,\n    force_tf_compat_v1: Optional[bool] = None,\n    save_options: Optional[SaveOptions] = None,\n)\n</code></pre> <p>Context manager for tensorflow-transform.</p> <p>All the attributes in this context are kept on a thread local state.</p>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.Context--attributes","title":"Attributes","text":"<p>temp_dir: (Optional) The temporary directory used within in this block.   desired_batch_size: (Optional) A batch size to batch elements by. If not       provided, a batch size will be computed automatically.   passthrough_keys: (Optional) A set of strings that are keys to       instances that should pass through the pipeline and be hidden from       the preprocessing_fn. This should only be used in cases where additional       information should be attached to instances in the pipeline which should       not be part of the transformation graph, instance keys is one such       example.   use_deep_copy_optimization: (Optional) If True, makes deep copies of       PCollections that are used in multiple TFT phases.   force_tf_compat_v1: (Optional) If True, TFT's public APIs       (e.g. AnalyzeDataset) will use Tensorflow in compat.v1 mode irrespective       of installed version of Tensorflow. Defaults to <code>False</code>.   save_options: (Optional) If set, the tf.saved_model.SaveOptions to save       the transform_fn with. Only applies for TF2.</p> <p>Note that the temp dir should be accessible to worker jobs, e.g. if running with the Cloud Dataflow runner, the temp dir should be on GCS and should have permissions that allow both launcher and workers to access it.</p> Source code in <code>tensorflow_transform/beam/context.py</code> <pre><code>def __init__(\n    self,\n    temp_dir: Optional[str] = None,\n    desired_batch_size: Optional[int] = None,\n    passthrough_keys: Optional[Iterable[str]] = None,\n    use_deep_copy_optimization: Optional[bool] = None,\n    force_tf_compat_v1: Optional[bool] = None,\n    save_options: Optional[tf.saved_model.SaveOptions] = None,\n):\n    state = getattr(self._thread_local, \"state\", None)\n    if not state:\n        self._thread_local.state = self._StateStack()\n        self._thread_local.state.frames.append(\n            self._State(*(None,) * len(dataclasses.fields(self._State)))\n        )\n\n    self._temp_dir = temp_dir\n    self._desired_batch_size = desired_batch_size\n    self._passthrough_keys = passthrough_keys\n    self._use_deep_copy_optimization = use_deep_copy_optimization\n    self._force_tf_compat_v1 = force_tf_compat_v1\n    self._save_options = save_options\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.Context-functions","title":"Functions","text":""},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.Context.create_base_temp_dir","title":"create_base_temp_dir  <code>classmethod</code>","text":"<pre><code>create_base_temp_dir() -&gt; str\n</code></pre> <p>Generate a temporary location.</p> Source code in <code>tensorflow_transform/beam/context.py</code> <pre><code>@classmethod\ndef create_base_temp_dir(cls) -&gt; str:\n    \"\"\"Generate a temporary location.\"\"\"\n    state = cls._get_topmost_state_frame()\n    if not state.temp_dir:\n        raise ValueError(\n            \"A tf.Transform function that required a temp dir was called but no \"\n            \"temp dir was set.  To set a temp dir use the impl.Context context \"\n            \"manager.\"\n        )\n    base_temp_dir = os.path.join(state.temp_dir, cls._TEMP_SUBDIR)\n\n    # TODO(b/35363519): Perhaps use Beam IO eventually?\n    tf.io.gfile.makedirs(base_temp_dir)\n    return base_temp_dir\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.Context.get_desired_batch_size","title":"get_desired_batch_size  <code>classmethod</code>","text":"<pre><code>get_desired_batch_size() -&gt; Optional[int]\n</code></pre> <p>Retrieves a user set fixed batch size, None if not set.</p> Source code in <code>tensorflow_transform/beam/context.py</code> <pre><code>@classmethod\ndef get_desired_batch_size(cls) -&gt; Optional[int]:\n    \"\"\"Retrieves a user set fixed batch size, None if not set.\"\"\"\n    state = cls._get_topmost_state_frame()\n    if state.desired_batch_size is not None:\n        tf.compat.v1.logging.info(\n            \"Using fixed batch size: %d\", state.desired_batch_size\n        )\n        return state.desired_batch_size\n    return None\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.Context.get_passthrough_keys","title":"get_passthrough_keys  <code>classmethod</code>","text":"<pre><code>get_passthrough_keys() -&gt; Iterable[str]\n</code></pre> <p>Retrieves a user set passthrough_keys, None if not set.</p> Source code in <code>tensorflow_transform/beam/context.py</code> <pre><code>@classmethod\ndef get_passthrough_keys(cls) -&gt; Iterable[str]:\n    \"\"\"Retrieves a user set passthrough_keys, None if not set.\"\"\"\n    state = cls._get_topmost_state_frame()\n    if state.passthrough_keys is not None:\n        return state.passthrough_keys\n    return set()\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.Context.get_save_options","title":"get_save_options  <code>classmethod</code>","text":"<pre><code>get_save_options() -&gt; Optional[SaveOptions]\n</code></pre> <p>Retrieves a user set save_options, None if not set.</p> Source code in <code>tensorflow_transform/beam/context.py</code> <pre><code>@classmethod\ndef get_save_options(cls) -&gt; Optional[tf.saved_model.SaveOptions]:\n    \"\"\"Retrieves a user set save_options, None if not set.\"\"\"\n    state = cls._get_topmost_state_frame()\n    if state.save_options is not None:\n        tf.compat.v1.logging.info(\"Using save_options: %s\", state.save_options)\n        return state.save_options\n    return None\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.Context.get_use_deep_copy_optimization","title":"get_use_deep_copy_optimization  <code>classmethod</code>","text":"<pre><code>get_use_deep_copy_optimization() -&gt; bool\n</code></pre> <p>Retrieves a user set use_deep_copy_optimization, None if not set.</p> Source code in <code>tensorflow_transform/beam/context.py</code> <pre><code>@classmethod\ndef get_use_deep_copy_optimization(cls) -&gt; bool:\n    \"\"\"Retrieves a user set use_deep_copy_optimization, None if not set.\"\"\"\n    state = cls._get_topmost_state_frame()\n    if state.use_deep_copy_optimization is not None:\n        return state.use_deep_copy_optimization\n    return False\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.Context.get_use_tf_compat_v1","title":"get_use_tf_compat_v1  <code>classmethod</code>","text":"<pre><code>get_use_tf_compat_v1() -&gt; bool\n</code></pre> <p>Computes use_tf_compat_v1 from TF environment and force_tf_compat_v1.</p> Source code in <code>tensorflow_transform/beam/context.py</code> <pre><code>@classmethod\ndef get_use_tf_compat_v1(cls) -&gt; bool:\n    \"\"\"Computes use_tf_compat_v1 from TF environment and force_tf_compat_v1.\"\"\"\n    force_tf_compat_v1 = cls._get_force_tf_compat_v1()\n    return tf2_utils.use_tf_compat_v1(force_tf_compat_v1)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset","title":"EncodeTransformedDataset","text":"<pre><code>EncodeTransformedDataset(label=None)\n</code></pre> <p>               Bases: <code>PTransform</code></p> <p>Encodes transformed data into serialized tf.Examples.</p> <p>Should operate on the output of <code>TransformDataset</code>, this can operate on either record batch or instance dict data. The expected input is a (transformed_data, transformed_metadata) tuple.</p> <p>Example use:</p> <p>def preprocessing_fn(inputs): ...   return {'x_scaled': tft.scale_to_z_score(inputs['x'], name='x')} raw_data = [dict(x=1), dict(x=2), dict(x=3)] feature_spec = dict(x=tf.io.FixedLenFeature([], tf.int64)) raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec) output_path = os.path.join(tempfile.mkdtemp(), 'result') with beam.Pipeline() as p: ...   with tft_beam.Context(temp_dir=tempfile.mkdtemp()): ...     data_pcoll = p | beam.Create(raw_data) ...     transformed_dataset, transform_fn = ( ...         (data_pcoll, raw_data_metadata) ...         | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn)) ...     _ = ( ...       transformed_dataset ...       | tft_beam.EncodeTransformedDataset() ...       | beam.io.WriteToTFRecord(output_path, shard_name_template='')) result_feature_spec ={'x_scaled': tf.io.FixedLenFeature([], tf.float32)} list(tf.data.TFRecordDataset([output_path]) ...      .map(lambda x: tf.io.parse_example(x, result_feature_spec)) ...      .as_numpy_iterator()) [{'x_scaled': -1.2247448}, {'x_scaled': 0.0}, {'x_scaled': 1.2247448}]</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def __init__(self, label=None):\n  # type: (Optional[str]) -&gt; None\n  super().__init__()\n  self.label = label  # type: ignore # https://github.com/python/mypy/issues/3004\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset-attributes","title":"Attributes","text":""},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.label","title":"label  <code>property</code> <code>writable</code>","text":"<pre><code>label\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.pipeline","title":"pipeline  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline = None\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.side_inputs","title":"side_inputs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>side_inputs = ()\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset-functions","title":"Functions","text":""},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.annotations","title":"annotations","text":"<pre><code>annotations() -&gt; dict[str, Union[bytes, str, Message]]\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def annotations(self) -&gt; dict[str, Union[bytes, str, message.Message]]:\n  return {\n      'python_type':  #\n      f'{self.__class__.__module__}.{self.__class__.__qualname__}'\n  }\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.default_label","title":"default_label","text":"<pre><code>default_label()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_label(self):\n  # type: () -&gt; str\n  return self.__class__.__name__\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.default_type_hints","title":"default_type_hints","text":"<pre><code>default_type_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_type_hints(self):\n  fn_type_hints = IOTypeHints.from_callable(self.expand)\n  if fn_type_hints is not None:\n    fn_type_hints = fn_type_hints.strip_pcoll()\n\n  # Prefer class decorator type hints for backwards compatibility.\n  return get_type_hints(self.__class__).with_defaults(fn_type_hints)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.display_data","title":"display_data","text":"<pre><code>display_data()\n</code></pre> <p>Returns the display data associated to a pipeline component.</p> <p>It should be reimplemented in pipeline components that wish to have static display data.</p> RETURNS DESCRIPTION <p>Dict[str, Any]: A dictionary containing <code>key:value</code> pairs.</p> <p>The value might be an integer, float or string value; a</p> <p>class:<code>DisplayDataItem</code> for values that have more data</p> <p>(e.g. short value, label, url); or a :class:<code>HasDisplayData</code> instance</p> <p>that has more display data that should be picked up. For example::</p> <p>{   'key1': 'string_value',   'key2': 1234,   'key3': 3.14159265,   'key4': DisplayDataItem('apache.org', url='http://apache.org'),   'key5': subComponent }</p> Source code in <code>apache_beam/transforms/display.py</code> <pre><code>def display_data(self):\n  # type: () -&gt; dict\n\n  \"\"\" Returns the display data associated to a pipeline component.\n\n  It should be reimplemented in pipeline components that wish to have\n  static display data.\n\n  Returns:\n    Dict[str, Any]: A dictionary containing ``key:value`` pairs.\n    The value might be an integer, float or string value; a\n    :class:`DisplayDataItem` for values that have more data\n    (e.g. short value, label, url); or a :class:`HasDisplayData` instance\n    that has more display data that should be picked up. For example::\n\n      {\n        'key1': 'string_value',\n        'key2': 1234,\n        'key3': 3.14159265,\n        'key4': DisplayDataItem('apache.org', url='http://apache.org'),\n        'key5': subComponent\n      }\n  \"\"\"\n  return {}\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.expand","title":"expand","text":"<pre><code>expand(transformed_data_and_metadata)\n</code></pre> Source code in <code>tensorflow_transform/beam/impl.py</code> <pre><code>def expand(self, transformed_data_and_metadata):\n    transformed_data, transformed_metadata = transformed_data_and_metadata\n\n    deferred_schema = (\n        transformed_metadata.deferred_metadata\n        | \"GetDeferredSchema\" &gt;&gt; beam.Map(lambda m: m.schema)\n    )\n\n    if transformed_metadata.dataset_metadata._output_record_batches:  # pylint: disable=protected-access\n        transformed_data_coder_pcol = (\n            deferred_schema\n            | \"RecordBatchToExamplesEncoder\"\n            &gt;&gt; beam.Map(example_coder.RecordBatchToExamplesEncoder)\n        )\n        encode_ptransform = \"EncodeRecordBatches\" &gt;&gt; beam.FlatMap(\n            # Dropping passthrough features.\n            lambda elem, coder: coder.encode(elem[0]),\n            coder=beam.pvalue.AsSingleton(transformed_data_coder_pcol),\n        )\n    else:\n        transformed_data_coder_pcol = (\n            deferred_schema\n            | \"ExampleProtoCoder\" &gt;&gt; beam.Map(example_proto_coder.ExampleProtoCoder)\n        )\n        encode_ptransform = \"EncodeInstances\" &gt;&gt; beam.Map(\n            lambda data, data_coder: data_coder.encode(data),\n            data_coder=beam.pvalue.AsSingleton(transformed_data_coder_pcol),\n        )\n\n    return transformed_data | encode_ptransform\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.from_runner_api","title":"from_runner_api  <code>classmethod</code>","text":"<pre><code>from_runner_api(proto, context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef from_runner_api(\n    cls,\n    proto,  # type: Optional[beam_runner_api_pb2.PTransform]\n    context  # type: PipelineContext\n):\n  # type: (...) -&gt; Optional[PTransform]\n  if proto is None or proto.spec is None or not proto.spec.urn:\n    return None\n  parameter_type, constructor = cls._known_urns[proto.spec.urn]\n\n  return constructor(\n      proto,\n      proto_utils.parse_Bytes(proto.spec.payload, parameter_type),\n      context)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.get_resource_hints","title":"get_resource_hints","text":"<pre><code>get_resource_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_resource_hints(self):\n  # type: () -&gt; dict[str, bytes]\n  if '_resource_hints' not in self.__dict__:\n    # PTransform subclasses don't always call super(), so prefer lazy\n    # initialization. By default, transforms don't have any resource hints.\n    self._resource_hints = {}  # type: dict[str, bytes]\n  return self._resource_hints\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.get_type_hints","title":"get_type_hints","text":"<pre><code>get_type_hints()\n</code></pre> <p>Gets and/or initializes type hints for this object.</p> <p>If type hints have not been set, attempts to initialize type hints in this order: - Using self.default_type_hints(). - Using self.class type hints.</p> Source code in <code>apache_beam/typehints/decorators.py</code> <pre><code>def get_type_hints(self):\n  \"\"\"Gets and/or initializes type hints for this object.\n\n  If type hints have not been set, attempts to initialize type hints in this\n  order:\n  - Using self.default_type_hints().\n  - Using self.__class__ type hints.\n  \"\"\"\n  return (\n      self._get_or_create_type_hints().with_defaults(\n          self.default_type_hints()).with_defaults(\n              get_type_hints(self.__class__)))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.get_windowing","title":"get_windowing","text":"<pre><code>get_windowing(inputs)\n</code></pre> <p>Returns the window function to be associated with transform's output.</p> <p>By default most transforms just return the windowing function associated with the input PCollection (or the first input if several).</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_windowing(self, inputs):\n  # type: (Any) -&gt; Windowing\n\n  \"\"\"Returns the window function to be associated with transform's output.\n\n  By default most transforms just return the windowing function associated\n  with the input PCollection (or the first input if several).\n  \"\"\"\n  if inputs:\n    return inputs[0].windowing\n  else:\n    from apache_beam.transforms.core import Windowing\n    from apache_beam.transforms.window import GlobalWindows\n    # TODO(robertwb): Return something compatible with every windowing?\n    return Windowing(GlobalWindows())\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.infer_output_type","title":"infer_output_type","text":"<pre><code>infer_output_type(unused_input_type)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def infer_output_type(self, unused_input_type):\n  return self.get_type_hints().simple_output_type(self.label) or typehints.Any\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.register_urn","title":"register_urn  <code>classmethod</code>","text":"<pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre> <pre><code>register_urn(urn, parameter_type, constructor=None)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef register_urn(cls, urn, parameter_type, constructor=None):\n  def register(constructor):\n    if isinstance(constructor, type):\n      constructor.from_runner_api_parameter = register(\n          constructor.from_runner_api_parameter)\n    else:\n      cls._known_urns[urn] = parameter_type, constructor\n    return constructor\n\n  if constructor:\n    # Used as a statement.\n    register(constructor)\n  else:\n    # Used as a decorator.\n    return register\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.runner_api_requires_keyed_input","title":"runner_api_requires_keyed_input","text":"<pre><code>runner_api_requires_keyed_input()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def runner_api_requires_keyed_input(self):\n  return False\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.to_runner_api","title":"to_runner_api","text":"<pre><code>to_runner_api(context, has_parts=False, **extra_kwargs)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api(self, context, has_parts=False, **extra_kwargs):\n  # type: (PipelineContext, bool, Any) -&gt; beam_runner_api_pb2.FunctionSpec\n  from apache_beam.portability.api import beam_runner_api_pb2\n  # typing: only ParDo supports extra_kwargs\n  urn, typed_param = self.to_runner_api_parameter(context, **extra_kwargs)\n  if urn == python_urns.GENERIC_COMPOSITE_TRANSFORM and not has_parts:\n    # TODO(https://github.com/apache/beam/issues/18713): Remove this fallback.\n    urn, typed_param = self.to_runner_api_pickled(context)\n  return beam_runner_api_pb2.FunctionSpec(\n      urn=urn,\n      payload=typed_param.SerializeToString() if isinstance(\n          typed_param, message.Message) else typed_param.encode('utf-8')\n      if isinstance(typed_param, str) else typed_param)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.to_runner_api_parameter","title":"to_runner_api_parameter","text":"<pre><code>to_runner_api_parameter(unused_context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_parameter(\n    self,\n    unused_context  # type: PipelineContext\n):\n  # type: (...) -&gt; tuple[str, Optional[Union[message.Message, bytes, str]]]\n  # The payload here is just to ease debugging.\n  return (\n      python_urns.GENERIC_COMPOSITE_TRANSFORM,\n      getattr(self, '_fn_api_payload', str(self)))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.to_runner_api_pickled","title":"to_runner_api_pickled","text":"<pre><code>to_runner_api_pickled(context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_pickled(self, context):\n  # type: (PipelineContext) -&gt; tuple[str, bytes]\n  return (\n      python_urns.PICKLED_TRANSFORM,\n      pickler.dumps(\n          self,\n          enable_best_effort_determinism=context.\n          enable_best_effort_deterministic_pickling,\n      ),\n  )\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.type_check_inputs","title":"type_check_inputs","text":"<pre><code>type_check_inputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'input')\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.type_check_inputs_or_outputs","title":"type_check_inputs_or_outputs","text":"<pre><code>type_check_inputs_or_outputs(pvalueish, input_or_output)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs_or_outputs(self, pvalueish, input_or_output):\n  type_hints = self.get_type_hints()\n  hints = getattr(type_hints, input_or_output + '_types')\n  if hints is None or not any(hints):\n    return\n  arg_hints, kwarg_hints = hints\n  if arg_hints and kwarg_hints:\n    raise TypeCheckError(\n        'PTransform cannot have both positional and keyword type hints '\n        'without overriding %s._type_check_%s()' %\n        (self.__class__, input_or_output))\n  root_hint = (\n      arg_hints[0] if len(arg_hints) == 1 else arg_hints or kwarg_hints)\n  for context, pvalue_, hint in _ZipPValues().visit(pvalueish, root_hint):\n    if isinstance(pvalue_, DoOutputsTuple):\n      continue\n    if pvalue_.element_type is None:\n      # TODO(robertwb): It's a bug that we ever get here. (typecheck)\n      continue\n    if hint and not typehints.is_consistent_with(pvalue_.element_type, hint):\n      at_context = ' %s %s' % (input_or_output, context) if context else ''\n      raise TypeCheckError(\n          '{type} type hint violation at {label}{context}: expected {hint}, '\n          'got {actual_type}'.format(\n              type=input_or_output.title(),\n              label=self.label,\n              context=at_context,\n              hint=hint,\n              actual_type=pvalue_.element_type))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.type_check_outputs","title":"type_check_outputs","text":"<pre><code>type_check_outputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_outputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'output')\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.with_input_types","title":"with_input_types","text":"<pre><code>with_input_types(input_type_hint)\n</code></pre> <p>Annotates the input type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>input_type_hint</code> <p>An instance of an allowed built-in type, a custom class, or an instance of a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If input_type_hint is not a valid type-hint. See :obj:<code>apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_input_types(self, input_type_hint):\n  \"\"\"Annotates the input type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    input_type_hint (type): An instance of an allowed built-in type, a custom\n      class, or an instance of a\n      :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **input_type_hint** is not a valid type-hint.\n      See\n      :obj:`apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  input_type_hint = native_type_compatibility.convert_to_beam_type(\n      input_type_hint)\n  validate_composite_type_param(\n      input_type_hint, 'Type hints for a PTransform')\n  return super().with_input_types(input_type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.with_output_types","title":"with_output_types","text":"<pre><code>with_output_types(type_hint)\n</code></pre> <p>Annotates the output type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>type_hint</code> <p>An instance of an allowed built-in type, a custom class, or a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If type_hint is not a valid type-hint. See :obj:<code>~apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_output_types(self, type_hint):\n  \"\"\"Annotates the output type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    type_hint (type): An instance of an allowed built-in type, a custom class,\n      or a :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **type_hint** is not a valid type-hint. See\n      :obj:`~apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  type_hint = native_type_compatibility.convert_to_beam_type(type_hint)\n  validate_composite_type_param(type_hint, 'Type hints for a PTransform')\n  return super().with_output_types(type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.EncodeTransformedDataset.with_resource_hints","title":"with_resource_hints","text":"<pre><code>with_resource_hints(**kwargs)\n</code></pre> <p>Adds resource hints to the :class:<code>PTransform</code>.</p> <p>Resource hints allow users to express constraints on the environment where the transform should be executed.  Interpretation of the resource hints is defined by Beam Runners. Runners may ignore the unsupported hints.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>key-value pairs describing hints and their values.</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>if provided hints are unknown to the SDK. See :mod:<code>apache_beam.transforms.resources</code> for a list of known hints.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_resource_hints(self, **kwargs):  # type: (...) -&gt; PTransform\n  \"\"\"Adds resource hints to the :class:`PTransform`.\n\n  Resource hints allow users to express constraints on the environment where\n  the transform should be executed.  Interpretation of the resource hints is\n  defined by Beam Runners. Runners may ignore the unsupported hints.\n\n  Args:\n    **kwargs: key-value pairs describing hints and their values.\n\n  Raises:\n    ValueError: if provided hints are unknown to the SDK. See\n      :mod:`apache_beam.transforms.resources` for a list of known hints.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object.\n  \"\"\"\n  self.get_resource_hints().update(resources.parse_resource_hints(kwargs))\n  return self\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn","title":"ReadTransformFn","text":"<pre><code>ReadTransformFn(path)\n</code></pre> <p>               Bases: <code>PTransform</code></p> <p>Reads a TransformFn written by WriteTransformFn.</p> Source code in <code>tensorflow_transform/beam/tft_beam_io/transform_fn_io.py</code> <pre><code>def __init__(self, path):\n    super().__init__()\n    self._path = path\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn-attributes","title":"Attributes","text":""},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.label","title":"label  <code>property</code> <code>writable</code>","text":"<pre><code>label\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.pipeline","title":"pipeline  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline = None\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.side_inputs","title":"side_inputs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>side_inputs = ()\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn-functions","title":"Functions","text":""},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.annotations","title":"annotations","text":"<pre><code>annotations() -&gt; dict[str, Union[bytes, str, Message]]\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def annotations(self) -&gt; dict[str, Union[bytes, str, message.Message]]:\n  return {\n      'python_type':  #\n      f'{self.__class__.__module__}.{self.__class__.__qualname__}'\n  }\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.default_label","title":"default_label","text":"<pre><code>default_label()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_label(self):\n  # type: () -&gt; str\n  return self.__class__.__name__\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.default_type_hints","title":"default_type_hints","text":"<pre><code>default_type_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_type_hints(self):\n  fn_type_hints = IOTypeHints.from_callable(self.expand)\n  if fn_type_hints is not None:\n    fn_type_hints = fn_type_hints.strip_pcoll()\n\n  # Prefer class decorator type hints for backwards compatibility.\n  return get_type_hints(self.__class__).with_defaults(fn_type_hints)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.display_data","title":"display_data","text":"<pre><code>display_data()\n</code></pre> <p>Returns the display data associated to a pipeline component.</p> <p>It should be reimplemented in pipeline components that wish to have static display data.</p> RETURNS DESCRIPTION <p>Dict[str, Any]: A dictionary containing <code>key:value</code> pairs.</p> <p>The value might be an integer, float or string value; a</p> <p>class:<code>DisplayDataItem</code> for values that have more data</p> <p>(e.g. short value, label, url); or a :class:<code>HasDisplayData</code> instance</p> <p>that has more display data that should be picked up. For example::</p> <p>{   'key1': 'string_value',   'key2': 1234,   'key3': 3.14159265,   'key4': DisplayDataItem('apache.org', url='http://apache.org'),   'key5': subComponent }</p> Source code in <code>apache_beam/transforms/display.py</code> <pre><code>def display_data(self):\n  # type: () -&gt; dict\n\n  \"\"\" Returns the display data associated to a pipeline component.\n\n  It should be reimplemented in pipeline components that wish to have\n  static display data.\n\n  Returns:\n    Dict[str, Any]: A dictionary containing ``key:value`` pairs.\n    The value might be an integer, float or string value; a\n    :class:`DisplayDataItem` for values that have more data\n    (e.g. short value, label, url); or a :class:`HasDisplayData` instance\n    that has more display data that should be picked up. For example::\n\n      {\n        'key1': 'string_value',\n        'key2': 1234,\n        'key3': 3.14159265,\n        'key4': DisplayDataItem('apache.org', url='http://apache.org'),\n        'key5': subComponent\n      }\n  \"\"\"\n  return {}\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.expand","title":"expand","text":"<pre><code>expand(pvalue)\n</code></pre> Source code in <code>tensorflow_transform/beam/tft_beam_io/transform_fn_io.py</code> <pre><code>def expand(self, pvalue):\n    transform_fn_path = os.path.join(\n        self._path, tft.TFTransformOutput.TRANSFORM_FN_DIR\n    )\n    saved_model_dir_pcoll = (\n        pvalue.pipeline\n        | \"CreateTransformFnPath\" &gt;&gt; beam.Create([transform_fn_path])\n    )\n\n    metadata = metadata_io.read_metadata(\n        os.path.join(self._path, tft.TFTransformOutput.TRANSFORMED_METADATA_DIR)\n    )\n\n    return saved_model_dir_pcoll, metadata\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.from_runner_api","title":"from_runner_api  <code>classmethod</code>","text":"<pre><code>from_runner_api(proto, context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef from_runner_api(\n    cls,\n    proto,  # type: Optional[beam_runner_api_pb2.PTransform]\n    context  # type: PipelineContext\n):\n  # type: (...) -&gt; Optional[PTransform]\n  if proto is None or proto.spec is None or not proto.spec.urn:\n    return None\n  parameter_type, constructor = cls._known_urns[proto.spec.urn]\n\n  return constructor(\n      proto,\n      proto_utils.parse_Bytes(proto.spec.payload, parameter_type),\n      context)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.get_resource_hints","title":"get_resource_hints","text":"<pre><code>get_resource_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_resource_hints(self):\n  # type: () -&gt; dict[str, bytes]\n  if '_resource_hints' not in self.__dict__:\n    # PTransform subclasses don't always call super(), so prefer lazy\n    # initialization. By default, transforms don't have any resource hints.\n    self._resource_hints = {}  # type: dict[str, bytes]\n  return self._resource_hints\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.get_type_hints","title":"get_type_hints","text":"<pre><code>get_type_hints()\n</code></pre> <p>Gets and/or initializes type hints for this object.</p> <p>If type hints have not been set, attempts to initialize type hints in this order: - Using self.default_type_hints(). - Using self.class type hints.</p> Source code in <code>apache_beam/typehints/decorators.py</code> <pre><code>def get_type_hints(self):\n  \"\"\"Gets and/or initializes type hints for this object.\n\n  If type hints have not been set, attempts to initialize type hints in this\n  order:\n  - Using self.default_type_hints().\n  - Using self.__class__ type hints.\n  \"\"\"\n  return (\n      self._get_or_create_type_hints().with_defaults(\n          self.default_type_hints()).with_defaults(\n              get_type_hints(self.__class__)))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.get_windowing","title":"get_windowing","text":"<pre><code>get_windowing(inputs)\n</code></pre> <p>Returns the window function to be associated with transform's output.</p> <p>By default most transforms just return the windowing function associated with the input PCollection (or the first input if several).</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_windowing(self, inputs):\n  # type: (Any) -&gt; Windowing\n\n  \"\"\"Returns the window function to be associated with transform's output.\n\n  By default most transforms just return the windowing function associated\n  with the input PCollection (or the first input if several).\n  \"\"\"\n  if inputs:\n    return inputs[0].windowing\n  else:\n    from apache_beam.transforms.core import Windowing\n    from apache_beam.transforms.window import GlobalWindows\n    # TODO(robertwb): Return something compatible with every windowing?\n    return Windowing(GlobalWindows())\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.infer_output_type","title":"infer_output_type","text":"<pre><code>infer_output_type(unused_input_type)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def infer_output_type(self, unused_input_type):\n  return self.get_type_hints().simple_output_type(self.label) or typehints.Any\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.register_urn","title":"register_urn  <code>classmethod</code>","text":"<pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre> <pre><code>register_urn(urn, parameter_type, constructor=None)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef register_urn(cls, urn, parameter_type, constructor=None):\n  def register(constructor):\n    if isinstance(constructor, type):\n      constructor.from_runner_api_parameter = register(\n          constructor.from_runner_api_parameter)\n    else:\n      cls._known_urns[urn] = parameter_type, constructor\n    return constructor\n\n  if constructor:\n    # Used as a statement.\n    register(constructor)\n  else:\n    # Used as a decorator.\n    return register\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.runner_api_requires_keyed_input","title":"runner_api_requires_keyed_input","text":"<pre><code>runner_api_requires_keyed_input()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def runner_api_requires_keyed_input(self):\n  return False\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.to_runner_api","title":"to_runner_api","text":"<pre><code>to_runner_api(context, has_parts=False, **extra_kwargs)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api(self, context, has_parts=False, **extra_kwargs):\n  # type: (PipelineContext, bool, Any) -&gt; beam_runner_api_pb2.FunctionSpec\n  from apache_beam.portability.api import beam_runner_api_pb2\n  # typing: only ParDo supports extra_kwargs\n  urn, typed_param = self.to_runner_api_parameter(context, **extra_kwargs)\n  if urn == python_urns.GENERIC_COMPOSITE_TRANSFORM and not has_parts:\n    # TODO(https://github.com/apache/beam/issues/18713): Remove this fallback.\n    urn, typed_param = self.to_runner_api_pickled(context)\n  return beam_runner_api_pb2.FunctionSpec(\n      urn=urn,\n      payload=typed_param.SerializeToString() if isinstance(\n          typed_param, message.Message) else typed_param.encode('utf-8')\n      if isinstance(typed_param, str) else typed_param)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.to_runner_api_parameter","title":"to_runner_api_parameter","text":"<pre><code>to_runner_api_parameter(unused_context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_parameter(\n    self,\n    unused_context  # type: PipelineContext\n):\n  # type: (...) -&gt; tuple[str, Optional[Union[message.Message, bytes, str]]]\n  # The payload here is just to ease debugging.\n  return (\n      python_urns.GENERIC_COMPOSITE_TRANSFORM,\n      getattr(self, '_fn_api_payload', str(self)))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.to_runner_api_pickled","title":"to_runner_api_pickled","text":"<pre><code>to_runner_api_pickled(context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_pickled(self, context):\n  # type: (PipelineContext) -&gt; tuple[str, bytes]\n  return (\n      python_urns.PICKLED_TRANSFORM,\n      pickler.dumps(\n          self,\n          enable_best_effort_determinism=context.\n          enable_best_effort_deterministic_pickling,\n      ),\n  )\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.type_check_inputs","title":"type_check_inputs","text":"<pre><code>type_check_inputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'input')\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.type_check_inputs_or_outputs","title":"type_check_inputs_or_outputs","text":"<pre><code>type_check_inputs_or_outputs(pvalueish, input_or_output)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs_or_outputs(self, pvalueish, input_or_output):\n  type_hints = self.get_type_hints()\n  hints = getattr(type_hints, input_or_output + '_types')\n  if hints is None or not any(hints):\n    return\n  arg_hints, kwarg_hints = hints\n  if arg_hints and kwarg_hints:\n    raise TypeCheckError(\n        'PTransform cannot have both positional and keyword type hints '\n        'without overriding %s._type_check_%s()' %\n        (self.__class__, input_or_output))\n  root_hint = (\n      arg_hints[0] if len(arg_hints) == 1 else arg_hints or kwarg_hints)\n  for context, pvalue_, hint in _ZipPValues().visit(pvalueish, root_hint):\n    if isinstance(pvalue_, DoOutputsTuple):\n      continue\n    if pvalue_.element_type is None:\n      # TODO(robertwb): It's a bug that we ever get here. (typecheck)\n      continue\n    if hint and not typehints.is_consistent_with(pvalue_.element_type, hint):\n      at_context = ' %s %s' % (input_or_output, context) if context else ''\n      raise TypeCheckError(\n          '{type} type hint violation at {label}{context}: expected {hint}, '\n          'got {actual_type}'.format(\n              type=input_or_output.title(),\n              label=self.label,\n              context=at_context,\n              hint=hint,\n              actual_type=pvalue_.element_type))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.type_check_outputs","title":"type_check_outputs","text":"<pre><code>type_check_outputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_outputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'output')\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.with_input_types","title":"with_input_types","text":"<pre><code>with_input_types(input_type_hint)\n</code></pre> <p>Annotates the input type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>input_type_hint</code> <p>An instance of an allowed built-in type, a custom class, or an instance of a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If input_type_hint is not a valid type-hint. See :obj:<code>apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_input_types(self, input_type_hint):\n  \"\"\"Annotates the input type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    input_type_hint (type): An instance of an allowed built-in type, a custom\n      class, or an instance of a\n      :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **input_type_hint** is not a valid type-hint.\n      See\n      :obj:`apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  input_type_hint = native_type_compatibility.convert_to_beam_type(\n      input_type_hint)\n  validate_composite_type_param(\n      input_type_hint, 'Type hints for a PTransform')\n  return super().with_input_types(input_type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.with_output_types","title":"with_output_types","text":"<pre><code>with_output_types(type_hint)\n</code></pre> <p>Annotates the output type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>type_hint</code> <p>An instance of an allowed built-in type, a custom class, or a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If type_hint is not a valid type-hint. See :obj:<code>~apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_output_types(self, type_hint):\n  \"\"\"Annotates the output type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    type_hint (type): An instance of an allowed built-in type, a custom class,\n      or a :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **type_hint** is not a valid type-hint. See\n      :obj:`~apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  type_hint = native_type_compatibility.convert_to_beam_type(type_hint)\n  validate_composite_type_param(type_hint, 'Type hints for a PTransform')\n  return super().with_output_types(type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.ReadTransformFn.with_resource_hints","title":"with_resource_hints","text":"<pre><code>with_resource_hints(**kwargs)\n</code></pre> <p>Adds resource hints to the :class:<code>PTransform</code>.</p> <p>Resource hints allow users to express constraints on the environment where the transform should be executed.  Interpretation of the resource hints is defined by Beam Runners. Runners may ignore the unsupported hints.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>key-value pairs describing hints and their values.</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>if provided hints are unknown to the SDK. See :mod:<code>apache_beam.transforms.resources</code> for a list of known hints.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_resource_hints(self, **kwargs):  # type: (...) -&gt; PTransform\n  \"\"\"Adds resource hints to the :class:`PTransform`.\n\n  Resource hints allow users to express constraints on the environment where\n  the transform should be executed.  Interpretation of the resource hints is\n  defined by Beam Runners. Runners may ignore the unsupported hints.\n\n  Args:\n    **kwargs: key-value pairs describing hints and their values.\n\n  Raises:\n    ValueError: if provided hints are unknown to the SDK. See\n      :mod:`apache_beam.transforms.resources` for a list of known hints.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object.\n  \"\"\"\n  self.get_resource_hints().update(resources.parse_resource_hints(kwargs))\n  return self\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset","title":"TransformDataset","text":"<pre><code>TransformDataset(\n    exclude_outputs=None, output_record_batches=False\n)\n</code></pre> <p>               Bases: <code>PTransform</code></p> <p>Applies the transformation computed by transforming a Dataset.</p> <p>TransformDataset's <code>expand</code> method is called on a (dataset, transform_fn) pair. It applies the transform_fn to each row of the input dataset and returns the resulting dataset.</p> <p>exclude_outputs: (Optional) Output features that should not be produced.   output_record_batches: (Optional) A bool. If <code>True</code>, <code>TransformDataset</code>       outputs <code>pyarrow.RecordBatch</code>es; otherwise, outputs instance dicts.</p> Source code in <code>tensorflow_transform/beam/impl.py</code> <pre><code>def __init__(self, exclude_outputs=None, output_record_batches=False):\n    self._exclude_outputs = exclude_outputs\n    self._output_record_batches = output_record_batches\n    self._use_tf_compat_v1 = Context.get_use_tf_compat_v1()\n    if self._use_tf_compat_v1:\n        _warn_about_tf_compat_v1()\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset-attributes","title":"Attributes","text":""},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.label","title":"label  <code>property</code> <code>writable</code>","text":"<pre><code>label\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.pipeline","title":"pipeline  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline = None\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.side_inputs","title":"side_inputs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>side_inputs = ()\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset-functions","title":"Functions","text":""},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.annotations","title":"annotations","text":"<pre><code>annotations() -&gt; dict[str, Union[bytes, str, Message]]\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def annotations(self) -&gt; dict[str, Union[bytes, str, message.Message]]:\n  return {\n      'python_type':  #\n      f'{self.__class__.__module__}.{self.__class__.__qualname__}'\n  }\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.default_label","title":"default_label","text":"<pre><code>default_label()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_label(self):\n  # type: () -&gt; str\n  return self.__class__.__name__\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.default_type_hints","title":"default_type_hints","text":"<pre><code>default_type_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_type_hints(self):\n  fn_type_hints = IOTypeHints.from_callable(self.expand)\n  if fn_type_hints is not None:\n    fn_type_hints = fn_type_hints.strip_pcoll()\n\n  # Prefer class decorator type hints for backwards compatibility.\n  return get_type_hints(self.__class__).with_defaults(fn_type_hints)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.display_data","title":"display_data","text":"<pre><code>display_data()\n</code></pre> <p>Returns the display data associated to a pipeline component.</p> <p>It should be reimplemented in pipeline components that wish to have static display data.</p> RETURNS DESCRIPTION <p>Dict[str, Any]: A dictionary containing <code>key:value</code> pairs.</p> <p>The value might be an integer, float or string value; a</p> <p>class:<code>DisplayDataItem</code> for values that have more data</p> <p>(e.g. short value, label, url); or a :class:<code>HasDisplayData</code> instance</p> <p>that has more display data that should be picked up. For example::</p> <p>{   'key1': 'string_value',   'key2': 1234,   'key3': 3.14159265,   'key4': DisplayDataItem('apache.org', url='http://apache.org'),   'key5': subComponent }</p> Source code in <code>apache_beam/transforms/display.py</code> <pre><code>def display_data(self):\n  # type: () -&gt; dict\n\n  \"\"\" Returns the display data associated to a pipeline component.\n\n  It should be reimplemented in pipeline components that wish to have\n  static display data.\n\n  Returns:\n    Dict[str, Any]: A dictionary containing ``key:value`` pairs.\n    The value might be an integer, float or string value; a\n    :class:`DisplayDataItem` for values that have more data\n    (e.g. short value, label, url); or a :class:`HasDisplayData` instance\n    that has more display data that should be picked up. For example::\n\n      {\n        'key1': 'string_value',\n        'key2': 1234,\n        'key3': 3.14159265,\n        'key4': DisplayDataItem('apache.org', url='http://apache.org'),\n        'key5': subComponent\n      }\n  \"\"\"\n  return {}\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.expand","title":"expand","text":"<pre><code>expand(dataset_and_transform_fn)\n</code></pre> <p>Transforms the dataset using the transform_fn.</p> <p>dataset_and_transform_fn: A tuple of dataset and preprocessing   function.</p> <p>A dataset transformed according to the transform_fn.</p> Source code in <code>tensorflow_transform/beam/impl.py</code> <pre><code>def expand(self, dataset_and_transform_fn):\n    \"\"\"Transforms the dataset using the transform_fn.\n\n    Args:\n    ----\n      dataset_and_transform_fn: A tuple of dataset and preprocessing\n      function.\n\n    Returns:\n    -------\n      A dataset transformed according to the transform_fn.\n    \"\"\"\n    (input_values, input_metadata), (transform_fn, output_metadata) = (\n        dataset_and_transform_fn\n    )\n    if isinstance(input_metadata, dataset_metadata.DatasetMetadata):\n        if Context.get_passthrough_keys():\n            raise ValueError(\n                \"passthrough_keys is set to {} but it is not \"\n                \"supported with instance dicts + DatasetMetadata \"\n                \"input. Follow the guide to switch to the TFXIO \"\n                \"format.\".format(Context.get_passthrough_keys())\n            )\n        logging.warning(\n            \"You are passing instance dicts and DatasetMetadata to TFT which \"\n            \"will not provide optimal performance. Consider following the TFT \"\n            \"guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\"\n        )\n        to_tfxio_ptransform = _InstanceDictInputToTFXIOInput(\n            input_metadata.schema, Context.get_desired_batch_size()\n        )\n        input_tensor_adapter_config = to_tfxio_ptransform.tensor_adapter_config()\n        input_values |= \"InstanceDictToRecordBatch\" &gt;&gt; to_tfxio_ptransform\n    else:\n        input_tensor_adapter_config = input_metadata\n\n    # If exclude_outputs is set, update the output metadata.\n    if self._exclude_outputs is not None:\n        if isinstance(output_metadata, beam_metadata_io.BeamDatasetMetadata):\n            new_metadata = _remove_columns_from_metadata(\n                output_metadata.dataset_metadata, self._exclude_outputs\n            )\n            new_deferred_metadata = (\n                output_metadata.deferred_metadata\n                | \"RemoveColumns\"\n                &gt;&gt; beam.Map(_remove_columns_from_metadata, self._exclude_outputs)\n            )\n            output_metadata = beam_metadata_io.BeamDatasetMetadata(\n                new_metadata, new_deferred_metadata, output_metadata.asset_map\n            )\n        else:\n            output_metadata = _remove_columns_from_metadata(\n                output_metadata, self._exclude_outputs\n            )\n\n    if isinstance(output_metadata, beam_metadata_io.BeamDatasetMetadata):\n        deferred_schema = (\n            output_metadata.deferred_metadata\n            | \"GetDeferredSchema\" &gt;&gt; beam.Map(lambda m: m.schema)\n        )\n        output_dataset_metadata = output_metadata.dataset_metadata\n    else:\n        deferred_schema = self.pipeline | \"CreateDeferredSchema\" &gt;&gt; beam.Create(\n            [output_metadata.schema]\n        )\n        output_dataset_metadata = output_metadata\n    output_dataset_metadata._output_record_batches = self._output_record_batches  # pylint: disable=protected-access\n\n    # Increment input metrics.\n    _ = (\n        input_values\n        | \"InstrumentInputBytes[Transform]\"\n        &gt;&gt; telemetry.TrackRecordBatchBytes(\n            beam_common.METRICS_NAMESPACE, \"transform_input_bytes\"\n        )\n    )\n\n    _ = (\n        self.pipeline\n        | \"CreateTransformInputTensorRepresentations\"\n        &gt;&gt; beam.Create([input_tensor_adapter_config.tensor_representations])\n        | \"InstrumentTransformInputTensors\"\n        &gt;&gt; telemetry.TrackTensorRepresentations(\n            telemetry_util.AppendToNamespace(\n                beam_common.METRICS_NAMESPACE, [\"transform_input_tensors\"]\n            )\n        )\n    )\n\n    tf_config = _DEFAULT_TENSORFLOW_CONFIG_BY_BEAM_RUNNER_TYPE.get(\n        type(self.pipeline.runner)\n    )\n    output_batches = input_values | \"Transform\" &gt;&gt; beam.ParDo(\n        _RunMetaGraphDoFn(\n            tf_config,\n            input_tensor_adapter_config=input_tensor_adapter_config,\n            use_tf_compat_v1=self._use_tf_compat_v1,\n            shared_graph_state_handle=shared.Shared(),\n            passthrough_keys=Context.get_passthrough_keys(),\n            exclude_outputs=self._exclude_outputs,\n        ),\n        saved_model_dir=beam.pvalue.AsSingleton(transform_fn),\n    )\n\n    # Since we are using a deferred schema, obtain a pcollection containing\n    # the converter that will be created from it.\n    converter_pcol = deferred_schema | \"MakeTensorToArrowConverter\" &gt;&gt; beam.Map(\n        impl_helper.make_tensor_to_arrow_converter\n    )\n\n    # Increment output data metrics.\n    _ = (\n        converter_pcol\n        | \"MapToTensorRepresentations\"\n        &gt;&gt; beam.Map(lambda converter: converter.tensor_representations())\n        | \"InstrumentTransformOutputTensors\"\n        &gt;&gt; telemetry.TrackTensorRepresentations(\n            telemetry_util.AppendToNamespace(\n                beam_common.METRICS_NAMESPACE, [\"transform_output_tensors\"]\n            )\n        )\n    )\n\n    output_data = output_batches | \"ConvertToRecordBatch\" &gt;&gt; beam.FlatMap(\n        _convert_to_record_batch,\n        converter=beam.pvalue.AsSingleton(converter_pcol),\n        passthrough_keys=Context.get_passthrough_keys(),\n        input_metadata=input_metadata,\n        # TODO(b/254822532): Consider always doing the validation.\n        validate_varlen_sparse_values=not self._output_record_batches,\n    )\n\n    if not self._output_record_batches:\n        logging.warning(\n            \"You are outputting instance dicts from `TransformDataset` which \"\n            \"will not provide optimal performance. Consider setting  \"\n            \"`output_record_batches=True` to upgrade to the TFXIO format (Apache \"\n            \"Arrow RecordBatch). Encoding functionality in this module works \"\n            \"with both formats.\"\n        )\n        output_data |= \"ConvertAndUnbatchToInstanceDicts\" &gt;&gt; beam.FlatMap(\n            _transformed_batch_to_instance_dicts,\n            schema=beam.pvalue.AsSingleton(deferred_schema),\n        )\n\n    _clear_shared_state_after_barrier(self.pipeline, output_data)\n\n    return (output_data, output_metadata)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.from_runner_api","title":"from_runner_api  <code>classmethod</code>","text":"<pre><code>from_runner_api(proto, context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef from_runner_api(\n    cls,\n    proto,  # type: Optional[beam_runner_api_pb2.PTransform]\n    context  # type: PipelineContext\n):\n  # type: (...) -&gt; Optional[PTransform]\n  if proto is None or proto.spec is None or not proto.spec.urn:\n    return None\n  parameter_type, constructor = cls._known_urns[proto.spec.urn]\n\n  return constructor(\n      proto,\n      proto_utils.parse_Bytes(proto.spec.payload, parameter_type),\n      context)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.get_resource_hints","title":"get_resource_hints","text":"<pre><code>get_resource_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_resource_hints(self):\n  # type: () -&gt; dict[str, bytes]\n  if '_resource_hints' not in self.__dict__:\n    # PTransform subclasses don't always call super(), so prefer lazy\n    # initialization. By default, transforms don't have any resource hints.\n    self._resource_hints = {}  # type: dict[str, bytes]\n  return self._resource_hints\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.get_type_hints","title":"get_type_hints","text":"<pre><code>get_type_hints()\n</code></pre> <p>Gets and/or initializes type hints for this object.</p> <p>If type hints have not been set, attempts to initialize type hints in this order: - Using self.default_type_hints(). - Using self.class type hints.</p> Source code in <code>apache_beam/typehints/decorators.py</code> <pre><code>def get_type_hints(self):\n  \"\"\"Gets and/or initializes type hints for this object.\n\n  If type hints have not been set, attempts to initialize type hints in this\n  order:\n  - Using self.default_type_hints().\n  - Using self.__class__ type hints.\n  \"\"\"\n  return (\n      self._get_or_create_type_hints().with_defaults(\n          self.default_type_hints()).with_defaults(\n              get_type_hints(self.__class__)))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.get_windowing","title":"get_windowing","text":"<pre><code>get_windowing(inputs)\n</code></pre> <p>Returns the window function to be associated with transform's output.</p> <p>By default most transforms just return the windowing function associated with the input PCollection (or the first input if several).</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_windowing(self, inputs):\n  # type: (Any) -&gt; Windowing\n\n  \"\"\"Returns the window function to be associated with transform's output.\n\n  By default most transforms just return the windowing function associated\n  with the input PCollection (or the first input if several).\n  \"\"\"\n  if inputs:\n    return inputs[0].windowing\n  else:\n    from apache_beam.transforms.core import Windowing\n    from apache_beam.transforms.window import GlobalWindows\n    # TODO(robertwb): Return something compatible with every windowing?\n    return Windowing(GlobalWindows())\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.infer_output_type","title":"infer_output_type","text":"<pre><code>infer_output_type(unused_input_type)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def infer_output_type(self, unused_input_type):\n  return self.get_type_hints().simple_output_type(self.label) or typehints.Any\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.register_urn","title":"register_urn  <code>classmethod</code>","text":"<pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre> <pre><code>register_urn(urn, parameter_type, constructor=None)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef register_urn(cls, urn, parameter_type, constructor=None):\n  def register(constructor):\n    if isinstance(constructor, type):\n      constructor.from_runner_api_parameter = register(\n          constructor.from_runner_api_parameter)\n    else:\n      cls._known_urns[urn] = parameter_type, constructor\n    return constructor\n\n  if constructor:\n    # Used as a statement.\n    register(constructor)\n  else:\n    # Used as a decorator.\n    return register\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.runner_api_requires_keyed_input","title":"runner_api_requires_keyed_input","text":"<pre><code>runner_api_requires_keyed_input()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def runner_api_requires_keyed_input(self):\n  return False\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.to_runner_api","title":"to_runner_api","text":"<pre><code>to_runner_api(context, has_parts=False, **extra_kwargs)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api(self, context, has_parts=False, **extra_kwargs):\n  # type: (PipelineContext, bool, Any) -&gt; beam_runner_api_pb2.FunctionSpec\n  from apache_beam.portability.api import beam_runner_api_pb2\n  # typing: only ParDo supports extra_kwargs\n  urn, typed_param = self.to_runner_api_parameter(context, **extra_kwargs)\n  if urn == python_urns.GENERIC_COMPOSITE_TRANSFORM and not has_parts:\n    # TODO(https://github.com/apache/beam/issues/18713): Remove this fallback.\n    urn, typed_param = self.to_runner_api_pickled(context)\n  return beam_runner_api_pb2.FunctionSpec(\n      urn=urn,\n      payload=typed_param.SerializeToString() if isinstance(\n          typed_param, message.Message) else typed_param.encode('utf-8')\n      if isinstance(typed_param, str) else typed_param)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.to_runner_api_parameter","title":"to_runner_api_parameter","text":"<pre><code>to_runner_api_parameter(unused_context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_parameter(\n    self,\n    unused_context  # type: PipelineContext\n):\n  # type: (...) -&gt; tuple[str, Optional[Union[message.Message, bytes, str]]]\n  # The payload here is just to ease debugging.\n  return (\n      python_urns.GENERIC_COMPOSITE_TRANSFORM,\n      getattr(self, '_fn_api_payload', str(self)))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.to_runner_api_pickled","title":"to_runner_api_pickled","text":"<pre><code>to_runner_api_pickled(context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_pickled(self, context):\n  # type: (PipelineContext) -&gt; tuple[str, bytes]\n  return (\n      python_urns.PICKLED_TRANSFORM,\n      pickler.dumps(\n          self,\n          enable_best_effort_determinism=context.\n          enable_best_effort_deterministic_pickling,\n      ),\n  )\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.type_check_inputs","title":"type_check_inputs","text":"<pre><code>type_check_inputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'input')\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.type_check_inputs_or_outputs","title":"type_check_inputs_or_outputs","text":"<pre><code>type_check_inputs_or_outputs(pvalueish, input_or_output)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs_or_outputs(self, pvalueish, input_or_output):\n  type_hints = self.get_type_hints()\n  hints = getattr(type_hints, input_or_output + '_types')\n  if hints is None or not any(hints):\n    return\n  arg_hints, kwarg_hints = hints\n  if arg_hints and kwarg_hints:\n    raise TypeCheckError(\n        'PTransform cannot have both positional and keyword type hints '\n        'without overriding %s._type_check_%s()' %\n        (self.__class__, input_or_output))\n  root_hint = (\n      arg_hints[0] if len(arg_hints) == 1 else arg_hints or kwarg_hints)\n  for context, pvalue_, hint in _ZipPValues().visit(pvalueish, root_hint):\n    if isinstance(pvalue_, DoOutputsTuple):\n      continue\n    if pvalue_.element_type is None:\n      # TODO(robertwb): It's a bug that we ever get here. (typecheck)\n      continue\n    if hint and not typehints.is_consistent_with(pvalue_.element_type, hint):\n      at_context = ' %s %s' % (input_or_output, context) if context else ''\n      raise TypeCheckError(\n          '{type} type hint violation at {label}{context}: expected {hint}, '\n          'got {actual_type}'.format(\n              type=input_or_output.title(),\n              label=self.label,\n              context=at_context,\n              hint=hint,\n              actual_type=pvalue_.element_type))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.type_check_outputs","title":"type_check_outputs","text":"<pre><code>type_check_outputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_outputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'output')\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.with_input_types","title":"with_input_types","text":"<pre><code>with_input_types(input_type_hint)\n</code></pre> <p>Annotates the input type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>input_type_hint</code> <p>An instance of an allowed built-in type, a custom class, or an instance of a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If input_type_hint is not a valid type-hint. See :obj:<code>apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_input_types(self, input_type_hint):\n  \"\"\"Annotates the input type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    input_type_hint (type): An instance of an allowed built-in type, a custom\n      class, or an instance of a\n      :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **input_type_hint** is not a valid type-hint.\n      See\n      :obj:`apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  input_type_hint = native_type_compatibility.convert_to_beam_type(\n      input_type_hint)\n  validate_composite_type_param(\n      input_type_hint, 'Type hints for a PTransform')\n  return super().with_input_types(input_type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.with_output_types","title":"with_output_types","text":"<pre><code>with_output_types(type_hint)\n</code></pre> <p>Annotates the output type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>type_hint</code> <p>An instance of an allowed built-in type, a custom class, or a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If type_hint is not a valid type-hint. See :obj:<code>~apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_output_types(self, type_hint):\n  \"\"\"Annotates the output type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    type_hint (type): An instance of an allowed built-in type, a custom class,\n      or a :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **type_hint** is not a valid type-hint. See\n      :obj:`~apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  type_hint = native_type_compatibility.convert_to_beam_type(type_hint)\n  validate_composite_type_param(type_hint, 'Type hints for a PTransform')\n  return super().with_output_types(type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.TransformDataset.with_resource_hints","title":"with_resource_hints","text":"<pre><code>with_resource_hints(**kwargs)\n</code></pre> <p>Adds resource hints to the :class:<code>PTransform</code>.</p> <p>Resource hints allow users to express constraints on the environment where the transform should be executed.  Interpretation of the resource hints is defined by Beam Runners. Runners may ignore the unsupported hints.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>key-value pairs describing hints and their values.</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>if provided hints are unknown to the SDK. See :mod:<code>apache_beam.transforms.resources</code> for a list of known hints.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_resource_hints(self, **kwargs):  # type: (...) -&gt; PTransform\n  \"\"\"Adds resource hints to the :class:`PTransform`.\n\n  Resource hints allow users to express constraints on the environment where\n  the transform should be executed.  Interpretation of the resource hints is\n  defined by Beam Runners. Runners may ignore the unsupported hints.\n\n  Args:\n    **kwargs: key-value pairs describing hints and their values.\n\n  Raises:\n    ValueError: if provided hints are unknown to the SDK. See\n      :mod:`apache_beam.transforms.resources` for a list of known hints.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object.\n  \"\"\"\n  self.get_resource_hints().update(resources.parse_resource_hints(kwargs))\n  return self\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata","title":"WriteMetadata","text":"<pre><code>WriteMetadata(\n    path, pipeline, write_to_unique_subdirectory=False\n)\n</code></pre> <p>               Bases: <code>PTransform</code></p> <p>A PTransform to write Metadata to disk.</p> <p>Input can either be a DatasetMetadata or a tuple of properties.</p> <p>Depending on the optional <code>write_to_unique_subdirectory</code>, writes the given metadata to either <code>path</code> or a new unique subdirectory under <code>path</code>.</p> <p>Returns a singleton with the path to which the metadata was written.</p> <p>Init method.</p> <p>path: A str, the default path that the metadata should be written to.   pipeline: A beam Pipeline.   write_to_unique_subdirectory: (Optional) A bool indicating whether to     write the metadata out to <code>path</code> or a unique subdirectory under <code>path</code>.</p> Source code in <code>tensorflow_transform/beam/tft_beam_io/beam_metadata_io.py</code> <pre><code>def __init__(self, path, pipeline, write_to_unique_subdirectory=False):\n    \"\"\"Init method.\n\n    Args:\n    ----\n      path: A str, the default path that the metadata should be written to.\n      pipeline: A beam Pipeline.\n      write_to_unique_subdirectory: (Optional) A bool indicating whether to\n        write the metadata out to `path` or a unique subdirectory under `path`.\n    \"\"\"\n    super().__init__()\n    self._path = path\n    self._write_to_unique_subdirectory = write_to_unique_subdirectory\n    self.pipeline = pipeline\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata-attributes","title":"Attributes","text":""},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.label","title":"label  <code>property</code> <code>writable</code>","text":"<pre><code>label\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.pipeline","title":"pipeline  <code>instance-attribute</code>","text":"<pre><code>pipeline = pipeline\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.side_inputs","title":"side_inputs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>side_inputs = ()\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata-functions","title":"Functions","text":""},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.annotations","title":"annotations","text":"<pre><code>annotations() -&gt; dict[str, Union[bytes, str, Message]]\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def annotations(self) -&gt; dict[str, Union[bytes, str, message.Message]]:\n  return {\n      'python_type':  #\n      f'{self.__class__.__module__}.{self.__class__.__qualname__}'\n  }\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.default_label","title":"default_label","text":"<pre><code>default_label()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_label(self):\n  # type: () -&gt; str\n  return self.__class__.__name__\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.default_type_hints","title":"default_type_hints","text":"<pre><code>default_type_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_type_hints(self):\n  fn_type_hints = IOTypeHints.from_callable(self.expand)\n  if fn_type_hints is not None:\n    fn_type_hints = fn_type_hints.strip_pcoll()\n\n  # Prefer class decorator type hints for backwards compatibility.\n  return get_type_hints(self.__class__).with_defaults(fn_type_hints)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.display_data","title":"display_data","text":"<pre><code>display_data()\n</code></pre> <p>Returns the display data associated to a pipeline component.</p> <p>It should be reimplemented in pipeline components that wish to have static display data.</p> RETURNS DESCRIPTION <p>Dict[str, Any]: A dictionary containing <code>key:value</code> pairs.</p> <p>The value might be an integer, float or string value; a</p> <p>class:<code>DisplayDataItem</code> for values that have more data</p> <p>(e.g. short value, label, url); or a :class:<code>HasDisplayData</code> instance</p> <p>that has more display data that should be picked up. For example::</p> <p>{   'key1': 'string_value',   'key2': 1234,   'key3': 3.14159265,   'key4': DisplayDataItem('apache.org', url='http://apache.org'),   'key5': subComponent }</p> Source code in <code>apache_beam/transforms/display.py</code> <pre><code>def display_data(self):\n  # type: () -&gt; dict\n\n  \"\"\" Returns the display data associated to a pipeline component.\n\n  It should be reimplemented in pipeline components that wish to have\n  static display data.\n\n  Returns:\n    Dict[str, Any]: A dictionary containing ``key:value`` pairs.\n    The value might be an integer, float or string value; a\n    :class:`DisplayDataItem` for values that have more data\n    (e.g. short value, label, url); or a :class:`HasDisplayData` instance\n    that has more display data that should be picked up. For example::\n\n      {\n        'key1': 'string_value',\n        'key2': 1234,\n        'key3': 3.14159265,\n        'key4': DisplayDataItem('apache.org', url='http://apache.org'),\n        'key5': subComponent\n      }\n  \"\"\"\n  return {}\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.expand","title":"expand","text":"<pre><code>expand(metadata)\n</code></pre> Source code in <code>tensorflow_transform/beam/tft_beam_io/beam_metadata_io.py</code> <pre><code>def expand(self, metadata):\n    if hasattr(metadata, \"deferred_metadata\"):\n        metadata_pcoll = metadata.deferred_metadata\n    else:\n        metadata_pcoll = self.pipeline | beam.Create([metadata])\n\n    asset_map = getattr(metadata, \"asset_map\", {})\n\n    def write_metadata_output(metadata):\n        output_path = self._path\n        if self._write_to_unique_subdirectory:\n            output_path = common.get_unique_temp_path(self._path)\n        metadata_io.write_metadata(metadata, output_path)\n        if asset_map:\n            with tf.io.gfile.GFile(\n                os.path.join(\n                    output_path, output_wrapper.TFTransformOutput.ASSET_MAP\n                ),\n                \"w\",\n            ) as f:\n                f.write(json.dumps(asset_map))\n        return output_path\n\n    return metadata_pcoll | \"WriteMetadata\" &gt;&gt; beam.Map(write_metadata_output)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.from_runner_api","title":"from_runner_api  <code>classmethod</code>","text":"<pre><code>from_runner_api(proto, context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef from_runner_api(\n    cls,\n    proto,  # type: Optional[beam_runner_api_pb2.PTransform]\n    context  # type: PipelineContext\n):\n  # type: (...) -&gt; Optional[PTransform]\n  if proto is None or proto.spec is None or not proto.spec.urn:\n    return None\n  parameter_type, constructor = cls._known_urns[proto.spec.urn]\n\n  return constructor(\n      proto,\n      proto_utils.parse_Bytes(proto.spec.payload, parameter_type),\n      context)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.get_resource_hints","title":"get_resource_hints","text":"<pre><code>get_resource_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_resource_hints(self):\n  # type: () -&gt; dict[str, bytes]\n  if '_resource_hints' not in self.__dict__:\n    # PTransform subclasses don't always call super(), so prefer lazy\n    # initialization. By default, transforms don't have any resource hints.\n    self._resource_hints = {}  # type: dict[str, bytes]\n  return self._resource_hints\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.get_type_hints","title":"get_type_hints","text":"<pre><code>get_type_hints()\n</code></pre> <p>Gets and/or initializes type hints for this object.</p> <p>If type hints have not been set, attempts to initialize type hints in this order: - Using self.default_type_hints(). - Using self.class type hints.</p> Source code in <code>apache_beam/typehints/decorators.py</code> <pre><code>def get_type_hints(self):\n  \"\"\"Gets and/or initializes type hints for this object.\n\n  If type hints have not been set, attempts to initialize type hints in this\n  order:\n  - Using self.default_type_hints().\n  - Using self.__class__ type hints.\n  \"\"\"\n  return (\n      self._get_or_create_type_hints().with_defaults(\n          self.default_type_hints()).with_defaults(\n              get_type_hints(self.__class__)))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.get_windowing","title":"get_windowing","text":"<pre><code>get_windowing(inputs)\n</code></pre> <p>Returns the window function to be associated with transform's output.</p> <p>By default most transforms just return the windowing function associated with the input PCollection (or the first input if several).</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_windowing(self, inputs):\n  # type: (Any) -&gt; Windowing\n\n  \"\"\"Returns the window function to be associated with transform's output.\n\n  By default most transforms just return the windowing function associated\n  with the input PCollection (or the first input if several).\n  \"\"\"\n  if inputs:\n    return inputs[0].windowing\n  else:\n    from apache_beam.transforms.core import Windowing\n    from apache_beam.transforms.window import GlobalWindows\n    # TODO(robertwb): Return something compatible with every windowing?\n    return Windowing(GlobalWindows())\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.infer_output_type","title":"infer_output_type","text":"<pre><code>infer_output_type(unused_input_type)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def infer_output_type(self, unused_input_type):\n  return self.get_type_hints().simple_output_type(self.label) or typehints.Any\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.register_urn","title":"register_urn  <code>classmethod</code>","text":"<pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre> <pre><code>register_urn(urn, parameter_type, constructor=None)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef register_urn(cls, urn, parameter_type, constructor=None):\n  def register(constructor):\n    if isinstance(constructor, type):\n      constructor.from_runner_api_parameter = register(\n          constructor.from_runner_api_parameter)\n    else:\n      cls._known_urns[urn] = parameter_type, constructor\n    return constructor\n\n  if constructor:\n    # Used as a statement.\n    register(constructor)\n  else:\n    # Used as a decorator.\n    return register\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.runner_api_requires_keyed_input","title":"runner_api_requires_keyed_input","text":"<pre><code>runner_api_requires_keyed_input()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def runner_api_requires_keyed_input(self):\n  return False\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.to_runner_api","title":"to_runner_api","text":"<pre><code>to_runner_api(context, has_parts=False, **extra_kwargs)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api(self, context, has_parts=False, **extra_kwargs):\n  # type: (PipelineContext, bool, Any) -&gt; beam_runner_api_pb2.FunctionSpec\n  from apache_beam.portability.api import beam_runner_api_pb2\n  # typing: only ParDo supports extra_kwargs\n  urn, typed_param = self.to_runner_api_parameter(context, **extra_kwargs)\n  if urn == python_urns.GENERIC_COMPOSITE_TRANSFORM and not has_parts:\n    # TODO(https://github.com/apache/beam/issues/18713): Remove this fallback.\n    urn, typed_param = self.to_runner_api_pickled(context)\n  return beam_runner_api_pb2.FunctionSpec(\n      urn=urn,\n      payload=typed_param.SerializeToString() if isinstance(\n          typed_param, message.Message) else typed_param.encode('utf-8')\n      if isinstance(typed_param, str) else typed_param)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.to_runner_api_parameter","title":"to_runner_api_parameter","text":"<pre><code>to_runner_api_parameter(unused_context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_parameter(\n    self,\n    unused_context  # type: PipelineContext\n):\n  # type: (...) -&gt; tuple[str, Optional[Union[message.Message, bytes, str]]]\n  # The payload here is just to ease debugging.\n  return (\n      python_urns.GENERIC_COMPOSITE_TRANSFORM,\n      getattr(self, '_fn_api_payload', str(self)))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.to_runner_api_pickled","title":"to_runner_api_pickled","text":"<pre><code>to_runner_api_pickled(context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_pickled(self, context):\n  # type: (PipelineContext) -&gt; tuple[str, bytes]\n  return (\n      python_urns.PICKLED_TRANSFORM,\n      pickler.dumps(\n          self,\n          enable_best_effort_determinism=context.\n          enable_best_effort_deterministic_pickling,\n      ),\n  )\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.type_check_inputs","title":"type_check_inputs","text":"<pre><code>type_check_inputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'input')\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.type_check_inputs_or_outputs","title":"type_check_inputs_or_outputs","text":"<pre><code>type_check_inputs_or_outputs(pvalueish, input_or_output)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs_or_outputs(self, pvalueish, input_or_output):\n  type_hints = self.get_type_hints()\n  hints = getattr(type_hints, input_or_output + '_types')\n  if hints is None or not any(hints):\n    return\n  arg_hints, kwarg_hints = hints\n  if arg_hints and kwarg_hints:\n    raise TypeCheckError(\n        'PTransform cannot have both positional and keyword type hints '\n        'without overriding %s._type_check_%s()' %\n        (self.__class__, input_or_output))\n  root_hint = (\n      arg_hints[0] if len(arg_hints) == 1 else arg_hints or kwarg_hints)\n  for context, pvalue_, hint in _ZipPValues().visit(pvalueish, root_hint):\n    if isinstance(pvalue_, DoOutputsTuple):\n      continue\n    if pvalue_.element_type is None:\n      # TODO(robertwb): It's a bug that we ever get here. (typecheck)\n      continue\n    if hint and not typehints.is_consistent_with(pvalue_.element_type, hint):\n      at_context = ' %s %s' % (input_or_output, context) if context else ''\n      raise TypeCheckError(\n          '{type} type hint violation at {label}{context}: expected {hint}, '\n          'got {actual_type}'.format(\n              type=input_or_output.title(),\n              label=self.label,\n              context=at_context,\n              hint=hint,\n              actual_type=pvalue_.element_type))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.type_check_outputs","title":"type_check_outputs","text":"<pre><code>type_check_outputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_outputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'output')\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.with_input_types","title":"with_input_types","text":"<pre><code>with_input_types(input_type_hint)\n</code></pre> <p>Annotates the input type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>input_type_hint</code> <p>An instance of an allowed built-in type, a custom class, or an instance of a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If input_type_hint is not a valid type-hint. See :obj:<code>apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_input_types(self, input_type_hint):\n  \"\"\"Annotates the input type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    input_type_hint (type): An instance of an allowed built-in type, a custom\n      class, or an instance of a\n      :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **input_type_hint** is not a valid type-hint.\n      See\n      :obj:`apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  input_type_hint = native_type_compatibility.convert_to_beam_type(\n      input_type_hint)\n  validate_composite_type_param(\n      input_type_hint, 'Type hints for a PTransform')\n  return super().with_input_types(input_type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.with_output_types","title":"with_output_types","text":"<pre><code>with_output_types(type_hint)\n</code></pre> <p>Annotates the output type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>type_hint</code> <p>An instance of an allowed built-in type, a custom class, or a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If type_hint is not a valid type-hint. See :obj:<code>~apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_output_types(self, type_hint):\n  \"\"\"Annotates the output type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    type_hint (type): An instance of an allowed built-in type, a custom class,\n      or a :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **type_hint** is not a valid type-hint. See\n      :obj:`~apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  type_hint = native_type_compatibility.convert_to_beam_type(type_hint)\n  validate_composite_type_param(type_hint, 'Type hints for a PTransform')\n  return super().with_output_types(type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteMetadata.with_resource_hints","title":"with_resource_hints","text":"<pre><code>with_resource_hints(**kwargs)\n</code></pre> <p>Adds resource hints to the :class:<code>PTransform</code>.</p> <p>Resource hints allow users to express constraints on the environment where the transform should be executed.  Interpretation of the resource hints is defined by Beam Runners. Runners may ignore the unsupported hints.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>key-value pairs describing hints and their values.</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>if provided hints are unknown to the SDK. See :mod:<code>apache_beam.transforms.resources</code> for a list of known hints.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_resource_hints(self, **kwargs):  # type: (...) -&gt; PTransform\n  \"\"\"Adds resource hints to the :class:`PTransform`.\n\n  Resource hints allow users to express constraints on the environment where\n  the transform should be executed.  Interpretation of the resource hints is\n  defined by Beam Runners. Runners may ignore the unsupported hints.\n\n  Args:\n    **kwargs: key-value pairs describing hints and their values.\n\n  Raises:\n    ValueError: if provided hints are unknown to the SDK. See\n      :mod:`apache_beam.transforms.resources` for a list of known hints.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object.\n  \"\"\"\n  self.get_resource_hints().update(resources.parse_resource_hints(kwargs))\n  return self\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn","title":"WriteTransformFn","text":"<pre><code>WriteTransformFn(path)\n</code></pre> <p>               Bases: <code>PTransform</code></p> <p>Writes a TransformFn to disk.</p> <p>The internal structure is a directory containing two subdirectories.  The first is 'transformed_metadata' and contains metadata of the transformed data. The second is 'transform_fn' and contains a SavedModel representing the transformed data.</p> Source code in <code>tensorflow_transform/beam/tft_beam_io/transform_fn_io.py</code> <pre><code>def __init__(self, path):\n    super().__init__()\n    self._path = path\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn-attributes","title":"Attributes","text":""},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.label","title":"label  <code>property</code> <code>writable</code>","text":"<pre><code>label\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.pipeline","title":"pipeline  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pipeline = None\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.side_inputs","title":"side_inputs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>side_inputs = ()\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn-functions","title":"Functions","text":""},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.annotations","title":"annotations","text":"<pre><code>annotations() -&gt; dict[str, Union[bytes, str, Message]]\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def annotations(self) -&gt; dict[str, Union[bytes, str, message.Message]]:\n  return {\n      'python_type':  #\n      f'{self.__class__.__module__}.{self.__class__.__qualname__}'\n  }\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.default_label","title":"default_label","text":"<pre><code>default_label()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_label(self):\n  # type: () -&gt; str\n  return self.__class__.__name__\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.default_type_hints","title":"default_type_hints","text":"<pre><code>default_type_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def default_type_hints(self):\n  fn_type_hints = IOTypeHints.from_callable(self.expand)\n  if fn_type_hints is not None:\n    fn_type_hints = fn_type_hints.strip_pcoll()\n\n  # Prefer class decorator type hints for backwards compatibility.\n  return get_type_hints(self.__class__).with_defaults(fn_type_hints)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.display_data","title":"display_data","text":"<pre><code>display_data()\n</code></pre> <p>Returns the display data associated to a pipeline component.</p> <p>It should be reimplemented in pipeline components that wish to have static display data.</p> RETURNS DESCRIPTION <p>Dict[str, Any]: A dictionary containing <code>key:value</code> pairs.</p> <p>The value might be an integer, float or string value; a</p> <p>class:<code>DisplayDataItem</code> for values that have more data</p> <p>(e.g. short value, label, url); or a :class:<code>HasDisplayData</code> instance</p> <p>that has more display data that should be picked up. For example::</p> <p>{   'key1': 'string_value',   'key2': 1234,   'key3': 3.14159265,   'key4': DisplayDataItem('apache.org', url='http://apache.org'),   'key5': subComponent }</p> Source code in <code>apache_beam/transforms/display.py</code> <pre><code>def display_data(self):\n  # type: () -&gt; dict\n\n  \"\"\" Returns the display data associated to a pipeline component.\n\n  It should be reimplemented in pipeline components that wish to have\n  static display data.\n\n  Returns:\n    Dict[str, Any]: A dictionary containing ``key:value`` pairs.\n    The value might be an integer, float or string value; a\n    :class:`DisplayDataItem` for values that have more data\n    (e.g. short value, label, url); or a :class:`HasDisplayData` instance\n    that has more display data that should be picked up. For example::\n\n      {\n        'key1': 'string_value',\n        'key2': 1234,\n        'key3': 3.14159265,\n        'key4': DisplayDataItem('apache.org', url='http://apache.org'),\n        'key5': subComponent\n      }\n  \"\"\"\n  return {}\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.expand","title":"expand","text":"<pre><code>expand(transform_fn)\n</code></pre> Source code in <code>tensorflow_transform/beam/tft_beam_io/transform_fn_io.py</code> <pre><code>def expand(self, transform_fn):\n    saved_model_dir, metadata = transform_fn\n    pipeline = saved_model_dir.pipeline\n\n    # Using a temp dir within `path` ensures that the source and dstination\n    # paths for the rename below are in the same file system.\n    base_temp_dir = os.path.join(self._path, \"transform_tmp\")\n    temp_metadata_path = (\n        metadata\n        | \"WriteMetadataToTemp\"\n        &gt;&gt; beam_metadata_io.WriteMetadata(\n            base_temp_dir, pipeline, write_to_unique_subdirectory=True\n        )\n    )\n\n    temp_transform_fn_path = saved_model_dir | \"WriteTransformFnToTemp\" &gt;&gt; beam.Map(\n        _copy_tree_to_unique_temp_dir, base_temp_dir\n    )\n\n    metadata_path = os.path.join(\n        self._path, tft.TFTransformOutput.TRANSFORMED_METADATA_DIR\n    )\n    transform_fn_path = os.path.join(\n        self._path, tft.TFTransformOutput.TRANSFORM_FN_DIR\n    )\n\n    def publish_outputs(\n        unused_element, metadata_source_path, transform_fn_source_path\n    ):\n        import tensorflow as tf  # pylint: disable=g-import-not-at-top\n\n        if not tf.io.gfile.exists(self._path):\n            tf.io.gfile.makedirs(self._path)\n\n        if tf.io.gfile.exists(metadata_path):\n            tf.io.gfile.rmtree(metadata_path)\n        tf.io.gfile.rename(metadata_source_path, metadata_path, overwrite=True)\n\n        if tf.io.gfile.exists(transform_fn_path):\n            tf.io.gfile.rmtree(transform_fn_path)\n        tf.io.gfile.rename(\n            transform_fn_source_path, transform_fn_path, overwrite=True\n        )\n\n        # TODO(b/211615643): Remove the exists check once importing TFIO in S3\n        # addresses NotFoundError.\n        if tf.io.gfile.exists(base_temp_dir):\n            tf.io.gfile.rmtree(base_temp_dir)\n\n    # TODO(KesterTong): Move this \"must follows\" logic into a tfx_bsl helper\n    # function or into Beam.\n    return (\n        pipeline\n        | \"CreateSole\" &gt;&gt; beam.Create([None])\n        | \"PublishMetadataAndTransformFn\"\n        &gt;&gt; beam.Map(\n            publish_outputs,\n            metadata_source_path=beam.pvalue.AsSingleton(temp_metadata_path),\n            transform_fn_source_path=beam.pvalue.AsSingleton(\n                temp_transform_fn_path\n            ),\n        )\n    )\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.from_runner_api","title":"from_runner_api  <code>classmethod</code>","text":"<pre><code>from_runner_api(proto, context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef from_runner_api(\n    cls,\n    proto,  # type: Optional[beam_runner_api_pb2.PTransform]\n    context  # type: PipelineContext\n):\n  # type: (...) -&gt; Optional[PTransform]\n  if proto is None or proto.spec is None or not proto.spec.urn:\n    return None\n  parameter_type, constructor = cls._known_urns[proto.spec.urn]\n\n  return constructor(\n      proto,\n      proto_utils.parse_Bytes(proto.spec.payload, parameter_type),\n      context)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.get_resource_hints","title":"get_resource_hints","text":"<pre><code>get_resource_hints()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_resource_hints(self):\n  # type: () -&gt; dict[str, bytes]\n  if '_resource_hints' not in self.__dict__:\n    # PTransform subclasses don't always call super(), so prefer lazy\n    # initialization. By default, transforms don't have any resource hints.\n    self._resource_hints = {}  # type: dict[str, bytes]\n  return self._resource_hints\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.get_type_hints","title":"get_type_hints","text":"<pre><code>get_type_hints()\n</code></pre> <p>Gets and/or initializes type hints for this object.</p> <p>If type hints have not been set, attempts to initialize type hints in this order: - Using self.default_type_hints(). - Using self.class type hints.</p> Source code in <code>apache_beam/typehints/decorators.py</code> <pre><code>def get_type_hints(self):\n  \"\"\"Gets and/or initializes type hints for this object.\n\n  If type hints have not been set, attempts to initialize type hints in this\n  order:\n  - Using self.default_type_hints().\n  - Using self.__class__ type hints.\n  \"\"\"\n  return (\n      self._get_or_create_type_hints().with_defaults(\n          self.default_type_hints()).with_defaults(\n              get_type_hints(self.__class__)))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.get_windowing","title":"get_windowing","text":"<pre><code>get_windowing(inputs)\n</code></pre> <p>Returns the window function to be associated with transform's output.</p> <p>By default most transforms just return the windowing function associated with the input PCollection (or the first input if several).</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def get_windowing(self, inputs):\n  # type: (Any) -&gt; Windowing\n\n  \"\"\"Returns the window function to be associated with transform's output.\n\n  By default most transforms just return the windowing function associated\n  with the input PCollection (or the first input if several).\n  \"\"\"\n  if inputs:\n    return inputs[0].windowing\n  else:\n    from apache_beam.transforms.core import Windowing\n    from apache_beam.transforms.window import GlobalWindows\n    # TODO(robertwb): Return something compatible with every windowing?\n    return Windowing(GlobalWindows())\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.infer_output_type","title":"infer_output_type","text":"<pre><code>infer_output_type(unused_input_type)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def infer_output_type(self, unused_input_type):\n  return self.get_type_hints().simple_output_type(self.label) or typehints.Any\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.register_urn","title":"register_urn  <code>classmethod</code>","text":"<pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre><pre><code>register_urn(urn, parameter_type, constructor)\n</code></pre> <pre><code>register_urn(urn, parameter_type, constructor=None)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>@classmethod\ndef register_urn(cls, urn, parameter_type, constructor=None):\n  def register(constructor):\n    if isinstance(constructor, type):\n      constructor.from_runner_api_parameter = register(\n          constructor.from_runner_api_parameter)\n    else:\n      cls._known_urns[urn] = parameter_type, constructor\n    return constructor\n\n  if constructor:\n    # Used as a statement.\n    register(constructor)\n  else:\n    # Used as a decorator.\n    return register\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.runner_api_requires_keyed_input","title":"runner_api_requires_keyed_input","text":"<pre><code>runner_api_requires_keyed_input()\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def runner_api_requires_keyed_input(self):\n  return False\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.to_runner_api","title":"to_runner_api","text":"<pre><code>to_runner_api(context, has_parts=False, **extra_kwargs)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api(self, context, has_parts=False, **extra_kwargs):\n  # type: (PipelineContext, bool, Any) -&gt; beam_runner_api_pb2.FunctionSpec\n  from apache_beam.portability.api import beam_runner_api_pb2\n  # typing: only ParDo supports extra_kwargs\n  urn, typed_param = self.to_runner_api_parameter(context, **extra_kwargs)\n  if urn == python_urns.GENERIC_COMPOSITE_TRANSFORM and not has_parts:\n    # TODO(https://github.com/apache/beam/issues/18713): Remove this fallback.\n    urn, typed_param = self.to_runner_api_pickled(context)\n  return beam_runner_api_pb2.FunctionSpec(\n      urn=urn,\n      payload=typed_param.SerializeToString() if isinstance(\n          typed_param, message.Message) else typed_param.encode('utf-8')\n      if isinstance(typed_param, str) else typed_param)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.to_runner_api_parameter","title":"to_runner_api_parameter","text":"<pre><code>to_runner_api_parameter(unused_context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_parameter(\n    self,\n    unused_context  # type: PipelineContext\n):\n  # type: (...) -&gt; tuple[str, Optional[Union[message.Message, bytes, str]]]\n  # The payload here is just to ease debugging.\n  return (\n      python_urns.GENERIC_COMPOSITE_TRANSFORM,\n      getattr(self, '_fn_api_payload', str(self)))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.to_runner_api_pickled","title":"to_runner_api_pickled","text":"<pre><code>to_runner_api_pickled(context)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def to_runner_api_pickled(self, context):\n  # type: (PipelineContext) -&gt; tuple[str, bytes]\n  return (\n      python_urns.PICKLED_TRANSFORM,\n      pickler.dumps(\n          self,\n          enable_best_effort_determinism=context.\n          enable_best_effort_deterministic_pickling,\n      ),\n  )\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.type_check_inputs","title":"type_check_inputs","text":"<pre><code>type_check_inputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'input')\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.type_check_inputs_or_outputs","title":"type_check_inputs_or_outputs","text":"<pre><code>type_check_inputs_or_outputs(pvalueish, input_or_output)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_inputs_or_outputs(self, pvalueish, input_or_output):\n  type_hints = self.get_type_hints()\n  hints = getattr(type_hints, input_or_output + '_types')\n  if hints is None or not any(hints):\n    return\n  arg_hints, kwarg_hints = hints\n  if arg_hints and kwarg_hints:\n    raise TypeCheckError(\n        'PTransform cannot have both positional and keyword type hints '\n        'without overriding %s._type_check_%s()' %\n        (self.__class__, input_or_output))\n  root_hint = (\n      arg_hints[0] if len(arg_hints) == 1 else arg_hints or kwarg_hints)\n  for context, pvalue_, hint in _ZipPValues().visit(pvalueish, root_hint):\n    if isinstance(pvalue_, DoOutputsTuple):\n      continue\n    if pvalue_.element_type is None:\n      # TODO(robertwb): It's a bug that we ever get here. (typecheck)\n      continue\n    if hint and not typehints.is_consistent_with(pvalue_.element_type, hint):\n      at_context = ' %s %s' % (input_or_output, context) if context else ''\n      raise TypeCheckError(\n          '{type} type hint violation at {label}{context}: expected {hint}, '\n          'got {actual_type}'.format(\n              type=input_or_output.title(),\n              label=self.label,\n              context=at_context,\n              hint=hint,\n              actual_type=pvalue_.element_type))\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.type_check_outputs","title":"type_check_outputs","text":"<pre><code>type_check_outputs(pvalueish)\n</code></pre> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def type_check_outputs(self, pvalueish):\n  self.type_check_inputs_or_outputs(pvalueish, 'output')\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.with_input_types","title":"with_input_types","text":"<pre><code>with_input_types(input_type_hint)\n</code></pre> <p>Annotates the input type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>input_type_hint</code> <p>An instance of an allowed built-in type, a custom class, or an instance of a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If input_type_hint is not a valid type-hint. See :obj:<code>apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_input_types(self, input_type_hint):\n  \"\"\"Annotates the input type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    input_type_hint (type): An instance of an allowed built-in type, a custom\n      class, or an instance of a\n      :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **input_type_hint** is not a valid type-hint.\n      See\n      :obj:`apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  input_type_hint = native_type_compatibility.convert_to_beam_type(\n      input_type_hint)\n  validate_composite_type_param(\n      input_type_hint, 'Type hints for a PTransform')\n  return super().with_input_types(input_type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.with_output_types","title":"with_output_types","text":"<pre><code>with_output_types(type_hint)\n</code></pre> <p>Annotates the output type of a :class:<code>PTransform</code> with a type-hint.</p> PARAMETER DESCRIPTION <code>type_hint</code> <p>An instance of an allowed built-in type, a custom class, or a :class:<code>~apache_beam.typehints.typehints.TypeConstraint</code>.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If type_hint is not a valid type-hint. See :obj:<code>~apache_beam.typehints.typehints.validate_composite_type_param()</code> for further details.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object. This allows chaining type-hinting related</p> <p>methods.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_output_types(self, type_hint):\n  \"\"\"Annotates the output type of a :class:`PTransform` with a type-hint.\n\n  Args:\n    type_hint (type): An instance of an allowed built-in type, a custom class,\n      or a :class:`~apache_beam.typehints.typehints.TypeConstraint`.\n\n  Raises:\n    TypeError: If **type_hint** is not a valid type-hint. See\n      :obj:`~apache_beam.typehints.typehints.validate_composite_type_param()`\n      for further details.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object. This allows chaining type-hinting related\n    methods.\n  \"\"\"\n  type_hint = native_type_compatibility.convert_to_beam_type(type_hint)\n  validate_composite_type_param(type_hint, 'Type hints for a PTransform')\n  return super().with_output_types(type_hint)\n</code></pre>"},{"location":"api_docs/python/tft-beam/#tensorflow_transform.beam.WriteTransformFn.with_resource_hints","title":"with_resource_hints","text":"<pre><code>with_resource_hints(**kwargs)\n</code></pre> <p>Adds resource hints to the :class:<code>PTransform</code>.</p> <p>Resource hints allow users to express constraints on the environment where the transform should be executed.  Interpretation of the resource hints is defined by Beam Runners. Runners may ignore the unsupported hints.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>key-value pairs describing hints and their values.</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>if provided hints are unknown to the SDK. See :mod:<code>apache_beam.transforms.resources</code> for a list of known hints.</p> RETURNS DESCRIPTION <code>PTransform</code> <p>A reference to the instance of this particular</p> <p>class:<code>PTransform</code> object.</p> Source code in <code>apache_beam/transforms/ptransform.py</code> <pre><code>def with_resource_hints(self, **kwargs):  # type: (...) -&gt; PTransform\n  \"\"\"Adds resource hints to the :class:`PTransform`.\n\n  Resource hints allow users to express constraints on the environment where\n  the transform should be executed.  Interpretation of the resource hints is\n  defined by Beam Runners. Runners may ignore the unsupported hints.\n\n  Args:\n    **kwargs: key-value pairs describing hints and their values.\n\n  Raises:\n    ValueError: if provided hints are unknown to the SDK. See\n      :mod:`apache_beam.transforms.resources` for a list of known hints.\n\n  Returns:\n    PTransform: A reference to the instance of this particular\n    :class:`PTransform` object.\n  \"\"\"\n  self.get_resource_hints().update(resources.parse_resource_hints(kwargs))\n  return self\n</code></pre>"},{"location":"api_docs/python/tft-coders/","title":"TensorFlow Transform <code>tft.coders</code> Module","text":""},{"location":"api_docs/python/tft-coders/#tensorflow_transform.coders","title":"tensorflow_transform.coders","text":"<p>Module level imports for tensorflow_transform.coders.</p>"},{"location":"api_docs/python/tft-coders/#tensorflow_transform.coders-classes","title":"Classes","text":""},{"location":"api_docs/python/tft-coders/#tensorflow_transform.coders.CsvCoder","title":"CsvCoder","text":"<pre><code>CsvCoder(\n    column_names,\n    schema,\n    delimiter=\",\",\n    secondary_delimiter=None,\n    multivalent_columns=None,\n)\n</code></pre> <p>A coder to encode CSV formatted data.</p> <p>Initializes CsvCoder.</p> <p>column_names: Tuple of strings. Order must match the order in the file.   schema: A <code>Schema</code> proto.   delimiter: A one-character string used to separate fields.   secondary_delimiter: A one-character string used to separate values within     the same field.   multivalent_columns: A list of names for multivalent columns that need to     be split based on secondary delimiter.</p> <p>ValueError: If <code>schema</code> is invalid.</p> Source code in <code>tensorflow_transform/coders/csv_coder.py</code> <pre><code>def __init__(\n    self,\n    column_names,\n    schema,\n    delimiter=\",\",\n    secondary_delimiter=None,\n    multivalent_columns=None,\n):\n    \"\"\"Initializes CsvCoder.\n\n    Args:\n    ----\n      column_names: Tuple of strings. Order must match the order in the file.\n      schema: A `Schema` proto.\n      delimiter: A one-character string used to separate fields.\n      secondary_delimiter: A one-character string used to separate values within\n        the same field.\n      multivalent_columns: A list of names for multivalent columns that need to\n        be split based on secondary delimiter.\n\n    Raises:\n    ------\n      ValueError: If `schema` is invalid.\n    \"\"\"\n    self._column_names = column_names\n    self._schema = schema\n    self._delimiter = delimiter\n    self._secondary_delimiter = secondary_delimiter\n    self._encoder = self._WriterWrapper(delimiter)\n\n    if multivalent_columns is None:\n        multivalent_columns = []\n    self._multivalent_columns = multivalent_columns\n\n    if secondary_delimiter:\n        secondary_encoder = self._WriterWrapper(secondary_delimiter)\n    elif multivalent_columns:\n        raise ValueError(\n            'secondary_delimiter unspecified for multivalent columns \"{}\"'.format(\n                multivalent_columns\n            )\n        )\n    secondary_encoder_by_name = {\n        name: secondary_encoder for name in multivalent_columns\n    }\n    indices_by_name = {name: index for index, name in enumerate(self._column_names)}\n\n    def index(name):\n        index = indices_by_name.get(name)\n        if index is None:\n            raise ValueError('Column not found: \"{}\"'.format(name))\n        else:\n            return index\n\n    self._feature_handlers = []\n    for name, feature_spec in schema_utils.schema_as_feature_spec(\n        schema\n    ).feature_spec.items():\n        if isinstance(feature_spec, tf.io.FixedLenFeature):\n            self._feature_handlers.append(\n                _FixedLenFeatureHandler(\n                    name,\n                    feature_spec,\n                    index(name),\n                    secondary_encoder_by_name.get(name),\n                )\n            )\n        elif isinstance(feature_spec, tf.io.VarLenFeature):\n            self._feature_handlers.append(\n                _VarLenFeatureHandler(\n                    name,\n                    feature_spec.dtype,\n                    index(name),\n                    secondary_encoder_by_name.get(name),\n                )\n            )\n        elif isinstance(feature_spec, tf.io.SparseFeature):\n            index_keys = (\n                feature_spec.index_key\n                if isinstance(feature_spec.index_key, list)\n                else [feature_spec.index_key]\n            )\n            for key in index_keys:\n                self._feature_handlers.append(\n                    _VarLenFeatureHandler(\n                        key,\n                        tf.int64,\n                        index(key),\n                        secondary_encoder_by_name.get(name),\n                    )\n                )\n            self._feature_handlers.append(\n                _VarLenFeatureHandler(\n                    feature_spec.value_key,\n                    feature_spec.dtype,\n                    index(feature_spec.value_key),\n                    secondary_encoder_by_name.get(name),\n                )\n            )\n        else:\n            raise ValueError(\n                \"feature_spec should be one of tf.FixedLenFeature, \"\n                \"tf.VarLenFeature or tf.SparseFeature: {!r} was {!r}\".format(\n                    name, type(feature_spec)\n                )\n            )\n</code></pre>"},{"location":"api_docs/python/tft-coders/#tensorflow_transform.coders.CsvCoder-functions","title":"Functions","text":""},{"location":"api_docs/python/tft-coders/#tensorflow_transform.coders.CsvCoder.encode","title":"encode","text":"<pre><code>encode(instance)\n</code></pre> <p>Encode a tf.transform encoded dict to a csv-formatted string.</p> <p>instance: A python dictionary where the keys are the column names and the     values are fixed len or var len encoded features.</p> <p>A csv-formatted string. The order of the columns is given by column_names.</p> Source code in <code>tensorflow_transform/coders/csv_coder.py</code> <pre><code>def encode(self, instance):\n    \"\"\"Encode a tf.transform encoded dict to a csv-formatted string.\n\n    Args:\n    ----\n      instance: A python dictionary where the keys are the column names and the\n        values are fixed len or var len encoded features.\n\n    Returns:\n    -------\n      A csv-formatted string. The order of the columns is given by column_names.\n    \"\"\"\n    string_list = [None] * len(self._column_names)\n    for feature_handler in self._feature_handlers:\n        try:\n            feature_handler.encode_value(\n                string_list, instance[feature_handler.name]\n            )\n        except TypeError as e:\n            raise TypeError(\n                '{} while encoding feature \"{}\"'.format(e, feature_handler.name)\n            )\n    return self._encoder.encode_record(string_list)\n</code></pre>"},{"location":"api_docs/python/tft-coders/#tensorflow_transform.coders.ExampleProtoCoder","title":"ExampleProtoCoder","text":"<pre><code>ExampleProtoCoder(schema, serialized=True)\n</code></pre> <p>A coder between maybe-serialized TF Examples and tf.Transform datasets.</p> <p>Build an ExampleProtoCoder.</p> <p>schema: A <code>Schema</code> proto.   serialized: Whether to encode serialized Example protos (as opposed to     in-memory Example protos).</p> <p>ValueError: If <code>schema</code> is invalid.</p> Source code in <code>tensorflow_transform/coders/example_proto_coder.py</code> <pre><code>def __init__(self, schema, serialized=True):\n    \"\"\"Build an ExampleProtoCoder.\n\n    Args:\n    ----\n      schema: A `Schema` proto.\n      serialized: Whether to encode serialized Example protos (as opposed to\n        in-memory Example protos).\n\n    Raises:\n    ------\n      ValueError: If `schema` is invalid.\n    \"\"\"\n    self._schema = schema\n    self._serialized = serialized\n\n    # Using pre-allocated tf.train.Example and FeatureHandler objects for\n    # performance reasons.\n    #\n    # Since the output of \"encode\" is deep as opposed to shallow\n    # transformations, and since the schema always fully defines the Example's\n    # FeatureMap (ie all fields are always cleared/assigned or copied), the\n    # optimization and implementation are correct and thread-compatible.\n    self._encode_example_cache = tf.train.Example()\n    self._feature_handlers = []\n    for name, feature_spec in schema_utils.schema_as_feature_spec(\n        schema\n    ).feature_spec.items():\n        if isinstance(feature_spec, tf.io.FixedLenFeature):\n            self._feature_handlers.append(\n                _FixedLenFeatureHandler(name, feature_spec)\n            )\n        elif isinstance(feature_spec, tf.io.VarLenFeature):\n            self._feature_handlers.append(\n                _VarLenFeatureHandler(name, feature_spec.dtype)\n            )\n        elif isinstance(feature_spec, tf.io.SparseFeature):\n            index_keys = (\n                feature_spec.index_key\n                if isinstance(feature_spec.index_key, list)\n                else [feature_spec.index_key]\n            )\n            for index_key in index_keys:\n                self._feature_handlers.append(\n                    _VarLenFeatureHandler(index_key, tf.int64)\n                )\n            self._feature_handlers.append(\n                _VarLenFeatureHandler(feature_spec.value_key, feature_spec.dtype)\n            )\n        elif isinstance(feature_spec, tf.io.RaggedFeature):\n            uniform_partition = False\n            for partition in feature_spec.partitions:\n                if isinstance(partition, tf.io.RaggedFeature.RowLengths):\n                    if uniform_partition:\n                        raise ValueError(\n                            \"Encountered ragged dimension after uniform for feature \"\n                            '\"{}\": only inner dimensions can be uniform. Feature spec '\n                            \"is {}\".format(name, feature_spec)\n                        )\n                    self._feature_handlers.append(\n                        _VarLenFeatureHandler(partition.key, tf.int64)\n                    )\n                elif isinstance(partition, tf.io.RaggedFeature.UniformRowLength):\n                    # We don't encode uniform partitions since they can be recovered\n                    # from the shape information.\n                    uniform_partition = True\n                else:\n                    raise ValueError(\n                        \"Only `RowLengths` and `UniformRowLength` partitions of ragged \"\n                        \"features are supported, got {}\".format(type(partition))\n                    )\n            self._feature_handlers.append(\n                _VarLenFeatureHandler(feature_spec.value_key, feature_spec.dtype)\n            )\n        else:\n            raise ValueError(\n                \"feature_spec should be one of tf.io.FixedLenFeature, \"\n                \"tf.io.VarLenFeature, tf.io.SparseFeature or \"\n                'tf.io.RaggedFeature: \"{}\" was {}'.format(name, type(feature_spec))\n            )\n\n    for feature_handler in self._feature_handlers:\n        feature_handler.initialize_encode_cache(self._encode_example_cache)\n</code></pre>"},{"location":"api_docs/python/tft-coders/#tensorflow_transform.coders.ExampleProtoCoder-functions","title":"Functions","text":""},{"location":"api_docs/python/tft-coders/#tensorflow_transform.coders.ExampleProtoCoder.encode","title":"encode","text":"<pre><code>encode(instance)\n</code></pre> <p>Encode a tf.transform encoded dict as tf.Example.</p> Source code in <code>tensorflow_transform/coders/example_proto_coder.py</code> <pre><code>def encode(self, instance):\n    \"\"\"Encode a tf.transform encoded dict as tf.Example.\"\"\"\n    # The feature handles encode using the self._encode_example_cache.\n    for feature_handler in self._feature_handlers:\n        value = instance[feature_handler.name]\n        try:\n            feature_handler.encode_value(value)\n        except TypeError as e:\n            raise TypeError(\n                '%s while encoding feature \"%s\"' % (e, feature_handler.name)\n            )\n\n    if self._serialized:\n        return self._encode_example_cache.SerializeToString()\n\n    result = tf.train.Example()\n    result.CopyFrom(self._encode_example_cache)\n    return result\n</code></pre>"},{"location":"api_docs/python/tft-experimental/","title":"TensorFlow Transform <code>tft.experimental</code> Module","text":""},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental","title":"tensorflow_transform.experimental","text":"<p>Module level imports for tensorflow_transform.experimental.</p>"},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental-attributes","title":"Attributes","text":""},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental.PTransformAnalyzerCacheCoder","title":"PTransformAnalyzerCacheCoder  <code>module-attribute</code>","text":"<pre><code>PTransformAnalyzerCacheCoder = CacheCoder\n</code></pre>"},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental.Sequence","title":"Sequence  <code>module-attribute</code>","text":"<pre><code>Sequence = _alias(Sequence, 1)\n</code></pre>"},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental.SimpleJsonPTransformAnalyzerCacheCoder","title":"SimpleJsonPTransformAnalyzerCacheCoder  <code>module-attribute</code>","text":"<pre><code>SimpleJsonPTransformAnalyzerCacheCoder = JsonNumpyCacheCoder\n</code></pre>"},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental-classes","title":"Classes","text":""},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental.CacheablePTransformAnalyzer","title":"CacheablePTransformAnalyzer","text":"<p>               Bases: <code>TypedNamedTuple('PTransformCachedAnalyzer', [('make_accumulators_ptransform', _BeamPTransform), ('merge_accumulators_ptransform', _BeamPTransform), ('extract_output_ptransform', _BeamPTransform), ('cache_coder', PTransformAnalyzerCacheCoder)])</code></p> <p>A PTransformAnalyzer which enables analyzer cache.</p> <p>WARNING: This should only be used if the analyzer can correctly be separated into make_accumulators, merge_accumulators and extract_output stages. 1. make_accumulators_ptransform: this is a <code>beam.PTransform</code> which maps data    to a more compact mergeable representation (accumulator). Mergeable here    means that it is possible to combine multiple representations produced from    a partition of the dataset into a representation of the entire dataset. 1. merge_accumulators_ptransform: this is a <code>beam.PTransform</code> which operates    on a collection of accumulators, i.e. the results of both the    make_accumulators_ptransform and merge_accumulators_ptransform stages,    and produces a single reduced accumulator. This operation must be    associative and commutative in order to have reliably reproducible results. 1. extract_output: this is a <code>beam.PTransform</code> which operates on the result of    the merge_accumulators_ptransform stage, and produces the outputs of the    analyzer. These outputs must be consistent with the <code>output_dtypes</code> and    <code>output_shapes</code> provided to <code>ptransform_analyzer</code>.</p> <p>This container also holds a <code>cache_coder</code> (<code>PTransformAnalyzerCacheCoder</code>) which can encode outputs and decode the inputs of the <code>merge_accumulators_ptransform</code> stage. In many cases, <code>SimpleJsonPTransformAnalyzerCacheCoder</code> would be sufficient.</p> <p>To ensure the correctness of this analyzer, the following must hold: merge(make({D1, ..., Dn})) == merge({make(D1), ..., make(Dn)})</p>"},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental-functions","title":"Functions","text":""},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental.Any","title":"Any","text":"<pre><code>Any(self, parameters)\n</code></pre> <p>Special type indicating an unconstrained type.</p> <ul> <li>Any is compatible with every type.</li> <li>Any assumed to have all methods.</li> <li>All values assumed to be instances of Any.</li> </ul> <p>Note that all the above statements are true from the point of view of static type checkers. At runtime, Any should not be used with instance or class checks.</p> Source code in <code>python3.9/typing.py</code> <pre><code>@_SpecialForm\ndef Any(self, parameters):\n    \"\"\"Special type indicating an unconstrained type.\n\n    - Any is compatible with every type.\n    - Any assumed to have all methods.\n    - All values assumed to be instances of Any.\n\n    Note that all the above statements are true from the point of view of\n    static type checkers. At runtime, Any should not be used with instance\n    or class checks.\n    \"\"\"\n    raise TypeError(f\"{self} is not subscriptable\")\n</code></pre>"},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental.Optional","title":"Optional","text":"<pre><code>Optional(self, parameters)\n</code></pre> <p>Optional type.</p> <p>Optional[X] is equivalent to Union[X, None].</p> Source code in <code>python3.9/typing.py</code> <pre><code>@_SpecialForm\ndef Optional(self, parameters):\n    \"\"\"Optional type.\n\n    Optional[X] is equivalent to Union[X, None].\n    \"\"\"\n    arg = _type_check(parameters, f\"{self} requires a single type.\")\n    return Union[arg, type(None)]\n</code></pre>"},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental.Union","title":"Union","text":"<pre><code>Union(self, parameters)\n</code></pre> <p>Union type; Union[X, Y] means either X or Y.</p> <p>To define a union, use e.g. Union[int, str].  Details: - The arguments must be types and there must be at least one. - None as an argument is a special case and is replaced by   type(None). - Unions of unions are flattened, e.g.::</p> <pre><code>Union[Union[int, str], float] == Union[int, str, float]\n</code></pre> <ul> <li> <p>Unions of a single argument vanish, e.g.::</p> <p>Union[int] == int  # The constructor actually returns int</p> </li> <li> <p>Redundant arguments are skipped, e.g.::</p> <p>Union[int, str, int] == Union[int, str]</p> </li> <li> <p>When comparing unions, the argument order is ignored, e.g.::</p> <p>Union[int, str] == Union[str, int]</p> </li> <li> <p>You cannot subclass or instantiate a union.</p> </li> <li>You can use Optional[X] as a shorthand for Union[X, None].</li> </ul> Source code in <code>python3.9/typing.py</code> <pre><code>@_SpecialForm\ndef Union(self, parameters):\n    \"\"\"Union type; Union[X, Y] means either X or Y.\n\n    To define a union, use e.g. Union[int, str].  Details:\n    - The arguments must be types and there must be at least one.\n    - None as an argument is a special case and is replaced by\n      type(None).\n    - Unions of unions are flattened, e.g.::\n\n        Union[Union[int, str], float] == Union[int, str, float]\n\n    - Unions of a single argument vanish, e.g.::\n\n        Union[int] == int  # The constructor actually returns int\n\n    - Redundant arguments are skipped, e.g.::\n\n        Union[int, str, int] == Union[int, str]\n\n    - When comparing unions, the argument order is ignored, e.g.::\n\n        Union[int, str] == Union[str, int]\n\n    - You cannot subclass or instantiate a union.\n    - You can use Optional[X] as a shorthand for Union[X, None].\n    \"\"\"\n    if parameters == ():\n        raise TypeError(\"Cannot take a Union of no types.\")\n    if not isinstance(parameters, tuple):\n        parameters = (parameters,)\n    msg = \"Union[arg, ...]: each arg must be a type.\"\n    parameters = tuple(_type_check(p, msg) for p in parameters)\n    parameters = _remove_dups_flatten(parameters)\n    if len(parameters) == 1:\n        return parameters[0]\n    return _UnionGenericAlias(self, parameters)\n</code></pre>"},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental.annotate_sparse_output_shape","title":"annotate_sparse_output_shape","text":"<pre><code>annotate_sparse_output_shape(\n    tensor: SparseTensor,\n    shape: Union[Sequence[int], Tensor],\n)\n</code></pre> <p>Annotates a sparse output to have a given dense_shape.</p> <p>tensor: An <code>SparseTensor</code> to be annotated.   shape: A dense_shape to annotate <code>tensor</code> with. Note that this shape does     not include batch_size.</p> Source code in <code>tensorflow_transform/experimental/annotators.py</code> <pre><code>def annotate_sparse_output_shape(\n    tensor: tf.SparseTensor, shape: Union[Sequence[int], tf.Tensor]\n):\n    \"\"\"Annotates a sparse output to have a given dense_shape.\n\n    Args:\n    ----\n      tensor: An `SparseTensor` to be annotated.\n      shape: A dense_shape to annotate `tensor` with. Note that this shape does\n        not include batch_size.\n    \"\"\"\n    if not isinstance(shape, tf.Tensor):\n        if (tensor.shape.rank &gt; 1 and tensor.shape.rank - 1 != len(shape)) or (\n            tensor.shape.rank == 1 and len(shape) != 1\n        ):\n            raise ValueError(\n                f\"Annotated shape {shape} was expected to have rank\"\n                f\" {tensor.shape.rank - 1}\"\n            )\n        if not all(a is None or a &lt;= b for a, b in zip(tensor.shape[1:], shape)):\n            raise ValueError(f\"Shape {shape} cannot contain annotated tensor {tensor}\")\n        shape = tf.convert_to_tensor(shape, dtype=tf.int64)\n    elif shape.shape.rank &gt; 1 or (\n        shape.shape.rank == 1 and shape.shape[0] != tensor.shape.rank - 1\n    ):\n        raise ValueError(\n            f\"Annotation shape has rank {shape.shape.rank} but expected to have\"\n            f\" rank {tensor.shape.rank - 1}\"\n        )\n    if shape.shape.rank &lt; 1:\n        shape = tf.expand_dims(shape, -1)\n    # There's currently no way to override SparseTensor.dense_shape directly,\n    # unless composing and returning a new SparseTensor.\n    tensor._dense_shape = tf.concat(  # pylint: disable=protected-access\n        [tf.expand_dims(tensor.dense_shape[0], -1), tf.cast(shape, tf.int64)], axis=0\n    )\n    schema_inference.annotate_sparse_output_shape(tensor, shape)\n</code></pre>"},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental.annotate_true_sparse_output","title":"annotate_true_sparse_output","text":"<pre><code>annotate_true_sparse_output(tensor: SparseTensor)\n</code></pre> <p>Annotates a sparse output to be truely sparse and not varlen.</p> Source code in <code>tensorflow_transform/experimental/annotators.py</code> <pre><code>def annotate_true_sparse_output(tensor: tf.SparseTensor):\n    \"\"\"Annotates a sparse output to be truely sparse and not varlen.\"\"\"\n    schema_inference.annotate_true_sparse_output(tensor)\n</code></pre>"},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental.approximate_vocabulary","title":"approximate_vocabulary","text":"<pre><code>approximate_vocabulary(\n    x: TensorType,\n    top_k: int,\n    *,\n    vocab_filename: Optional[str] = None,\n    store_frequency: bool = False,\n    reserved_tokens: Optional[\n        Union[Sequence[str], Tensor]\n    ] = None,\n    weights: Optional[Tensor] = None,\n    file_format: VocabularyFileFormatType = DEFAULT_VOCABULARY_FILE_FORMAT,\n    name: Optional[str] = None,\n) -&gt; TemporaryAnalyzerOutputType\n</code></pre> <p>Computes the unique values of a <code>Tensor</code> over the whole dataset.</p> <p>Approximately computes the unique values taken by <code>x</code>, which can be a <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of any size.  The unique values will be aggregated over all dimensions of <code>x</code> and all instances.</p> <p>This analyzer provides an approximate alternative to <code>tft.vocabulary</code> that can be more efficient with smaller <code>top_k</code> and/or smaller number of unique elements in <code>x</code>. As a rule of thumb, <code>approximate_vocabulary</code> becomes more efficient than <code>tft.vocabulary</code> if <code>top_k</code> or the number of unique elements in <code>x</code> is smaller than 2*10^5. Moreover, this analyzer is subject to combiner packing optimization that does not apply to <code>tft.vocabulary</code>. Caching is also more efficient with the approximate implementation since the filtration happens before writing out cache. Output artifact of <code>approximate_vocabulary</code> is consistent with <code>tft.vocabulary</code> and can be used in <code>tft.apply_vocabulary</code> mapper.</p> <p>Implementation of this analyzer is based on the Misra-Gries algorithm [1]. It stores at most <code>top_k</code> elements with lower bound frequency estimates at a time. The algorithm keeps track of the approximation error <code>delta</code> such that for any item x with true frequency X:</p> <pre><code>        frequency[x] &lt;= X &lt;= frequency[x] + delta,\n        delta &lt;= (m - m') / (top_k + 1),\n</code></pre> <p>where m is the total frequency of the items in the dataset and m' is the sum of the lower bound estimates in <code>frequency</code> [2]. For datasets that are Zipfian distributed with parameter <code>a</code>, the algorithm provides an expected value of delta = m / (top_k ^ a) [3].</p> <p>[1] https://www.cs.utexas.edu/users/misra/scannedPdf.dir/FindRepeatedElements.pdf [2] http://www.cohenwang.com/edith/bigdataclass2013/lectures/lecture1.pdf [3] http://dimacs.rutgers.edu/~graham/pubs/papers/countersj.pdf</p> <p>In case <code>file_format</code> is 'text' and one of the tokens contains the '\\n' or '\\r' characters or is empty it will be discarded.</p> <p>If an integer <code>Tensor</code> is provided, its semantic type should be categorical not a continuous/numeric, since computing a vocabulary over a continuous feature is not appropriate.</p> <p>The unique values are sorted by decreasing frequency and then reverse lexicographical order (e.g. [('a', 5), ('c', 3), ('b', 3)]). This is true even if <code>x</code> is numerical dtype (e.g. [('3', 5), ('2', 3), ('111', 3)]).</p> <p>x: A categorical/discrete input <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>     with dtype tf.string or tf.int[8|16|32|64].   top_k: Limit the generated vocabulary to the first <code>top_k</code> elements. Note     that if <code>top_k</code> is larger than the number of unique elements in <code>x</code>, then     the result will be exact.   vocab_filename: The file name for the vocabulary file. If None, a file name     will be chosen based on the current scope. If not None, should be unique     within a given preprocessing function. NOTE: To make your pipelines     resilient to implementation details please set <code>vocab_filename</code> when you     are using the vocab_filename on a downstream component.   store_frequency: If True, frequency of the words is stored in the vocabulary     file. Each line in the file will be of the form 'frequency word'. NOTE: if     this is True then the computed vocabulary cannot be used with     <code>tft.apply_vocabulary</code> directly, since frequencies are added to the     beginning of each row of the vocabulary, which the mapper will not ignore.   reserved_tokens: (Optional) A list of tokens that should appear in the     vocabulary regardless of their appearance in the input. These tokens would     maintain their order, and have a reserved spot at the beginning of the     vocabulary. Note: this field has no affect on cache.   weights: (Optional) Weights <code>Tensor</code> for the vocabulary. It must have the     same shape as x.   file_format: (Optional) A str. The format of the resulting vocabulary file.     Accepted formats are: 'tfrecord_gzip', 'text'. 'tfrecord_gzip' requires     tensorflow&gt;=2.4. The default value is 'text'.   name: (Optional) A name for this operation.</p> <p>The path name for the vocabulary file containing the unique values of <code>x</code>.</p> <p>ValueError: If <code>top_k</code> is negative.     If <code>file_format</code> is not in the list of allowed formats.     If x.dtype is not string or integral.</p> Source code in <code>tensorflow_transform/experimental/analyzers.py</code> <pre><code>@common.log_api_use(common.ANALYZER_COLLECTION)\ndef approximate_vocabulary(\n    x: common_types.TensorType,\n    top_k: int,\n    *,  # Force passing optional parameters by keys.\n    vocab_filename: Optional[str] = None,\n    store_frequency: bool = False,\n    reserved_tokens: Optional[Union[Sequence[str], tf.Tensor]] = None,\n    weights: Optional[tf.Tensor] = None,\n    file_format: common_types.VocabularyFileFormatType = analyzers.DEFAULT_VOCABULARY_FILE_FORMAT,\n    name: Optional[str] = None,\n) -&gt; common_types.TemporaryAnalyzerOutputType:\n    r\"\"\"Computes the unique values of a `Tensor` over the whole dataset.\n\n    Approximately computes the unique values taken by `x`, which can be a\n    `Tensor`, `SparseTensor`, or `RaggedTensor` of any size.  The unique values\n    will be aggregated over all dimensions of `x` and all instances.\n\n    This analyzer provides an approximate alternative to `tft.vocabulary` that can\n    be more efficient with smaller `top_k` and/or smaller number of unique\n    elements in `x`. As a rule of thumb, `approximate_vocabulary` becomes more\n    efficient than `tft.vocabulary` if `top_k` or the number of unique elements in\n    `x` is smaller than 2*10^5. Moreover, this analyzer is subject to combiner\n    packing optimization that does not apply to `tft.vocabulary`. Caching is also\n    more efficient with the approximate implementation since the filtration\n    happens before writing out cache. Output artifact of `approximate_vocabulary`\n    is consistent with `tft.vocabulary` and can be used in `tft.apply_vocabulary`\n    mapper.\n\n    Implementation of this analyzer is based on the Misra-Gries algorithm [1]. It\n    stores at most `top_k` elements with lower bound frequency estimates at a\n    time. The algorithm keeps track of the approximation error `delta` such that\n    for any item x with true frequency X:\n\n                frequency[x] &lt;= X &lt;= frequency[x] + delta,\n                delta &lt;= (m - m') / (top_k + 1),\n\n    where m is the total frequency of the items in the dataset and m' is the sum\n    of the lower bound estimates in `frequency` [2]. For datasets that are Zipfian\n    distributed with parameter `a`, the algorithm provides an expected value of\n    delta = m / (top_k ^ a) [3].\n\n    [1]\n    https://www.cs.utexas.edu/users/misra/scannedPdf.dir/FindRepeatedElements.pdf\n    [2] http://www.cohenwang.com/edith/bigdataclass2013/lectures/lecture1.pdf\n    [3] http://dimacs.rutgers.edu/~graham/pubs/papers/countersj.pdf\n\n    In case `file_format` is 'text' and one of the tokens contains the '\\n' or\n    '\\r' characters or is empty it will be discarded.\n\n    If an integer `Tensor` is provided, its semantic type should be categorical\n    not a continuous/numeric, since computing a vocabulary over a continuous\n    feature is not appropriate.\n\n    The unique values are sorted by decreasing frequency and then reverse\n    lexicographical order (e.g. [('a', 5), ('c', 3), ('b', 3)]). This is true even\n    if `x` is numerical dtype (e.g. [('3', 5), ('2', 3), ('111', 3)]).\n\n    Args:\n    ----\n      x: A categorical/discrete input `Tensor`, `SparseTensor`, or `RaggedTensor`\n        with dtype tf.string or tf.int[8|16|32|64].\n      top_k: Limit the generated vocabulary to the first `top_k` elements. Note\n        that if `top_k` is larger than the number of unique elements in `x`, then\n        the result will be exact.\n      vocab_filename: The file name for the vocabulary file. If None, a file name\n        will be chosen based on the current scope. If not None, should be unique\n        within a given preprocessing function. NOTE: To make your pipelines\n        resilient to implementation details please set `vocab_filename` when you\n        are using the vocab_filename on a downstream component.\n      store_frequency: If True, frequency of the words is stored in the vocabulary\n        file. Each line in the file will be of the form 'frequency word'. NOTE: if\n        this is True then the computed vocabulary cannot be used with\n        `tft.apply_vocabulary` directly, since frequencies are added to the\n        beginning of each row of the vocabulary, which the mapper will not ignore.\n      reserved_tokens: (Optional) A list of tokens that should appear in the\n        vocabulary regardless of their appearance in the input. These tokens would\n        maintain their order, and have a reserved spot at the beginning of the\n        vocabulary. Note: this field has no affect on cache.\n      weights: (Optional) Weights `Tensor` for the vocabulary. It must have the\n        same shape as x.\n      file_format: (Optional) A str. The format of the resulting vocabulary file.\n        Accepted formats are: 'tfrecord_gzip', 'text'. 'tfrecord_gzip' requires\n        tensorflow&gt;=2.4. The default value is 'text'.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      The path name for the vocabulary file containing the unique values of `x`.\n\n    Raises:\n    ------\n      ValueError: If `top_k` is negative.\n        If `file_format` is not in the list of allowed formats.\n        If x.dtype is not string or integral.\n    \"\"\"\n    if top_k &lt;= 0:\n        raise ValueError(\"top_k must be positive, but got: %r\" % top_k)\n    elif top_k &gt; analyzers.LARGE_VOCAB_TOP_K:\n        raise ValueError(\n            \"Provided top_k threshold is too large for the \"\n            \"approximate calculation: if the expected number of \"\n            \"unique elements is larger than top_k, tft.vocabulary may \"\n            \"be more efficient. Maximum allowed top_k is {}\".format(\n                analyzers.LARGE_VOCAB_TOP_K\n            )\n        )\n\n    if file_format not in analyzers.ALLOWED_VOCABULARY_FILE_FORMATS:\n        raise ValueError(\n            '\"{}\" is not an accepted file_format. It should be one of: {}'.format(\n                file_format, analyzers.ALLOWED_VOCABULARY_FILE_FORMATS\n            )\n        )\n\n    if x.dtype != tf.string and not x.dtype.is_integer:\n        raise ValueError(\"expected tf.string or integer but got %r\" % x.dtype)\n\n    with tf.compat.v1.name_scope(name, \"approximate_vocabulary\"):\n        vocabulary_key = vocab_filename\n        vocab_filename = _get_approx_vocab_filename(vocab_filename, store_frequency)\n        analyzer_inputs = _get_approximate_vocabulary_analyzer_inputs(\n            x=x, file_format=file_format, weights=weights\n        )\n        return _approximate_vocabulary_analyzer_nodes(\n            analyzer_inputs=analyzer_inputs,\n            input_dtype=x.dtype.name,\n            vocab_filename=vocab_filename,\n            top_k=top_k,\n            store_frequency=store_frequency,\n            reserved_tokens=reserved_tokens,\n            file_format=file_format,\n            vocabulary_key=vocabulary_key,\n        )\n</code></pre>"},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental.compute_and_apply_approximate_vocabulary","title":"compute_and_apply_approximate_vocabulary","text":"<pre><code>compute_and_apply_approximate_vocabulary(\n    x: ConsistentTensorType,\n    *,\n    default_value: Any = -1,\n    top_k: Optional[int] = None,\n    num_oov_buckets: int = 0,\n    vocab_filename: Optional[str] = None,\n    weights: Optional[Tensor] = None,\n    file_format: VocabularyFileFormatType = DEFAULT_VOCABULARY_FILE_FORMAT,\n    store_frequency: Optional[bool] = False,\n    reserved_tokens: Optional[\n        Union[Sequence[str], Tensor]\n    ] = None,\n    name: Optional[str] = None,\n) -&gt; ConsistentTensorType\n</code></pre> <p>Generates an approximate vocabulary for <code>x</code> and maps it to an integer.</p> <p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of type tf.string or     tf.int[8|16|32|64].   default_value: The value to use for out-of-vocabulary values, unless     'num_oov_buckets' is greater than zero.   top_k: Limit the generated vocabulary to the first <code>top_k</code> elements. If set     to None, the full vocabulary is generated.   num_oov_buckets:  Any lookup of an out-of-vocabulary token will return a     bucket ID based on its hash if <code>num_oov_buckets</code> is greater than zero.     Otherwise it is assigned the <code>default_value</code>.   vocab_filename: The file name for the vocabulary file. If None, a name based     on the scope name in the context of this graph will be used as the file     name. If not None, should be unique within a given preprocessing function.     NOTE in order to make your pipelines resilient to implementation details     please set <code>vocab_filename</code> when you are using the vocab_filename on a     downstream component.   weights: (Optional) Weights <code>Tensor</code> for the vocabulary. It must have the     same shape as x.   file_format: (Optional) A str. The format of the resulting vocabulary file.     Accepted formats are: 'tfrecord_gzip', 'text'. 'tfrecord_gzip' requires     tensorflow&gt;=2.4. The default value is 'text'.   store_frequency: If True, frequency of the words is stored in the vocabulary     file. In the case labels are provided, the mutual information is stored in     the file instead. Each line in the file will be of the form 'frequency     word'. NOTE: if True and text_format is 'text' then spaces will be     replaced to avoid information loss.   reserved_tokens: (Optional) A list of tokens that should appear in the     vocabulary regardless of their appearance in the input. These tokens would     maintain their order, and have a reserved spot at the beginning of the     vocabulary. Note: this field has no affect on cache.   name: (Optional) A name for this operation.</p> <p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> where each string value is   mapped to an integer. Each unique string value that appears in the   vocabulary is mapped to a different integer and integers are consecutive   starting from zero. String value not in the vocabulary is assigned   <code>default_value</code>. Alternatively, if <code>num_oov_buckets</code> is specified, out of   vocabulary strings are hashed to values in   [vocab_size, vocab_size + num_oov_buckets) for an overall range of   [0, vocab_size + num_oov_buckets).</p> <p>ValueError: If <code>top_k</code> is negative.     If <code>file_format</code> is not in the list of allowed formats.     If x.dtype is not string or integral.</p> Source code in <code>tensorflow_transform/experimental/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef compute_and_apply_approximate_vocabulary(\n    x: common_types.ConsistentTensorType,\n    *,  # Force passing optional parameters by keys.\n    default_value: Any = -1,\n    top_k: Optional[int] = None,\n    num_oov_buckets: int = 0,\n    vocab_filename: Optional[str] = None,\n    weights: Optional[tf.Tensor] = None,\n    file_format: common_types.VocabularyFileFormatType = analyzers.DEFAULT_VOCABULARY_FILE_FORMAT,\n    store_frequency: Optional[bool] = False,\n    reserved_tokens: Optional[Union[Sequence[str], tf.Tensor]] = None,\n    name: Optional[str] = None,\n) -&gt; common_types.ConsistentTensorType:\n    \"\"\"Generates an approximate vocabulary for `x` and maps it to an integer.\n\n    Args:\n    ----\n      x: A `Tensor`, `SparseTensor`, or `RaggedTensor` of type tf.string or\n        tf.int[8|16|32|64].\n      default_value: The value to use for out-of-vocabulary values, unless\n        'num_oov_buckets' is greater than zero.\n      top_k: Limit the generated vocabulary to the first `top_k` elements. If set\n        to None, the full vocabulary is generated.\n      num_oov_buckets:  Any lookup of an out-of-vocabulary token will return a\n        bucket ID based on its hash if `num_oov_buckets` is greater than zero.\n        Otherwise it is assigned the `default_value`.\n      vocab_filename: The file name for the vocabulary file. If None, a name based\n        on the scope name in the context of this graph will be used as the file\n        name. If not None, should be unique within a given preprocessing function.\n        NOTE in order to make your pipelines resilient to implementation details\n        please set `vocab_filename` when you are using the vocab_filename on a\n        downstream component.\n      weights: (Optional) Weights `Tensor` for the vocabulary. It must have the\n        same shape as x.\n      file_format: (Optional) A str. The format of the resulting vocabulary file.\n        Accepted formats are: 'tfrecord_gzip', 'text'. 'tfrecord_gzip' requires\n        tensorflow&gt;=2.4. The default value is 'text'.\n      store_frequency: If True, frequency of the words is stored in the vocabulary\n        file. In the case labels are provided, the mutual information is stored in\n        the file instead. Each line in the file will be of the form 'frequency\n        word'. NOTE: if True and text_format is 'text' then spaces will be\n        replaced to avoid information loss.\n      reserved_tokens: (Optional) A list of tokens that should appear in the\n        vocabulary regardless of their appearance in the input. These tokens would\n        maintain their order, and have a reserved spot at the beginning of the\n        vocabulary. Note: this field has no affect on cache.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A `Tensor`, `SparseTensor`, or `RaggedTensor` where each string value is\n      mapped to an integer. Each unique string value that appears in the\n      vocabulary is mapped to a different integer and integers are consecutive\n      starting from zero. String value not in the vocabulary is assigned\n      `default_value`. Alternatively, if `num_oov_buckets` is specified, out of\n      vocabulary strings are hashed to values in\n      [vocab_size, vocab_size + num_oov_buckets) for an overall range of\n      [0, vocab_size + num_oov_buckets).\n\n    Raises:\n    ------\n      ValueError: If `top_k` is negative.\n        If `file_format` is not in the list of allowed formats.\n        If x.dtype is not string or integral.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"compute_and_apply_approximate_vocabulary\"):\n        if store_frequency and file_format == \"text\":\n            x = tf_utils.maybe_format_vocabulary_input(x)\n        deferred_vocab_and_filename = experimental_analyzers.approximate_vocabulary(\n            x=x,\n            top_k=top_k,\n            vocab_filename=vocab_filename,\n            weights=weights,\n            file_format=file_format,\n            store_frequency=store_frequency,\n            reserved_tokens=reserved_tokens,\n            name=name,\n        )\n        return mappers._apply_vocabulary_internal(  # pylint: disable=protected-access\n            x,\n            deferred_vocab_and_filename,\n            default_value,\n            num_oov_buckets,\n            lookup_fn=None,\n            file_format=file_format,\n            store_frequency=store_frequency,\n            name=None,\n        )\n</code></pre>"},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental.document_frequency","title":"document_frequency","text":"<pre><code>document_frequency(\n    x: SparseTensor,\n    vocab_size: int,\n    name: Optional[str] = None,\n) -&gt; SparseTensor\n</code></pre> <p>Maps the terms in x to their document frequency in the same order.</p> <p>The document frequency of a term is the number of documents that contain the term in the entire dataset. Each unique vocab term has a unique document frequency.</p> <p>Example usage:</p> <p>def preprocessing_fn(inputs): ...   integerized = tft.compute_and_apply_vocabulary(inputs['x']) ...   vocab_size = tft.get_num_buckets_for_transformed_feature(integerized) ...   return { ...      'df': tft.experimental.document_frequency(integerized, vocab_size), ...      'integerized': integerized, ...   } raw_data = [dict(x=[\"I\", \"like\", \"pie\", \"pie\", \"pie\"]), ...             dict(x=[\"yum\", \"yum\", \"pie\"])] feature_spec = dict(x=tf.io.VarLenFeature(tf.string)) raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec) with tft_beam.Context(temp_dir=tempfile.mkdtemp()): ...   transformed_dataset, transform_fn = ( ...       (raw_data, raw_data_metadata) ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn)) transformed_data, transformed_metadata = transformed_dataset transformed_data [{'df': array([1, 1, 2, 2, 2]), 'integerized': array([3, 2, 0, 0, 0])},  {'df': array([1, 1, 2]), 'integerized': array([1, 1, 0])}]</p> <pre><code>example strings: [[\"I\", \"like\", \"pie\", \"pie\", \"pie\"], [\"yum\", \"yum\", \"pie]]\nin: SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4],\n                          [1, 0], [1, 1], [1, 2]],\n                 values=[1, 2, 0, 0, 0, 3, 3, 0])\nout: SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4],\n                          [1, 0], [1, 1], [1, 2]],\n                 values=[1, 1, 2, 2, 2, 1, 1, 2])\n</code></pre> <p>x: A 2D <code>SparseTensor</code> representing int64 values (most likely that are the     result of calling <code>compute_and_apply_vocabulary</code> on a tokenized string).   vocab_size: An int - the count of vocab used to turn the string into int64s     including any OOV buckets.   name: (Optional) A name for this operation.</p> <p><code>SparseTensor</code>s with indices [index_in_batch, index_in_local_sequence] and   values document_frequency. Same shape as the input <code>x</code>.</p> <p>ValueError if <code>x</code> does not have 2 dimensions.</p> Source code in <code>tensorflow_transform/experimental/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef document_frequency(\n    x: tf.SparseTensor, vocab_size: int, name: Optional[str] = None\n) -&gt; tf.SparseTensor:\n    \"\"\"Maps the terms in x to their document frequency in the same order.\n\n    The document frequency of a term is the number of documents that contain the\n    term in the entire dataset. Each unique vocab term has a unique document\n    frequency.\n\n    Example usage:\n\n    &gt;&gt;&gt; def preprocessing_fn(inputs):\n    ...   integerized = tft.compute_and_apply_vocabulary(inputs['x'])\n    ...   vocab_size = tft.get_num_buckets_for_transformed_feature(integerized)\n    ...   return {\n    ...      'df': tft.experimental.document_frequency(integerized, vocab_size),\n    ...      'integerized': integerized,\n    ...   }\n    &gt;&gt;&gt; raw_data = [dict(x=[\"I\", \"like\", \"pie\", \"pie\", \"pie\"]),\n    ...             dict(x=[\"yum\", \"yum\", \"pie\"])]\n    &gt;&gt;&gt; feature_spec = dict(x=tf.io.VarLenFeature(tf.string))\n    &gt;&gt;&gt; raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec)\n    &gt;&gt;&gt; with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n    ...   transformed_dataset, transform_fn = (\n    ...       (raw_data, raw_data_metadata)\n    ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\n    &gt;&gt;&gt; transformed_data, transformed_metadata = transformed_dataset\n    &gt;&gt;&gt; transformed_data\n    [{'df': array([1, 1, 2, 2, 2]), 'integerized': array([3, 2, 0, 0, 0])},\n     {'df': array([1, 1, 2]), 'integerized': array([1, 1, 0])}]\n\n      ```\n      example strings: [[\"I\", \"like\", \"pie\", \"pie\", \"pie\"], [\"yum\", \"yum\", \"pie]]\n      in: SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4],\n                                [1, 0], [1, 1], [1, 2]],\n                       values=[1, 2, 0, 0, 0, 3, 3, 0])\n      out: SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4],\n                                [1, 0], [1, 1], [1, 2]],\n                       values=[1, 1, 2, 2, 2, 1, 1, 2])\n      ```\n\n    Args:\n    ----\n      x: A 2D `SparseTensor` representing int64 values (most likely that are the\n        result of calling `compute_and_apply_vocabulary` on a tokenized string).\n      vocab_size: An int - the count of vocab used to turn the string into int64s\n        including any OOV buckets.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      `SparseTensor`s with indices [index_in_batch, index_in_local_sequence] and\n      values document_frequency. Same shape as the input `x`.\n\n    Raises:\n    ------\n      ValueError if `x` does not have 2 dimensions.\n    \"\"\"\n    if x.get_shape().ndims != 2:\n        raise ValueError(\n            \"tft.tfidf requires a 2D SparseTensor input. \"\n            \"Input had {} dimensions.\".format(x.get_shape().ndims)\n        )\n\n    with tf.compat.v1.name_scope(name, \"df\"):\n        cleaned_input = tf_utils.to_vocab_range(x, vocab_size)\n\n        # all_df is a (1, vocab_size)-shaped sparse tensor storing number of docs\n        # containing each term in the entire dataset.\n        all_df = _to_global_document_frequency(cleaned_input, vocab_size)\n\n        # df_values is a batch_size * sequence_size sparse tensor storing the\n        # document frequency of each term, following the same order as the terms\n        # within each document.\n        df_values = tf.gather(tf.squeeze(all_df), cleaned_input.values)\n\n        return tf.SparseTensor(\n            indices=cleaned_input.indices,\n            values=df_values,\n            dense_shape=cleaned_input.dense_shape,\n        )\n</code></pre>"},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental.get_vocabulary_size_by_name","title":"get_vocabulary_size_by_name","text":"<pre><code>get_vocabulary_size_by_name(vocab_filename: str) -&gt; Tensor\n</code></pre> <p>Gets the size of a vocabulary created using <code>tft.vocabulary</code>.</p> <p>This is the number of keys in the output <code>vocab_filename</code> and does not include number of OOV buckets.</p> <p>vocab_filename: The name of the vocabulary file whose size is to be     retrieved.</p>"},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental.get_vocabulary_size_by_name--example","title":"Example:","text":"<p>def preprocessing_fn(inputs): ...   num_oov_buckets = 1 ...   x_int = tft.compute_and_apply_vocabulary( ...     inputs['x'], vocab_filename='my_vocab', ...     num_oov_buckets=num_oov_buckets) ...   depth = ( ...     tft.experimental.get_vocabulary_size_by_name('my_vocab') + ...     num_oov_buckets) ...   x_encoded = tf.one_hot( ...     x_int, depth=tf.cast(depth, tf.int32), dtype=tf.int64) ...   return {'x_encoded': x_encoded} raw_data = [dict(x='foo'), dict(x='foo'), dict(x='bar')] feature_spec = dict(x=tf.io.FixedLenFeature([], tf.string)) raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec) with tft_beam.Context(temp_dir=tempfile.mkdtemp()): ...   transformed_dataset, transform_fn = ( ...       (raw_data, raw_data_metadata) ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn)) transformed_data, transformed_metadata = transformed_dataset transformed_data [{'x_encoded': array([1, 0, 0])}, {'x_encoded': array([1, 0, 0])}, {'x_encoded': array([0, 1, 0])}]</p> <p>An integer tensor containing the size of the requested vocabulary.</p> <p>ValueError: if no vocabulary size found for the given <code>vocab_filename</code>.</p> Source code in <code>tensorflow_transform/experimental/annotators.py</code> <pre><code>def get_vocabulary_size_by_name(vocab_filename: str) -&gt; tf.Tensor:\n    # pyformat: disable\n    \"\"\"Gets the size of a vocabulary created using `tft.vocabulary`.\n\n    This is the number of keys in the output `vocab_filename` and does not include\n    number of OOV buckets.\n\n    Args:\n    ----\n      vocab_filename: The name of the vocabulary file whose size is to be\n        retrieved.\n\n    Example:\n    -------\n    &gt;&gt;&gt; def preprocessing_fn(inputs):\n    ...   num_oov_buckets = 1\n    ...   x_int = tft.compute_and_apply_vocabulary(\n    ...     inputs['x'], vocab_filename='my_vocab',\n    ...     num_oov_buckets=num_oov_buckets)\n    ...   depth = (\n    ...     tft.experimental.get_vocabulary_size_by_name('my_vocab') +\n    ...     num_oov_buckets)\n    ...   x_encoded = tf.one_hot(\n    ...     x_int, depth=tf.cast(depth, tf.int32), dtype=tf.int64)\n    ...   return {'x_encoded': x_encoded}\n    &gt;&gt;&gt; raw_data = [dict(x='foo'), dict(x='foo'), dict(x='bar')]\n    &gt;&gt;&gt; feature_spec = dict(x=tf.io.FixedLenFeature([], tf.string))\n    &gt;&gt;&gt; raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec)\n    &gt;&gt;&gt; with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n    ...   transformed_dataset, transform_fn = (\n    ...       (raw_data, raw_data_metadata)\n    ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\n    &gt;&gt;&gt; transformed_data, transformed_metadata = transformed_dataset\n    &gt;&gt;&gt; transformed_data\n    [{'x_encoded': array([1, 0, 0])}, {'x_encoded': array([1, 0, 0])},\n    {'x_encoded': array([0, 1, 0])}]\n\n    Returns:\n    -------\n      An integer tensor containing the size of the requested vocabulary.\n\n    Raises:\n    ------\n      ValueError: if no vocabulary size found for the given `vocab_filename`.\n\n    \"\"\"\n    # pyformat: enable\n    vocabulary_sizes_coll = ops.get_default_graph().get_collection(\n        annotators.VOCABULARY_SIZE_BY_NAME_COLLECTION\n    )\n\n    result = dict(vocabulary_sizes_coll).get(vocab_filename, None)\n\n    if result is None:\n        raise ValueError(\n            f\"Vocabulary size not found for {vocab_filename}. If this vocabulary \"\n            \"was created using `tft.vocabulary`, this should be the same as the \"\n            \"`vocab_filename` argument passed to it.\"\n        )\n\n    return result\n</code></pre>"},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental.idf","title":"idf","text":"<pre><code>idf(\n    x: SparseTensor,\n    vocab_size: int,\n    smooth: bool = True,\n    add_baseline: bool = True,\n    name: Optional[str] = None,\n) -&gt; SparseTensor\n</code></pre> <p>Maps the terms in x to their inverse document frequency in the same order.</p> <p>The inverse document frequency of a term, by default, is calculated as 1 + log ((corpus size + 1) / (count of documents containing term + 1)).</p> <p>Example usage:</p> <p>def preprocessing_fn(inputs): ...   integerized = tft.compute_and_apply_vocabulary(inputs['x']) ...   vocab_size = tft.get_num_buckets_for_transformed_feature(integerized) ...   idf_weights = tft.experimental.idf(integerized, vocab_size) ...   return { ...      'idf': idf_weights, ...      'integerized': integerized, ...   } raw_data = [dict(x=[\"I\", \"like\", \"pie\", \"pie\", \"pie\"]), ...             dict(x=[\"yum\", \"yum\", \"pie\"])] feature_spec = dict(x=tf.io.VarLenFeature(tf.string)) raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec) with tft_beam.Context(temp_dir=tempfile.mkdtemp()): ...   transformed_dataset, transform_fn = ( ...       (raw_data, raw_data_metadata) ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn)) transformed_data, transformed_metadata = transformed_dataset</p> <pre><code>example strings: [[\"I\", \"like\", \"pie\", \"pie\", \"pie\"], [\"yum\", \"yum\", \"pie]]\nin: SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4],\n                          [1, 0], [1, 1], [1, 2]],\n                 values=[1, 2, 0, 0, 0, 3, 3, 0])\nout: SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4],\n                          [1, 0], [1, 1], [1, 2]],\n                 values=[1 + log(3/2), 1 + log(3/2), 1, 1, 1,\n                         1 + log(3/2), 1 + log(3/2), 1])\n</code></pre> <p>x: A 2D <code>SparseTensor</code> representing int64 values (most likely that are the     result of calling <code>compute_and_apply_vocabulary</code> on a tokenized string).   vocab_size: An int - the count of vocab used to turn the string into int64s     including any OOV buckets.   smooth: A bool indicating if the inverse document frequency should be     smoothed. If True, which is the default, then the idf is calculated as 1 +     log((corpus size + 1) / (document frequency of term + 1)). Otherwise, the     idf is 1 + log((corpus size) / (document frequency of term)), which could     result in a division by zero error.   add_baseline: A bool indicating if the inverse document frequency should be     added with a constant baseline 1.0. If True, which is the default, then     the idf is calculated as 1 + log(). Otherwise, the idf is log() without     the constant 1 baseline. Keeping the baseline reduces the discrepancy in     idf between commonly seen terms and rare terms.   name: (Optional) A name for this operation.</p> <p><code>SparseTensor</code>s with indices [index_in_batch, index_in_local_sequence] and   values inverse document frequency. Same shape as the input <code>x</code>.</p> <p>ValueError if <code>x</code> does not have 2 dimensions.</p> Source code in <code>tensorflow_transform/experimental/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef idf(\n    x: tf.SparseTensor,\n    vocab_size: int,\n    smooth: bool = True,\n    add_baseline: bool = True,\n    name: Optional[str] = None,\n) -&gt; tf.SparseTensor:\n    \"\"\"Maps the terms in x to their inverse document frequency in the same order.\n\n    The inverse document frequency of a term, by default, is calculated as\n    1 + log ((corpus size + 1) / (count of documents containing term + 1)).\n\n    Example usage:\n\n    &gt;&gt;&gt; def preprocessing_fn(inputs):\n    ...   integerized = tft.compute_and_apply_vocabulary(inputs['x'])\n    ...   vocab_size = tft.get_num_buckets_for_transformed_feature(integerized)\n    ...   idf_weights = tft.experimental.idf(integerized, vocab_size)\n    ...   return {\n    ...      'idf': idf_weights,\n    ...      'integerized': integerized,\n    ...   }\n    &gt;&gt;&gt; raw_data = [dict(x=[\"I\", \"like\", \"pie\", \"pie\", \"pie\"]),\n    ...             dict(x=[\"yum\", \"yum\", \"pie\"])]\n    &gt;&gt;&gt; feature_spec = dict(x=tf.io.VarLenFeature(tf.string))\n    &gt;&gt;&gt; raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec)\n    &gt;&gt;&gt; with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n    ...   transformed_dataset, transform_fn = (\n    ...       (raw_data, raw_data_metadata)\n    ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\n    &gt;&gt;&gt; transformed_data, transformed_metadata = transformed_dataset\n    &gt;&gt;&gt; # 1 + log(3/2) = 1.4054651\n    &gt;&gt;&gt; transformed_data\n    [{'idf': array([1.4054651, 1.4054651, 1., 1., 1.], dtype=float32),\n      'integerized': array([3, 2, 0, 0, 0])},\n     {'idf': array([1.4054651, 1.4054651, 1.], dtype=float32),\n      'integerized': array([1, 1, 0])}]\n\n      ```\n      example strings: [[\"I\", \"like\", \"pie\", \"pie\", \"pie\"], [\"yum\", \"yum\", \"pie]]\n      in: SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4],\n                                [1, 0], [1, 1], [1, 2]],\n                       values=[1, 2, 0, 0, 0, 3, 3, 0])\n      out: SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4],\n                                [1, 0], [1, 1], [1, 2]],\n                       values=[1 + log(3/2), 1 + log(3/2), 1, 1, 1,\n                               1 + log(3/2), 1 + log(3/2), 1])\n      ```\n\n    Args:\n    ----\n      x: A 2D `SparseTensor` representing int64 values (most likely that are the\n        result of calling `compute_and_apply_vocabulary` on a tokenized string).\n      vocab_size: An int - the count of vocab used to turn the string into int64s\n        including any OOV buckets.\n      smooth: A bool indicating if the inverse document frequency should be\n        smoothed. If True, which is the default, then the idf is calculated as 1 +\n        log((corpus size + 1) / (document frequency of term + 1)). Otherwise, the\n        idf is 1 + log((corpus size) / (document frequency of term)), which could\n        result in a division by zero error.\n      add_baseline: A bool indicating if the inverse document frequency should be\n        added with a constant baseline 1.0. If True, which is the default, then\n        the idf is calculated as 1 + log(*). Otherwise, the idf is log(*) without\n        the constant 1 baseline. Keeping the baseline reduces the discrepancy in\n        idf between commonly seen terms and rare terms.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      `SparseTensor`s with indices [index_in_batch, index_in_local_sequence] and\n      values inverse document frequency. Same shape as the input `x`.\n\n    Raises:\n    ------\n      ValueError if `x` does not have 2 dimensions.\n    \"\"\"\n    if x.get_shape().ndims != 2:\n        raise ValueError(\n            \"tft.tfidf requires a 2D SparseTensor input. \"\n            \"Input had {} dimensions.\".format(x.get_shape().ndims)\n        )\n\n    with tf.compat.v1.name_scope(name, \"idf\"):\n        cleaned_input = tf_utils.to_vocab_range(x, vocab_size)\n\n        batch_sizes = tf.expand_dims(tf.shape(input=cleaned_input)[0], 0)\n\n        # all_df is a (1, vocab_size)-shaped tensor storing number of documents\n        # containing each term in the entire dataset.\n        all_df = _to_global_document_frequency(cleaned_input, vocab_size)\n\n        # all_idf is a (1, vocab_size)-shaped tensor storing the inverse document\n        # frequency of each term in the entire dataset.\n        all_idf = tf_utils.document_frequency_to_idf(\n            all_df, analyzers.sum(batch_sizes), smooth=smooth, add_baseline=add_baseline\n        )\n\n        # idf_values is a batch_size * sequence_size sparse tensor storing the\n        # inverse document frequency of each term, following the same order as the\n        # terms within each document.\n        idf_values = tf.gather(\n            tf.reshape(all_idf, [-1]), tf.cast(cleaned_input.values, dtype=tf.int64)\n        )\n\n        return tf.SparseTensor(\n            indices=cleaned_input.indices,\n            values=idf_values,\n            dense_shape=cleaned_input.dense_shape,\n        )\n</code></pre>"},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental.idf--1-log32-14054651","title":"1 + log(3/2) = 1.4054651","text":"<p>transformed_data [{'idf': array([1.4054651, 1.4054651, 1., 1., 1.], dtype=float32),   'integerized': array([3, 2, 0, 0, 0])},  {'idf': array([1.4054651, 1.4054651, 1.], dtype=float32),   'integerized': array([1, 1, 0])}]</p>"},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental.ptransform_analyzer","title":"ptransform_analyzer","text":"<pre><code>ptransform_analyzer(\n    inputs: Collection[Tensor],\n    ptransform: Union[\n        _BeamPTransform, CacheablePTransformAnalyzer\n    ],\n    output_dtypes: Collection[DType],\n    output_shapes: Collection[List[int]],\n    output_asset_default_values: Optional[\n        Collection[Optional[bytes]]\n    ] = None,\n    name: Optional[str] = None,\n)\n</code></pre> <p>Applies a user-provided PTransform over the whole dataset.</p> <p>WARNING: This is experimental.</p> <p>Note that in order to have asset files copied correctly, any outputs that represent asset filenames must be added to the <code>tf.GraphKeys.ASSET_FILEPATHS</code> collection by the caller if using Transform's APIs in compat v1 mode.</p>"},{"location":"api_docs/python/tft-experimental/#tensorflow_transform.experimental.ptransform_analyzer--example","title":"Example:","text":"<p>class MeanPerKey(beam.PTransform): ...   def expand(self, pcoll: beam.PCollection[Tuple[np.ndarray, np.ndarray]]) -&gt; Tuple[beam.PCollection[np.ndarray], beam.PCollection[np.ndarray]]: ...     def extract_output(key_value_pairs): ...       keys, values = zip(key_value_pairs) ...       return [beam.TaggedOutput('keys', keys), ...               beam.TaggedOutput('values', values)] ...     return tuple( ...         pcoll ...         | 'ZipAndFlatten' &gt;&gt; beam.FlatMap(lambda batches: list(zip(batches))) ...         | 'MeanPerKey' &gt;&gt; beam.CombinePerKey(beam.combiners.MeanCombineFn()) ...         | 'ToList' &gt;&gt; beam.combiners.ToList() ...         | 'Extract' &gt;&gt; beam.FlatMap(extract_output).with_outputs( ...             'keys', 'values')) def preprocessing_fn(inputs): ...   outputs = tft.experimental.ptransform_analyzer( ...       inputs=[inputs['s'], inputs['x']], ...       ptransform=MeanPerKey(), ...       output_dtypes=[tf.string, tf.float32], ...       output_shapes=[[2], [2]]) ...   (keys, means) = outputs ...   mean_a = tf.reshape(tf.gather(means, tf.where(keys == 'a')), []) ...   return { 'x/mean_a': inputs['x'] / mean_a } raw_data = [dict(x=1, s='a'), dict(x=8, s='b'), dict(x=3, s='a')] feature_spec = dict( ...     x=tf.io.FixedLenFeature([], tf.float32), ...     s=tf.io.FixedLenFeature([], tf.string)) raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec) with tft_beam.Context(temp_dir=tempfile.mkdtemp()): ...   transformed_dataset, transform_fn = ( ...       (raw_data, raw_data_metadata) ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn)) transformed_data, transformed_metadata = transformed_dataset transformed_data [{'x/mean_a': 0.5}, {'x/mean_a': 4.0}, {'x/mean_a': 1.5}]</p> <p>inputs: An ordered collection of input <code>Tensor</code>s.   ptransform: A Beam PTransform that accepts a Beam PCollection where each     element is a tuple of <code>ndarray</code>s.  Each element in the tuple contains a     batch of values for the corresponding input tensor of the analyzer and     maintain their shapes and dtypes.     It returns a <code>PCollection</code>, or a tuple of <code>PCollections</code>, each containing     a single element which is an <code>ndarray</code> or a list of primitive types. The     contents of these output <code>PCollection</code>s must be consistent with the given     values of <code>output_dtypes</code> and <code>output_shapes</code>.     It may inherit from <code>tft_beam.experimental.PTransformAnalyzer</code> if access     to a temp base directory is needed.     Alternatively, it could be an instance of     <code>tft.experimental.CacheablePTransformAnalyzer</code> in order to enable cache     for this analyzer, when analyzer cache is enabled for this pipeline.   output_dtypes: An ordered collection of TensorFlow dtypes of the output of     the analyzer.   output_shapes: An ordered collection of shapes of the output of the     analyzer. Must have the same length as output_dtypes.   output_asset_default_values: (Optional) An ordered collection of optional     <code>bytes</code> aligned with output_dtypes/output_shapes. Every item in this     collection which is not <code>None</code> indicates that the output is a TF asset     path, and its value would be used as the default value of this asset file     prior to analysis.   name: (Optional) Similar to a TF op name.  Used to define a unique scope for     this analyzer, which can be used for debugging info.</p> <p>A list of output <code>Tensor</code>s.  These will have <code>dtype</code> and <code>shape</code> as     specified by <code>output_dtypes</code> and <code>output_shapes</code>.</p> <p>ValueError: If output_dtypes and output_shapes have different lengths.</p> Source code in <code>tensorflow_transform/experimental/analyzers.py</code> <pre><code>@common.log_api_use(common.ANALYZER_COLLECTION)\ndef ptransform_analyzer(\n    inputs: Collection[tf.Tensor],\n    ptransform: Union[_BeamPTransform, CacheablePTransformAnalyzer],\n    output_dtypes: Collection[tf.dtypes.DType],\n    output_shapes: Collection[List[int]],\n    output_asset_default_values: Optional[Collection[Optional[bytes]]] = None,\n    name: Optional[str] = None,\n):\n    # pylint: disable=line-too-long\n    \"\"\"Applies a user-provided PTransform over the whole dataset.\n\n    WARNING: This is experimental.\n\n    Note that in order to have asset files copied correctly, any outputs that\n    represent asset filenames must be added to the `tf.GraphKeys.ASSET_FILEPATHS`\n    collection by the caller if using Transform's APIs in compat v1 mode.\n\n    Example:\n    -------\n    &gt;&gt;&gt; class MeanPerKey(beam.PTransform):\n    ...   def expand(self, pcoll: beam.PCollection[Tuple[np.ndarray, np.ndarray]]) -&gt; Tuple[beam.PCollection[np.ndarray], beam.PCollection[np.ndarray]]:\n    ...     def extract_output(key_value_pairs):\n    ...       keys, values = zip(*key_value_pairs)\n    ...       return [beam.TaggedOutput('keys', keys),\n    ...               beam.TaggedOutput('values', values)]\n    ...     return tuple(\n    ...         pcoll\n    ...         | 'ZipAndFlatten' &gt;&gt; beam.FlatMap(lambda batches: list(zip(*batches)))\n    ...         | 'MeanPerKey' &gt;&gt; beam.CombinePerKey(beam.combiners.MeanCombineFn())\n    ...         | 'ToList' &gt;&gt; beam.combiners.ToList()\n    ...         | 'Extract' &gt;&gt; beam.FlatMap(extract_output).with_outputs(\n    ...             'keys', 'values'))\n    &gt;&gt;&gt; def preprocessing_fn(inputs):\n    ...   outputs = tft.experimental.ptransform_analyzer(\n    ...       inputs=[inputs['s'], inputs['x']],\n    ...       ptransform=MeanPerKey(),\n    ...       output_dtypes=[tf.string, tf.float32],\n    ...       output_shapes=[[2], [2]])\n    ...   (keys, means) = outputs\n    ...   mean_a = tf.reshape(tf.gather(means, tf.where(keys == 'a')), [])\n    ...   return { 'x/mean_a': inputs['x'] / mean_a }\n    &gt;&gt;&gt; raw_data = [dict(x=1, s='a'), dict(x=8, s='b'), dict(x=3, s='a')]\n    &gt;&gt;&gt; feature_spec = dict(\n    ...     x=tf.io.FixedLenFeature([], tf.float32),\n    ...     s=tf.io.FixedLenFeature([], tf.string))\n    &gt;&gt;&gt; raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec)\n    &gt;&gt;&gt; with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n    ...   transformed_dataset, transform_fn = (\n    ...       (raw_data, raw_data_metadata)\n    ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\n    &gt;&gt;&gt; transformed_data, transformed_metadata = transformed_dataset\n    &gt;&gt;&gt; transformed_data\n    [{'x/mean_a': 0.5}, {'x/mean_a': 4.0}, {'x/mean_a': 1.5}]\n\n    Args:\n    ----\n      inputs: An ordered collection of input `Tensor`s.\n      ptransform: A Beam PTransform that accepts a Beam PCollection where each\n        element is a tuple of `ndarray`s.  Each element in the tuple contains a\n        batch of values for the corresponding input tensor of the analyzer and\n        maintain their shapes and dtypes.\n        It returns a `PCollection`, or a tuple of `PCollections`, each containing\n        a single element which is an `ndarray` or a list of primitive types. The\n        contents of these output `PCollection`s must be consistent with the given\n        values of `output_dtypes` and `output_shapes`.\n        It may inherit from `tft_beam.experimental.PTransformAnalyzer` if access\n        to a temp base directory is needed.\n        Alternatively, it could be an instance of\n        `tft.experimental.CacheablePTransformAnalyzer` in order to enable cache\n        for this analyzer, when analyzer cache is enabled for this pipeline.\n      output_dtypes: An ordered collection of TensorFlow dtypes of the output of\n        the analyzer.\n      output_shapes: An ordered collection of shapes of the output of the\n        analyzer. Must have the same length as output_dtypes.\n      output_asset_default_values: (Optional) An ordered collection of optional\n        `bytes` aligned with output_dtypes/output_shapes. Every item in this\n        collection which is not `None` indicates that the output is a TF asset\n        path, and its value would be used as the default value of this asset file\n        prior to analysis.\n      name: (Optional) Similar to a TF op name.  Used to define a unique scope for\n        this analyzer, which can be used for debugging info.\n\n    Returns:\n    -------\n      A list of output `Tensor`s.  These will have `dtype` and `shape` as\n        specified by `output_dtypes` and `output_shapes`.\n\n    Raises:\n    ------\n      ValueError: If output_dtypes and output_shapes have different lengths.\n    \"\"\"\n    # pylint: enable=line-too-long\n    if len(output_dtypes) != len(output_shapes):\n        raise ValueError(\n            \"output_dtypes ({}) and output_shapes ({}) had different\" \" lengths\".format(\n                output_dtypes, output_shapes\n            )\n        )\n    if output_asset_default_values is not None:\n        if len(output_asset_default_values) != len(output_dtypes):\n            raise ValueError(\n                \"output_dtypes ({}) and output_asset_default_values ({}) had \"\n                \"different lengths\".format(output_dtypes, output_asset_default_values)\n            )\n        output_asset_default_values = [\n            analyzer_nodes.TemporaryAssetInfo(value, \"text\")\n            for value in output_asset_default_values\n        ]\n    else:\n        output_asset_default_values = [None] * len(output_dtypes)\n    with tf.compat.v1.name_scope(name, \"ptransform\"):\n        output_tensor_infos = [\n            analyzer_nodes.TensorInfo(dtype, shape, default_asset_content)\n            for dtype, shape, default_asset_content in zip(\n                output_dtypes, output_shapes, output_asset_default_values\n            )\n        ]\n        return _apply_analyzer(\n            ptransform, *inputs, output_tensor_info_list=output_tensor_infos\n        )\n</code></pre>"},{"location":"api_docs/python/tft/","title":"TensorFlow Transform <code>tft</code> Module","text":""},{"location":"api_docs/python/tft/#tensorflow_transform","title":"tensorflow_transform","text":"<p>Init module for TF.Transform.</p>"},{"location":"api_docs/python/tft/#tensorflow_transform-attributes","title":"Attributes","text":""},{"location":"api_docs/python/tft/#tensorflow_transform.Callable","title":"Callable  <code>module-attribute</code>","text":"<pre><code>Callable = _CallableType(Callable, 2)\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.Iterable","title":"Iterable  <code>module-attribute</code>","text":"<pre><code>Iterable = _alias(Iterable, 1)\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.List","title":"List  <code>module-attribute</code>","text":"<pre><code>List = _alias(list, 1, inst=False, name='List')\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.Mapping","title":"Mapping  <code>module-attribute</code>","text":"<pre><code>Mapping = _alias(Mapping, 2)\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.Tuple","title":"Tuple  <code>module-attribute</code>","text":"<pre><code>Tuple = _TupleType(tuple, -1, inst=False, name='Tuple')\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.__version__","title":"__version__  <code>module-attribute</code>","text":"<pre><code>__version__ = '1.18.0.dev'\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform-classes","title":"Classes","text":""},{"location":"api_docs/python/tft/#tensorflow_transform.DatasetMetadata","title":"DatasetMetadata","text":"<pre><code>DatasetMetadata(schema: Schema)\n</code></pre> <p>Metadata about a dataset used for the \"instance dict\" format.</p> <p>Caution: The \"instance dict\" format used with <code>DatasetMetadata</code> is much less efficient than TFXIO. For any serious workloads you should use TFXIO with a <code>tfxio.TensorAdapterConfig</code> instance as the metadata. Refer to Get started with TF-Transform for more details.</p> <p>This is an in-memory representation that may be serialized and deserialized to and from a variety of disk representations.</p> Source code in <code>tensorflow_transform/tf_metadata/dataset_metadata.py</code> <pre><code>def __init__(self, schema: schema_pb2.Schema):\n    self._schema = schema\n    self._output_record_batches = True\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.DatasetMetadata-attributes","title":"Attributes","text":""},{"location":"api_docs/python/tft/#tensorflow_transform.DatasetMetadata.schema","title":"schema  <code>property</code>","text":"<pre><code>schema: Schema\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.DatasetMetadata-functions","title":"Functions","text":""},{"location":"api_docs/python/tft/#tensorflow_transform.DatasetMetadata.from_feature_spec","title":"from_feature_spec  <code>classmethod</code>","text":"<pre><code>from_feature_spec(\n    feature_spec: Mapping[str, FeatureSpecType],\n    domains: Optional[Mapping[str, DomainType]] = None,\n) -&gt; _DatasetMetadataType\n</code></pre> <p>Creates a DatasetMetadata from a TF feature spec dict.</p> Source code in <code>tensorflow_transform/tf_metadata/dataset_metadata.py</code> <pre><code>@classmethod\ndef from_feature_spec(\n    cls: Type[_DatasetMetadataType],\n    feature_spec: Mapping[str, common_types.FeatureSpecType],\n    domains: Optional[Mapping[str, common_types.DomainType]] = None,\n) -&gt; _DatasetMetadataType:\n    \"\"\"Creates a DatasetMetadata from a TF feature spec dict.\"\"\"\n    return cls(schema_utils.schema_from_feature_spec(feature_spec, domains))\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput","title":"TFTransformOutput","text":"<pre><code>TFTransformOutput(transform_output_dir: str)\n</code></pre> <p>A wrapper around the output of the tf.Transform.</p> <p>Init method for TFTransformOutput.</p> <p>transform_output_dir: The directory containig tf.Transform output.</p> Source code in <code>tensorflow_transform/output_wrapper.py</code> <pre><code>def __init__(self, transform_output_dir: str):\n    \"\"\"Init method for TFTransformOutput.\n\n    Args:\n    ----\n      transform_output_dir: The directory containig tf.Transform output.\n    \"\"\"\n    self._transform_output_dir = transform_output_dir\n\n    # Lazily constructed properties.\n    self._transformed_metadata = None\n    self._raw_metadata = None\n    self._transform_features_layer = None\n    self._exported_as_v1_value = None\n    self._transformed_domains = None\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput-attributes","title":"Attributes","text":""},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.ASSET_MAP","title":"ASSET_MAP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ASSET_MAP = 'asset_map'\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.POST_TRANSFORM_FEATURE_STATS_PATH","title":"POST_TRANSFORM_FEATURE_STATS_PATH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>POST_TRANSFORM_FEATURE_STATS_PATH = join(\n    \"post_transform_feature_stats\", _FEATURE_STATS_PB\n)\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.PRE_TRANSFORM_FEATURE_STATS_PATH","title":"PRE_TRANSFORM_FEATURE_STATS_PATH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PRE_TRANSFORM_FEATURE_STATS_PATH = join(\n    \"pre_transform_feature_stats\", _FEATURE_STATS_PB\n)\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.RAW_METADATA_DIR","title":"RAW_METADATA_DIR  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RAW_METADATA_DIR = 'metadata'\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.TRANSFORMED_METADATA_DIR","title":"TRANSFORMED_METADATA_DIR  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TRANSFORMED_METADATA_DIR = 'transformed_metadata'\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.TRANSFORM_FN_DIR","title":"TRANSFORM_FN_DIR  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TRANSFORM_FN_DIR = 'transform_fn'\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.post_transform_statistics_path","title":"post_transform_statistics_path  <code>property</code>","text":"<pre><code>post_transform_statistics_path: str\n</code></pre> <p>Returns the path to the post-transform datum statistics.</p> <p>Note: post_transform_statistics is not guaranteed to exist in the output of tf.transform and hence using this could fail, if post_transform statistics is not present in TFTransformOutput.</p>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.pre_transform_statistics_path","title":"pre_transform_statistics_path  <code>property</code>","text":"<pre><code>pre_transform_statistics_path: str\n</code></pre> <p>Returns the path to the pre-transform datum statistics.</p> <p>Note: pre_transform_statistics is not guaranteed to exist in the output of tf.transform and hence using this could fail, if pre_transform statistics is not present in TFTransformOutput.</p>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.raw_metadata","title":"raw_metadata  <code>property</code>","text":"<pre><code>raw_metadata: DatasetMetadata\n</code></pre> <p>A DatasetMetadata.</p> <p>Note: raw_metadata is not guaranteed to exist in the output of tf.transform and hence using this could fail, if raw_metadata is not present in TFTransformOutput.</p>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.raw_metadata--returns","title":"Returns","text":"<p>A DatasetMetadata</p>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.transform_savedmodel_dir","title":"transform_savedmodel_dir  <code>property</code>","text":"<pre><code>transform_savedmodel_dir: str\n</code></pre> <p>A python str.</p>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.transformed_metadata","title":"transformed_metadata  <code>property</code>","text":"<pre><code>transformed_metadata: DatasetMetadata\n</code></pre> <p>A DatasetMetadata.</p>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput-functions","title":"Functions","text":""},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.load_transform_graph","title":"load_transform_graph","text":"<pre><code>load_transform_graph()\n</code></pre> <p>Load the transform graph without replacing any placeholders.</p> <p>This is necessary to ensure that variables in the transform graph are included in the training checkpoint when using tf.Estimator.  This should be called in the training input_fn.</p> Source code in <code>tensorflow_transform/output_wrapper.py</code> <pre><code>def load_transform_graph(self):\n    \"\"\"Load the transform graph without replacing any placeholders.\n\n    This is necessary to ensure that variables in the transform graph are\n    included in the training checkpoint when using tf.Estimator.  This should\n    be called in the training input_fn.\n    \"\"\"\n    if self._exported_as_v1 is None:\n        self._exported_as_v1 = saved_transform_io.exported_as_v1(\n            self.transform_savedmodel_dir\n        )\n\n    if self._exported_as_v1:\n        saved_transform_io.partially_apply_saved_transform_internal(\n            self.transform_savedmodel_dir, {}\n        )\n    else:\n        # Note: This should use the same mechanism as `transform_raw_features` to\n        # load the SavedModel into the current graph context.\n        _ = self.transform_features_layer()({})\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.num_buckets_for_transformed_feature","title":"num_buckets_for_transformed_feature","text":"<pre><code>num_buckets_for_transformed_feature(name: str) -&gt; int\n</code></pre> <p>Returns the number of buckets for an integerized transformed feature.</p> Source code in <code>tensorflow_transform/output_wrapper.py</code> <pre><code>def num_buckets_for_transformed_feature(self, name: str) -&gt; int:\n    \"\"\"Returns the number of buckets for an integerized transformed feature.\"\"\"\n    # Do checks that this tensor can be wrapped in\n    # sparse_column_with_integerized_feature\n    try:\n        domain = self.transformed_domains()[name]\n    except KeyError:\n        raise ValueError(\"Column {} did not have a domain provided.\".format(name))\n    if not isinstance(domain, schema_pb2.IntDomain):\n        raise ValueError(\n            \"Column {} has domain {}, expected an IntDomain\".format(name, domain)\n        )\n    if domain.min != 0:\n        raise ValueError(\n            \"Column {} has min value {}, should be 0\".format(name, domain.min)\n        )\n    return domain.max + 1\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.raw_domains","title":"raw_domains","text":"<pre><code>raw_domains() -&gt; Dict[str, DomainType]\n</code></pre> <p>Returns domains for the raw features.</p>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.raw_domains--returns","title":"Returns","text":"<p>A dict from feature names to one of schema_pb2.IntDomain,   schema_pb2.StringDomain or schema_pb2.FloatDomain.</p> Source code in <code>tensorflow_transform/output_wrapper.py</code> <pre><code>def raw_domains(self) -&gt; Dict[str, common_types.DomainType]:\n    \"\"\"Returns domains for the raw features.\n\n    Returns\n    -------\n      A dict from feature names to one of schema_pb2.IntDomain,\n      schema_pb2.StringDomain or schema_pb2.FloatDomain.\n    \"\"\"\n    return schema_utils.schema_as_feature_spec(self.raw_metadata.schema).domains\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.raw_feature_spec","title":"raw_feature_spec","text":"<pre><code>raw_feature_spec() -&gt; Dict[str, FeatureSpecType]\n</code></pre> <p>Returns a feature_spec for the raw features.</p>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.raw_feature_spec--returns","title":"Returns","text":"<p>A dict from feature names to FixedLenFeature/SparseFeature/VarLenFeature.</p> Source code in <code>tensorflow_transform/output_wrapper.py</code> <pre><code>def raw_feature_spec(self) -&gt; Dict[str, common_types.FeatureSpecType]:\n    \"\"\"Returns a feature_spec for the raw features.\n\n    Returns\n    -------\n      A dict from feature names to FixedLenFeature/SparseFeature/VarLenFeature.\n    \"\"\"\n    return schema_utils.schema_as_feature_spec(\n        self.raw_metadata.schema\n    ).feature_spec\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.transform_features_layer","title":"transform_features_layer","text":"<pre><code>transform_features_layer() -&gt; Model\n</code></pre> <p>Creates a <code>TransformFeaturesLayer</code> from this transform output.</p> <p>If a <code>TransformFeaturesLayer</code> has already been created for self, the same one will be returned.</p>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.transform_features_layer--returns","title":"Returns","text":"<p>A <code>TransformFeaturesLayer</code> instance.</p> Source code in <code>tensorflow_transform/output_wrapper.py</code> <pre><code>def transform_features_layer(self) -&gt; tf_keras.Model:\n    \"\"\"Creates a `TransformFeaturesLayer` from this transform output.\n\n    If a `TransformFeaturesLayer` has already been created for self, the same\n    one will be returned.\n\n    Returns\n    -------\n      A `TransformFeaturesLayer` instance.\n    \"\"\"\n    if self._transform_features_layer is None:\n        self._transform_features_layer = TransformFeaturesLayer(\n            self, exported_as_v1=self._exported_as_v1\n        )\n    return self._transform_features_layer\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.transform_raw_features","title":"transform_raw_features","text":"<pre><code>transform_raw_features(\n    raw_features: Mapping[str, TensorType],\n    drop_unused_features: bool = True,\n) -&gt; Dict[str, TensorType]\n</code></pre> <p>Takes a dict of tensors representing raw features and transforms them.</p> <p>Takes a dictionary of <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>s that represent the raw features, and applies the transformation defined by tf.Transform.</p> <p>If False it returns all transformed features defined by tf.Transform. To only return features transformed from the given 'raw_features', set <code>drop_unused_features</code> to True.</p> <p>Note: If eager execution is enabled and this API is invoked inside a tf.function or an API that uses tf.function such as dataset.map, please use <code>transform_features_layer</code> instead. It separates out loading of the transform graph and hence resources will not be initialized on each invocation. This can have significant performance improvement if the transform graph was exported as a TF1 SavedModel and guarantees correctness if it was exported as a TF2 SavedModel.</p> <p>raw_features: A dict whose keys are feature names and values are   <code>Tensor</code>s, <code>SparseTensor</code>s, or <code>RaggedTensor</code>s.   drop_unused_features: If True, the result will be filtered. Only the     features that are transformed from 'raw_features' will be included in     the returned result. If a feature is transformed from multiple raw     features (e.g, feature cross), it will only be included if all its base     raw features are present in <code>raw_features</code>.</p> <p>A dict whose keys are feature names and values are <code>Tensor</code>s,   <code>SparseTensor</code>s, or <code>RaggedTensor</code>s representing transformed features.</p> Source code in <code>tensorflow_transform/output_wrapper.py</code> <pre><code>def transform_raw_features(\n    self,\n    raw_features: Mapping[str, common_types.TensorType],\n    drop_unused_features: bool = True,  # LEGACY_VALUE=False\n) -&gt; Dict[str, common_types.TensorType]:\n    \"\"\"Takes a dict of tensors representing raw features and transforms them.\n\n    Takes a dictionary of `Tensor`, `SparseTensor`, or `RaggedTensor`s that\n    represent the raw features, and applies the transformation defined by\n    tf.Transform.\n\n    If False it returns all transformed features defined by tf.Transform. To\n    only return features transformed from the given 'raw_features', set\n    `drop_unused_features` to True.\n\n    Note: If eager execution is enabled and this API is invoked inside a\n    tf.function or an API that uses tf.function such as dataset.map, please use\n    `transform_features_layer` instead. It separates out loading of the\n    transform graph and hence resources will not be initialized on each\n    invocation. This can have significant performance improvement if the\n    transform graph was exported as a TF1 SavedModel and guarantees correctness\n    if it was exported as a TF2 SavedModel.\n\n    Args:\n    ----\n      raw_features: A dict whose keys are feature names and values are\n      `Tensor`s, `SparseTensor`s, or `RaggedTensor`s.\n      drop_unused_features: If True, the result will be filtered. Only the\n        features that are transformed from 'raw_features' will be included in\n        the returned result. If a feature is transformed from multiple raw\n        features (e.g, feature cross), it will only be included if all its base\n        raw features are present in `raw_features`.\n\n    Returns:\n    -------\n      A dict whose keys are feature names and values are `Tensor`s,\n      `SparseTensor`s, or `RaggedTensor`s representing transformed features.\n    \"\"\"\n    if self._exported_as_v1:\n        transformed_features = self._transform_raw_features_compat_v1(\n            raw_features, drop_unused_features\n        )\n    else:\n        tft_layer = self.transform_features_layer()\n        if not drop_unused_features:\n            tf.compat.v1.logging.warning(\n                \"Unused features are always dropped in the TF 2.x \"\n                \"implementation. Ignoring value of drop_unused_features.\"\n            )\n\n        transformed_features = tft_layer(raw_features)\n    return _TransformedFeaturesDict(transformed_features)\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.transformed_domains","title":"transformed_domains","text":"<pre><code>transformed_domains() -&gt; Dict[str, DomainType]\n</code></pre> <p>Returns domains for the transformed features.</p>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.transformed_domains--returns","title":"Returns","text":"<p>A dict from feature names to one of schema_pb2.IntDomain,   schema_pb2.StringDomain or schema_pb2.FloatDomain.</p> Source code in <code>tensorflow_transform/output_wrapper.py</code> <pre><code>def transformed_domains(self) -&gt; Dict[str, common_types.DomainType]:\n    \"\"\"Returns domains for the transformed features.\n\n    Returns\n    -------\n      A dict from feature names to one of schema_pb2.IntDomain,\n      schema_pb2.StringDomain or schema_pb2.FloatDomain.\n    \"\"\"\n    if self._transformed_domains is None:\n        self._transformed_domains = schema_utils.schema_as_feature_spec(\n            self.transformed_metadata.schema\n        ).domains\n    return self._transformed_domains\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.transformed_feature_spec","title":"transformed_feature_spec","text":"<pre><code>transformed_feature_spec() -&gt; Dict[str, FeatureSpecType]\n</code></pre> <p>Returns a feature_spec for the transformed features.</p>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.transformed_feature_spec--returns","title":"Returns","text":"<p>A dict from feature names to FixedLenFeature/SparseFeature/VarLenFeature.</p> Source code in <code>tensorflow_transform/output_wrapper.py</code> <pre><code>def transformed_feature_spec(self) -&gt; Dict[str, common_types.FeatureSpecType]:\n    \"\"\"Returns a feature_spec for the transformed features.\n\n    Returns\n    -------\n      A dict from feature names to FixedLenFeature/SparseFeature/VarLenFeature.\n    \"\"\"\n    return schema_utils.schema_as_feature_spec(\n        self.transformed_metadata.schema\n    ).feature_spec\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.vocabulary_by_name","title":"vocabulary_by_name","text":"<pre><code>vocabulary_by_name(vocab_filename: str) -&gt; List[bytes]\n</code></pre> <p>Like vocabulary_file_by_name but returns a list.</p> Source code in <code>tensorflow_transform/output_wrapper.py</code> <pre><code>def vocabulary_by_name(self, vocab_filename: str) -&gt; List[bytes]:\n    \"\"\"Like vocabulary_file_by_name but returns a list.\"\"\"\n    vocab_path = self.vocabulary_file_by_name(vocab_filename)\n    if not vocab_path:\n        raise ValueError(\n            \"Could not read vocabulary: {}, does not exist\".format(vocab_filename)\n        )\n    elif vocab_path.endswith(\"tfrecord.gz\"):\n        dataset = tf.data.TFRecordDataset(vocab_path, compression_type=\"GZIP\")\n        vocab_tensor = dataset.batch(tf.int32.max).reduce(\n            tf.constant([], dtype=tf.string),\n            lambda state, elem: tf.concat([state, elem], axis=-1),\n        )\n        # Using as_numpy_iterator only works when executing eagerly.\n        return _get_tensor_value(vocab_tensor).tolist()\n    else:\n        with tf.io.gfile.GFile(vocab_path, \"rb\") as f:\n            return [l.rstrip(os.linesep.encode(\"utf-8\")) for l in f]\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.vocabulary_file_by_name","title":"vocabulary_file_by_name","text":"<pre><code>vocabulary_file_by_name(\n    vocab_filename: str,\n) -&gt; Optional[str]\n</code></pre> <p>Returns the vocabulary file path created in the preprocessing function.</p> <p><code>vocab_filename</code> must either be (i) the name used as the vocab_filename argument to tft.compute_and_apply_vocabulary / tft.vocabulary or (ii) the key used in tft.annotate_asset.</p> <p>When a mapping has been specified by calls to tft.annotate_asset, it will be checked first for the provided filename. If present, this filename will be used directly to construct a path.</p> <p>If the mapping does not exist or <code>vocab_filename</code> is not present within it, we will default to sanitizing <code>vocab_filename</code> and searching for files matching it within the assets directory.</p> <p>In either case, if the constructed path does not point to an existing file within the assets subdirectory, we will return a None.</p> <p>vocab_filename: The vocabulary name to lookup.</p> Source code in <code>tensorflow_transform/output_wrapper.py</code> <pre><code>def vocabulary_file_by_name(self, vocab_filename: str) -&gt; Optional[str]:\n    \"\"\"Returns the vocabulary file path created in the preprocessing function.\n\n    `vocab_filename` must either be (i) the name used as the vocab_filename\n    argument to tft.compute_and_apply_vocabulary / tft.vocabulary or (ii) the\n    key used in tft.annotate_asset.\n\n    When a mapping has been specified by calls to tft.annotate_asset, it will be\n    checked first for the provided filename. If present, this filename will be\n    used directly to construct a path.\n\n    If the mapping does not exist or `vocab_filename` is not present within it,\n    we will default to sanitizing `vocab_filename` and searching for files\n    matching it within the assets directory.\n\n    In either case, if the constructed path does not point to an existing file\n    within the assets subdirectory, we will return a None.\n\n    Args:\n    ----\n      vocab_filename: The vocabulary name to lookup.\n    \"\"\"\n    mapping_path = os.path.join(self._transformed_metadata_dir, self.ASSET_MAP)\n\n    mapping = {}\n    if tf.io.gfile.exists(mapping_path):\n        with tf.io.gfile.GFile(mapping_path) as f:\n            mapping = json.loads(f.read())\n            if vocab_filename in mapping:\n                vocab_path = os.path.join(\n                    self.transform_savedmodel_dir,\n                    tf.saved_model.ASSETS_DIRECTORY,\n                    mapping[vocab_filename],\n                )\n                if tf.io.gfile.exists(vocab_path):\n                    return vocab_path\n\n    prefix = os.path.join(\n        self.transform_savedmodel_dir,\n        tf.saved_model.ASSETS_DIRECTORY,\n        sanitized_vocab_filename(filename=vocab_filename),\n    )\n    files = tf.io.gfile.glob(prefix) + tf.io.gfile.glob(\n        \"{}.tfrecord.gz\".format(prefix)\n    )\n    if not files:\n        return None\n    if len(files) != 1:\n        raise ValueError(\"Found too many vocabulary files: {}\".format(files))\n    return files[0]\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.TFTransformOutput.vocabulary_size_by_name","title":"vocabulary_size_by_name","text":"<pre><code>vocabulary_size_by_name(vocab_filename: str) -&gt; int\n</code></pre> <p>Like vocabulary_file_by_name, but returns the size of vocabulary.</p> Source code in <code>tensorflow_transform/output_wrapper.py</code> <pre><code>def vocabulary_size_by_name(self, vocab_filename: str) -&gt; int:\n    \"\"\"Like vocabulary_file_by_name, but returns the size of vocabulary.\"\"\"\n    vocab_size_from_annotations = self._vocabulary_size_from_annotations(\n        vocab_filename\n    )\n    if vocab_size_from_annotations is not None:\n        return vocab_size_from_annotations\n\n    vocab_path = self.vocabulary_file_by_name(vocab_filename)\n    if not vocab_path:\n        raise ValueError(\n            \"Could not compute vocabulary size for {}, does not exist\".format(\n                vocab_filename\n            )\n        )\n    elif vocab_path.endswith(\"tfrecord.gz\"):\n        dataset = tf.data.TFRecordDataset(vocab_path, compression_type=\"GZIP\")\n\n        def reduce_fn(accum, elem):\n            return tf.size(elem, out_type=tf.int64, name=\"vocabulary_size\") + accum\n\n        return _get_tensor_value(\n            dataset.batch(tf.int32.max).reduce(tf.constant(0, tf.int64), reduce_fn)\n        )\n    else:\n        with tf.io.gfile.GFile(vocab_path, \"rb\") as f:\n            return sum(1 for _ in f)\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.TransformFeaturesLayer","title":"TransformFeaturesLayer","text":"<pre><code>TransformFeaturesLayer(\n    tft_output: TFTransformOutput,\n    exported_as_v1: Optional[bool] = None,\n)\n</code></pre> <p>               Bases: <code>Model</code></p> <p>A Keras layer for applying a tf.Transform output to input layers.</p> Source code in <code>tensorflow_transform/output_wrapper.py</code> <pre><code>def __init__(\n    self, tft_output: TFTransformOutput, exported_as_v1: Optional[bool] = None\n):\n    super().__init__(trainable=False)\n    self._tft_output = tft_output\n    if exported_as_v1 is None:\n        self._exported_as_v1 = saved_transform_io.exported_as_v1(\n            tft_output.transform_savedmodel_dir\n        )\n    else:\n        self._exported_as_v1 = exported_as_v1\n    self._saved_model_loader_value = None\n    self._loaded_saved_model_graph = None\n    if tf.compat.v1.executing_eagerly_outside_functions():\n        # The model must be tracked by assigning to an attribute of the Keras\n        # layer. Hence, we track the attributes of _saved_model_loader here as\n        # well.\n        self._saved_model_loader_tracked_dict = self._saved_model_loader.__dict__\n\n    # TODO(b/162055065): This is needed because otherwise we'd get an error in\n    # some cases:\n    # ValueError: Your Layer or Model is in an invalid state. This can happen\n    # if you are interleaving estimator/non-estimator models or interleaving\n    # models/layers made in tf.compat.v1.Graph.as_default() with models/layers\n    # created outside of it. Converting a model to an estimator (via\n    # model_to_estimator) invalidates all models/layers made before the\n    # conversion (even if they were not the model converted to an estimator).\n    # Similarly, making a layer or a model inside a a tf.compat.v1.Graph\n    # invalidates all layers/models you previously made outside of the graph.\n    self._originally_built_as_v1 = True\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.TransformFeaturesLayer-functions","title":"Functions","text":""},{"location":"api_docs/python/tft/#tensorflow_transform.TransformFeaturesLayer.call","title":"call","text":"<pre><code>call(\n    inputs: Mapping[str, TensorType],\n) -&gt; Dict[str, TensorType]\n</code></pre> Source code in <code>tensorflow_transform/output_wrapper.py</code> <pre><code>def call(  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks\n    self, inputs: Mapping[str, common_types.TensorType]\n) -&gt; Dict[str, common_types.TensorType]:\n    if self._exported_as_v1 and not ops.executing_eagerly_outside_functions():\n        tf.compat.v1.logging.warning(\"Falling back to transform_raw_features...\")\n        return self._tft_output._transform_raw_features_compat_v1(  # pylint: disable=protected-access\n            inputs, drop_unused_features=True\n        )\n    else:\n        return self._saved_model_loader.apply_transform_model(inputs)\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform-functions","title":"Functions","text":""},{"location":"api_docs/python/tft/#tensorflow_transform.Any","title":"Any","text":"<pre><code>Any(self, parameters)\n</code></pre> <p>Special type indicating an unconstrained type.</p> <ul> <li>Any is compatible with every type.</li> <li>Any assumed to have all methods.</li> <li>All values assumed to be instances of Any.</li> </ul> <p>Note that all the above statements are true from the point of view of static type checkers. At runtime, Any should not be used with instance or class checks.</p> Source code in <code>python3.9/typing.py</code> <pre><code>@_SpecialForm\ndef Any(self, parameters):\n    \"\"\"Special type indicating an unconstrained type.\n\n    - Any is compatible with every type.\n    - Any assumed to have all methods.\n    - All values assumed to be instances of Any.\n\n    Note that all the above statements are true from the point of view of\n    static type checkers. At runtime, Any should not be used with instance\n    or class checks.\n    \"\"\"\n    raise TypeError(f\"{self} is not subscriptable\")\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.Optional","title":"Optional","text":"<pre><code>Optional(self, parameters)\n</code></pre> <p>Optional type.</p> <p>Optional[X] is equivalent to Union[X, None].</p> Source code in <code>python3.9/typing.py</code> <pre><code>@_SpecialForm\ndef Optional(self, parameters):\n    \"\"\"Optional type.\n\n    Optional[X] is equivalent to Union[X, None].\n    \"\"\"\n    arg = _type_check(parameters, f\"{self} requires a single type.\")\n    return Union[arg, type(None)]\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.Union","title":"Union","text":"<pre><code>Union(self, parameters)\n</code></pre> <p>Union type; Union[X, Y] means either X or Y.</p> <p>To define a union, use e.g. Union[int, str].  Details: - The arguments must be types and there must be at least one. - None as an argument is a special case and is replaced by   type(None). - Unions of unions are flattened, e.g.::</p> <pre><code>Union[Union[int, str], float] == Union[int, str, float]\n</code></pre> <ul> <li> <p>Unions of a single argument vanish, e.g.::</p> <p>Union[int] == int  # The constructor actually returns int</p> </li> <li> <p>Redundant arguments are skipped, e.g.::</p> <p>Union[int, str, int] == Union[int, str]</p> </li> <li> <p>When comparing unions, the argument order is ignored, e.g.::</p> <p>Union[int, str] == Union[str, int]</p> </li> <li> <p>You cannot subclass or instantiate a union.</p> </li> <li>You can use Optional[X] as a shorthand for Union[X, None].</li> </ul> Source code in <code>python3.9/typing.py</code> <pre><code>@_SpecialForm\ndef Union(self, parameters):\n    \"\"\"Union type; Union[X, Y] means either X or Y.\n\n    To define a union, use e.g. Union[int, str].  Details:\n    - The arguments must be types and there must be at least one.\n    - None as an argument is a special case and is replaced by\n      type(None).\n    - Unions of unions are flattened, e.g.::\n\n        Union[Union[int, str], float] == Union[int, str, float]\n\n    - Unions of a single argument vanish, e.g.::\n\n        Union[int] == int  # The constructor actually returns int\n\n    - Redundant arguments are skipped, e.g.::\n\n        Union[int, str, int] == Union[int, str]\n\n    - When comparing unions, the argument order is ignored, e.g.::\n\n        Union[int, str] == Union[str, int]\n\n    - You cannot subclass or instantiate a union.\n    - You can use Optional[X] as a shorthand for Union[X, None].\n    \"\"\"\n    if parameters == ():\n        raise TypeError(\"Cannot take a Union of no types.\")\n    if not isinstance(parameters, tuple):\n        parameters = (parameters,)\n    msg = \"Union[arg, ...]: each arg must be a type.\"\n    parameters = tuple(_type_check(p, msg) for p in parameters)\n    parameters = _remove_dups_flatten(parameters)\n    if len(parameters) == 1:\n        return parameters[0]\n    return _UnionGenericAlias(self, parameters)\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.annotate_asset","title":"annotate_asset","text":"<pre><code>annotate_asset(asset_key: str, asset_filename: str)\n</code></pre> <p>Creates mapping between user-defined keys and SavedModel assets.</p> <p>This mapping is made available in <code>BeamDatasetMetadata</code> and is also used to resolve vocabularies in <code>tft.TFTransformOutput</code>.</p> <p>Note: multiple mappings for the same key will overwrite the previous one.</p> <p>asset_key: The key to associate with the asset.   asset_filename: The filename as it appears within the assets/ subdirectory.     Must be sanitized and complete (e.g. include the tfrecord.gz for suffix     appropriate files).</p> Source code in <code>tensorflow_transform/annotators.py</code> <pre><code>def annotate_asset(asset_key: str, asset_filename: str):\n    \"\"\"Creates mapping between user-defined keys and SavedModel assets.\n\n    This mapping is made available in `BeamDatasetMetadata` and is also used to\n    resolve vocabularies in `tft.TFTransformOutput`.\n\n    Note: multiple mappings for the same key will overwrite the previous one.\n\n    Args:\n    ----\n      asset_key: The key to associate with the asset.\n      asset_filename: The filename as it appears within the assets/ subdirectory.\n        Must be sanitized and complete (e.g. include the tfrecord.gz for suffix\n        appropriate files).\n    \"\"\"\n    tf.compat.v1.add_to_collection(_ASSET_KEY_COLLECTION, asset_key)\n    tf.compat.v1.add_to_collection(_ASSET_FILENAME_COLLECTION, asset_filename)\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.apply_buckets","title":"apply_buckets","text":"<pre><code>apply_buckets(\n    x: ConsistentTensorType,\n    bucket_boundaries: BucketBoundariesType,\n    name: Optional[str] = None,\n) -&gt; ConsistentTensorType\n</code></pre> <p>Returns a bucketized column, with a bucket index assigned to each input.</p> <p>Each element <code>e</code> in <code>x</code> is mapped to a positive index <code>i</code> for which <code>bucket_boundaries[i-1] &lt;= e &lt; bucket_boundaries[i]</code>, if it exists. If <code>e &lt; bucket_boundaries[0]</code>, then <code>e</code> is mapped to <code>0</code>. If <code>e &gt;= bucket_boundaries[-1]</code>, then <code>e</code> is mapped to <code>len(bucket_boundaries)</code>. NaNs are mapped to <code>len(bucket_boundaries)</code>.</p>"},{"location":"api_docs/python/tft/#tensorflow_transform.apply_buckets--example","title":"Example:","text":"<p>x = tf.constant([[4.0, float('nan'), 1.0], [float('-inf'), 7.5, 10.0]]) bucket_boundaries = tf.constant([[2.0, 5.0, 10.0]]) tft.apply_buckets(x, bucket_boundaries) </p> <p>x: A numeric input <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> whose values     should be mapped to buckets.  For <code>CompositeTensor</code>s, the non-missing     values will be mapped to buckets and missing value left missing.   bucket_boundaries: A rank 2 <code>Tensor</code> or list representing the bucket     boundaries sorted in ascending order.   name: (Optional) A name for this operation.</p> <p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of the same shape as <code>x</code>, with   each element in the returned tensor representing the bucketized value.   Bucketized value is in the range [0, len(bucket_boundaries)].</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef apply_buckets(\n    x: common_types.ConsistentTensorType,\n    bucket_boundaries: common_types.BucketBoundariesType,\n    name: Optional[str] = None,\n) -&gt; common_types.ConsistentTensorType:\n    \"\"\"Returns a bucketized column, with a bucket index assigned to each input.\n\n    Each element `e` in `x` is mapped to a positive index `i` for which\n    `bucket_boundaries[i-1] &lt;= e &lt; bucket_boundaries[i]`, if it exists.\n    If `e &lt; bucket_boundaries[0]`, then `e` is mapped to `0`. If\n    `e &gt;= bucket_boundaries[-1]`, then `e` is mapped to `len(bucket_boundaries)`.\n    NaNs are mapped to `len(bucket_boundaries)`.\n\n    Example:\n    -------\n    &gt;&gt;&gt; x = tf.constant([[4.0, float('nan'), 1.0], [float('-inf'), 7.5, 10.0]])\n    &gt;&gt;&gt; bucket_boundaries = tf.constant([[2.0, 5.0, 10.0]])\n    &gt;&gt;&gt; tft.apply_buckets(x, bucket_boundaries)\n    &lt;tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n    array([[1, 3, 0],\n           [0, 2, 3]])&gt;\n\n    Args:\n    ----\n      x: A numeric input `Tensor`, `SparseTensor`, or `RaggedTensor` whose values\n        should be mapped to buckets.  For `CompositeTensor`s, the non-missing\n        values will be mapped to buckets and missing value left missing.\n      bucket_boundaries: A rank 2 `Tensor` or list representing the bucket\n        boundaries sorted in ascending order.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A `Tensor`, `SparseTensor`, or `RaggedTensor` of the same shape as `x`, with\n      each element in the returned tensor representing the bucketized value.\n      Bucketized value is in the range [0, len(bucket_boundaries)].\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"apply_buckets\"):\n        bucket_boundaries = tf.convert_to_tensor(bucket_boundaries)\n        tf.compat.v1.assert_rank(bucket_boundaries, 2)\n\n        bucketized_values = tf_utils.assign_buckets(\n            tf_utils.get_values(x), bucket_boundaries, side=tf_utils.Side.RIGHT\n        )\n\n        # Attach the relevant metadata to result, so that the corresponding\n        # output feature will have this metadata set.\n        min_value = tf.constant(0, tf.int64)\n        max_value = tf.shape(input=bucket_boundaries)[1]\n        schema_inference.set_tensor_schema_override(\n            bucketized_values, min_value, max_value\n        )\n        _annotate_buckets(bucketized_values, bucket_boundaries)\n        compose_result_fn = _make_composite_tensor_wrapper_if_composite(x)\n        return compose_result_fn(bucketized_values)\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.apply_buckets_with_interpolation","title":"apply_buckets_with_interpolation","text":"<pre><code>apply_buckets_with_interpolation(\n    x: ConsistentTensorType,\n    bucket_boundaries: BucketBoundariesType,\n    name: Optional[str] = None,\n) -&gt; ConsistentTensorType\n</code></pre> <p>Interpolates within the provided buckets and then normalizes to 0 to 1.</p> <p>A method for normalizing continuous numeric data to the range [0, 1]. Numeric values are first bucketized according to the provided boundaries, then linearly interpolated within their respective bucket ranges. Finally, the interpolated values are normalized to the range [0, 1]. Values that are less than or equal to the lowest boundary, or greater than or equal to the highest boundary, will be mapped to 0 and 1 respectively. NaN values will be mapped to the middle of the range (.5).</p> <p>This is a non-linear approach to normalization that is less sensitive to outliers than min-max or z-score scaling. When outliers are present, standard forms of normalization can leave the majority of the data compressed into a very small segment of the output range, whereas this approach tends to spread out the more frequent values (if quantile buckets are used). Note that distance relationships in the raw data are not necessarily preserved (data points that close to each other in the raw feature space may not be equally close in the transformed feature space). This means that unlike linear normalization methods, correlations between features may be distorted by the transformation. This scaling method may help with stability and minimize exploding gradients in neural networks.</p> <p>x: A numeric input <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>     (tf.float[32|64], tf.int[32|64]).   bucket_boundaries: Sorted bucket boundaries as a rank-2 <code>Tensor</code> or list.   name: (Optional) A name for this operation.</p> <p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of the same shape as <code>x</code>,   normalized to the range [0, 1]. If the input x is tf.float64, the returned   values will be tf.float64. Otherwise, returned values are tf.float32.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef apply_buckets_with_interpolation(\n    x: common_types.ConsistentTensorType,\n    bucket_boundaries: common_types.BucketBoundariesType,\n    name: Optional[str] = None,\n) -&gt; common_types.ConsistentTensorType:\n    \"\"\"Interpolates within the provided buckets and then normalizes to 0 to 1.\n\n    A method for normalizing continuous numeric data to the range [0, 1].\n    Numeric values are first bucketized according to the provided boundaries, then\n    linearly interpolated within their respective bucket ranges. Finally, the\n    interpolated values are normalized to the range [0, 1]. Values that are\n    less than or equal to the lowest boundary, or greater than or equal to the\n    highest boundary, will be mapped to 0 and 1 respectively. NaN values will be\n    mapped to the middle of the range (.5).\n\n    This is a non-linear approach to normalization that is less sensitive to\n    outliers than min-max or z-score scaling. When outliers are present, standard\n    forms of normalization can leave the majority of the data compressed into a\n    very small segment of the output range, whereas this approach tends to spread\n    out the more frequent values (if quantile buckets are used). Note that\n    distance relationships in the raw data are not necessarily preserved (data\n    points that close to each other in the raw feature space may not be equally\n    close in the transformed feature space). This means that unlike linear\n    normalization methods, correlations between features may be distorted by the\n    transformation. This scaling method may help with stability and minimize\n    exploding gradients in neural networks.\n\n    Args:\n    ----\n      x: A numeric input `Tensor`, `SparseTensor`, or `RaggedTensor`\n        (tf.float[32|64], tf.int[32|64]).\n      bucket_boundaries: Sorted bucket boundaries as a rank-2 `Tensor` or list.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A `Tensor`, `SparseTensor`, or `RaggedTensor` of the same shape as `x`,\n      normalized to the range [0, 1]. If the input x is tf.float64, the returned\n      values will be tf.float64. Otherwise, returned values are tf.float32.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"buckets_with_interpolation\"):\n        bucket_boundaries = tf.convert_to_tensor(bucket_boundaries)\n        tf.compat.v1.assert_rank(bucket_boundaries, 2)\n        x_values = tf_utils.get_values(x)\n        compose_result_fn = _make_composite_tensor_wrapper_if_composite(x)\n        if not (x_values.dtype.is_floating or x_values.dtype.is_integer):\n            raise ValueError(\n                \"Input tensor to be normalized must be numeric, got {}.\".format(\n                    x_values.dtype\n                )\n            )\n        # Remove any non-finite boundaries.\n        if bucket_boundaries.dtype in (tf.float64, tf.float32):\n            bucket_boundaries = tf.expand_dims(\n                tf.gather_nd(\n                    bucket_boundaries, tf.where(tf.math.is_finite(bucket_boundaries))\n                ),\n                axis=0,\n            )\n        return_type = tf.float64 if x.dtype == tf.float64 else tf.float32\n        num_boundaries = tf.cast(\n            tf.shape(bucket_boundaries)[1], dtype=tf.int64, name=\"num_boundaries\"\n        )\n        assert_some_finite_boundaries = tf.compat.v1.assert_greater(\n            num_boundaries,\n            tf.constant(0, tf.int64),\n            name=\"assert_1_or_more_finite_boundaries\",\n        )\n        with tf.control_dependencies([assert_some_finite_boundaries]):\n            bucket_indices = tf_utils.assign_buckets(\n                x_values, bucket_boundaries, side=tf_utils.Side.RIGHT\n            )\n            # Get max, min, and width of the corresponding bucket for each element.\n            bucket_max = tf.cast(\n                tf.gather(\n                    tf.concat([bucket_boundaries[0], bucket_boundaries[:, -1]], axis=0),\n                    bucket_indices,\n                ),\n                return_type,\n            )\n            bucket_min = tf.cast(\n                tf.gather(\n                    tf.concat([bucket_boundaries[:, 0], bucket_boundaries[0]], axis=0),\n                    bucket_indices,\n                ),\n                return_type,\n            )\n        bucket_width = bucket_max - bucket_min\n        zeros = tf.zeros_like(x_values, dtype=return_type)\n        ones = tf.ones_like(x_values, dtype=return_type)\n\n        # Linearly interpolate each value within its respective bucket range.\n        interpolation_value = (\n            tf.cast(x_values, return_type) - bucket_min\n        ) / bucket_width\n        bucket_interpolation = tf.compat.v1.verify_tensor_all_finite(\n            tf.where(\n                # If bucket index is first or last, which represents \"less than\n                # min\" and \"greater than max\" respectively, the bucket logically\n                # has an infinite width and we can't meaningfully interpolate.\n                tf.logical_or(\n                    tf.equal(bucket_indices, 0),\n                    tf.equal(bucket_indices, num_boundaries),\n                ),\n                zeros,\n                tf.where(\n                    # If the bucket width is zero due to numerical imprecision,\n                    # there is no point in interpolating\n                    tf.equal(bucket_width, 0.0),\n                    ones / 2.0,\n                    # Finally, for a bucket with a valid width, we can interpolate.\n                    interpolation_value,\n                ),\n            ),\n            \"bucket_interpolation\",\n        )\n        bucket_indices_with_interpolation = (\n            tf.cast(tf.maximum(bucket_indices - 1, 0), return_type)\n            + bucket_interpolation\n        )\n\n        # Normalize the interpolated values to the range [0, 1].\n        denominator = tf.cast(tf.maximum(num_boundaries - 1, 1), return_type)\n        normalized_values = bucket_indices_with_interpolation / denominator\n        if x_values.dtype.is_floating:\n            # Impute NaNs with .5, the middle value of the normalized output range.\n            imputed_values = tf.ones_like(x_values, dtype=return_type) / 2.0\n            normalized_values = tf.where(\n                tf.math.is_nan(x_values), imputed_values, normalized_values\n            )\n        # If there is only one boundary, all values &lt; the boundary are 0, all values\n        # &gt;= the boundary are 1.\n        single_boundary_values = lambda: tf.where(  # pylint: disable=g-long-lambda\n            tf.equal(bucket_indices, 0), zeros, ones\n        )\n        normalized_result = tf.cond(\n            tf.equal(num_boundaries, 1),\n            single_boundary_values,\n            lambda: normalized_values,\n        )\n        return compose_result_fn(normalized_result)\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.apply_pyfunc","title":"apply_pyfunc","text":"<pre><code>apply_pyfunc(func, Tout, stateful=True, name=None, *args)\n</code></pre> <p>Applies a python function to some <code>Tensor</code>s.</p> <p>Applies a python function to some <code>Tensor</code>s given by the argument list. The number of arguments should match the number of inputs to the function.</p> <p>This function is for using inside a preprocessing_fn.  It is a wrapper around <code>tf.py_func</code>.  A function added this way can run in Transform, and during training when the graph is imported using the <code>transform_raw_features</code> method of the <code>TFTransformOutput</code> class.  However if the resulting training graph is serialized and deserialized, then the <code>tf.py_func</code> op will not work and will cause an error.  This means that TensorFlow Serving will not be able to serve this graph.</p> <p>The underlying reason for this limited support is that <code>tf.py_func</code> ops were not designed to be serialized since they contain a reference to arbitrary Python functions. This function pickles those functions and including them in the graph, and <code>transform_raw_features</code> similarly unpickles the functions. But unpickling requires a Python environment, so there it's not possible to provide support in non-Python languages for loading such ops.  Therefore loading these ops in libraries such as TensorFlow Serving is not supported.</p> <p>Note: This API can only be used when TF2 is disabled or <code>tft_beam.Context.force_tf_compat_v1=True</code>.</p> <p>func: A Python function, which accepts a list of NumPy <code>ndarray</code> objects     having element types that match the corresponding <code>tf.Tensor</code> objects     in <code>*args</code>, and returns a list of <code>ndarray</code> objects (or a single     <code>ndarray</code>) having element types that match the corresponding values     in <code>Tout</code>.   Tout: A list or tuple of tensorflow data types or a single tensorflow data     type if there is only one, indicating what <code>func</code> returns.   stateful: (Boolean.) If True, the function should be considered stateful.     If a function is stateless, when given the same input it will return the     same output and have no observable side effects. Optimizations such as     common subexpression elimination are only performed on stateless     operations.   name: A name for the operation (optional).   *args: The list of <code>Tensor</code>s to apply the arguments to.</p> <p>A <code>Tensor</code> representing the application of the function.</p> Source code in <code>tensorflow_transform/py_func/api.py</code> <pre><code>def apply_pyfunc(func, Tout, stateful=True, name=None, *args):  # pylint: disable=invalid-name\n    \"\"\"Applies a python function to some `Tensor`s.\n\n    Applies a python function to some `Tensor`s given by the argument list. The\n    number of arguments should match the number of inputs to the function.\n\n    This function is for using inside a preprocessing_fn.  It is a wrapper around\n    `tf.py_func`.  A function added this way can run in Transform, and during\n    training when the graph is imported using the `transform_raw_features` method\n    of the `TFTransformOutput` class.  However if the resulting training graph is\n    serialized and deserialized, then the `tf.py_func` op will not work and will\n    cause an error.  This means that TensorFlow Serving will not be able to serve\n    this graph.\n\n    The underlying reason for this limited support is that `tf.py_func` ops were\n    not designed to be serialized since they contain a reference to arbitrary\n    Python functions. This function pickles those functions and including them in\n    the graph, and `transform_raw_features` similarly unpickles the functions.\n    But unpickling requires a Python environment, so there it's not possible to\n    provide support in non-Python languages for loading such ops.  Therefore\n    loading these ops in libraries such as TensorFlow Serving is not supported.\n\n    Note: This API can only be used when TF2 is disabled or\n    `tft_beam.Context.force_tf_compat_v1=True`.\n\n    Args:\n    ----\n      func: A Python function, which accepts a list of NumPy `ndarray` objects\n        having element types that match the corresponding `tf.Tensor` objects\n        in `*args`, and returns a list of `ndarray` objects (or a single\n        `ndarray`) having element types that match the corresponding values\n        in `Tout`.\n      Tout: A list or tuple of tensorflow data types or a single tensorflow data\n        type if there is only one, indicating what `func` returns.\n      stateful: (Boolean.) If True, the function should be considered stateful.\n        If a function is stateless, when given the same input it will return the\n        same output and have no observable side effects. Optimizations such as\n        common subexpression elimination are only performed on stateless\n        operations.\n      name: A name for the operation (optional).\n      *args: The list of `Tensor`s to apply the arguments to.\n\n    Returns:\n    -------\n      A `Tensor` representing the application of the function.\n    \"\"\"\n    return pyfunc_helper.insert_pyfunc(func, Tout, stateful, name, *args)\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.apply_vocabulary","title":"apply_vocabulary","text":"<pre><code>apply_vocabulary(\n    x: ConsistentTensorType,\n    deferred_vocab_filename_tensor: TemporaryAnalyzerOutputType,\n    *,\n    default_value: Any = -1,\n    num_oov_buckets: int = 0,\n    lookup_fn: Optional[\n        Callable[\n            [TensorType, Tensor], Tuple[Tensor, Tensor]\n        ]\n    ] = None,\n    file_format: VocabularyFileFormatType = DEFAULT_VOCABULARY_FILE_FORMAT,\n    name: Optional[str] = None,\n) -&gt; ConsistentTensorType\n</code></pre> <p>Maps <code>x</code> to a vocabulary specified by the deferred tensor.</p> <p>This function also writes domain statistics about the vocabulary min and max values. Note that the min and max are inclusive, and depend on the vocab size, num_oov_buckets and default_value.</p> <p>x: A categorical <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of type     tf.string or tf.int[8|16|32|64] to which the vocabulary transformation     should be applied. The column names are those intended for the transformed     tensors.   deferred_vocab_filename_tensor: The deferred vocab filename tensor as     returned by <code>tft.vocabulary</code>, as long as the frequencies were not stored.   default_value: The value to use for out-of-vocabulary values, unless     'num_oov_buckets' is greater than zero.   num_oov_buckets:  Any lookup of an out-of-vocabulary token will return a     bucket ID based on its hash if <code>num_oov_buckets</code> is greater than zero.     Otherwise it is assigned the <code>default_value</code>.   lookup_fn: Optional lookup function, if specified it should take a tensor     and a deferred vocab filename as an input and return a lookup <code>op</code> along     with the table size, by default <code>apply_vocabulary</code> constructs a     StaticHashTable for the table lookup.   file_format: (Optional) A str. The format of the given vocabulary. Accepted     formats are: 'tfrecord_gzip', 'text'. The default value is 'text'.   name: (Optional) A name for this operation.</p> <p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> where each string value is   mapped to an integer. Each unique string value that appears in the   vocabulary is mapped to a different integer and integers are consecutive   starting from zero, and string value not in the vocabulary is   assigned default_value.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef apply_vocabulary(\n    x: common_types.ConsistentTensorType,\n    deferred_vocab_filename_tensor: common_types.TemporaryAnalyzerOutputType,\n    *,  # Force passing optional parameters by keys.\n    default_value: Any = -1,\n    num_oov_buckets: int = 0,\n    lookup_fn: Optional[\n        Callable[[common_types.TensorType, tf.Tensor], Tuple[tf.Tensor, tf.Tensor]]\n    ] = None,\n    file_format: common_types.VocabularyFileFormatType = analyzers.DEFAULT_VOCABULARY_FILE_FORMAT,\n    name: Optional[str] = None,\n) -&gt; common_types.ConsistentTensorType:\n    r\"\"\"Maps `x` to a vocabulary specified by the deferred tensor.\n\n    This function also writes domain statistics about the vocabulary min and max\n    values. Note that the min and max are inclusive, and depend on the vocab size,\n    num_oov_buckets and default_value.\n\n    Args:\n    ----\n      x: A categorical `Tensor`, `SparseTensor`, or `RaggedTensor` of type\n        tf.string or tf.int[8|16|32|64] to which the vocabulary transformation\n        should be applied. The column names are those intended for the transformed\n        tensors.\n      deferred_vocab_filename_tensor: The deferred vocab filename tensor as\n        returned by `tft.vocabulary`, as long as the frequencies were not stored.\n      default_value: The value to use for out-of-vocabulary values, unless\n        'num_oov_buckets' is greater than zero.\n      num_oov_buckets:  Any lookup of an out-of-vocabulary token will return a\n        bucket ID based on its hash if `num_oov_buckets` is greater than zero.\n        Otherwise it is assigned the `default_value`.\n      lookup_fn: Optional lookup function, if specified it should take a tensor\n        and a deferred vocab filename as an input and return a lookup `op` along\n        with the table size, by default `apply_vocabulary` constructs a\n        StaticHashTable for the table lookup.\n      file_format: (Optional) A str. The format of the given vocabulary. Accepted\n        formats are: 'tfrecord_gzip', 'text'. The default value is 'text'.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A `Tensor`, `SparseTensor`, or `RaggedTensor` where each string value is\n      mapped to an integer. Each unique string value that appears in the\n      vocabulary is mapped to a different integer and integers are consecutive\n      starting from zero, and string value not in the vocabulary is\n      assigned default_value.\n    \"\"\"\n    return _apply_vocabulary_internal(\n        x,\n        deferred_vocab_filename_tensor,\n        default_value,\n        num_oov_buckets,\n        lookup_fn,\n        file_format,\n        False,\n        name,\n    )\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.bag_of_words","title":"bag_of_words","text":"<pre><code>bag_of_words(\n    tokens: SparseTensor,\n    ngram_range: Tuple[int, int],\n    separator: str,\n    name: Optional[str] = None,\n) -&gt; SparseTensor\n</code></pre> <p>Computes a bag of \"words\" based on the specified ngram configuration.</p> <p>A light wrapper around tft.ngrams. First computes ngrams, then transforms the ngram representation (list semantics) into a Bag of Words (set semantics) per row. Each row reflects the set of unique ngrams present in an input record.</p> <p>See tft.ngrams for more information.</p> <p>tokens: a two-dimensional <code>SparseTensor</code> of dtype <code>tf.string</code> containing     tokens that will be used to construct a bag of words.   ngram_range: A pair with the range (inclusive) of ngram sizes to compute.   separator: a string that will be inserted between tokens when ngrams are     constructed.   name: (Optional) A name for this operation.</p> <p>A <code>SparseTensor</code> containing the unique set of ngrams from each row of the     input. Note: the original order of the ngrams may not be preserved.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef bag_of_words(\n    tokens: tf.SparseTensor,\n    ngram_range: Tuple[int, int],\n    separator: str,\n    name: Optional[str] = None,\n) -&gt; tf.SparseTensor:\n    \"\"\"Computes a bag of \"words\" based on the specified ngram configuration.\n\n    A light wrapper around tft.ngrams. First computes ngrams, then transforms the\n    ngram representation (list semantics) into a Bag of Words (set semantics) per\n    row. Each row reflects the set of *unique* ngrams present in an input record.\n\n    See tft.ngrams for more information.\n\n    Args:\n    ----\n      tokens: a two-dimensional `SparseTensor` of dtype `tf.string` containing\n        tokens that will be used to construct a bag of words.\n      ngram_range: A pair with the range (inclusive) of ngram sizes to compute.\n      separator: a string that will be inserted between tokens when ngrams are\n        constructed.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A `SparseTensor` containing the unique set of ngrams from each row of the\n        input. Note: the original order of the ngrams may not be preserved.\n    \"\"\"\n    if tokens.get_shape().ndims != 2:\n        raise ValueError(\"bag_of_words requires `tokens` to be 2-dimensional\")\n    with tf.compat.v1.name_scope(name, \"bag_of_words\"):\n        # First compute the ngram representation, which will contain ordered and\n        # possibly duplicated ngrams per row.\n        all_ngrams = ngrams(tokens, ngram_range, separator)\n        # Then deduplicate the ngrams in each row.\n        return deduplicate_tensor_per_row(all_ngrams)\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.bucketize","title":"bucketize","text":"<pre><code>bucketize(\n    x: ConsistentTensorType,\n    num_buckets: int,\n    epsilon: Optional[float] = None,\n    weights: Optional[Tensor] = None,\n    elementwise: bool = False,\n    name: Optional[str] = None,\n) -&gt; ConsistentTensorType\n</code></pre> <p>Returns a bucketized column, with a bucket index assigned to each input.</p> <p>x: A numeric input <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> whose values     should be mapped to buckets.  For a <code>CompositeTensor</code> only non-missing     values will be included in the quantiles computation, and the result of     <code>bucketize</code> will be a <code>CompositeTensor</code> with non-missing values mapped to     buckets. If elementwise=True then <code>x</code> must be dense.   num_buckets: Values in the input <code>x</code> are divided into approximately     equal-sized buckets, where the number of buckets is <code>num_buckets</code>.   epsilon: (Optional) Error tolerance, typically a small fraction close to     zero. If a value is not specified by the caller, a suitable value is     computed based on experimental results.  For <code>num_buckets</code> less than 100,     the value of 0.01 is chosen to handle a dataset of up to ~1 trillion input     data values.  If <code>num_buckets</code> is larger, then epsilon is set to     (1/<code>num_buckets</code>) to enforce a stricter error tolerance, because more     buckets will result in smaller range for each bucket, and so we want the     boundaries to be less fuzzy. See analyzers.quantiles() for details.   weights: (Optional) Weights tensor for the quantiles. Tensor must have the     same shape as x.   elementwise: (Optional) If true, bucketize each element of the tensor     independently.   name: (Optional) A name for this operation.</p> <p>A <code>Tensor</code> of the same shape as <code>x</code>, with each element in the   returned tensor representing the bucketized value. Bucketized value is   in the range [0, actual_num_buckets). Sometimes the actual number of buckets   can be different than num_buckets hint, for example in case the number of   distinct values is smaller than num_buckets, or in cases where the   input values are not uniformly distributed.   NaN values are mapped to the last bucket. Values with NaN weights are   ignored in bucket boundaries calculation.</p> <p>TypeError: If num_buckets is not an int.   ValueError: If value of num_buckets is not &gt; 1.   ValueError: If elementwise=True and x is a <code>CompositeTensor</code>.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef bucketize(\n    x: common_types.ConsistentTensorType,\n    num_buckets: int,\n    epsilon: Optional[float] = None,\n    weights: Optional[tf.Tensor] = None,\n    elementwise: bool = False,\n    name: Optional[str] = None,\n) -&gt; common_types.ConsistentTensorType:\n    \"\"\"Returns a bucketized column, with a bucket index assigned to each input.\n\n    Args:\n    ----\n      x: A numeric input `Tensor`, `SparseTensor`, or `RaggedTensor` whose values\n        should be mapped to buckets.  For a `CompositeTensor` only non-missing\n        values will be included in the quantiles computation, and the result of\n        `bucketize` will be a `CompositeTensor` with non-missing values mapped to\n        buckets. If elementwise=True then `x` must be dense.\n      num_buckets: Values in the input `x` are divided into approximately\n        equal-sized buckets, where the number of buckets is `num_buckets`.\n      epsilon: (Optional) Error tolerance, typically a small fraction close to\n        zero. If a value is not specified by the caller, a suitable value is\n        computed based on experimental results.  For `num_buckets` less than 100,\n        the value of 0.01 is chosen to handle a dataset of up to ~1 trillion input\n        data values.  If `num_buckets` is larger, then epsilon is set to\n        (1/`num_buckets`) to enforce a stricter error tolerance, because more\n        buckets will result in smaller range for each bucket, and so we want the\n        boundaries to be less fuzzy. See analyzers.quantiles() for details.\n      weights: (Optional) Weights tensor for the quantiles. Tensor must have the\n        same shape as x.\n      elementwise: (Optional) If true, bucketize each element of the tensor\n        independently.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A `Tensor` of the same shape as `x`, with each element in the\n      returned tensor representing the bucketized value. Bucketized value is\n      in the range [0, actual_num_buckets). Sometimes the actual number of buckets\n      can be different than num_buckets hint, for example in case the number of\n      distinct values is smaller than num_buckets, or in cases where the\n      input values are not uniformly distributed.\n      NaN values are mapped to the last bucket. Values with NaN weights are\n      ignored in bucket boundaries calculation.\n\n    Raises:\n    ------\n      TypeError: If num_buckets is not an int.\n      ValueError: If value of num_buckets is not &gt; 1.\n      ValueError: If elementwise=True and x is a `CompositeTensor`.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"bucketize\"):\n        if not isinstance(num_buckets, int):\n            raise TypeError(\"num_buckets must be an int, got %s\" % type(num_buckets))\n\n        if num_buckets &lt; 1:\n            raise ValueError(\"Invalid num_buckets %d\" % num_buckets)\n\n        if isinstance(x, (tf.SparseTensor, tf.RaggedTensor)) and elementwise:\n            raise ValueError(\"bucketize requires `x` to be dense if `elementwise=True`\")\n\n        if epsilon is None:\n            # See explanation in args documentation for epsilon.\n            epsilon = min(1.0 / num_buckets, 0.01)\n\n        x_values = tf_utils.get_values(x)\n        bucket_boundaries = analyzers.quantiles(\n            x_values,\n            num_buckets,\n            epsilon,\n            weights,\n            reduce_instance_dims=not elementwise,\n        )\n\n        if not elementwise:\n            return apply_buckets(x, bucket_boundaries)\n\n        num_features = tf.math.reduce_prod(x.get_shape()[1:])\n        bucket_boundaries = tf.reshape(bucket_boundaries, [num_features, -1])\n        x_reshaped = tf.reshape(x, [-1, num_features])\n        bucketized = []\n        for idx, boundaries in enumerate(tf.unstack(bucket_boundaries, axis=0)):\n            bucketized.append(\n                apply_buckets(x_reshaped[:, idx], tf.expand_dims(boundaries, axis=0))\n            )\n        return tf.reshape(\n            tf.stack(bucketized, axis=1), [-1] + x.get_shape().as_list()[1:]\n        )\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.bucketize_per_key","title":"bucketize_per_key","text":"<pre><code>bucketize_per_key(\n    x: ConsistentTensorType,\n    key: ConsistentTensorType,\n    num_buckets: int,\n    epsilon: Optional[float] = None,\n    weights: Optional[ConsistentTensorType] = None,\n    name: Optional[str] = None,\n) -&gt; ConsistentTensorType\n</code></pre> <p>Returns a bucketized column, with a bucket index assigned to each input.</p> <p>x: A numeric input <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> with rank 1,     whose values should be mapped to buckets.  <code>CompositeTensor</code>s will have     their non-missing values mapped and missing values left as missing.   key: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> with the same shape as     <code>x</code> and dtype tf.string.  If <code>x</code> is a <code>CompositeTensor</code>, <code>key</code> must     exactly match <code>x</code> in everything except values, i.e. indices and     dense_shape or nested row splits must be identical.   num_buckets: Values in the input <code>x</code> are divided into approximately     equal-sized buckets, where the number of buckets is num_buckets.   epsilon: (Optional) see <code>bucketize</code>.   weights: (Optional) A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> with the     same shape as <code>x</code> and dtype tf.float32. Used as weights for quantiles     calculation. If <code>x</code> is a <code>CompositeTensor</code>, <code>weights</code> must exactly match     <code>x</code> in everything except values.   name: (Optional) A name for this operation.</p> <p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of the same shape as <code>x</code>, with   each element in the returned tensor representing the bucketized value.   Bucketized value is in the range [0, actual_num_buckets). If the computed   key vocabulary doesn't have an entry for <code>key</code> then the resulting bucket is   -1.</p> <p>ValueError: If value of num_buckets is not &gt; 1.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef bucketize_per_key(\n    x: common_types.ConsistentTensorType,\n    key: common_types.ConsistentTensorType,\n    num_buckets: int,\n    epsilon: Optional[float] = None,\n    weights: Optional[common_types.ConsistentTensorType] = None,\n    name: Optional[str] = None,\n) -&gt; common_types.ConsistentTensorType:\n    \"\"\"Returns a bucketized column, with a bucket index assigned to each input.\n\n    Args:\n    ----\n      x: A numeric input `Tensor`, `SparseTensor`, or `RaggedTensor` with rank 1,\n        whose values should be mapped to buckets.  `CompositeTensor`s will have\n        their non-missing values mapped and missing values left as missing.\n      key: A `Tensor`, `SparseTensor`, or `RaggedTensor` with the same shape as\n        `x` and dtype tf.string.  If `x` is a `CompositeTensor`, `key` must\n        exactly match `x` in everything except values, i.e. indices and\n        dense_shape or nested row splits must be identical.\n      num_buckets: Values in the input `x` are divided into approximately\n        equal-sized buckets, where the number of buckets is num_buckets.\n      epsilon: (Optional) see `bucketize`.\n      weights: (Optional) A `Tensor`, `SparseTensor`, or `RaggedTensor` with the\n        same shape as `x` and dtype tf.float32. Used as weights for quantiles\n        calculation. If `x` is a `CompositeTensor`, `weights` must exactly match\n        `x` in everything except values.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A `Tensor`, `SparseTensor`, or `RaggedTensor` of the same shape as `x`, with\n      each element in the returned tensor representing the bucketized value.\n      Bucketized value is in the range [0, actual_num_buckets). If the computed\n      key vocabulary doesn't have an entry for `key` then the resulting bucket is\n      -1.\n\n    Raises:\n    ------\n      ValueError: If value of num_buckets is not &gt; 1.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"bucketize_per_key\"):\n        if not isinstance(num_buckets, int):\n            raise TypeError(\n                \"num_buckets must be an int, got {}\".format(type(num_buckets))\n            )\n\n        if num_buckets &lt; 1:\n            raise ValueError(\"Invalid num_buckets {}\".format(num_buckets))\n\n        if epsilon is None:\n            # See explanation in args documentation for epsilon.\n            epsilon = min(1.0 / num_buckets, 0.01)\n\n        (\n            key_vocab,\n            bucket_boundaries,\n            scale_factor_per_key,\n            shift_per_key,\n            actual_num_buckets,\n        ) = analyzers._quantiles_per_key(  # pylint: disable=protected-access\n            tf_utils.get_values(x),\n            tf_utils.get_values(key),\n            num_buckets,\n            epsilon,\n            weights=tf_utils.get_values(weights),\n        )\n        return _apply_buckets_with_keys(\n            x,\n            key,\n            key_vocab,\n            bucket_boundaries,\n            scale_factor_per_key,\n            shift_per_key,\n            actual_num_buckets,\n        )\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.compute_and_apply_vocabulary","title":"compute_and_apply_vocabulary","text":"<pre><code>compute_and_apply_vocabulary(\n    x: ConsistentTensorType,\n    *,\n    default_value: Any = -1,\n    top_k: Optional[int] = None,\n    frequency_threshold: Optional[int] = None,\n    num_oov_buckets: int = 0,\n    vocab_filename: Optional[str] = None,\n    weights: Optional[Tensor] = None,\n    labels: Optional[Tensor] = None,\n    use_adjusted_mutual_info: bool = False,\n    min_diff_from_avg: float = 0.0,\n    coverage_top_k: Optional[int] = None,\n    coverage_frequency_threshold: Optional[int] = None,\n    key_fn: Optional[Callable[[Any], Any]] = None,\n    fingerprint_shuffle: bool = False,\n    file_format: VocabularyFileFormatType = DEFAULT_VOCABULARY_FILE_FORMAT,\n    store_frequency: Optional[bool] = False,\n    reserved_tokens: Optional[\n        Union[Iterable[str], Tensor]\n    ] = None,\n    name: Optional[str] = None,\n) -&gt; ConsistentTensorType\n</code></pre> <p>Generates a vocabulary for <code>x</code> and maps it to an integer with this vocab.</p> <p>In case one of the tokens contains the '\\n' or '\\r' characters or is empty it will be discarded since we are currently writing the vocabularies as text files. This behavior will likely be fixed/improved in the future.</p> <p>Note that this function will cause a vocabulary to be computed.  For large datasets it is highly recommended to either set frequency_threshold or top_k to control the size of the vocabulary, and also the run time of this operation.</p> <p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of type tf.string or     tf.int[8|16|32|64].   default_value: The value to use for out-of-vocabulary values, unless     'num_oov_buckets' is greater than zero.   top_k: Limit the generated vocabulary to the first <code>top_k</code> elements. If set     to None, the full vocabulary is generated.   frequency_threshold: Limit the generated vocabulary only to elements whose     absolute frequency is &gt;= to the supplied threshold. If set to None, the     full vocabulary is generated.  Absolute frequency means the number of     occurences of the element in the dataset, as opposed to the proportion of     instances that contain that element. If labels are provided and the vocab     is computed using mutual information, tokens are filtered if their mutual     information with the label is &lt; the supplied threshold.   num_oov_buckets:  Any lookup of an out-of-vocabulary token will return a     bucket ID based on its hash if <code>num_oov_buckets</code> is greater than zero.     Otherwise it is assigned the <code>default_value</code>.   vocab_filename: The file name for the vocabulary file. If None, a name based     on the scope name in the context of this graph will be used as the file     name. If not None, should be unique within a given preprocessing function.     NOTE in order to make your pipelines resilient to implementation details     please set <code>vocab_filename</code> when you are using the vocab_filename on a     downstream component.   weights: (Optional) Weights <code>Tensor</code> for the vocabulary. It must have the     same shape as x.   labels: (Optional) A <code>Tensor</code> of labels for the vocabulary. If provided, the     vocabulary is calculated based on mutual information with the label,     rather than frequency. The labels must have the same batch dimension as x.     If x is sparse, labels should be a 1D tensor reflecting row-wise labels.     If x is dense, labels can either be a 1D tensor of row-wise labels, or a     dense tensor of the identical shape as x (i.e. element-wise labels).     Labels should be a discrete integerized tensor (If the label is numeric,     it should first be bucketized; If the label is a string, an integer     vocabulary should first be applied). Note: <code>CompositeTensor</code> labels are     not yet supported (b/134931826). WARNING: when labels are provided, the     frequency_threshold argument functions as a mutual information threshold,     which is a float. TODO(b/116308354): Fix confusing naming.   use_adjusted_mutual_info: If true, use adjusted mutual information.   min_diff_from_avg: Mutual information of a feature will be adjusted to zero     whenever the difference between count of the feature with any label and     its expected count is lower than min_diff_from_average.   coverage_top_k: (Optional), (Experimental) The minimum number of elements     per key to be included in the vocabulary.   coverage_frequency_threshold: (Optional), (Experimental) Limit the coverage     arm of the vocabulary only to elements whose absolute frequency is &gt;= this     threshold for a given key.   key_fn: (Optional), (Experimental) A fn that takes in a single entry of <code>x</code>     and returns the corresponding key for coverage calculation. If this is     <code>None</code>, no coverage arm is added to the vocabulary.   fingerprint_shuffle: (Optional), (Experimental) Whether to sort the     vocabularies by fingerprint instead of counts. This is useful for load     balancing on the training parameter servers. Shuffle only happens while     writing the files, so all the filters above will still take effect.   file_format: (Optional) A str. The format of the resulting vocabulary file.     Accepted formats are: 'tfrecord_gzip', 'text'. 'tfrecord_gzip' requires     tensorflow&gt;=2.4. The default value is 'text'.   store_frequency: If True, frequency of the words is stored in the vocabulary     file. In the case labels are provided, the mutual information is stored in     the file instead. Each line in the file will be of the form 'frequency     word'. NOTE: if True and text_format is 'text' then spaces will be     replaced to avoid information loss.   reserved_tokens: (Optional) A list of tokens that should appear in the     vocabulary regardless of their appearance in the input. These tokens would     maintain their order, and have a reserved spot at the beginning of the     vocabulary. Note: this field has no affect on cache.   name: (Optional) A name for this operation.</p> <p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> where each string value is   mapped to an integer. Each unique string value that appears in the   vocabulary is mapped to a different integer and integers are consecutive   starting from zero. String value not in the vocabulary is assigned   <code>default_value</code>. Alternatively, if <code>num_oov_buckets</code> is specified, out of   vocabulary strings are hashed to values in   [vocab_size, vocab_size + num_oov_buckets) for an overall range of   [0, vocab_size + num_oov_buckets).</p> <p>ValueError: If <code>top_k</code> or <code>frequency_threshold</code> is negative.     If <code>coverage_top_k</code> or <code>coverage_frequency_threshold</code> is negative.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef compute_and_apply_vocabulary(\n    x: common_types.ConsistentTensorType,\n    *,  # Force passing optional parameters by keys.\n    default_value: Any = -1,\n    top_k: Optional[int] = None,\n    frequency_threshold: Optional[int] = None,\n    num_oov_buckets: int = 0,\n    vocab_filename: Optional[str] = None,\n    weights: Optional[tf.Tensor] = None,\n    labels: Optional[tf.Tensor] = None,\n    use_adjusted_mutual_info: bool = False,\n    min_diff_from_avg: float = 0.0,\n    coverage_top_k: Optional[int] = None,\n    coverage_frequency_threshold: Optional[int] = None,\n    key_fn: Optional[Callable[[Any], Any]] = None,\n    fingerprint_shuffle: bool = False,\n    file_format: common_types.VocabularyFileFormatType = analyzers.DEFAULT_VOCABULARY_FILE_FORMAT,\n    store_frequency: Optional[bool] = False,\n    reserved_tokens: Optional[Union[Iterable[str], tf.Tensor]] = None,\n    name: Optional[str] = None,\n) -&gt; common_types.ConsistentTensorType:\n    r\"\"\"Generates a vocabulary for `x` and maps it to an integer with this vocab.\n\n    In case one of the tokens contains the '\\n' or '\\r' characters or is empty it\n    will be discarded since we are currently writing the vocabularies as text\n    files. This behavior will likely be fixed/improved in the future.\n\n    Note that this function will cause a vocabulary to be computed.  For large\n    datasets it is highly recommended to either set frequency_threshold or top_k\n    to control the size of the vocabulary, and also the run time of this\n    operation.\n\n    Args:\n    ----\n      x: A `Tensor`, `SparseTensor`, or `RaggedTensor` of type tf.string or\n        tf.int[8|16|32|64].\n      default_value: The value to use for out-of-vocabulary values, unless\n        'num_oov_buckets' is greater than zero.\n      top_k: Limit the generated vocabulary to the first `top_k` elements. If set\n        to None, the full vocabulary is generated.\n      frequency_threshold: Limit the generated vocabulary only to elements whose\n        absolute frequency is &gt;= to the supplied threshold. If set to None, the\n        full vocabulary is generated.  Absolute frequency means the number of\n        occurences of the element in the dataset, as opposed to the proportion of\n        instances that contain that element. If labels are provided and the vocab\n        is computed using mutual information, tokens are filtered if their mutual\n        information with the label is &lt; the supplied threshold.\n      num_oov_buckets:  Any lookup of an out-of-vocabulary token will return a\n        bucket ID based on its hash if `num_oov_buckets` is greater than zero.\n        Otherwise it is assigned the `default_value`.\n      vocab_filename: The file name for the vocabulary file. If None, a name based\n        on the scope name in the context of this graph will be used as the file\n        name. If not None, should be unique within a given preprocessing function.\n        NOTE in order to make your pipelines resilient to implementation details\n        please set `vocab_filename` when you are using the vocab_filename on a\n        downstream component.\n      weights: (Optional) Weights `Tensor` for the vocabulary. It must have the\n        same shape as x.\n      labels: (Optional) A `Tensor` of labels for the vocabulary. If provided, the\n        vocabulary is calculated based on mutual information with the label,\n        rather than frequency. The labels must have the same batch dimension as x.\n        If x is sparse, labels should be a 1D tensor reflecting row-wise labels.\n        If x is dense, labels can either be a 1D tensor of row-wise labels, or a\n        dense tensor of the identical shape as x (i.e. element-wise labels).\n        Labels should be a discrete integerized tensor (If the label is numeric,\n        it should first be bucketized; If the label is a string, an integer\n        vocabulary should first be applied). Note: `CompositeTensor` labels are\n        not yet supported (b/134931826). WARNING: when labels are provided, the\n        frequency_threshold argument functions as a mutual information threshold,\n        which is a float. TODO(b/116308354): Fix confusing naming.\n      use_adjusted_mutual_info: If true, use adjusted mutual information.\n      min_diff_from_avg: Mutual information of a feature will be adjusted to zero\n        whenever the difference between count of the feature with any label and\n        its expected count is lower than min_diff_from_average.\n      coverage_top_k: (Optional), (Experimental) The minimum number of elements\n        per key to be included in the vocabulary.\n      coverage_frequency_threshold: (Optional), (Experimental) Limit the coverage\n        arm of the vocabulary only to elements whose absolute frequency is &gt;= this\n        threshold for a given key.\n      key_fn: (Optional), (Experimental) A fn that takes in a single entry of `x`\n        and returns the corresponding key for coverage calculation. If this is\n        `None`, no coverage arm is added to the vocabulary.\n      fingerprint_shuffle: (Optional), (Experimental) Whether to sort the\n        vocabularies by fingerprint instead of counts. This is useful for load\n        balancing on the training parameter servers. Shuffle only happens while\n        writing the files, so all the filters above will still take effect.\n      file_format: (Optional) A str. The format of the resulting vocabulary file.\n        Accepted formats are: 'tfrecord_gzip', 'text'. 'tfrecord_gzip' requires\n        tensorflow&gt;=2.4. The default value is 'text'.\n      store_frequency: If True, frequency of the words is stored in the vocabulary\n        file. In the case labels are provided, the mutual information is stored in\n        the file instead. Each line in the file will be of the form 'frequency\n        word'. NOTE: if True and text_format is 'text' then spaces will be\n        replaced to avoid information loss.\n      reserved_tokens: (Optional) A list of tokens that should appear in the\n        vocabulary regardless of their appearance in the input. These tokens would\n        maintain their order, and have a reserved spot at the beginning of the\n        vocabulary. Note: this field has no affect on cache.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A `Tensor`, `SparseTensor`, or `RaggedTensor` where each string value is\n      mapped to an integer. Each unique string value that appears in the\n      vocabulary is mapped to a different integer and integers are consecutive\n      starting from zero. String value not in the vocabulary is assigned\n      `default_value`. Alternatively, if `num_oov_buckets` is specified, out of\n      vocabulary strings are hashed to values in\n      [vocab_size, vocab_size + num_oov_buckets) for an overall range of\n      [0, vocab_size + num_oov_buckets).\n\n    Raises:\n    ------\n      ValueError: If `top_k` or `frequency_threshold` is negative.\n        If `coverage_top_k` or `coverage_frequency_threshold` is negative.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"compute_and_apply_vocabulary\"):\n        if store_frequency and file_format == \"text\":\n            x = tf_utils.maybe_format_vocabulary_input(x)\n        deferred_vocab_and_filename = analyzers.vocabulary(\n            x=x,\n            top_k=top_k,\n            frequency_threshold=frequency_threshold,\n            vocab_filename=vocab_filename,\n            store_frequency=store_frequency,\n            weights=weights,\n            labels=labels,\n            use_adjusted_mutual_info=use_adjusted_mutual_info,\n            min_diff_from_avg=min_diff_from_avg,\n            coverage_top_k=coverage_top_k,\n            coverage_frequency_threshold=coverage_frequency_threshold,\n            key_fn=key_fn,\n            fingerprint_shuffle=fingerprint_shuffle,\n            file_format=file_format,\n            reserved_tokens=reserved_tokens,\n        )\n        return _apply_vocabulary_internal(\n            x,\n            deferred_vocab_and_filename,\n            default_value,\n            num_oov_buckets,\n            lookup_fn=None,\n            store_frequency=store_frequency,\n            file_format=file_format,\n            name=None,\n        )\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.count_per_key","title":"count_per_key","text":"<pre><code>count_per_key(\n    key: TensorType,\n    key_vocabulary_filename: Optional[str] = None,\n    name: Optional[str] = None,\n)\n</code></pre> <p>Computes the count of each element of a <code>Tensor</code>.</p> <p>key: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of dtype tf.string or     tf.int.   key_vocabulary_filename: (Optional) The file name for the key-output mapping     file. If None and key are provided, this combiner assumes the keys fit in     memory and will not store the result in a file. If empty string, a file     name will be chosen based on the current scope. If not an empty string,     should be unique within a given preprocessing function.   name: (Optional) A name for this operation.</p> <p>Either:   (A) Two <code>Tensor</code>s: one the key vocab with dtype of input;       the other the count for each key, dtype tf.int64. (if       key_vocabulary_filename is None).   (B) The filename where the key-value mapping is stored (if       key_vocabulary_filename is not None).</p> <p>TypeError: If the type of <code>x</code> is not supported.</p> Source code in <code>tensorflow_transform/analyzers.py</code> <pre><code>@common.log_api_use(common.ANALYZER_COLLECTION)\ndef count_per_key(\n    key: common_types.TensorType,\n    key_vocabulary_filename: Optional[str] = None,\n    name: Optional[str] = None,\n):\n    \"\"\"Computes the count of each element of a `Tensor`.\n\n    Args:\n    ----\n      key: A `Tensor`, `SparseTensor`, or `RaggedTensor` of dtype tf.string or\n        tf.int.\n      key_vocabulary_filename: (Optional) The file name for the key-output mapping\n        file. If None and key are provided, this combiner assumes the keys fit in\n        memory and will not store the result in a file. If empty string, a file\n        name will be chosen based on the current scope. If not an empty string,\n        should be unique within a given preprocessing function.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      Either:\n      (A) Two `Tensor`s: one the key vocab with dtype of input;\n          the other the count for each key, dtype tf.int64. (if\n          key_vocabulary_filename is None).\n      (B) The filename where the key-value mapping is stored (if\n          key_vocabulary_filename is not None).\n\n    Raises:\n    ------\n      TypeError: If the type of `x` is not supported.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"count_per_key\"):\n        key_dtype = key.dtype\n        batch_keys, batch_counts = tf_utils.reduce_batch_count_per_key(key)\n\n        output_dtype, sum_fn = _sum_combine_fn_and_dtype(tf.int64)\n        numeric_combine_result = _numeric_combine(\n            inputs=[batch_counts],\n            fn=sum_fn,\n            default_accumulator_value=0,\n            reduce_instance_dims=True,\n            output_dtypes=[output_dtype],\n            key=batch_keys,\n            key_vocabulary_filename=key_vocabulary_filename,\n        )\n\n        if key_vocabulary_filename is not None:\n            return numeric_combine_result\n        keys, counts = numeric_combine_result\n        if key_dtype is not tf.string:\n            keys = tf.strings.to_number(keys, key_dtype)\n        return keys, counts\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.covariance","title":"covariance","text":"<pre><code>covariance(\n    x: Tensor, dtype: DType, name: Optional[str] = None\n) -&gt; Tensor\n</code></pre> <p>Computes the covariance matrix over the whole dataset.</p> <p>The covariance matrix M is defined as follows: Let x[:j] be a tensor of the jth element of all input vectors in x, and let u_j = mean(x[:j]). The entry M[i,j] = E[(x[:i] - u_i)(x[:j] - u_j)]. Notice that the diagonal entries correspond to variances of individual elements in the vector, i.e. M[i,i] corresponds to the variance of x[:i].</p> <p>x: A rank-2 <code>Tensor</code>, 0th dim are rows, 1st dim are indices in each input     vector.   dtype: Tensorflow dtype of entries in the returned matrix.   name: (Optional) A name for this operation.</p> <p>ValueError: if input is not a rank-2 Tensor.</p> <p>A rank-2 (matrix) covariance <code>Tensor</code></p> Source code in <code>tensorflow_transform/analyzers.py</code> <pre><code>@common.log_api_use(common.ANALYZER_COLLECTION)\ndef covariance(x: tf.Tensor, dtype: tf.DType, name: Optional[str] = None) -&gt; tf.Tensor:\n    \"\"\"Computes the covariance matrix over the whole dataset.\n\n    The covariance matrix M is defined as follows:\n    Let x[:j] be a tensor of the jth element of all input vectors in x, and let\n    u_j = mean(x[:j]). The entry M[i,j] = E[(x[:i] - u_i)(x[:j] - u_j)].\n    Notice that the diagonal entries correspond to variances of individual\n    elements in the vector, i.e. M[i,i] corresponds to the variance of x[:i].\n\n    Args:\n    ----\n      x: A rank-2 `Tensor`, 0th dim are rows, 1st dim are indices in each input\n        vector.\n      dtype: Tensorflow dtype of entries in the returned matrix.\n      name: (Optional) A name for this operation.\n\n    Raises:\n    ------\n      ValueError: if input is not a rank-2 Tensor.\n\n    Returns:\n    -------\n      A rank-2 (matrix) covariance `Tensor`\n    \"\"\"\n    if not isinstance(x, tf.Tensor):\n        raise TypeError(\"Expected a Tensor, but got %r\" % x)\n\n    with tf.compat.v1.name_scope(name, \"covariance\"):\n        x.shape.assert_has_rank(2)\n\n        input_dim = x.shape.as_list()[1]\n        shape = (input_dim, input_dim)\n\n        (result,) = _apply_cacheable_combiner(\n            CovarianceCombiner(shape, dtype.as_numpy_dtype), x\n        )\n        return result\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.deduplicate_tensor_per_row","title":"deduplicate_tensor_per_row","text":"<pre><code>deduplicate_tensor_per_row(input_tensor, name=None)\n</code></pre> <p>Deduplicates each row (0-th dimension) of the provided tensor.</p> <p>input_tensor: A two-dimensional <code>Tensor</code> or <code>SparseTensor</code>. The first     dimension is assumed to be the batch or \"row\" dimension, and deduplication     is done on the 2nd dimension. If the Tensor is 1D it is returned as the     equivalent <code>SparseTensor</code> since the \"row\" is a scalar can't be further     deduplicated.   name: Optional name for the operation.</p> <p>A  <code>SparseTensor</code> containing the unique set of values from each     row of the input. Note: the original order of the input may not be     preserved.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef deduplicate_tensor_per_row(input_tensor, name=None):\n    \"\"\"Deduplicates each row (0-th dimension) of the provided tensor.\n\n    Args:\n    ----\n      input_tensor: A two-dimensional `Tensor` or `SparseTensor`. The first\n        dimension is assumed to be the batch or \"row\" dimension, and deduplication\n        is done on the 2nd dimension. If the Tensor is 1D it is returned as the\n        equivalent `SparseTensor` since the \"row\" is a scalar can't be further\n        deduplicated.\n      name: Optional name for the operation.\n\n    Returns:\n    -------\n      A  `SparseTensor` containing the unique set of values from each\n        row of the input. Note: the original order of the input may not be\n        preserved.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"deduplicate_per_row\"):\n        if isinstance(input_tensor, tf.SparseTensor):\n            batch_dim = tf.cast(input_tensor.dense_shape[0], tf.int32)\n            rank = input_tensor.dense_shape.shape[0]\n        else:\n            batch_dim = tf.cast(tf.shape(input_tensor)[0], tf.int32)\n            rank = input_tensor.shape.rank\n\n        def _univalent_dense_to_sparse(batch_dim, input_tensor):\n            \"\"\"Helper to convert a 1D dense `Tensor` to a `SparseTensor`.\"\"\"\n            indices = tf.cast(\n                tf.stack(\n                    [\n                        tf.range(batch_dim, dtype=tf.int32),\n                        tf.zeros(batch_dim, dtype=tf.int32),\n                    ],\n                    axis=1,\n                ),\n                dtype=tf.int64,\n            )\n\n            return tf.SparseTensor(\n                indices=indices, values=input_tensor, dense_shape=(batch_dim, 1)\n            )\n\n        if rank is not None:\n            # If the rank is known at graph construction time, and it's rank 1, there\n            # is no deduplication to be done so we can return early.\n            if rank &lt;= 1:\n                if isinstance(input_tensor, tf.SparseTensor):\n                    return input_tensor\n                # Even though we are just returning as is, we convert to a SparseTensor\n                # to ensure consistent output type.\n                return _univalent_dense_to_sparse(batch_dim, input_tensor)\n            if rank &gt; 2:\n                raise ValueError(\n                    \"Deduplication assumes a rank 2 tensor, got {}.\".format(rank)\n                )\n            return _deduplicate_tensor_per_row(input_tensor, batch_dim)\n\n        if isinstance(input_tensor, tf.SparseTensor):\n            return _deduplicate_tensor_per_row(input_tensor, batch_dim)\n        else:\n            # Again check for rank 1 tensor (that doesn't need deduplication), this\n            # time handling inputs where rank isn't known until execution time.\n            dynamic_rank = tf.rank(input_tensor)\n            return tf.cond(\n                tf.equal(dynamic_rank, 1),\n                lambda: _univalent_dense_to_sparse(batch_dim, input_tensor),\n                lambda: _deduplicate_tensor_per_row(input_tensor, batch_dim),\n            )\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.estimated_probability_density","title":"estimated_probability_density","text":"<pre><code>estimated_probability_density(\n    x: Tensor,\n    boundaries: Optional[Union[Tensor, int]] = None,\n    categorical: bool = False,\n    name: Optional[str] = None,\n) -&gt; Tensor\n</code></pre> <p>Computes an approximate probability density at each x, given the bins.</p> <p>Using this type of fixed-interval method has several benefits compared to   bucketization, although may not always be preferred.   1. Quantiles does not work on categorical data.   2. The quantiles algorithm does not currently operate on multiple features   jointly, only independently.</p> Outlier detection in a multi-modal or arbitrary distribution. <p>Imagine a value x where a simple model is highly predictive of a target y within certain densely populated ranges. Outside these ranges, we may want to treat the data differently, but there are too few samples for the model to detect them by case-by-case treatment. One option would be to use the density estimate for this purpose:</p> <p>outputs['x_density'] = tft.estimated_prob(inputs['x'], bins=100) outputs['outlier_x'] = tf.where(outputs['x_density'] &lt; OUTLIER_THRESHOLD,                                 tf.constant([1]), tf.constant([0]))</p> <p>This exercise uses a single variable for illustration, but a direct density metric would become more useful with higher dimensions.</p> <p>Note that we normalize by average bin_width to arrive at a probability density estimate. The result resembles a pdf, not the probability that a value falls in the bucket (except in the categorical case).</p> <p>x: A <code>Tensor</code>.   boundaries: (Optional) A <code>Tensor</code> or int used to approximate the density.       If possible provide boundaries as a Tensor of multiple sorted values.       Will default to 10 intervals over the 0-1 range, or find the min/max       if an int is provided (not recommended because multi-phase analysis is       inefficient). If the boundaries are known as potentially arbitrary       interval boundaries, sizes are assumed to be equal. If the sizes are       unequal, density may be inaccurate. Ignored if <code>categorical</code> is true.   categorical: (Optional) A <code>bool</code> that will treat x as categorical if true.   name: (Optional) A name for this operation.</p> <p>A <code>Tensor</code> the same shape as x, the probability density estimate at x (or   probability mass estimate if <code>categorical</code> is True).</p> <p>NotImplementedError: If <code>x</code> is CompositeTensor.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef estimated_probability_density(\n    x: tf.Tensor,\n    boundaries: Optional[Union[tf.Tensor, int]] = None,\n    categorical: bool = False,\n    name: Optional[str] = None,\n) -&gt; tf.Tensor:\n    \"\"\"Computes an approximate probability density at each x, given the bins.\n\n    Using this type of fixed-interval method has several benefits compared to\n      bucketization, although may not always be preferred.\n      1. Quantiles does not work on categorical data.\n      2. The quantiles algorithm does not currently operate on multiple features\n      jointly, only independently.\n\n    Ex: Outlier detection in a multi-modal or arbitrary distribution.\n      Imagine a value x where a simple model is highly predictive of a target y\n      within certain densely populated ranges. Outside these ranges, we may want\n      to treat the data differently, but there are too few samples for the model\n      to detect them by case-by-case treatment.\n      One option would be to use the density estimate for this purpose:\n\n      outputs['x_density'] = tft.estimated_prob(inputs['x'], bins=100)\n      outputs['outlier_x'] = tf.where(outputs['x_density'] &lt; OUTLIER_THRESHOLD,\n                                      tf.constant([1]), tf.constant([0]))\n\n      This exercise uses a single variable for illustration, but a direct density\n      metric would become more useful with higher dimensions.\n\n    Note that we normalize by average bin_width to arrive at a probability density\n    estimate. The result resembles a pdf, not the probability that a value falls\n    in the bucket (except in the categorical case).\n\n    Args:\n    ----\n      x: A `Tensor`.\n      boundaries: (Optional) A `Tensor` or int used to approximate the density.\n          If possible provide boundaries as a Tensor of multiple sorted values.\n          Will default to 10 intervals over the 0-1 range, or find the min/max\n          if an int is provided (not recommended because multi-phase analysis is\n          inefficient). If the boundaries are known as potentially arbitrary\n          interval boundaries, sizes are assumed to be equal. If the sizes are\n          unequal, density may be inaccurate. Ignored if `categorical` is true.\n      categorical: (Optional) A `bool` that will treat x as categorical if true.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A `Tensor` the same shape as x, the probability density estimate at x (or\n      probability mass estimate if `categorical` is True).\n\n    Raises:\n    ------\n      NotImplementedError: If `x` is CompositeTensor.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"estimated_probability_density\"):\n        if isinstance(x, (tf.SparseTensor, tf.RaggedTensor)):\n            raise NotImplementedError(\n                \"estimated probability density does not support Composite Tensors\"\n            )\n        if x.get_shape().ndims &gt; 1 and x.shape[-1] &gt; 1:\n            raise NotImplementedError(\n                \"estimated probability density does not support multiple dimensions\"\n            )\n\n        counts, boundaries = analyzers.histogram(\n            x, boundaries=boundaries, categorical=categorical\n        )\n\n        xdims = x.get_shape().ndims\n        counts = tf.cast(counts, tf.float32)\n        probabilities = counts / tf.reduce_sum(counts)\n\n        x = tf.reshape(x, [-1])\n\n        if categorical:\n            bucket_indices = tf_utils.lookup_key(x, boundaries)\n            bucket_densities = probabilities\n        else:\n            # We need to compute the bin width so that density does not depend on\n            # number of intervals.\n            bin_width = tf.cast(boundaries[0, -1] - boundaries[0, 0], tf.float32) / (\n                tf.cast(tf.size(probabilities), tf.float32)\n            )\n            bucket_densities = probabilities / bin_width\n\n            bucket_indices = tf_utils.assign_buckets(\n                tf.cast(x, tf.float32), analyzers.remove_leftmost_boundary(boundaries)\n            )\n        bucket_indices = tf_utils._align_dims(bucket_indices, xdims)  # pylint: disable=protected-access\n\n        # In the categorical case, when keys are missing, the indices may be -1,\n        # therefore we replace those with 0 in order to use tf.gather.\n        adjusted_bucket_indices = tf.where(\n            bucket_indices &lt; 0,\n            _fill_shape(0, tf.shape(bucket_indices), tf.int64),\n            bucket_indices,\n        )\n        bucket_densities = tf.gather(bucket_densities, adjusted_bucket_indices)\n        return tf.where(\n            bucket_indices &lt; 0,\n            _fill_shape(0, tf.shape(bucket_indices), tf.float32),\n            bucket_densities,\n        )\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.get_analyze_input_columns","title":"get_analyze_input_columns","text":"<pre><code>get_analyze_input_columns(\n    preprocessing_fn: Callable[\n        [Mapping[str, TensorType]], Mapping[str, TensorType]\n    ],\n    specs: Mapping[str, Union[FeatureSpecType, TypeSpec]],\n    force_tf_compat_v1: bool = False,\n) -&gt; List[str]\n</code></pre> <p>Return columns that are required inputs of <code>AnalyzeDataset</code>.</p> <p>preprocessing_fn: A tf.transform preprocessing_fn.   specs: A dict of feature name to tf.TypeSpecs. If <code>force_tf_compat_v1</code> is     True, this can also be feature specifications.   force_tf_compat_v1: (Optional) If <code>True</code>, use Tensorflow in compat.v1 mode.     Defaults to <code>False</code>.</p> <p>A list of columns that are required inputs of analyzers.</p> Source code in <code>tensorflow_transform/inspect_preprocessing_fn.py</code> <pre><code>def get_analyze_input_columns(\n    preprocessing_fn: Callable[\n        [Mapping[str, common_types.TensorType]], Mapping[str, common_types.TensorType]\n    ],\n    specs: Mapping[str, Union[common_types.FeatureSpecType, tf.TypeSpec]],\n    force_tf_compat_v1: bool = False,\n) -&gt; List[str]:\n    \"\"\"Return columns that are required inputs of `AnalyzeDataset`.\n\n    Args:\n    ----\n      preprocessing_fn: A tf.transform preprocessing_fn.\n      specs: A dict of feature name to tf.TypeSpecs. If `force_tf_compat_v1` is\n        True, this can also be feature specifications.\n      force_tf_compat_v1: (Optional) If `True`, use Tensorflow in compat.v1 mode.\n        Defaults to `False`.\n\n    Returns:\n    -------\n      A list of columns that are required inputs of analyzers.\n    \"\"\"\n    use_tf_compat_v1 = tf2_utils.use_tf_compat_v1(force_tf_compat_v1)\n    if not use_tf_compat_v1:\n        assert all([isinstance(s, tf.TypeSpec) for s in specs.values()]), specs\n    graph, structured_inputs, structured_outputs = (\n        impl_helper.trace_preprocessing_function(\n            preprocessing_fn, specs, use_tf_compat_v1=use_tf_compat_v1\n        )\n    )\n\n    tensor_sinks = graph.get_collection(analyzer_nodes.TENSOR_REPLACEMENTS)\n    visitor = graph_tools.SourcedTensorsVisitor()\n    for tensor_sink in tensor_sinks:\n        nodes.Traverser(visitor).visit_value_node(tensor_sink.future)\n\n    if use_tf_compat_v1:\n        control_dependency_ops = []\n    else:\n        # If traced in TF2 as a tf.function, inputs that end up in control\n        # dependencies are required for the function to execute. Return such inputs\n        # as required inputs of analyzers as well.\n        _, control_dependency_ops = (\n            tf2_utils.strip_and_get_tensors_and_control_dependencies(\n                tf.nest.flatten(structured_outputs, expand_composites=True)\n            )\n        )\n\n    output_tensors = list(\n        itertools.chain(visitor.sourced_tensors, control_dependency_ops)\n    )\n    analyze_input_tensors = graph_tools.get_dependent_inputs(\n        graph, structured_inputs, output_tensors\n    )\n    return list(analyze_input_tensors.keys())\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.get_num_buckets_for_transformed_feature","title":"get_num_buckets_for_transformed_feature","text":"<pre><code>get_num_buckets_for_transformed_feature(\n    transformed_feature: TensorType,\n) -&gt; Tensor\n</code></pre> <p>Provides the number of buckets for a transformed feature if annotated.</p> <p>This for example can be used for the direct output of <code>tft.bucketize</code>, <code>tft.apply_buckets</code>, <code>tft.compute_and_apply_vocabulary</code>, <code>tft.apply_vocabulary</code>. These methods annotate the transformed feature with additional information. If the given <code>transformed_feature</code> isn't annotated, this method will fail.</p>"},{"location":"api_docs/python/tft/#tensorflow_transform.get_num_buckets_for_transformed_feature--example","title":"Example:","text":"<p>def preprocessing_fn(inputs): ...   bucketized = tft.bucketize(inputs['x'], num_buckets=3) ...   integerized = tft.compute_and_apply_vocabulary(inputs['x']) ...   zeros = tf.zeros_like(inputs['x'], tf.int64) ...   return { ...      'bucketized': bucketized, ...      'bucketized_num_buckets': ( ...         zeros + tft.get_num_buckets_for_transformed_feature(bucketized)), ...      'integerized': integerized, ...      'integerized_num_buckets': ( ...         zeros + tft.get_num_buckets_for_transformed_feature(integerized)), ...   } raw_data = [dict(x=3),dict(x=23)] feature_spec = dict(x=tf.io.FixedLenFeature([], tf.int64)) raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec) with tft_beam.Context(temp_dir=tempfile.mkdtemp()): ...   transformed_dataset, transform_fn = ( ...       (raw_data, raw_data_metadata) ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn)) transformed_data, transformed_metadata = transformed_dataset transformed_data [{'bucketized': 1, 'bucketized_num_buckets': 3,  'integerized': 0, 'integerized_num_buckets': 2}, {'bucketized': 2, 'bucketized_num_buckets': 3,  'integerized': 1, 'integerized_num_buckets': 2}]</p> <p>transformed_feature: A <code>Tensor</code> or <code>SparseTensor</code> which is the direct output     of <code>tft.bucketize</code>, <code>tft.apply_buckets</code>,     <code>tft.compute_and_apply_vocabulary</code> or <code>tft.apply_vocabulary</code>.</p> <p>ValueError: If the given tensor has not been annotated a the number of   buckets.</p> <p>A <code>Tensor</code> with the number of buckets for the given <code>transformed_feature</code>.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef get_num_buckets_for_transformed_feature(\n    transformed_feature: common_types.TensorType,\n) -&gt; tf.Tensor:\n    # pyformat: disable\n    \"\"\"Provides the number of buckets for a transformed feature if annotated.\n\n    This for example can be used for the direct output of `tft.bucketize`,\n    `tft.apply_buckets`, `tft.compute_and_apply_vocabulary`,\n    `tft.apply_vocabulary`.\n    These methods annotate the transformed feature with additional information.\n    If the given `transformed_feature` isn't annotated, this method will fail.\n\n    Example:\n    -------\n    &gt;&gt;&gt; def preprocessing_fn(inputs):\n    ...   bucketized = tft.bucketize(inputs['x'], num_buckets=3)\n    ...   integerized = tft.compute_and_apply_vocabulary(inputs['x'])\n    ...   zeros = tf.zeros_like(inputs['x'], tf.int64)\n    ...   return {\n    ...      'bucketized': bucketized,\n    ...      'bucketized_num_buckets': (\n    ...         zeros + tft.get_num_buckets_for_transformed_feature(bucketized)),\n    ...      'integerized': integerized,\n    ...      'integerized_num_buckets': (\n    ...         zeros + tft.get_num_buckets_for_transformed_feature(integerized)),\n    ...   }\n    &gt;&gt;&gt; raw_data = [dict(x=3),dict(x=23)]\n    &gt;&gt;&gt; feature_spec = dict(x=tf.io.FixedLenFeature([], tf.int64))\n    &gt;&gt;&gt; raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec)\n    &gt;&gt;&gt; with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n    ...   transformed_dataset, transform_fn = (\n    ...       (raw_data, raw_data_metadata)\n    ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\n    &gt;&gt;&gt; transformed_data, transformed_metadata = transformed_dataset\n    &gt;&gt;&gt; transformed_data\n    [{'bucketized': 1, 'bucketized_num_buckets': 3,\n     'integerized': 0, 'integerized_num_buckets': 2},\n    {'bucketized': 2, 'bucketized_num_buckets': 3,\n     'integerized': 1, 'integerized_num_buckets': 2}]\n\n    Args:\n    ----\n      transformed_feature: A `Tensor` or `SparseTensor` which is the direct output\n        of `tft.bucketize`, `tft.apply_buckets`,\n        `tft.compute_and_apply_vocabulary` or `tft.apply_vocabulary`.\n\n    Raises:\n    ------\n      ValueError: If the given tensor has not been annotated a the number of\n      buckets.\n\n    Returns:\n    -------\n      A `Tensor` with the number of buckets for the given `transformed_feature`.\n    \"\"\"\n    # pyformat: enable\n    # Adding 1 to the 2nd Tensor of the returned pair in order to compute max + 1.\n    return tf.cast(\n        schema_inference.get_tensor_schema_override(transformed_feature)[1] + 1,\n        tf.int64,\n    )\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.get_transform_input_columns","title":"get_transform_input_columns","text":"<pre><code>get_transform_input_columns(\n    preprocessing_fn: Callable[\n        [Mapping[str, TensorType]], Mapping[str, TensorType]\n    ],\n    specs: Mapping[str, Union[FeatureSpecType, TypeSpec]],\n    force_tf_compat_v1: bool = False,\n) -&gt; List[str]\n</code></pre> <p>Return columns that are required inputs of <code>TransformDataset</code>.</p> <p>preprocessing_fn: A tf.transform preprocessing_fn.   specs: A dict of feature name to tf.TypeSpecs. If <code>force_tf_compat_v1</code> is     True, this can also be feature specifications.   force_tf_compat_v1: (Optional) If <code>True</code>, use Tensorflow in compat.v1 mode.     Defaults to <code>False</code>.</p> <p>A list of columns that are required inputs of the transform <code>tf.Graph</code>   defined by <code>preprocessing_fn</code>.</p> Source code in <code>tensorflow_transform/inspect_preprocessing_fn.py</code> <pre><code>def get_transform_input_columns(\n    preprocessing_fn: Callable[\n        [Mapping[str, common_types.TensorType]], Mapping[str, common_types.TensorType]\n    ],\n    specs: Mapping[str, Union[common_types.FeatureSpecType, tf.TypeSpec]],\n    force_tf_compat_v1: bool = False,\n) -&gt; List[str]:\n    \"\"\"Return columns that are required inputs of `TransformDataset`.\n\n    Args:\n    ----\n      preprocessing_fn: A tf.transform preprocessing_fn.\n      specs: A dict of feature name to tf.TypeSpecs. If `force_tf_compat_v1` is\n        True, this can also be feature specifications.\n      force_tf_compat_v1: (Optional) If `True`, use Tensorflow in compat.v1 mode.\n        Defaults to `False`.\n\n    Returns:\n    -------\n      A list of columns that are required inputs of the transform `tf.Graph`\n      defined by `preprocessing_fn`.\n    \"\"\"\n    use_tf_compat_v1 = tf2_utils.use_tf_compat_v1(force_tf_compat_v1)\n    if not use_tf_compat_v1:\n        assert all([isinstance(s, tf.TypeSpec) for s in specs.values()]), specs\n    graph, structured_inputs, structured_outputs = (\n        impl_helper.trace_preprocessing_function(\n            preprocessing_fn, specs, use_tf_compat_v1=use_tf_compat_v1\n        )\n    )\n\n    transform_input_tensors = graph_tools.get_dependent_inputs(\n        graph, structured_inputs, structured_outputs\n    )\n    return list(transform_input_tensors.keys())\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.hash_strings","title":"hash_strings","text":"<pre><code>hash_strings(\n    strings: ConsistentTensorType,\n    hash_buckets: int,\n    key: Optional[Iterable[int]] = None,\n    name: Optional[str] = None,\n) -&gt; ConsistentTensorType\n</code></pre> <p>Hash strings into buckets.</p> <p>strings: a <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of dtype <code>tf.string</code>.   hash_buckets: the number of hash buckets.   key: optional. An array of two Python <code>uint64</code>. If passed, output will be a     deterministic function of <code>strings</code> and <code>key</code>. Note that hashing will be     slower if this value is specified.   name: (Optional) A name for this operation.</p> <p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of dtype <code>tf.int64</code> with the   same shape as   the input <code>strings</code>.</p> <p>TypeError: if <code>strings</code> is not a <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>   of dtype <code>tf.string</code>.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef hash_strings(\n    strings: common_types.ConsistentTensorType,\n    hash_buckets: int,\n    key: Optional[Iterable[int]] = None,\n    name: Optional[str] = None,\n) -&gt; common_types.ConsistentTensorType:\n    \"\"\"Hash strings into buckets.\n\n    Args:\n    ----\n      strings: a `Tensor`, `SparseTensor`, or `RaggedTensor` of dtype `tf.string`.\n      hash_buckets: the number of hash buckets.\n      key: optional. An array of two Python `uint64`. If passed, output will be a\n        deterministic function of `strings` and `key`. Note that hashing will be\n        slower if this value is specified.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A `Tensor`, `SparseTensor`, or `RaggedTensor` of dtype `tf.int64` with the\n      same shape as\n      the input `strings`.\n\n    Raises:\n    ------\n      TypeError: if `strings` is not a `Tensor`, `SparseTensor`, or `RaggedTensor`\n      of dtype `tf.string`.\n    \"\"\"\n    if (\n        not isinstance(strings, (tf.Tensor, tf.SparseTensor, tf.RaggedTensor))\n        or strings.dtype != tf.string\n    ):\n        raise TypeError(\n            \"Input to hash_strings must be a `Tensor`, `SparseTensor`, or \"\n            f\"`RaggedTensor` of dtype string; got {strings.dtype}\"\n        )\n    if isinstance(strings, tf.Tensor):\n        if name is None:\n            name = \"hash_strings\"\n        if key is None:\n            return tf.strings.to_hash_bucket_fast(strings, hash_buckets, name=name)\n        return tf.strings.to_hash_bucket_strong(strings, hash_buckets, key, name=name)\n    else:\n        compose_result_fn = _make_composite_tensor_wrapper_if_composite(strings)\n        values = tf_utils.get_values(strings)\n        return compose_result_fn(hash_strings(values, hash_buckets, key))\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.histogram","title":"histogram","text":"<pre><code>histogram(\n    x: TensorType,\n    boundaries: Optional[Union[Tensor, int]] = None,\n    categorical: Optional[bool] = False,\n    name: Optional[str] = None,\n) -&gt; Tuple[Tensor, Tensor]\n</code></pre> <p>Computes a histogram over x, given the bin boundaries or bin count.</p> <p>Ex (1): counts, boundaries = histogram([0, 1, 0, 1, 0, 3, 0, 1], range(5)) counts: [4, 3, 0, 1, 0] boundaries: [0, 1, 2, 3, 4]</p> <p>Ex (2): Can be used to compute class weights. counts, classes = histogram([0, 1, 0, 1, 0, 3, 0, 1], categorical=True) probabilities = counts / tf.reduce_sum(counts) class_weights = dict(map(lambda (a, b): (a.numpy(), 1.0 / b.numpy()),                          zip(classes, probabilities)))</p> <p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.   boundaries: (Optional) A <code>Tensor</code> or <code>int</code> used to build the histogram;     ignored if <code>categorical</code> is True. If possible, provide boundaries as     multiple sorted values.  Default to 10 intervals over the 0-1 range, or     find the min/max if an int is provided (not recommended because     multi-phase analysis is inefficient).   categorical: (Optional) A <code>bool</code> that treats <code>x</code> as discrete values if true.   name: (Optional) A name for this operation.</p> <p>counts: The histogram, as counts per bin.   boundaries: A <code>Tensor</code> used to build the histogram representing boundaries.</p> Source code in <code>tensorflow_transform/analyzers.py</code> <pre><code>@common.log_api_use(common.ANALYZER_COLLECTION)\ndef histogram(\n    x: common_types.TensorType,\n    boundaries: Optional[Union[tf.Tensor, int]] = None,\n    categorical: Optional[bool] = False,\n    name: Optional[str] = None,\n) -&gt; Tuple[tf.Tensor, tf.Tensor]:\n    \"\"\"Computes a histogram over x, given the bin boundaries or bin count.\n\n    Ex (1):\n    counts, boundaries = histogram([0, 1, 0, 1, 0, 3, 0, 1], range(5))\n    counts: [4, 3, 0, 1, 0]\n    boundaries: [0, 1, 2, 3, 4]\n\n    Ex (2):\n    Can be used to compute class weights.\n    counts, classes = histogram([0, 1, 0, 1, 0, 3, 0, 1], categorical=True)\n    probabilities = counts / tf.reduce_sum(counts)\n    class_weights = dict(map(lambda (a, b): (a.numpy(), 1.0 / b.numpy()),\n                             zip(classes, probabilities)))\n\n    Args:\n    ----\n      x: A `Tensor`, `SparseTensor`, or `RaggedTensor`.\n      boundaries: (Optional) A `Tensor` or `int` used to build the histogram;\n        ignored if `categorical` is True. If possible, provide boundaries as\n        multiple sorted values.  Default to 10 intervals over the 0-1 range, or\n        find the min/max if an int is provided (not recommended because\n        multi-phase analysis is inefficient).\n      categorical: (Optional) A `bool` that treats `x` as discrete values if true.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      counts: The histogram, as counts per bin.\n      boundaries: A `Tensor` used to build the histogram representing boundaries.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"histogram\"):\n        x = tf.reshape(tf_utils.get_values(x), [-1])\n        if categorical:\n            x_dtype = x.dtype\n            x = x if x_dtype == tf.string else tf.strings.as_string(x)\n            elements, counts = count_per_key(x)\n            if x_dtype != elements.dtype:\n                elements = tf.strings.to_number(elements, tf.int64)\n            return counts, elements\n\n        if boundaries is None:\n            boundaries = tf.range(11, dtype=tf.float32) / 10.0\n        elif isinstance(boundaries, int) or (\n            isinstance(boundaries, tf.Tensor) and boundaries.get_shape().ndims == 0\n        ):\n            min_value, max_value = _min_and_max(x, True)\n            boundaries = tf.linspace(\n                tf.cast(min_value, tf.float32),\n                tf.cast(max_value, tf.float32),\n                tf.cast(boundaries, tf.int64),\n            )\n\n        # Shift the boundaries slightly to account for floating point errors,\n        # and due to the fact that the rightmost boundary is essentially ignored.\n        boundaries = tf.expand_dims(tf.cast(boundaries, tf.float32), 0) - 0.0001\n\n        bucket_indices = tf_utils.assign_buckets(\n            tf.cast(x, tf.float32), remove_leftmost_boundary(boundaries)\n        )\n        bucket_vocab, counts = count_per_key(tf.strings.as_string(bucket_indices))\n        counts = tf_utils.reorder_histogram(\n            bucket_vocab, counts, tf.size(boundaries) - 1\n        )\n        return counts, boundaries\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.make_and_track_object","title":"make_and_track_object","text":"<pre><code>make_and_track_object(\n    trackable_factory_callable: Callable[[], Trackable],\n    name: Optional[str] = None,\n) -&gt; Trackable\n</code></pre> <p>Keeps track of the object created by invoking <code>trackable_factory_callable</code>.</p> <p>This API is only for use when Transform APIs are run with TF2 behaviors enabled and <code>tft_beam.Context.force_tf_compat_v1</code> is set to False.</p> <p>Use this API to track TF Trackable objects created in the <code>preprocessing_fn</code> such as tf.hub modules, tf.data.Dataset etc. This ensures they are serialized correctly when exporting to SavedModel.</p> <p>trackable_factory_callable: A callable that creates and returns a Trackable     object.   name: (Optional) Provide a unique name to track this object with. If the     Trackable object created is a Keras Layer or Model this is needed for     proper tracking.</p>"},{"location":"api_docs/python/tft/#tensorflow_transform.make_and_track_object--example","title":"Example:","text":"<p>def preprocessing_fn(inputs): ...   dataset = tft.make_and_track_object( ...       lambda: tf.data.Dataset.from_tensor_slices([1, 2, 3])) ...   with tf.init_scope(): ...     dataset_list = list(dataset.as_numpy_iterator()) ...   return {'x_0': dataset_list[0] + inputs['x']} raw_data = [dict(x=1), dict(x=2), dict(x=3)] feature_spec = dict(x=tf.io.FixedLenFeature([], tf.int64)) raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec) with tft_beam.Context(temp_dir=tempfile.mkdtemp(), ...                       force_tf_compat_v1=False): ...   transformed_dataset, transform_fn = ( ...       (raw_data, raw_data_metadata) ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn)) transformed_data, transformed_metadata = transformed_dataset transformed_data [{'x_0': 2}, {'x_0': 3}, {'x_0': 4}]</p> <p>The object returned when trackable_factory_callable is invoked. The object   creation is lifted out to the eager context using <code>tf.init_scope</code>.</p> Source code in <code>tensorflow_transform/annotators.py</code> <pre><code>def make_and_track_object(\n    trackable_factory_callable: Callable[[], base.Trackable], name: Optional[str] = None\n) -&gt; base.Trackable:\n    # pyformat: disable\n    \"\"\"Keeps track of the object created by invoking `trackable_factory_callable`.\n\n    This API is only for use when Transform APIs are run with TF2 behaviors\n    enabled and `tft_beam.Context.force_tf_compat_v1` is set to False.\n\n    Use this API to track TF Trackable objects created in the `preprocessing_fn`\n    such as tf.hub modules, tf.data.Dataset etc. This ensures they are serialized\n    correctly when exporting to SavedModel.\n\n    Args:\n    ----\n      trackable_factory_callable: A callable that creates and returns a Trackable\n        object.\n      name: (Optional) Provide a unique name to track this object with. If the\n        Trackable object created is a Keras Layer or Model this is needed for\n        proper tracking.\n\n    Example:\n    -------\n    &gt;&gt;&gt; def preprocessing_fn(inputs):\n    ...   dataset = tft.make_and_track_object(\n    ...       lambda: tf.data.Dataset.from_tensor_slices([1, 2, 3]))\n    ...   with tf.init_scope():\n    ...     dataset_list = list(dataset.as_numpy_iterator())\n    ...   return {'x_0': dataset_list[0] + inputs['x']}\n    &gt;&gt;&gt; raw_data = [dict(x=1), dict(x=2), dict(x=3)]\n    &gt;&gt;&gt; feature_spec = dict(x=tf.io.FixedLenFeature([], tf.int64))\n    &gt;&gt;&gt; raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec)\n    &gt;&gt;&gt; with tft_beam.Context(temp_dir=tempfile.mkdtemp(),\n    ...                       force_tf_compat_v1=False):\n    ...   transformed_dataset, transform_fn = (\n    ...       (raw_data, raw_data_metadata)\n    ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\n    &gt;&gt;&gt; transformed_data, transformed_metadata = transformed_dataset\n    &gt;&gt;&gt; transformed_data\n    [{'x_0': 2}, {'x_0': 3}, {'x_0': 4}]\n\n    Returns:\n    -------\n      The object returned when trackable_factory_callable is invoked. The object\n      creation is lifted out to the eager context using `tf.init_scope`.\n    \"\"\"\n    # pyformat: enable\n    if not tf.inside_function():\n        raise ValueError(\n            \"This API should only be invoked inside the user defined \"\n            \"`preprocessing_fn` with TF2 behaviors enabled and \"\n            \"`force_tf_compat_v1=False`. \"\n        )\n    result = _get_object(name) if name is not None else None\n    if result is None:\n        with tf.init_scope():\n            result = trackable_factory_callable()\n            if name is None and isinstance(result, tf_keras.layers.Layer):\n                raise ValueError(\n                    \"Please pass a unique `name` to this API to ensure Keras objects \"\n                    \"are tracked correctly.\"\n                )\n            track_object(result, name)\n    return result\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.max","title":"max","text":"<pre><code>max(\n    x: TensorType,\n    reduce_instance_dims: bool = True,\n    name: Optional[str] = None,\n) -&gt; Tensor\n</code></pre> <p>Computes the maximum of the values of <code>x</code> over the whole dataset.</p> <p>In the case of a <code>CompositeTensor</code> missing values will be used in return value: for float, NaN is used and for other dtypes the min is used.</p> <p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.   reduce_instance_dims: By default collapses the batch and instance dimensions     to arrive at a single scalar output. If False, only collapses the batch     dimension and outputs a vector of the same shape as the input.   name: (Optional) A name for this operation.</p> <p>A <code>Tensor</code>. Has the same type as <code>x</code>.</p> <p>TypeError: If the type of <code>x</code> is not supported.</p> Source code in <code>tensorflow_transform/analyzers.py</code> <pre><code>@common.log_api_use(common.ANALYZER_COLLECTION)\ndef max(  # pylint: disable=redefined-builtin\n    x: common_types.TensorType,\n    reduce_instance_dims: bool = True,\n    name: Optional[str] = None,\n) -&gt; tf.Tensor:\n    \"\"\"Computes the maximum of the values of `x` over the whole dataset.\n\n    In the case of a `CompositeTensor` missing values will be used in return\n    value: for float, NaN is used and for other dtypes the min is used.\n\n    Args:\n    ----\n      x: A `Tensor`, `SparseTensor`, or `RaggedTensor`.\n      reduce_instance_dims: By default collapses the batch and instance dimensions\n        to arrive at a single scalar output. If False, only collapses the batch\n        dimension and outputs a vector of the same shape as the input.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A `Tensor`. Has the same type as `x`.\n\n    Raises:\n    ------\n      TypeError: If the type of `x` is not supported.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"max\"):\n        return _min_and_max(x, reduce_instance_dims, name)[1]\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.mean","title":"mean","text":"<pre><code>mean(\n    x: TensorType,\n    reduce_instance_dims: bool = True,\n    name: Optional[str] = None,\n    output_dtype: Optional[DType] = None,\n) -&gt; Tensor\n</code></pre> <p>Computes the mean of the values of a <code>Tensor</code> over the whole dataset.</p> <p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>. Its type must be floating       point (float{16|32|64}), or integral ([u]int{8|16|32|64}).   reduce_instance_dims: By default collapses the batch and instance dimensions       to arrive at a single scalar output. If False, only collapses the batch       dimension and outputs a vector of the same shape as the input.   name: (Optional) A name for this operation.   output_dtype: (Optional) If not None, casts the output tensor to this type.</p> <p>A <code>Tensor</code> containing the mean. If <code>x</code> is floating point, the mean will have   the same type as <code>x</code>. If <code>x</code> is integral, the output is cast to float32.   NaNs and infinite input values are ignored.</p> <p>TypeError: If the type of <code>x</code> is not supported.</p> Source code in <code>tensorflow_transform/analyzers.py</code> <pre><code>@common.log_api_use(common.ANALYZER_COLLECTION)\ndef mean(\n    x: common_types.TensorType,\n    reduce_instance_dims: bool = True,\n    name: Optional[str] = None,\n    output_dtype: Optional[tf.DType] = None,\n) -&gt; tf.Tensor:\n    \"\"\"Computes the mean of the values of a `Tensor` over the whole dataset.\n\n    Args:\n    ----\n      x: A `Tensor`, `SparseTensor`, or `RaggedTensor`. Its type must be floating\n          point (float{16|32|64}), or integral ([u]int{8|16|32|64}).\n      reduce_instance_dims: By default collapses the batch and instance dimensions\n          to arrive at a single scalar output. If False, only collapses the batch\n          dimension and outputs a vector of the same shape as the input.\n      name: (Optional) A name for this operation.\n      output_dtype: (Optional) If not None, casts the output tensor to this type.\n\n    Returns:\n    -------\n      A `Tensor` containing the mean. If `x` is floating point, the mean will have\n      the same type as `x`. If `x` is integral, the output is cast to float32.\n      NaNs and infinite input values are ignored.\n\n    Raises:\n    ------\n      TypeError: If the type of `x` is not supported.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"mean\"):\n        return _mean_and_var(x, reduce_instance_dims, output_dtype)[0]\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.min","title":"min","text":"<pre><code>min(\n    x: TensorType,\n    reduce_instance_dims: bool = True,\n    name: Optional[str] = None,\n) -&gt; Tensor\n</code></pre> <p>Computes the minimum of the values of <code>x</code> over the whole dataset.</p> <p>In the case of a <code>CompositeTensor</code> missing values will be used in return value: for float, NaN is used and for other dtypes the max is used.</p> <p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.   reduce_instance_dims: By default collapses the batch and instance dimensions     to arrive at a single scalar output. If False, only collapses the batch     dimension and outputs a <code>Tensor</code> of the same shape as the input.   name: (Optional) A name for this operation.</p> <p>A <code>Tensor</code> with the same type as <code>x</code>.</p> <p>TypeError: If the type of <code>x</code> is not supported.</p> Source code in <code>tensorflow_transform/analyzers.py</code> <pre><code>@common.log_api_use(common.ANALYZER_COLLECTION)\ndef min(  # pylint: disable=redefined-builtin\n    x: common_types.TensorType,\n    reduce_instance_dims: bool = True,\n    name: Optional[str] = None,\n) -&gt; tf.Tensor:\n    \"\"\"Computes the minimum of the values of `x` over the whole dataset.\n\n    In the case of a `CompositeTensor` missing values will be used in return\n    value: for float, NaN is used and for other dtypes the max is used.\n\n    Args:\n    ----\n      x: A `Tensor`, `SparseTensor`, or `RaggedTensor`.\n      reduce_instance_dims: By default collapses the batch and instance dimensions\n        to arrive at a single scalar output. If False, only collapses the batch\n        dimension and outputs a `Tensor` of the same shape as the input.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A `Tensor` with the same type as `x`.\n\n    Raises:\n    ------\n      TypeError: If the type of `x` is not supported.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"min\"):\n        return _min_and_max(x, reduce_instance_dims, name)[0]\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.ngrams","title":"ngrams","text":"<pre><code>ngrams(\n    tokens: SparseTensor,\n    ngram_range: Tuple[int, int],\n    separator: str,\n    name: Optional[str] = None,\n) -&gt; SparseTensor\n</code></pre> <p>Create a <code>SparseTensor</code> of n-grams.</p> <p>Given a <code>SparseTensor</code> of tokens, returns a <code>SparseTensor</code> containing the ngrams that can be constructed from each row.</p> <p><code>separator</code> is inserted between each pair of tokens, so \" \" would be an appropriate choice if the tokens are words, while \"\" would be an appropriate choice if they are characters.</p>"},{"location":"api_docs/python/tft/#tensorflow_transform.ngrams--example","title":"Example:","text":"<p>tokens = tf.SparseTensor( ...         indices=[[0, 0], [0, 1], [0, 2], [1, 0], [1, 1], [1, 2], [1, 3]], ...         values=['One', 'was', 'Johnny', 'Two', 'was', 'a', 'rat'], ...         dense_shape=[2, 4]) print(tft.ngrams(tokens, ngram_range=(1, 3), separator=' ')) SparseTensor(indices=tf.Tensor(     [[0 0][0 1] [0 2][0 3] [0 4][0 5]      [1 0][1 1] [1 2][1 3] [1 4][1 5] [1 6][1 7] [1 8]],      shape=(15, 2), dtype=int64),   values=tf.Tensor(     [b'One' b'One was' b'One was Johnny' b'was' b'was Johnny' b'Johnny' b'Two'      b'Two was' b'Two was a' b'was' b'was a' b'was a rat' b'a' b'a rat'      b'rat'], shape=(15,), dtype=string),   dense_shape=tf.Tensor([2 9], shape=(2,), dtype=int64))</p> <p>tokens: a two-dimensional<code>SparseTensor</code> of dtype <code>tf.string</code> containing     tokens that will be used to construct ngrams.   ngram_range: A pair with the range (inclusive) of ngram sizes to return.   separator: a string that will be inserted between tokens when ngrams are     constructed.   name: (Optional) A name for this operation.</p> <p>A <code>SparseTensor</code> containing all ngrams from each row of the input. Note:   if an ngram appears multiple times in the input row, it will be present the   same number of times in the output. For unique ngrams, see tft.bag_of_words.</p> <p>ValueError: if <code>tokens</code> is not 2D.   ValueError: if ngram_range[0] &lt; 1 or ngram_range[1] &lt; ngram_range[0]</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef ngrams(\n    tokens: tf.SparseTensor,\n    ngram_range: Tuple[int, int],\n    separator: str,\n    name: Optional[str] = None,\n) -&gt; tf.SparseTensor:\n    \"\"\"Create a `SparseTensor` of n-grams.\n\n    Given a `SparseTensor` of tokens, returns a `SparseTensor` containing the\n    ngrams that can be constructed from each row.\n\n    `separator` is inserted between each pair of tokens, so \" \" would be an\n    appropriate choice if the tokens are words, while \"\" would be an appropriate\n    choice if they are characters.\n\n    Example:\n    -------\n    &gt;&gt;&gt; tokens = tf.SparseTensor(\n    ...         indices=[[0, 0], [0, 1], [0, 2], [1, 0], [1, 1], [1, 2], [1, 3]],\n    ...         values=['One', 'was', 'Johnny', 'Two', 'was', 'a', 'rat'],\n    ...         dense_shape=[2, 4])\n    &gt;&gt;&gt; print(tft.ngrams(tokens, ngram_range=(1, 3), separator=' '))\n    SparseTensor(indices=tf.Tensor(\n        [[0 0] [0 1] [0 2] [0 3] [0 4] [0 5]\n         [1 0] [1 1] [1 2] [1 3] [1 4] [1 5] [1 6] [1 7] [1 8]],\n         shape=(15, 2), dtype=int64),\n      values=tf.Tensor(\n        [b'One' b'One was' b'One was Johnny' b'was' b'was Johnny' b'Johnny' b'Two'\n         b'Two was' b'Two was a' b'was' b'was a' b'was a rat' b'a' b'a rat'\n         b'rat'], shape=(15,), dtype=string),\n      dense_shape=tf.Tensor([2 9], shape=(2,), dtype=int64))\n\n    Args:\n    ----\n      tokens: a two-dimensional`SparseTensor` of dtype `tf.string` containing\n        tokens that will be used to construct ngrams.\n      ngram_range: A pair with the range (inclusive) of ngram sizes to return.\n      separator: a string that will be inserted between tokens when ngrams are\n        constructed.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A `SparseTensor` containing all ngrams from each row of the input. Note:\n      if an ngram appears multiple times in the input row, it will be present the\n      same number of times in the output. For unique ngrams, see tft.bag_of_words.\n\n    Raises:\n    ------\n      ValueError: if `tokens` is not 2D.\n      ValueError: if ngram_range[0] &lt; 1 or ngram_range[1] &lt; ngram_range[0]\n    \"\"\"\n    # This function is implemented as follows.  Assume we start with the following\n    # `SparseTensor`:\n    #\n    # indices=[[0, 0], [0, 1], [0, 2], [0, 3], [1, 0], [2, 0], [2, 1], [2, 2]]\n    # values=['a', 'b', 'c', 'd', 'q', 'x', 'y', 'z']\n    # dense_shape=[3, 4]\n    #\n    # First we then create shifts of the values and first column of indices,\n    # buffering to avoid overrunning the end of the array, so the shifted values\n    # (if we are ngrams up to size 3) are\n    #\n    # shifted_batch_indices[0]=[0, 0, 0, 0, 1, 2, 2, 2]\n    # shifted_tokens[0]=['a', 'b', 'c', 'd', 'q', 'x', 'y', 'z']\n    #\n    # shifted_batch_indices[1]=[0, 0, 0, 1, 2, 2, 2, -1]\n    # shifted_tokens[1]=['b', 'c', 'd', 'q', 'x', 'y', 'z', '']\n    #\n    # shifted_batch_indices[2]=[0, 0, 1, 2, 2, 2, -1, -1]\n    # shifted_tokens[2]=['c', 'd', 'q', 'x', 'y', 'z', '', '']\n    #\n    # These shifted ngrams are used to create the ngrams as follows.  We use\n    # tf.string_join to join shifted_tokens[:k] to create k-grams. The `separator`\n    # string is inserted between each pair of tokens in the k-gram.\n    # The batch that the first of these belonged to is given by\n    # shifted_batch_indices[0]. However some of these will cross the boundaries\n    # between 'batches' and so we we create a boolean mask which is True when\n    # shifted_indices[:k] are all equal.\n    #\n    # This results in tensors of ngrams, their batch indices and a boolean mask,\n    # which we then use to construct the output SparseTensor.\n    if tokens.get_shape().ndims != 2:\n        raise ValueError(\"ngrams requires `tokens` to be 2-dimensional\")\n    with tf.compat.v1.name_scope(name, \"ngrams\"):\n        if ngram_range[0] &lt; 1 or ngram_range[1] &lt; ngram_range[0]:\n            raise ValueError(\"Invalid ngram_range: %r\" % (ngram_range,))\n\n        def _sliding_windows(values, num_shifts, fill_value):\n            buffered_values = tf.concat(\n                [values, tf.fill([num_shifts - 1], fill_value)], 0\n            )\n            return [\n                tf.slice(buffered_values, [i], tf.shape(input=values))\n                for i in range(num_shifts)\n            ]\n\n        shifted_batch_indices = _sliding_windows(\n            tokens.indices[:, 0], ngram_range[1] + 1, tf.constant(-1, dtype=tf.int64)\n        )\n        shifted_tokens = _sliding_windows(tokens.values, ngram_range[1] + 1, \"\")\n\n        # Construct a tensor of the form\n        # [['a', 'ab, 'abc'], ['b', 'bcd', cde'], ...]\n        def _string_join(tensors):\n            if tensors:\n                return tf.strings.join(tensors, separator=separator)\n            else:\n                return None\n\n        ngrams_array = [\n            _string_join(shifted_tokens[:k])\n            for k in range(ngram_range[0], ngram_range[1] + 1)\n        ]\n        ngrams_tensor = tf.stack(ngrams_array, 1)\n\n        # Construct a boolean mask for whether each ngram in ngram_tensor is valid,\n        # in that each character came from the same batch.\n        valid_ngram = tf.equal(\n            tf.math.cumprod(\n                tf.cast(\n                    tf.equal(\n                        tf.stack(shifted_batch_indices, 1),\n                        tf.expand_dims(shifted_batch_indices[0], 1),\n                    ),\n                    dtype=tf.int32,\n                ),\n                axis=1,\n            ),\n            1,\n        )\n        valid_ngram = valid_ngram[:, (ngram_range[0] - 1) : ngram_range[1]]\n\n        # Construct a tensor with the batch that each ngram in ngram_tensor belongs\n        # to.\n        batch_indices = tf.tile(\n            tf.expand_dims(tokens.indices[:, 0], 1),\n            [1, ngram_range[1] + 1 - ngram_range[0]],\n        )\n\n        # Apply the boolean mask and construct a SparseTensor with the given indices\n        # and values, where another index is added to give the position within a\n        # batch.\n        batch_indices = tf.boolean_mask(tensor=batch_indices, mask=valid_ngram)\n        ngrams_tensor = tf.boolean_mask(tensor=ngrams_tensor, mask=valid_ngram)\n        instance_indices = segment_indices(batch_indices)\n        dense_shape_second_dim = (\n            tf.maximum(tf.reduce_max(input_tensor=instance_indices), -1) + 1\n        )\n        return tf.SparseTensor(\n            indices=tf.stack([batch_indices, instance_indices], 1),\n            values=ngrams_tensor,\n            dense_shape=tf.stack([tokens.dense_shape[0], dense_shape_second_dim]),\n        )\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.pca","title":"pca","text":"<pre><code>pca(\n    x: Tensor,\n    output_dim: int,\n    dtype: DType,\n    name: Optional[str] = None,\n) -&gt; Tensor\n</code></pre> <p>Computes PCA on the dataset using biased covariance.</p> <p>The PCA analyzer computes output_dim orthonormal vectors that capture directions/axes corresponding to the highest variances in the input vectors of <code>x</code>. The output vectors are returned as a rank-2 tensor with shape <code>(input_dim, output_dim)</code>, where the 0th dimension are the components of each output vector, and the 1st dimension are the output vectors representing orthogonal directions in the input space, sorted in order of decreasing variances.</p> <p>The output rank-2 tensor (matrix) serves a useful transform purpose. Formally, the matrix can be used downstream in the transform step by multiplying it to the input tensor <code>x</code>. This transform reduces the dimension of input vectors to output_dim in a way that retains the maximal variance.</p> <p>NOTE: To properly use PCA, input vector components should be converted to similar units of measurement such that the vectors represent a Euclidean space. If no such conversion is available (e.g. one element represents time, another element distance), the canonical approach is to first apply a transformation to the input data to normalize numerical variances, i.e. <code>tft.scale_to_z_score()</code>. Normalization allows PCA to choose output axes that help decorrelate input axes.</p> <p>Below are a couple intuitive examples of PCA.</p> <p>Consider a simple 2-dimensional example:</p> <p>Input x is a series of vectors <code>[e, e]</code> where <code>e</code> is Gaussian with mean 0, variance 1. The two components are perfectly correlated, and the resulting covariance matrix is</p> <pre><code>[[1 1],\n [1 1]].\n</code></pre> <p>Applying PCA with <code>output_dim = 1</code> would discover the first principal component <code>[1 / sqrt(2), 1 / sqrt(2)]</code>. When multipled to the original example, each vector <code>[e, e]</code> would be mapped to a scalar <code>sqrt(2) * e</code>. The second principal component would be <code>[-1 / sqrt(2), 1 / sqrt(2)]</code> and would map <code>[e, e]</code> to 0, which indicates that the second component captures no variance at all. This agrees with our intuition since we know that the two axes in the input are perfectly correlated and can be fully explained by a single scalar <code>e</code>.</p> <p>Consider a 3-dimensional example:</p> <p>Input <code>x</code> is a series of vectors <code>[a, a, b]</code>, where <code>a</code> is a zero-mean, unit variance Gaussian and <code>b</code> is a zero-mean, variance 4 Gaussian and is independent of <code>a</code>. The first principal component of the unnormalized vector would be <code>[0, 0, 1]</code> since <code>b</code> has a much larger variance than any linear combination of the first two components. This would map <code>[a, a, b]</code> onto <code>b</code>, asserting that the axis with highest energy is the third component. While this may be the desired output if <code>a</code> and <code>b</code> correspond to the same units, it is not statistically desireable when the units are irreconciliable. In such a case, one should first normalize each component to unit variance first, i.e. <code>b := b / 2</code>. The first principal component of a normalized vector would yield <code>[1 / sqrt(2), 1 / sqrt(2), 0]</code>, and would map <code>[a, a, b]</code> to <code>sqrt(2) * a</code>. The second component would be <code>[0, 0, 1]</code> and map <code>[a, a, b]</code> to <code>b</code>. As can be seen, the benefit of normalization is that PCA would capture highly correlated components first and collapse them into a lower dimension.</p> <p>x: A rank-2 <code>Tensor</code>, 0th dim are rows, 1st dim are indices in row vectors.   output_dim: The PCA output dimension (number of eigenvectors to return).   dtype: Tensorflow dtype of entries in the returned matrix.   name: (Optional) A name for this operation.</p> <p>ValueError: if input is not a rank-2 Tensor.</p> <p>A 2D <code>Tensor</code> (matrix) M of shape (input_dim, output_dim).</p> Source code in <code>tensorflow_transform/analyzers.py</code> <pre><code>@common.log_api_use(common.ANALYZER_COLLECTION)\ndef pca(\n    x: tf.Tensor, output_dim: int, dtype: tf.DType, name: Optional[str] = None\n) -&gt; tf.Tensor:\n    \"\"\"Computes PCA on the dataset using biased covariance.\n\n    The PCA analyzer computes output_dim orthonormal vectors that capture\n    directions/axes corresponding to the highest variances in the input vectors of\n    `x`. The output vectors are returned as a rank-2 tensor with shape\n    `(input_dim, output_dim)`, where the 0th dimension are the components of each\n    output vector, and the 1st dimension are the output vectors representing\n    orthogonal directions in the input space, sorted in order of decreasing\n    variances.\n\n    The output rank-2 tensor (matrix) serves a useful transform purpose. Formally,\n    the matrix can be used downstream in the transform step by multiplying it to\n    the input tensor `x`. This transform reduces the dimension of input vectors to\n    output_dim in a way that retains the maximal variance.\n\n    NOTE: To properly use PCA, input vector components should be converted to\n    similar units of measurement such that the vectors represent a Euclidean\n    space. If no such conversion is available (e.g. one element represents time,\n    another element distance), the canonical approach is to first apply a\n    transformation to the input data to normalize numerical variances, i.e.\n    `tft.scale_to_z_score()`. Normalization allows PCA to choose output axes that\n    help decorrelate input axes.\n\n    Below are a couple intuitive examples of PCA.\n\n    Consider a simple 2-dimensional example:\n\n    Input x is a series of vectors `[e, e]` where `e` is Gaussian with mean 0,\n    variance 1. The two components are perfectly correlated, and the resulting\n    covariance matrix is\n\n    ```\n    [[1 1],\n     [1 1]].\n    ```\n\n    Applying PCA with `output_dim = 1` would discover the first principal\n    component `[1 / sqrt(2), 1 / sqrt(2)]`. When multipled to the original\n    example, each vector `[e, e]` would be mapped to a scalar `sqrt(2) * e`. The\n    second principal component would be `[-1 / sqrt(2), 1 / sqrt(2)]` and would\n    map `[e, e]` to 0, which indicates that the second component captures no\n    variance at all. This agrees with our intuition since we know that the two\n    axes in the input are perfectly correlated and can be fully explained by a\n    single scalar `e`.\n\n    Consider a 3-dimensional example:\n\n    Input `x` is a series of vectors `[a, a, b]`, where `a` is a zero-mean, unit\n    variance Gaussian and `b` is a zero-mean, variance 4 Gaussian and is\n    independent of `a`. The first principal component of the unnormalized vector\n    would be `[0, 0, 1]` since `b` has a much larger variance than any linear\n    combination of the first two components. This would map `[a, a, b]` onto `b`,\n    asserting that the axis with highest energy is the third component. While this\n    may be the desired output if `a` and `b` correspond to the same units, it is\n    not statistically desireable when the units are irreconciliable. In such a\n    case, one should first normalize each component to unit variance first, i.e.\n    `b := b / 2`. The first principal component of a normalized vector would yield\n    `[1 / sqrt(2), 1 / sqrt(2), 0]`, and would map `[a, a, b]` to `sqrt(2) * a`.\n    The second component would be `[0, 0, 1]` and map `[a, a, b]` to `b`. As can\n    be seen, the benefit of normalization is that PCA would capture highly\n    correlated components first and collapse them into a lower dimension.\n\n    Args:\n    ----\n      x: A rank-2 `Tensor`, 0th dim are rows, 1st dim are indices in row vectors.\n      output_dim: The PCA output dimension (number of eigenvectors to return).\n      dtype: Tensorflow dtype of entries in the returned matrix.\n      name: (Optional) A name for this operation.\n\n    Raises:\n    ------\n      ValueError: if input is not a rank-2 Tensor.\n\n    Returns:\n    -------\n      A 2D `Tensor` (matrix) M of shape (input_dim, output_dim).\n    \"\"\"\n    if not isinstance(x, tf.Tensor):\n        raise TypeError(\"Expected a Tensor, but got %r\" % x)\n\n    with tf.compat.v1.name_scope(name, \"pca\"):\n        x.shape.assert_has_rank(2)\n\n        input_dim = x.shape.as_list()[1]\n        shape = (input_dim, output_dim)\n\n        (result,) = _apply_cacheable_combiner(\n            PCACombiner(shape, output_dim, dtype.as_numpy_dtype), x\n        )\n        return result\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.quantiles","title":"quantiles","text":"<pre><code>quantiles(\n    x: Tensor,\n    num_buckets: int,\n    epsilon: float,\n    weights: Optional[Tensor] = None,\n    reduce_instance_dims: bool = True,\n    name: Optional[str] = None,\n) -&gt; Tensor\n</code></pre> <p>Computes the quantile boundaries of a <code>Tensor</code> over the whole dataset.</p> <p>Quantile boundaries are computed using approximate quantiles, and error tolerance is specified using <code>epsilon</code>. The boundaries divide the input tensor into approximately equal <code>num_buckets</code> parts. See go/squawd for details, and how to control the error due to approximation. NaN input values and values with NaN weights are ignored.</p> <p>x: An input <code>Tensor</code>.   num_buckets: Values in the <code>x</code> are divided into approximately equal-sized     buckets, where the number of buckets is <code>num_buckets</code>. The number of     returned quantiles is <code>num_buckets</code> - 1.   epsilon: Error tolerance, typically a small fraction close to zero (e.g.     0.01). Higher values of epsilon increase the quantile approximation, and     hence result in more unequal buckets, but could improve performance,     and resource consumption.  Some measured results on memory consumption:       For epsilon = 0.001, the amount of memory for each buffer to hold the       summary for 1 trillion input values is ~25000 bytes. If epsilon is       relaxed to 0.01, the buffer size drops to ~2000 bytes for the same input       size. The buffer size also determines the amount of work in the       different stages of the beam pipeline, in general, larger epsilon       results in fewer and smaller stages, and less time. For more performance       trade-offs see also http://web.cs.ucla.edu/~weiwang/paper/SSDBM07_2.pdf   weights: (Optional) Weights tensor for the quantiles. Tensor must have the     same batch size as x.   reduce_instance_dims: By default collapses the batch and instance dimensions       to arrive at a single output vector. If False, only collapses the batch       dimension and outputs a vector of the same shape as the input.   name: (Optional) A name for this operation.</p> <p>The bucket boundaries represented as a list, with num_bucket-1 elements,   unless reduce_instance_dims is False, which results in a Tensor of   shape x.shape + [num_bucket-1].   See code below for discussion on the type of bucket boundaries.</p> Source code in <code>tensorflow_transform/analyzers.py</code> <pre><code>@common.log_api_use(common.ANALYZER_COLLECTION)\ndef quantiles(\n    x: tf.Tensor,\n    num_buckets: int,\n    epsilon: float,\n    weights: Optional[tf.Tensor] = None,\n    reduce_instance_dims: bool = True,\n    name: Optional[str] = None,\n) -&gt; tf.Tensor:\n    \"\"\"Computes the quantile boundaries of a `Tensor` over the whole dataset.\n\n    Quantile boundaries are computed using approximate quantiles,\n    and error tolerance is specified using `epsilon`. The boundaries divide the\n    input tensor into approximately equal `num_buckets` parts.\n    See go/squawd for details, and how to control the error due to approximation.\n    NaN input values and values with NaN weights are ignored.\n\n    Args:\n    ----\n      x: An input `Tensor`.\n      num_buckets: Values in the `x` are divided into approximately equal-sized\n        buckets, where the number of buckets is `num_buckets`. The number of\n        returned quantiles is `num_buckets` - 1.\n      epsilon: Error tolerance, typically a small fraction close to zero (e.g.\n        0.01). Higher values of epsilon increase the quantile approximation, and\n        hence result in more unequal buckets, but could improve performance,\n        and resource consumption.  Some measured results on memory consumption:\n          For epsilon = 0.001, the amount of memory for each buffer to hold the\n          summary for 1 trillion input values is ~25000 bytes. If epsilon is\n          relaxed to 0.01, the buffer size drops to ~2000 bytes for the same input\n          size. The buffer size also determines the amount of work in the\n          different stages of the beam pipeline, in general, larger epsilon\n          results in fewer and smaller stages, and less time. For more performance\n          trade-offs see also http://web.cs.ucla.edu/~weiwang/paper/SSDBM07_2.pdf\n      weights: (Optional) Weights tensor for the quantiles. Tensor must have the\n        same batch size as x.\n      reduce_instance_dims: By default collapses the batch and instance dimensions\n          to arrive at a single output vector. If False, only collapses the batch\n          dimension and outputs a vector of the same shape as the input.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      The bucket boundaries represented as a list, with num_bucket-1 elements,\n      unless reduce_instance_dims is False, which results in a Tensor of\n      shape x.shape + [num_bucket-1].\n      See code below for discussion on the type of bucket boundaries.\n    \"\"\"\n    # Quantile ops convert input values to double under the hood. Keep bucket\n    # boundaries as float for all numeric types.\n    bucket_dtype = tf.float32\n    with tf.compat.v1.name_scope(name, \"quantiles\"):\n        if weights is None:\n            analyzer_inputs = [x]\n            has_weights = False\n        else:\n            analyzer_inputs = [x, weights]\n            has_weights = True\n        feature_shape = [] if reduce_instance_dims else x.get_shape().as_list()[1:]\n        output_shape = (feature_shape if feature_shape else [1]) + [num_buckets - 1]\n        combiner = QuantilesCombiner(\n            num_buckets,\n            epsilon,\n            bucket_dtype.as_numpy_dtype,\n            has_weights=has_weights,\n            output_shape=output_shape,\n            feature_shape=feature_shape,\n        )\n        (quantile_boundaries,) = _apply_cacheable_combiner(combiner, *analyzer_inputs)\n        return quantile_boundaries\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.scale_by_min_max","title":"scale_by_min_max","text":"<pre><code>scale_by_min_max(\n    x: ConsistentTensorType,\n    output_min: float = 0.0,\n    output_max: float = 1.0,\n    elementwise: bool = False,\n    name: Optional[str] = None,\n) -&gt; ConsistentTensorType\n</code></pre> <p>Scale a numerical column into the range [output_min, output_max].</p> <p>x: A numeric <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.   output_min: The minimum of the range of output values.   output_max: The maximum of the range of output values.   elementwise: If true, scale each element of the tensor independently.   name: (Optional) A name for this operation.</p> <p>A <code>Tensor</code> containing the input column scaled to [output_min, output_max].   If the analysis dataset is empty or contains a singe distinct value, then   <code>x</code> is scaled using a sigmoid function.</p> <p>ValueError: If output_min, output_max have the wrong order.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef scale_by_min_max(\n    x: common_types.ConsistentTensorType,\n    output_min: float = 0.0,\n    output_max: float = 1.0,\n    elementwise: bool = False,\n    name: Optional[str] = None,\n) -&gt; common_types.ConsistentTensorType:\n    \"\"\"Scale a numerical column into the range [output_min, output_max].\n\n    Args:\n    ----\n      x: A numeric `Tensor`, `SparseTensor`, or `RaggedTensor`.\n      output_min: The minimum of the range of output values.\n      output_max: The maximum of the range of output values.\n      elementwise: If true, scale each element of the tensor independently.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A `Tensor` containing the input column scaled to [output_min, output_max].\n      If the analysis dataset is empty or contains a singe distinct value, then\n      `x` is scaled using a sigmoid function.\n\n    Raises:\n    ------\n      ValueError: If output_min, output_max have the wrong order.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"scale_by_min_max\"):\n        return _scale_by_min_max_internal(\n            x,\n            key=None,\n            output_min=output_min,\n            output_max=output_max,\n            elementwise=elementwise,\n            key_vocabulary_filename=None,\n        )\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.scale_by_min_max_per_key","title":"scale_by_min_max_per_key","text":"<pre><code>scale_by_min_max_per_key(\n    x: ConsistentTensorType,\n    key: TensorType,\n    output_min: float = 0.0,\n    output_max: float = 1.0,\n    elementwise: bool = False,\n    key_vocabulary_filename: Optional[str] = None,\n    name: Optional[str] = None,\n) -&gt; ConsistentTensorType\n</code></pre> <p>Scale a numerical column into a predefined range on a per-key basis.</p> <p>x: A numeric <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.   key: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of dtype tf.string.       Must meet one of the following conditions:       0. key is None       1. Both x and key are dense,       2. Both x and key are composite and <code>key</code> must exactly match <code>x</code> in          everything except values,       3. The axis=1 index of each x matches its index of dense key.   output_min: The minimum of the range of output values.   output_max: The maximum of the range of output values.   elementwise: If true, scale each element of the tensor independently.   key_vocabulary_filename: (Optional) The file name for the per-key file.     If None, this combiner will assume the keys fit in memory and will not     store the analyzer result in a file. If '', a file name will be chosen     based on the current TensorFlow scope. If not '', it should be unique     within a given preprocessing function.   name: (Optional) A name for this operation.</p>"},{"location":"api_docs/python/tft/#tensorflow_transform.scale_by_min_max_per_key--example","title":"Example:","text":"<p>def preprocessing_fn(inputs): ...   return { ...      'scaled': tft.scale_by_min_max_per_key(inputs['x'], inputs['s']) ...   } raw_data = [dict(x=1, s='a'), dict(x=0, s='b'), dict(x=3, s='a')] feature_spec = dict( ...     x=tf.io.FixedLenFeature([], tf.float32), ...     s=tf.io.FixedLenFeature([], tf.string)) raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec) with tft_beam.Context(temp_dir=tempfile.mkdtemp()): ...   transformed_dataset, transform_fn = ( ...       (raw_data, raw_data_metadata) ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn)) transformed_data, transformed_metadata = transformed_dataset transformed_data [{'scaled': 0.0}, {'scaled': 0.5}, {'scaled': 1.0}]</p> <p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> containing the input column scaled to   [output_min, output_max] on a per-key basis if a key is provided. If the   analysis dataset is empty, a certain key contains a single distinct value or   the computed key vocabulary doesn't have an entry for <code>key</code>, then <code>x</code> is   scaled using a sigmoid function.</p> <p>ValueError: If output_min, output_max have the wrong order.   NotImplementedError: If elementwise is True and key is not None.   InvalidArgumentError: If indices of sparse x and key do not match.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef scale_by_min_max_per_key(\n    x: common_types.ConsistentTensorType,\n    key: common_types.TensorType,\n    output_min: float = 0.0,\n    output_max: float = 1.0,\n    elementwise: bool = False,\n    key_vocabulary_filename: Optional[str] = None,\n    name: Optional[str] = None,\n) -&gt; common_types.ConsistentTensorType:\n    # pyformat: disable\n    \"\"\"Scale a numerical column into a predefined range on a per-key basis.\n\n    Args:\n    ----\n      x: A numeric `Tensor`, `SparseTensor`, or `RaggedTensor`.\n      key: A `Tensor`, `SparseTensor`, or `RaggedTensor` of dtype tf.string.\n          Must meet one of the following conditions:\n          0. key is None\n          1. Both x and key are dense,\n          2. Both x and key are composite and `key` must exactly match `x` in\n             everything except values,\n          3. The axis=1 index of each x matches its index of dense key.\n      output_min: The minimum of the range of output values.\n      output_max: The maximum of the range of output values.\n      elementwise: If true, scale each element of the tensor independently.\n      key_vocabulary_filename: (Optional) The file name for the per-key file.\n        If None, this combiner will assume the keys fit in memory and will not\n        store the analyzer result in a file. If '', a file name will be chosen\n        based on the current TensorFlow scope. If not '', it should be unique\n        within a given preprocessing function.\n      name: (Optional) A name for this operation.\n\n    Example:\n    -------\n    &gt;&gt;&gt; def preprocessing_fn(inputs):\n    ...   return {\n    ...      'scaled': tft.scale_by_min_max_per_key(inputs['x'], inputs['s'])\n    ...   }\n    &gt;&gt;&gt; raw_data = [dict(x=1, s='a'), dict(x=0, s='b'), dict(x=3, s='a')]\n    &gt;&gt;&gt; feature_spec = dict(\n    ...     x=tf.io.FixedLenFeature([], tf.float32),\n    ...     s=tf.io.FixedLenFeature([], tf.string))\n    &gt;&gt;&gt; raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec)\n    &gt;&gt;&gt; with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n    ...   transformed_dataset, transform_fn = (\n    ...       (raw_data, raw_data_metadata)\n    ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\n    &gt;&gt;&gt; transformed_data, transformed_metadata = transformed_dataset\n    &gt;&gt;&gt; transformed_data\n    [{'scaled': 0.0}, {'scaled': 0.5}, {'scaled': 1.0}]\n\n    Returns:\n    -------\n      A `Tensor`, `SparseTensor`, or `RaggedTensor` containing the input column scaled to\n      [output_min, output_max] on a per-key basis if a key is provided. If the\n      analysis dataset is empty, a certain key contains a single distinct value or\n      the computed key vocabulary doesn't have an entry for `key`, then `x` is\n      scaled using a sigmoid function.\n\n    Raises:\n    ------\n      ValueError: If output_min, output_max have the wrong order.\n      NotImplementedError: If elementwise is True and key is not None.\n      InvalidArgumentError: If indices of sparse x and key do not match.\n    \"\"\"\n    # pyformat: enable\n    with tf.compat.v1.name_scope(name, \"scale_by_min_max_per_key\"):\n        if key is None:\n            raise ValueError(\"key is None, call `tft.scale_by_min_max` instead\")\n        return _scale_by_min_max_internal(\n            x,\n            key=key,\n            output_min=output_min,\n            output_max=output_max,\n            elementwise=elementwise,\n            key_vocabulary_filename=key_vocabulary_filename,\n        )\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.scale_to_0_1","title":"scale_to_0_1","text":"<pre><code>scale_to_0_1(\n    x: ConsistentTensorType,\n    elementwise: bool = False,\n    name: Optional[str] = None,\n) -&gt; ConsistentTensorType\n</code></pre> <p>Returns a column which is the input column scaled to have range [0,1].</p> <p>x: A numeric <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.   elementwise: If true, scale each element of the tensor independently.   name: (Optional) A name for this operation.</p> <p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> containing the input column   scaled to   [0, 1]. If the analysis dataset is empty or contains a single distinct   value, then <code>x</code> is scaled using a sigmoid function.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef scale_to_0_1(\n    x: common_types.ConsistentTensorType,\n    elementwise: bool = False,\n    name: Optional[str] = None,\n) -&gt; common_types.ConsistentTensorType:\n    \"\"\"Returns a column which is the input column scaled to have range [0,1].\n\n    Args:\n    ----\n      x: A numeric `Tensor`, `SparseTensor`, or `RaggedTensor`.\n      elementwise: If true, scale each element of the tensor independently.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A `Tensor`, `SparseTensor`, or `RaggedTensor` containing the input column\n      scaled to\n      [0, 1]. If the analysis dataset is empty or contains a single distinct\n      value, then `x` is scaled using a sigmoid function.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"scale_to_0_1\"):\n        return _scale_by_min_max_internal(\n            x,\n            key=None,\n            output_min=0,\n            output_max=1,\n            elementwise=elementwise,\n            key_vocabulary_filename=None,\n        )\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.scale_to_0_1_per_key","title":"scale_to_0_1_per_key","text":"<pre><code>scale_to_0_1_per_key(\n    x: ConsistentTensorType,\n    key: TensorType,\n    elementwise: bool = False,\n    key_vocabulary_filename: Optional[str] = None,\n    name: Optional[str] = None,\n) -&gt; ConsistentTensorType\n</code></pre> <p>Returns a column which is the input column scaled to have range [0,1].</p> <p>x: A numeric <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.   key: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of type string.   elementwise: If true, scale each element of the tensor independently.   key_vocabulary_filename: (Optional) The file name for the per-key file. If     None, this combiner will assume the keys fit in memory and will not store     the analyzer result in a file. If '', a file name will be chosen based on     the current TensorFlow scope. If not '', it should be unique within a     given preprocessing function.   name: (Optional) A name for this operation.</p>"},{"location":"api_docs/python/tft/#tensorflow_transform.scale_to_0_1_per_key--example","title":"Example:","text":"<p>def preprocessing_fn(inputs): ...   return { ...      'scaled': tft.scale_to_0_1_per_key(inputs['x'], inputs['s']) ...   } raw_data = [dict(x=1, s='a'), dict(x=0, s='b'), dict(x=3, s='a')] feature_spec = dict( ...     x=tf.io.FixedLenFeature([], tf.float32), ...     s=tf.io.FixedLenFeature([], tf.string)) raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec) with tft_beam.Context(temp_dir=tempfile.mkdtemp()): ...   transformed_dataset, transform_fn = ( ...       (raw_data, raw_data_metadata) ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn)) transformed_data, transformed_metadata = transformed_dataset transformed_data [{'scaled': 0.0}, {'scaled': 0.5}, {'scaled': 1.0}]</p> <p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> containing the input column scaled to [0, 1],   per key. If the analysis dataset is empty, contains a single distinct value   or the computed key vocabulary doesn't have an entry for <code>key</code>, then <code>x</code> is   scaled using a sigmoid function.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef scale_to_0_1_per_key(\n    x: common_types.ConsistentTensorType,\n    key: common_types.TensorType,\n    elementwise: bool = False,\n    key_vocabulary_filename: Optional[str] = None,\n    name: Optional[str] = None,\n) -&gt; common_types.ConsistentTensorType:\n    # pyformat: disable\n    \"\"\"Returns a column which is the input column scaled to have range [0,1].\n\n    Args:\n    ----\n      x: A numeric `Tensor`, `SparseTensor`, or `RaggedTensor`.\n      key: A `Tensor`, `SparseTensor`, or `RaggedTensor` of type string.\n      elementwise: If true, scale each element of the tensor independently.\n      key_vocabulary_filename: (Optional) The file name for the per-key file. If\n        None, this combiner will assume the keys fit in memory and will not store\n        the analyzer result in a file. If '', a file name will be chosen based on\n        the current TensorFlow scope. If not '', it should be unique within a\n        given preprocessing function.\n      name: (Optional) A name for this operation.\n\n    Example:\n    -------\n    &gt;&gt;&gt; def preprocessing_fn(inputs):\n    ...   return {\n    ...      'scaled': tft.scale_to_0_1_per_key(inputs['x'], inputs['s'])\n    ...   }\n    &gt;&gt;&gt; raw_data = [dict(x=1, s='a'), dict(x=0, s='b'), dict(x=3, s='a')]\n    &gt;&gt;&gt; feature_spec = dict(\n    ...     x=tf.io.FixedLenFeature([], tf.float32),\n    ...     s=tf.io.FixedLenFeature([], tf.string))\n    &gt;&gt;&gt; raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec)\n    &gt;&gt;&gt; with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n    ...   transformed_dataset, transform_fn = (\n    ...       (raw_data, raw_data_metadata)\n    ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\n    &gt;&gt;&gt; transformed_data, transformed_metadata = transformed_dataset\n    &gt;&gt;&gt; transformed_data\n    [{'scaled': 0.0}, {'scaled': 0.5}, {'scaled': 1.0}]\n\n    Returns:\n    -------\n      A `Tensor`, `SparseTensor`, or `RaggedTensor` containing the input column scaled to [0, 1],\n      per key. If the analysis dataset is empty, contains a single distinct value\n      or the computed key vocabulary doesn't have an entry for `key`, then `x` is\n      scaled using a sigmoid function.\n    \"\"\"\n    # pyformat: enable\n    with tf.compat.v1.name_scope(name, \"scale_to_0_1_per_key\"):\n        if key is None:\n            raise ValueError(\"key is None, call `tft.scale_to_0_1` instead\")\n        return _scale_by_min_max_internal(\n            x,\n            key=key,\n            output_min=0,\n            output_max=1,\n            elementwise=elementwise,\n            key_vocabulary_filename=key_vocabulary_filename,\n        )\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.scale_to_gaussian","title":"scale_to_gaussian","text":"<pre><code>scale_to_gaussian(\n    x: ConsistentTensorType,\n    elementwise: bool = False,\n    name: Optional[str] = None,\n    output_dtype: Optional[DType] = None,\n) -&gt; ConsistentTensorType\n</code></pre> <p>Returns an (approximately) normal column with mean to 0 and variance 1.</p> <p>We transform the column to values that are approximately distributed according to a standard normal distribution. The transformation is obtained by applying the moments method to estimate the parameters of a Tukey HH distribution and applying the inverse of the estimated function to the column values. The method is partially described in</p> <p>Georg M. Georgm \"The Lambert Way to Gaussianize Heavy-Tailed Data with the Inverse of Tukey's h Transformation as a Special Case,\" The Scientific World Journal, Vol. 2015, Hindawi Publishing Corporation.</p> <p>We use the L-moments instead of conventional moments to be able to deal with long-tailed distributions. The expressions of the L-moments for the Tukey HH distribution is in</p> <p>Todd C. Headrick, and Mohan D. Pant. \"Characterizing Tukey H and HH-Distributions through L-Moments and the L-Correlation,\" ISRN Applied Mathematics, vol. 2012, 2012. doi:10.5402/2012/980153</p> <p>Note that the transformation to Gaussian is applied only if the column has long-tails. If this is not the case, for instance if values are uniformly distributed, the values are only normalized using the z score. This applies also to the cases where only one of the tails is long; the other tail is only rescaled but not non linearly transformed. Also, if the analysis set is empty, the transformation is set to to leave the input vaules unchanged.</p> <p>x: A numeric <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.   elementwise: If true, scales each element of the tensor independently;     otherwise uses the parameters of the whole tensor.   name: (Optional) A name for this operation.   output_dtype: (Optional) If not None, casts the output tensor to this type.</p> <p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> containing the input column   transformed to be approximately standard distributed (i.e. a Gaussian with   mean 0 and variance 1). If <code>x</code> is floating point, the mean will have the   same type as <code>x</code>. If <code>x</code> is integral, the output is cast to tf.float32.</p> <p>Note that TFLearn generally permits only tf.int64 and tf.float32, so casting   this scaler's output may be necessary.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef scale_to_gaussian(\n    x: common_types.ConsistentTensorType,\n    elementwise: bool = False,\n    name: Optional[str] = None,\n    output_dtype: Optional[tf.DType] = None,\n) -&gt; common_types.ConsistentTensorType:\n    \"\"\"Returns an (approximately) normal column with mean to 0 and variance 1.\n\n    We transform the column to values that are approximately distributed\n    according to a standard normal distribution.\n    The transformation is obtained by applying the moments method to estimate\n    the parameters of a Tukey HH distribution and applying the inverse of the\n    estimated function to the column values.\n    The method is partially described in\n\n    Georg M. Georgm \"The Lambert Way to Gaussianize Heavy-Tailed Data with the\n    Inverse of Tukey's h Transformation as a Special Case,\" The Scientific World\n    Journal, Vol. 2015, Hindawi Publishing Corporation.\n\n    We use the L-moments instead of conventional moments to be able to deal with\n    long-tailed distributions. The expressions of the L-moments for the Tukey HH\n    distribution is in\n\n    Todd C. Headrick, and Mohan D. Pant. \"Characterizing Tukey H and\n    HH-Distributions through L-Moments and the L-Correlation,\" ISRN Applied\n    Mathematics, vol. 2012, 2012. doi:10.5402/2012/980153\n\n    Note that the transformation to Gaussian is applied only if the column has\n    long-tails. If this is not the case, for instance if values are uniformly\n    distributed, the values are only normalized using the z score. This applies\n    also to the cases where only one of the tails is long; the other tail is only\n    rescaled but not non linearly transformed.\n    Also, if the analysis set is empty, the transformation is set to to leave the\n    input vaules unchanged.\n\n    Args:\n    ----\n      x: A numeric `Tensor`, `SparseTensor`, or `RaggedTensor`.\n      elementwise: If true, scales each element of the tensor independently;\n        otherwise uses the parameters of the whole tensor.\n      name: (Optional) A name for this operation.\n      output_dtype: (Optional) If not None, casts the output tensor to this type.\n\n    Returns:\n    -------\n      A `Tensor`, `SparseTensor`, or `RaggedTensor` containing the input column\n      transformed to be approximately standard distributed (i.e. a Gaussian with\n      mean 0 and variance 1). If `x` is floating point, the mean will have the\n      same type as `x`. If `x` is integral, the output is cast to tf.float32.\n\n      Note that TFLearn generally permits only tf.int64 and tf.float32, so casting\n      this scaler's output may be necessary.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"scale_to_gaussian\"):\n        return _scale_to_gaussian_internal(\n            x=x, elementwise=elementwise, output_dtype=output_dtype\n        )\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.scale_to_z_score","title":"scale_to_z_score","text":"<pre><code>scale_to_z_score(\n    x: ConsistentTensorType,\n    elementwise: bool = False,\n    name: Optional[str] = None,\n    output_dtype: Optional[DType] = None,\n) -&gt; ConsistentTensorType\n</code></pre> <p>Returns a standardized column with mean 0 and variance 1.</p> <p>Scaling to z-score subtracts out the mean and divides by standard deviation. Note that the standard deviation computed here is based on the biased variance (0 delta degrees of freedom), as computed by analyzers.var.</p> <p>x: A numeric <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.   elementwise: If true, scales each element of the tensor independently;     otherwise uses the mean and variance of the whole tensor.   name: (Optional) A name for this operation.   output_dtype: (Optional) If not None, casts the output tensor to this type.</p> <p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> containing the input column   scaled to mean 0   and variance 1 (standard deviation 1), given by: (x - mean(x)) / std_dev(x).   If <code>x</code> is floating point, the mean will have the same type as <code>x</code>. If <code>x</code> is   integral, the output is cast to tf.float32. If the analysis dataset is empty   or contains a single distinct value, then the input is returned without   scaling.</p> <p>Note that TFLearn generally permits only tf.int64 and tf.float32, so casting   this scaler's output may be necessary.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef scale_to_z_score(\n    x: common_types.ConsistentTensorType,\n    elementwise: bool = False,\n    name: Optional[str] = None,\n    output_dtype: Optional[tf.DType] = None,\n) -&gt; common_types.ConsistentTensorType:\n    \"\"\"Returns a standardized column with mean 0 and variance 1.\n\n    Scaling to z-score subtracts out the mean and divides by standard deviation.\n    Note that the standard deviation computed here is based on the biased variance\n    (0 delta degrees of freedom), as computed by analyzers.var.\n\n    Args:\n    ----\n      x: A numeric `Tensor`, `SparseTensor`, or `RaggedTensor`.\n      elementwise: If true, scales each element of the tensor independently;\n        otherwise uses the mean and variance of the whole tensor.\n      name: (Optional) A name for this operation.\n      output_dtype: (Optional) If not None, casts the output tensor to this type.\n\n    Returns:\n    -------\n      A `Tensor`, `SparseTensor`, or `RaggedTensor` containing the input column\n      scaled to mean 0\n      and variance 1 (standard deviation 1), given by: (x - mean(x)) / std_dev(x).\n      If `x` is floating point, the mean will have the same type as `x`. If `x` is\n      integral, the output is cast to tf.float32. If the analysis dataset is empty\n      or contains a single distinct value, then the input is returned without\n      scaling.\n\n      Note that TFLearn generally permits only tf.int64 and tf.float32, so casting\n      this scaler's output may be necessary.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"scale_to_z_score\"):\n        return _scale_to_z_score_internal(\n            x=x,\n            key=None,\n            elementwise=elementwise,\n            key_vocabulary_filename=None,\n            output_dtype=output_dtype,\n        )\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.scale_to_z_score_per_key","title":"scale_to_z_score_per_key","text":"<pre><code>scale_to_z_score_per_key(\n    x: ConsistentTensorType,\n    key: TensorType,\n    elementwise: bool = False,\n    key_vocabulary_filename: Optional[str] = None,\n    name: Optional[str] = None,\n    output_dtype: Optional[DType] = None,\n) -&gt; ConsistentTensorType\n</code></pre> <p>Returns a standardized column with mean 0 and variance 1, grouped per key.</p> <p>Scaling to z-score subtracts out the mean and divides by standard deviation. Note that the standard deviation computed here is based on the biased variance (0 delta degrees of freedom), as computed by analyzers.var.</p> <p>x: A numeric <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.   key: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of dtype tf.string. Must     meet one of the following conditions:     0. key is None,     1. Both x and key are dense,     2. Both x and key are sparse and <code>key</code> must exactly match <code>x</code> in     everything except values,     3. The axis=1 index of each x matches its index of dense key.   elementwise: If true, scales each element of the tensor independently;     otherwise uses the mean and variance of the whole tensor. Currently, not     supported for per-key operations.   key_vocabulary_filename: (Optional) The file name for the per-key file. If     None, this combiner will assume the keys fit in memory and will not store     the analyzer result in a file. If '', a file name will be chosen based on     the current TensorFlow scope. If not '', it should be unique within a     given preprocessing function.   name: (Optional) A name for this operation.   output_dtype: (Optional) If not None, casts the output tensor to this type.</p> <p>A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> containing the input column   scaled to mean 0   and variance 1 (standard deviation 1), grouped per key if a key is provided.</p> <p>That is, for all keys k: (x - mean(x)) / std_dev(x) for all x with key k.   If <code>x</code> is floating point, the mean will have the same type as <code>x</code>. If <code>x</code> is   integral, the output is cast to tf.float32. If the analysis dataset is   empty, contains a single distinct value or the computed key vocabulary   doesn't have an entry for <code>key</code>, then the input is returned without scaling.</p> <p>Note that TFLearn generally permits only tf.int64 and tf.float32, so casting   this scaler's output may be necessary.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef scale_to_z_score_per_key(\n    x: common_types.ConsistentTensorType,\n    key: common_types.TensorType,\n    elementwise: bool = False,\n    key_vocabulary_filename: Optional[str] = None,\n    name: Optional[str] = None,\n    output_dtype: Optional[tf.DType] = None,\n) -&gt; common_types.ConsistentTensorType:\n    \"\"\"Returns a standardized column with mean 0 and variance 1, grouped per key.\n\n    Scaling to z-score subtracts out the mean and divides by standard deviation.\n    Note that the standard deviation computed here is based on the biased variance\n    (0 delta degrees of freedom), as computed by analyzers.var.\n\n    Args:\n    ----\n      x: A numeric `Tensor`, `SparseTensor`, or `RaggedTensor`.\n      key: A `Tensor`, `SparseTensor`, or `RaggedTensor` of dtype tf.string. Must\n        meet one of the following conditions:\n        0. key is None,\n        1. Both x and key are dense,\n        2. Both x and key are sparse and `key` must exactly match `x` in\n        everything except values,\n        3. The axis=1 index of each x matches its index of dense key.\n      elementwise: If true, scales each element of the tensor independently;\n        otherwise uses the mean and variance of the whole tensor. Currently, not\n        supported for per-key operations.\n      key_vocabulary_filename: (Optional) The file name for the per-key file. If\n        None, this combiner will assume the keys fit in memory and will not store\n        the analyzer result in a file. If '', a file name will be chosen based on\n        the current TensorFlow scope. If not '', it should be unique within a\n        given preprocessing function.\n      name: (Optional) A name for this operation.\n      output_dtype: (Optional) If not None, casts the output tensor to this type.\n\n    Returns:\n    -------\n      A `Tensor`, `SparseTensor`, or `RaggedTensor` containing the input column\n      scaled to mean 0\n      and variance 1 (standard deviation 1), grouped per key if a key is provided.\n\n      That is, for all keys k: (x - mean(x)) / std_dev(x) for all x with key k.\n      If `x` is floating point, the mean will have the same type as `x`. If `x` is\n      integral, the output is cast to tf.float32. If the analysis dataset is\n      empty, contains a single distinct value or the computed key vocabulary\n      doesn't have an entry for `key`, then the input is returned without scaling.\n\n      Note that TFLearn generally permits only tf.int64 and tf.float32, so casting\n      this scaler's output may be necessary.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"scale_to_z_score_per_key\"):\n        if key is None:\n            raise ValueError(\"key is None, call `tft.scale_to_z_score` instead\")\n        return _scale_to_z_score_internal(\n            x=x,\n            key=key,\n            elementwise=elementwise,\n            key_vocabulary_filename=key_vocabulary_filename,\n            output_dtype=output_dtype,\n        )\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.segment_indices","title":"segment_indices","text":"<pre><code>segment_indices(\n    segment_ids: Tensor, name: Optional[str] = None\n) -&gt; Tensor\n</code></pre> <p>Returns a <code>Tensor</code> of indices within each segment.</p> <p>segment_ids should be a sequence of non-decreasing non-negative integers that define a set of segments, e.g. [0, 0, 1, 2, 2, 2] defines 3 segments of length 2, 1 and 3.  The return value is a <code>Tensor</code> containing the indices within each segment.</p>"},{"location":"api_docs/python/tft/#tensorflow_transform.segment_indices--example","title":"Example:","text":"<p>result = tft.segment_indices(tf.constant([0, 0, 1, 2, 2, 2])) print(result) tf.Tensor([0 1 0 0 1 2], shape=(6,), dtype=int32)</p> <p>segment_ids: A 1-d <code>Tensor</code> containing an non-decreasing sequence of     non-negative integers with type <code>tf.int32</code> or <code>tf.int64</code>.   name: (Optional) A name for this operation.</p> <p>A <code>Tensor</code> containing the indices within each segment.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef segment_indices(segment_ids: tf.Tensor, name: Optional[str] = None) -&gt; tf.Tensor:\n    \"\"\"Returns a `Tensor` of indices within each segment.\n\n    segment_ids should be a sequence of non-decreasing non-negative integers that\n    define a set of segments, e.g. [0, 0, 1, 2, 2, 2] defines 3 segments of length\n    2, 1 and 3.  The return value is a `Tensor` containing the indices within each\n    segment.\n\n    Example:\n    -------\n    &gt;&gt;&gt; result = tft.segment_indices(tf.constant([0, 0, 1, 2, 2, 2]))\n    &gt;&gt;&gt; print(result)\n    tf.Tensor([0 1 0 0 1 2], shape=(6,), dtype=int32)\n\n    Args:\n    ----\n      segment_ids: A 1-d `Tensor` containing an non-decreasing sequence of\n        non-negative integers with type `tf.int32` or `tf.int64`.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A `Tensor` containing the indices within each segment.\n    \"\"\"\n    ndims = segment_ids.get_shape().ndims\n    if ndims != 1 and ndims is not None:\n        raise ValueError(\n            \"segment_indices requires a 1-dimensional input. \"\n            \"segment_indices has {} dimensions.\".format(ndims)\n        )\n    with tf.compat.v1.name_scope(name, \"segment_indices\"):\n        # TODO(KesterTong): This is a fundamental operation for segments, write a C++\n        # op to do this.\n        # TODO(KesterTong): Add a check that segment_ids are increasing.\n        segment_lengths = tf.math.segment_sum(tf.ones_like(segment_ids), segment_ids)\n        segment_starts = tf.gather(\n            tf.concat([[0], tf.cumsum(segment_lengths)], 0), segment_ids\n        )\n        return (\n            tf.range(tf.size(input=segment_ids, out_type=segment_ids.dtype))\n            - segment_starts\n        )\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.size","title":"size","text":"<pre><code>size(\n    x: TensorType,\n    reduce_instance_dims: bool = True,\n    name: Optional[str] = None,\n) -&gt; Tensor\n</code></pre> <p>Computes the total size of instances in a <code>Tensor</code> over the whole dataset.</p> <p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>.   reduce_instance_dims: By default collapses the batch and instance dimensions     to arrive at a single scalar output. If False, only collapses the batch     dimension and outputs a vector of the same shape as the input.   name: (Optional) A name for this operation.</p> <p>A <code>Tensor</code> of type int64.</p> Source code in <code>tensorflow_transform/analyzers.py</code> <pre><code>@common.log_api_use(common.ANALYZER_COLLECTION)\ndef size(\n    x: common_types.TensorType,\n    reduce_instance_dims: bool = True,\n    name: Optional[str] = None,\n) -&gt; tf.Tensor:\n    \"\"\"Computes the total size of instances in a `Tensor` over the whole dataset.\n\n    Args:\n    ----\n      x: A `Tensor`, `SparseTensor`, or `RaggedTensor`.\n      reduce_instance_dims: By default collapses the batch and instance dimensions\n        to arrive at a single scalar output. If False, only collapses the batch\n        dimension and outputs a vector of the same shape as the input.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A `Tensor` of type int64.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"size\"):\n        # Note: Calling `sum` defined in this module, not the builtin.\n        if isinstance(x, tf.SparseTensor):\n            ones_like_x = tf.SparseTensor(\n                indices=x.indices,\n                values=tf.ones_like(x.values, tf.int64),\n                dense_shape=x.dense_shape,\n            )\n        else:\n            ones_like_x = tf.ones_like(x, dtype=tf.int64)\n        return sum(ones_like_x, reduce_instance_dims)\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.sparse_tensor_left_align","title":"sparse_tensor_left_align","text":"<pre><code>sparse_tensor_left_align(\n    sparse_tensor: SparseTensor,\n) -&gt; SparseTensor\n</code></pre> <p>Re-arranges a <code>tf.SparseTensor</code> and returns a left-aligned version of it.</p> <p>This mapper can be useful when returning a sparse tensor that may not be left-aligned from a preprocessing_fn.</p> <p>sparse_tensor: A 2D <code>tf.SparseTensor</code>.</p> <p>ValueError if <code>sparse_tensor</code> is not 2D.</p> <p>A left-aligned version of sparse_tensor as a <code>tf.SparseTensor</code>.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef sparse_tensor_left_align(sparse_tensor: tf.SparseTensor) -&gt; tf.SparseTensor:\n    \"\"\"Re-arranges a `tf.SparseTensor` and returns a left-aligned version of it.\n\n    This mapper can be useful when returning a sparse tensor that may not be\n    left-aligned from a preprocessing_fn.\n\n    Args:\n    ----\n      sparse_tensor: A 2D `tf.SparseTensor`.\n\n    Raises:\n    ------\n      ValueError if `sparse_tensor` is not 2D.\n\n    Returns:\n    -------\n      A left-aligned version of sparse_tensor as a `tf.SparseTensor`.\n    \"\"\"\n    if sparse_tensor.get_shape().ndims != 2:\n        raise ValueError(\"sparse_tensor_left_align requires a 2D input\")\n    reordered_tensor = tf.sparse.reorder(sparse_tensor)\n    transposed_indices = tf.transpose(reordered_tensor.indices)\n    row_indices = transposed_indices[0]\n    row_counts = tf.unique_with_counts(row_indices, out_idx=tf.int64).count\n    column_indices = tf.ragged.range(row_counts).flat_values\n    return tf.SparseTensor(\n        indices=tf.transpose(tf.stack([row_indices, column_indices])),\n        values=reordered_tensor.values,\n        dense_shape=reordered_tensor.dense_shape,\n    )\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.sparse_tensor_to_dense_with_shape","title":"sparse_tensor_to_dense_with_shape","text":"<pre><code>sparse_tensor_to_dense_with_shape(\n    x: SparseTensor,\n    shape: Union[TensorShape, Iterable[int]],\n    default_value: Union[Tensor, int, float, str] = 0,\n) -&gt; Tensor\n</code></pre> <p>Converts a <code>SparseTensor</code> into a dense tensor and sets its shape.</p> <p>x: A <code>SparseTensor</code>.   shape: The desired shape of the densified <code>Tensor</code>.   default_value: (Optional) Value to set for indices not specified. Defaults     to zero.</p> <p>A <code>Tensor</code> with the desired shape.</p> <p>ValueError: If input is not a <code>SparseTensor</code>.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef sparse_tensor_to_dense_with_shape(\n    x: tf.SparseTensor,\n    shape: Union[tf.TensorShape, Iterable[int]],\n    default_value: Union[tf.Tensor, int, float, str] = 0,\n) -&gt; tf.Tensor:\n    \"\"\"Converts a `SparseTensor` into a dense tensor and sets its shape.\n\n    Args:\n    ----\n      x: A `SparseTensor`.\n      shape: The desired shape of the densified `Tensor`.\n      default_value: (Optional) Value to set for indices not specified. Defaults\n        to zero.\n\n    Returns:\n    -------\n      A `Tensor` with the desired shape.\n\n    Raises:\n    ------\n      ValueError: If input is not a `SparseTensor`.\n    \"\"\"\n    if not isinstance(x, tf.SparseTensor):\n        raise ValueError(\"input must be a SparseTensor\")\n    new_dense_shape = [\n        x.dense_shape[i] if size is None else size for i, size in enumerate(shape)\n    ]\n    dense = tf.raw_ops.SparseToDense(\n        sparse_indices=x.indices,\n        output_shape=new_dense_shape,\n        sparse_values=x.values,\n        default_value=default_value,\n    )\n    dense.set_shape(shape)\n    return dense\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.sum","title":"sum","text":"<pre><code>sum(\n    x: TensorType,\n    reduce_instance_dims: bool = True,\n    name: Optional[str] = None,\n) -&gt; Tensor\n</code></pre> <p>Computes the sum of the values of a <code>Tensor</code> over the whole dataset.</p> <p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>. Its type must be floating       point (float{16|32|64}),integral (int{8|16|32|64}), or unsigned       integral (uint{8|16}).   reduce_instance_dims: By default collapses the batch and instance dimensions       to arrive at a single scalar output. If False, only collapses the batch       dimension and outputs a vector of the same shape as the input.   name: (Optional) A name for this operation.</p> <p>A <code>Tensor</code> containing the sum. If <code>x</code> is float32 or float64, the sum will   have the same type as <code>x</code>. If <code>x</code> is float16, the output is cast to float32.   If <code>x</code> is integral, the output is cast to [u]int64. If <code>x</code> is sparse and   reduce_inst_dims is False will return 0 in place where column has no values   across batches.</p> <p>TypeError: If the type of <code>x</code> is not supported.</p> Source code in <code>tensorflow_transform/analyzers.py</code> <pre><code>@common.log_api_use(common.ANALYZER_COLLECTION)\ndef sum(  # pylint: disable=redefined-builtin\n    x: common_types.TensorType,\n    reduce_instance_dims: bool = True,\n    name: Optional[str] = None,\n) -&gt; tf.Tensor:\n    \"\"\"Computes the sum of the values of a `Tensor` over the whole dataset.\n\n    Args:\n    ----\n      x: A `Tensor`, `SparseTensor`, or `RaggedTensor`. Its type must be floating\n          point (float{16|32|64}),integral (int{8|16|32|64}), or unsigned\n          integral (uint{8|16}).\n      reduce_instance_dims: By default collapses the batch and instance dimensions\n          to arrive at a single scalar output. If False, only collapses the batch\n          dimension and outputs a vector of the same shape as the input.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A `Tensor` containing the sum. If `x` is float32 or float64, the sum will\n      have the same type as `x`. If `x` is float16, the output is cast to float32.\n      If `x` is integral, the output is cast to [u]int64. If `x` is sparse and\n      reduce_inst_dims is False will return 0 in place where column has no values\n      across batches.\n\n    Raises:\n    ------\n      TypeError: If the type of `x` is not supported.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"sum\"):\n        if reduce_instance_dims:\n            x = tf.reduce_sum(input_tensor=tf_utils.get_values(x))\n        elif isinstance(x, tf.SparseTensor):\n            if x.dtype == tf.uint8 or x.dtype == tf.uint16:\n                x = tf.cast(x, tf.int64)\n            elif x.dtype == tf.uint32 or x.dtype == tf.uint64:\n                raise TypeError(\"Data type %r is not supported\" % x.dtype)\n            x = tf.sparse.reduce_sum(x, axis=0)\n        elif isinstance(x, tf.RaggedTensor):\n            raise NotImplementedError(\"Elementwise sum does not support RaggedTensors.\")\n        else:\n            x = tf.reduce_sum(input_tensor=x, axis=0)\n        output_dtype, sum_fn = _sum_combine_fn_and_dtype(x.dtype)\n        return _numeric_combine(\n            inputs=[x],\n            fn=sum_fn,\n            default_accumulator_value=0,\n            reduce_instance_dims=reduce_instance_dims,\n            output_dtypes=[output_dtype],\n        )[0]\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.tfidf","title":"tfidf","text":"<pre><code>tfidf(\n    x: SparseTensor,\n    vocab_size: int,\n    smooth: bool = True,\n    name: Optional[str] = None,\n) -&gt; Tuple[SparseTensor, SparseTensor]\n</code></pre> <p>Maps the terms in x to their term frequency * inverse document frequency.</p> <p>The term frequency of a term in a document is calculated as (count of term in document) / (document size)</p> <p>The inverse document frequency of a term is, by default, calculated as 1 + log((corpus size + 1) / (count of documents containing term + 1)).</p> <p>Example usage:</p> <p>def preprocessing_fn(inputs): ...   integerized = tft.compute_and_apply_vocabulary(inputs['x']) ...   vocab_size = tft.get_num_buckets_for_transformed_feature(integerized) ...   vocab_index, tfidf_weight = tft.tfidf(integerized, vocab_size) ...   return { ...      'index': vocab_index, ...      'tf_idf': tfidf_weight, ...      'integerized': integerized, ...   } raw_data = [dict(x=[\"I\", \"like\", \"pie\", \"pie\", \"pie\"]), ...             dict(x=[\"yum\", \"yum\", \"pie\"])] feature_spec = dict(x=tf.io.VarLenFeature(tf.string)) raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec) with tft_beam.Context(temp_dir=tempfile.mkdtemp()): ...   transformed_dataset, transform_fn = ( ...       (raw_data, raw_data_metadata) ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn)) transformed_data, transformed_metadata = transformed_dataset transformed_data [{'index': array([0, 2, 3]), 'integerized': array([3, 2, 0, 0, 0]),   'tf_idf': array([0.6, 0.28109303, 0.28109303], dtype=float32)},  {'index': array([0, 1]), 'integerized': array([1, 1, 0]),   'tf_idf': array([0.33333334, 0.9369768 ], dtype=float32)}]</p> <pre><code>example strings: [[\"I\", \"like\", \"pie\", \"pie\", \"pie\"], [\"yum\", \"yum\", \"pie]]\nin: SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4],\n                          [1, 0], [1, 1], [1, 2]],\n                 values=[1, 2, 0, 0, 0, 3, 3, 0])\nout: SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [1, 0], [1, 1]],\n                  values=[1, 2, 0, 3, 0])\n     SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [1, 0], [1, 1]],\n                  values=[(1/5)*(log(3/2)+1), (1/5)*(log(3/2)+1), (3/5),\n                          (2/3)*(log(3/2)+1), (1/3)]\n</code></pre> <p>NOTE: the first doc's duplicate \"pie\" strings have been combined to   one output, as have the second doc's duplicate \"yum\" strings.</p> <p>x: A 2D <code>SparseTensor</code> representing int64 values (most likely that are the       result of calling <code>compute_and_apply_vocabulary</code> on a tokenized string).   vocab_size: An int - the count of vocab used to turn the string into int64s       including any OOV buckets.   smooth: A bool indicating if the inverse document frequency should be       smoothed. If True, which is the default, then the idf is calculated as       1 + log((corpus size + 1) / (document frequency of term + 1)).       Otherwise, the idf is       1 +log((corpus size) / (document frequency of term)), which could       result in a division by zero error.   name: (Optional) A name for this operation.</p> <p>Two <code>SparseTensor</code>s with indices [index_in_batch, index_in_bag_of_words].   The first has values vocab_index, which is taken from input <code>x</code>.   The second has values tfidf_weight.</p> <p>ValueError if <code>x</code> does not have 2 dimensions.</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef tfidf(\n    x: tf.SparseTensor, vocab_size: int, smooth: bool = True, name: Optional[str] = None\n) -&gt; Tuple[tf.SparseTensor, tf.SparseTensor]:\n    # pyformat: disable\n    \"\"\"Maps the terms in x to their term frequency * inverse document frequency.\n\n    The term frequency of a term in a document is calculated as\n    (count of term in document) / (document size)\n\n    The inverse document frequency of a term is, by default, calculated as\n    1 + log((corpus size + 1) / (count of documents containing term + 1)).\n\n\n    Example usage:\n\n    &gt;&gt;&gt; def preprocessing_fn(inputs):\n    ...   integerized = tft.compute_and_apply_vocabulary(inputs['x'])\n    ...   vocab_size = tft.get_num_buckets_for_transformed_feature(integerized)\n    ...   vocab_index, tfidf_weight = tft.tfidf(integerized, vocab_size)\n    ...   return {\n    ...      'index': vocab_index,\n    ...      'tf_idf': tfidf_weight,\n    ...      'integerized': integerized,\n    ...   }\n    &gt;&gt;&gt; raw_data = [dict(x=[\"I\", \"like\", \"pie\", \"pie\", \"pie\"]),\n    ...             dict(x=[\"yum\", \"yum\", \"pie\"])]\n    &gt;&gt;&gt; feature_spec = dict(x=tf.io.VarLenFeature(tf.string))\n    &gt;&gt;&gt; raw_data_metadata = tft.DatasetMetadata.from_feature_spec(feature_spec)\n    &gt;&gt;&gt; with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n    ...   transformed_dataset, transform_fn = (\n    ...       (raw_data, raw_data_metadata)\n    ...       | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\n    &gt;&gt;&gt; transformed_data, transformed_metadata = transformed_dataset\n    &gt;&gt;&gt; transformed_data\n    [{'index': array([0, 2, 3]), 'integerized': array([3, 2, 0, 0, 0]),\n      'tf_idf': array([0.6, 0.28109303, 0.28109303], dtype=float32)},\n     {'index': array([0, 1]), 'integerized': array([1, 1, 0]),\n      'tf_idf': array([0.33333334, 0.9369768 ], dtype=float32)}]\n\n      ```\n      example strings: [[\"I\", \"like\", \"pie\", \"pie\", \"pie\"], [\"yum\", \"yum\", \"pie]]\n      in: SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4],\n                                [1, 0], [1, 1], [1, 2]],\n                       values=[1, 2, 0, 0, 0, 3, 3, 0])\n      out: SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [1, 0], [1, 1]],\n                        values=[1, 2, 0, 3, 0])\n           SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [1, 0], [1, 1]],\n                        values=[(1/5)*(log(3/2)+1), (1/5)*(log(3/2)+1), (3/5),\n                                (2/3)*(log(3/2)+1), (1/3)]\n      ```\n\n      NOTE: the first doc's duplicate \"pie\" strings have been combined to\n      one output, as have the second doc's duplicate \"yum\" strings.\n\n    Args:\n    ----\n      x: A 2D `SparseTensor` representing int64 values (most likely that are the\n          result of calling `compute_and_apply_vocabulary` on a tokenized string).\n      vocab_size: An int - the count of vocab used to turn the string into int64s\n          including any OOV buckets.\n      smooth: A bool indicating if the inverse document frequency should be\n          smoothed. If True, which is the default, then the idf is calculated as\n          1 + log((corpus size + 1) / (document frequency of term + 1)).\n          Otherwise, the idf is\n          1 +log((corpus size) / (document frequency of term)), which could\n          result in a division by zero error.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      Two `SparseTensor`s with indices [index_in_batch, index_in_bag_of_words].\n      The first has values vocab_index, which is taken from input `x`.\n      The second has values tfidf_weight.\n\n    Raises:\n    ------\n      ValueError if `x` does not have 2 dimensions.\n    \"\"\"\n    # pyformat: enable\n    if x.get_shape().ndims != 2:\n        raise ValueError(\n            \"tft.tfidf requires a 2D SparseTensor input. \"\n            \"Input had {} dimensions.\".format(x.get_shape().ndims)\n        )\n\n    with tf.compat.v1.name_scope(name, \"tfidf\"):\n        cleaned_input = tf_utils.to_vocab_range(x, vocab_size)\n\n        term_frequencies = _to_term_frequency(cleaned_input, vocab_size)\n\n        count_docs_with_term_column = _count_docs_with_term(term_frequencies)\n        # Expand dims to get around the min_tensor_rank checks\n        sizes = tf.expand_dims(tf.shape(input=cleaned_input)[0], 0)\n        # [batch, vocab] - tfidf\n        tfidfs = _to_tfidf(\n            term_frequencies,\n            analyzers.sum(count_docs_with_term_column, reduce_instance_dims=False),\n            analyzers.sum(sizes),\n            smooth,\n        )\n        return _split_tfidfs_to_outputs(tfidfs)\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.tukey_h_params","title":"tukey_h_params","text":"<pre><code>tukey_h_params(\n    x: TensorType,\n    reduce_instance_dims: bool = True,\n    output_dtype: Optional[DType] = None,\n    name: Optional[str] = None,\n) -&gt; Tuple[Tensor, Tensor]\n</code></pre> <p>Computes the h parameters of the values of a <code>Tensor</code> over the dataset.</p> <p>This computes the parameters (hl, hr) of the samples, assuming a Tukey HH distribution, i.e. (x - tukey_location) / tukey_scale is a Tukey HH distribution with parameters hl (left parameter) and hr (right parameter). See the following publication for the definition of the Tukey HH distribution:</p> <p>Todd C. Headrick, and Mohan D. Pant. \"Characterizing Tukey h and hh-Distributions through L-Moments and the L-Correlation,\" ISRN Applied Mathematics, vol. 2012, 2012. doi:10.5402/2012/980153</p> <p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>. Its type must be floating       point (float{16|32|64}), or integral ([u]int{8|16|32|64}).   reduce_instance_dims: By default collapses the batch and instance dimensions       to arrive at a single scalar output. If False, only collapses the batch       dimension and outputs a vector of the same shape as the input.   output_dtype: (Optional) If not None, casts the output tensor to this type.   name: (Optional) A name for this operation.</p> <p>The tuple (hl, hr) containing two <code>Tensor</code> instances with the hl and hr   parameters. If <code>x</code> is floating point, each parameter will have the same type   as <code>x</code>. If <code>x</code> is integral, the output is cast to float32.</p> <p>TypeError: If the type of <code>x</code> is not supported.</p> Source code in <code>tensorflow_transform/analyzers.py</code> <pre><code>@common.log_api_use(common.ANALYZER_COLLECTION)\ndef tukey_h_params(\n    x: common_types.TensorType,\n    reduce_instance_dims: bool = True,\n    output_dtype: Optional[tf.DType] = None,\n    name: Optional[str] = None,\n) -&gt; Tuple[tf.Tensor, tf.Tensor]:\n    \"\"\"Computes the h parameters of the values of a `Tensor` over the dataset.\n\n    This computes the parameters (hl, hr) of the samples, assuming a Tukey HH\n    distribution, i.e. (x - tukey_location) / tukey_scale is a Tukey HH\n    distribution with parameters hl (left parameter) and hr (right parameter).\n    See the following publication for the definition of the Tukey HH distribution:\n\n    Todd C. Headrick, and Mohan D. Pant. \"Characterizing Tukey h and\n    hh-Distributions through L-Moments and the L-Correlation,\" ISRN Applied\n    Mathematics, vol. 2012, 2012. doi:10.5402/2012/980153\n\n    Args:\n    ----\n      x: A `Tensor`, `SparseTensor`, or `RaggedTensor`. Its type must be floating\n          point (float{16|32|64}), or integral ([u]int{8|16|32|64}).\n      reduce_instance_dims: By default collapses the batch and instance dimensions\n          to arrive at a single scalar output. If False, only collapses the batch\n          dimension and outputs a vector of the same shape as the input.\n      output_dtype: (Optional) If not None, casts the output tensor to this type.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      The tuple (hl, hr) containing two `Tensor` instances with the hl and hr\n      parameters. If `x` is floating point, each parameter will have the same type\n      as `x`. If `x` is integral, the output is cast to float32.\n\n    Raises:\n    ------\n      TypeError: If the type of `x` is not supported.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"tukey_h_params\"):\n        return _tukey_parameters(x, reduce_instance_dims, output_dtype)[2:]\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.tukey_location","title":"tukey_location","text":"<pre><code>tukey_location(\n    x: TensorType,\n    reduce_instance_dims: Optional[bool] = True,\n    output_dtype: Optional[DType] = None,\n    name: Optional[str] = None,\n) -&gt; Tensor\n</code></pre> <p>Computes the location of the values of a <code>Tensor</code> over the whole dataset.</p> <p>This computes the location of x, assuming a Tukey HH distribution, i.e. (x - tukey_location) / tukey_scale is a Tukey HH distribution with parameters tukey_h_params. See the following publication for the definition of the Tukey HH distribution:</p> <p>Todd C. Headrick, and Mohan D. Pant. \"Characterizing Tukey h and hh-Distributions through L-Moments and the L-Correlation,\" ISRN Applied Mathematics, vol. 2012, 2012. doi:10.5402/2012/980153</p> <p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>. Its type must be floating       point (float{16|32|64}), or integral ([u]int{8|16|32|64}).   reduce_instance_dims: By default collapses the batch and instance dimensions       to arrive at a single scalar output. If False, only collapses the batch       dimension and outputs a vector of the same shape as the input.   output_dtype: (Optional) If not None, casts the output tensor to this type.   name: (Optional) A name for this operation.</p> <p>A <code>Tensor</code> containing the location. If <code>x</code> is floating point, the location   will have the same type as <code>x</code>. If <code>x</code> is integral, the output is cast to   float32.</p> <p>TypeError: If the type of <code>x</code> is not supported.</p> Source code in <code>tensorflow_transform/analyzers.py</code> <pre><code>@common.log_api_use(common.ANALYZER_COLLECTION)\ndef tukey_location(\n    x: common_types.TensorType,\n    reduce_instance_dims: Optional[bool] = True,\n    output_dtype: Optional[tf.DType] = None,\n    name: Optional[str] = None,\n) -&gt; tf.Tensor:\n    \"\"\"Computes the location of the values of a `Tensor` over the whole dataset.\n\n    This computes the location of x, assuming a Tukey HH distribution, i.e.\n    (x - tukey_location) / tukey_scale is a Tukey HH distribution with parameters\n    tukey_h_params. See the following publication for the definition of the Tukey\n    HH distribution:\n\n    Todd C. Headrick, and Mohan D. Pant. \"Characterizing Tukey h and\n    hh-Distributions through L-Moments and the L-Correlation,\" ISRN Applied\n    Mathematics, vol. 2012, 2012. doi:10.5402/2012/980153\n\n    Args:\n    ----\n      x: A `Tensor`, `SparseTensor`, or `RaggedTensor`. Its type must be floating\n          point (float{16|32|64}), or integral ([u]int{8|16|32|64}).\n      reduce_instance_dims: By default collapses the batch and instance dimensions\n          to arrive at a single scalar output. If False, only collapses the batch\n          dimension and outputs a vector of the same shape as the input.\n      output_dtype: (Optional) If not None, casts the output tensor to this type.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A `Tensor` containing the location. If `x` is floating point, the location\n      will have the same type as `x`. If `x` is integral, the output is cast to\n      float32.\n\n    Raises:\n    ------\n      TypeError: If the type of `x` is not supported.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"tukey_location\"):\n        return _tukey_parameters(x, reduce_instance_dims, output_dtype)[0]\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.tukey_scale","title":"tukey_scale","text":"<pre><code>tukey_scale(\n    x: TensorType,\n    reduce_instance_dims: Optional[bool] = True,\n    output_dtype: Optional[DType] = None,\n    name: Optional[str] = None,\n) -&gt; Tensor\n</code></pre> <p>Computes the scale of the values of a <code>Tensor</code> over the whole dataset.</p> <p>This computes the scale of x, assuming a Tukey HH distribution, i.e. (x - tukey_location) / tukey_scale is a Tukey HH distribution with parameters tukey_h_params. See the following publication for the definition of the Tukey HH distribution:</p> <p>Todd C. Headrick, and Mohan D. Pant. \"Characterizing Tukey h and hh-Distributions through L-Moments and the L-Correlation,\" ISRN Applied Mathematics, vol. 2012, 2012. doi:10.5402/2012/980153</p> <p>x: A <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>. Its type must be floating       point (float{16|32|64}), or integral ([u]int{8|16|32|64}).   reduce_instance_dims: By default collapses the batch and instance dimensions       to arrive at a single scalar output. If False, only collapses the batch       dimension and outputs a vector of the same shape as the input.   output_dtype: (Optional) If not None, casts the output tensor to this type.   name: (Optional) A name for this operation.</p> <p>A <code>Tensor</code> containing the scale. If <code>x</code> is floating point, the location   will have the same type as <code>x</code>. If <code>x</code> is integral, the output is cast to   float32.</p> <p>TypeError: If the type of <code>x</code> is not supported.</p> Source code in <code>tensorflow_transform/analyzers.py</code> <pre><code>@common.log_api_use(common.ANALYZER_COLLECTION)\ndef tukey_scale(\n    x: common_types.TensorType,\n    reduce_instance_dims: Optional[bool] = True,\n    output_dtype: Optional[tf.DType] = None,\n    name: Optional[str] = None,\n) -&gt; tf.Tensor:\n    \"\"\"Computes the scale of the values of a `Tensor` over the whole dataset.\n\n    This computes the scale of x, assuming a Tukey HH distribution, i.e.\n    (x - tukey_location) / tukey_scale is a Tukey HH distribution with parameters\n    tukey_h_params. See the following publication for the definition of the Tukey\n    HH distribution:\n\n    Todd C. Headrick, and Mohan D. Pant. \"Characterizing Tukey h and\n    hh-Distributions through L-Moments and the L-Correlation,\" ISRN Applied\n    Mathematics, vol. 2012, 2012. doi:10.5402/2012/980153\n\n\n    Args:\n    ----\n      x: A `Tensor`, `SparseTensor`, or `RaggedTensor`. Its type must be floating\n          point (float{16|32|64}), or integral ([u]int{8|16|32|64}).\n      reduce_instance_dims: By default collapses the batch and instance dimensions\n          to arrive at a single scalar output. If False, only collapses the batch\n          dimension and outputs a vector of the same shape as the input.\n      output_dtype: (Optional) If not None, casts the output tensor to this type.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A `Tensor` containing the scale. If `x` is floating point, the location\n      will have the same type as `x`. If `x` is integral, the output is cast to\n      float32.\n\n    Raises:\n    ------\n      TypeError: If the type of `x` is not supported.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"tukey_scale\"):\n        return _tukey_parameters(x, reduce_instance_dims, output_dtype)[1]\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.var","title":"var","text":"<pre><code>var(\n    x: TensorType,\n    reduce_instance_dims: bool = True,\n    name: Optional[str] = None,\n    output_dtype: Optional[DType] = None,\n) -&gt; Tensor\n</code></pre> <p>Computes the variance of the values of a <code>Tensor</code> over the whole dataset.</p> <p>Uses the biased variance (0 delta degrees of freedom), as given by (x - mean(x))**2 / length(x).</p> <p>x: <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>. Its type must be floating       point (float{16|32|64}), or integral ([u]int{8|16|32|64}).   reduce_instance_dims: By default collapses the batch and instance dimensions       to arrive at a single scalar output. If False, only collapses the batch       dimension and outputs a vector of the same shape as the input.   name: (Optional) A name for this operation.   output_dtype: (Optional) If not None, casts the output tensor to this type.</p> <p>A <code>Tensor</code> containing the variance. If <code>x</code> is floating point, the variance   will have the same type as <code>x</code>. If <code>x</code> is integral, the output is cast to   float32. NaNs and infinite input values are ignored.</p> <p>TypeError: If the type of <code>x</code> is not supported.</p> Source code in <code>tensorflow_transform/analyzers.py</code> <pre><code>@common.log_api_use(common.ANALYZER_COLLECTION)\ndef var(\n    x: common_types.TensorType,\n    reduce_instance_dims: bool = True,\n    name: Optional[str] = None,\n    output_dtype: Optional[tf.DType] = None,\n) -&gt; tf.Tensor:\n    \"\"\"Computes the variance of the values of a `Tensor` over the whole dataset.\n\n    Uses the biased variance (0 delta degrees of freedom), as given by\n    (x - mean(x))**2 / length(x).\n\n    Args:\n    ----\n      x: `Tensor`, `SparseTensor`, or `RaggedTensor`. Its type must be floating\n          point (float{16|32|64}), or integral ([u]int{8|16|32|64}).\n      reduce_instance_dims: By default collapses the batch and instance dimensions\n          to arrive at a single scalar output. If False, only collapses the batch\n          dimension and outputs a vector of the same shape as the input.\n      name: (Optional) A name for this operation.\n      output_dtype: (Optional) If not None, casts the output tensor to this type.\n\n    Returns:\n    -------\n      A `Tensor` containing the variance. If `x` is floating point, the variance\n      will have the same type as `x`. If `x` is integral, the output is cast to\n      float32. NaNs and infinite input values are ignored.\n\n    Raises:\n    ------\n      TypeError: If the type of `x` is not supported.\n    \"\"\"\n    with tf.compat.v1.name_scope(name, \"var\"):\n        return _mean_and_var(x, reduce_instance_dims, output_dtype)[1]\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.vocabulary","title":"vocabulary","text":"<pre><code>vocabulary(\n    x: TensorType,\n    *,\n    top_k: Optional[int] = None,\n    frequency_threshold: Optional[int] = None,\n    vocab_filename: Optional[str] = None,\n    store_frequency: Optional[bool] = False,\n    reserved_tokens: Optional[\n        Union[Sequence[str], Tensor]\n    ] = None,\n    weights: Optional[Tensor] = None,\n    labels: Optional[Union[Tensor, SparseTensor]] = None,\n    use_adjusted_mutual_info: bool = False,\n    min_diff_from_avg: Optional[int] = None,\n    coverage_top_k: Optional[int] = None,\n    coverage_frequency_threshold: Optional[int] = None,\n    key_fn: Optional[Callable[[Any], Any]] = None,\n    fingerprint_shuffle: Optional[bool] = False,\n    file_format: VocabularyFileFormatType = DEFAULT_VOCABULARY_FILE_FORMAT,\n    name: Optional[str] = None,\n) -&gt; TemporaryAnalyzerOutputType\n</code></pre> <p>Computes the unique values of <code>x</code> over the whole dataset.</p> <p>Computes The unique values taken by <code>x</code>, which can be a <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code> of any size.  The unique values will be aggregated over all dimensions of <code>x</code> and all instances.</p> <p>In case <code>file_format</code> is 'text' and one of the tokens contains the '\\n' or '\\r' characters or is empty it will be discarded.</p> <p>If an integer <code>Tensor</code> is provided, its semantic type should be categorical not a continuous/numeric, since computing a vocabulary over a continuous feature is not appropriate.</p> <p>The unique values are sorted by decreasing frequency and then reverse lexicographical order (e.g. [('a', 5), ('c', 3), ('b', 3)]). This is true even if <code>x</code> is numerical dtype (e.g. [('3', 5), ('2', 3), ('111', 3)]).</p> <p>For large datasets it is highly recommended to either set frequency_threshold or top_k to control the size of the output, and also the run time of this operation.</p> <p>When labels are provided, we filter the vocabulary based on the relationship between the token's presence in a record and the label for that record, using (possibly adjusted) Mutual Information. Note: If labels are provided, the x input must be a unique set of per record, as the semantics of the mutual information calculation depend on a multi-hot representation of the input. Having unique input tokens per row is advisable but not required for a frequency-based vocabulary.</p> <p>WARNING: The following is experimental and is still being actively worked on.</p> <p>Supply <code>key_fn</code> if you would like to generate a vocabulary with coverage over specific keys.</p> <p>A \"coverage vocabulary\" is the union of two vocabulary \"arms\". The \"standard arm\" of the vocabulary is equivalent to the one generated by the same function call with no coverage arguments. Adding coverage only appends additional entries to the end of the standard vocabulary.</p> <p>The \"coverage arm\" of the vocabulary is determined by taking the <code>coverage_top_k</code> most frequent unique terms per key. A term's key is obtained by applying <code>key_fn</code> to the term. Use <code>coverage_frequency_threshold</code> to lower bound the frequency of entries in the coverage arm of the vocabulary.</p> <p>Note this is currently implemented for the case where the key is contained within each vocabulary entry (b/117796748).</p> <p>x: A categorical/discrete input <code>Tensor</code>, <code>SparseTensor</code>, or <code>RaggedTensor</code>     with dtype tf.string or tf.int[8|16|32|64]. The inputs should generally be     unique per row (i.e. a bag of words/ngrams representation).   top_k: Limit the generated vocabulary to the first <code>top_k</code> elements. If set     to None, the full vocabulary is generated.   frequency_threshold: Limit the generated vocabulary only to elements whose     absolute frequency is &gt;= to the supplied threshold. If set to None, the     full vocabulary is generated.  Absolute frequency means the number of     occurrences of the element in the dataset, as opposed to the proportion of     instances that contain that element.   vocab_filename: The file name for the vocabulary file. If None, a file name     will be chosen based on the current scope. If not None, should be unique     within a given preprocessing function. NOTE To make your pipelines     resilient to implementation details please set <code>vocab_filename</code> when you     are using the vocab_filename on a downstream component.   store_frequency: If True, frequency of the words is stored in the vocabulary     file. In the case labels are provided, the mutual information is stored in     the file instead. Each line in the file will be of the form 'frequency     word'. NOTE: if this is True then the computed vocabulary cannot be used     with <code>tft.apply_vocabulary</code> directly, since frequencies are added to the     beginning of each row of the vocabulary, which the mapper will not ignore.   reserved_tokens: (Optional) A list of tokens that should appear in the     vocabulary regardless of their appearance in the input. These tokens would     maintain their order, and have a reserved spot at the beginning of the     vocabulary. Note: this field has no affect on cache.   weights: (Optional) Weights <code>Tensor</code> for the vocabulary. It must have the     same shape as x.   labels: (Optional) Labels dense <code>Tensor</code> for the vocabulary. If provided,     the vocabulary is calculated based on mutual information with the label,     rather than frequency. The labels must have the same batch dimension as x.     If x is sparse, labels should be a 1D tensor reflecting row-wise labels.     If x is dense, labels can either be a 1D tensor of row-wise labels, or a     dense tensor of the identical shape as x (i.e. element-wise labels).     Labels should be a discrete integerized tensor (If the label is numeric,     it should first be bucketized; If the label is a string, an integer     vocabulary should first be applied). Note: <code>CompositeTensor</code> labels are     not yet supported (b/134931826). WARNING: When labels are provided, the     frequency_threshold argument functions as a mutual information threshold,     which is a float. TODO(b/116308354): Fix confusing naming.   use_adjusted_mutual_info: If true, and labels are provided, calculate     vocabulary using adjusted rather than raw mutual information.   min_diff_from_avg: MI (or AMI) of a feature x label will be adjusted to zero     whenever the difference between count and the expected (average) count is     lower than min_diff_from_average. This can be thought of as a regularizing     parameter that pushes small MI/AMI values to zero. If None, a default     parameter will be selected based on the size of the dataset (see     calculate_recommended_min_diff_from_avg).   coverage_top_k: (Optional), (Experimental) The minimum number of elements     per key to be included in the vocabulary.   coverage_frequency_threshold: (Optional), (Experimental) Limit the coverage     arm of the vocabulary only to elements whose absolute frequency is &gt;= this     threshold for a given key.   key_fn: (Optional), (Experimental) A fn that takes in a single entry of <code>x</code>     and returns the corresponding key for coverage calculation. If this is     <code>None</code>, no coverage arm is added to the vocabulary.   fingerprint_shuffle: (Optional), (Experimental) Whether to sort the     vocabularies by fingerprint instead of counts. This is useful for load     balancing on the training parameter servers. Shuffle only happens while     writing the files, so all the filters above (top_k, frequency_threshold,     etc) will still take effect.   file_format: (Optional) A str. The format of the resulting vocabulary file.     Accepted formats are: 'tfrecord_gzip', 'text'. 'tfrecord_gzip' requires     tensorflow&gt;=2.4. The default value is 'text'.   name: (Optional) A name for this operation.</p> <p>The path name for the vocabulary file containing the unique values of <code>x</code>.</p> <p>ValueError: If <code>top_k</code> or <code>frequency_threshold</code> is negative.     If <code>coverage_top_k</code> or <code>coverage_frequency_threshold</code> is negative.     If either <code>coverage_top_k</code> or <code>coverage_frequency_threshold</code> is specified       and <code>key_fn</code> is not.     If <code>key_fn</code> is specified and neither <code>coverage_top_k</code>, nor</p> Source code in <code>tensorflow_transform/analyzers.py</code> <pre><code>@common.log_api_use(common.ANALYZER_COLLECTION)\ndef vocabulary(\n    x: common_types.TensorType,\n    *,  # Force passing optional parameters by keys.\n    top_k: Optional[int] = None,\n    frequency_threshold: Optional[int] = None,\n    vocab_filename: Optional[str] = None,\n    store_frequency: Optional[bool] = False,\n    reserved_tokens: Optional[Union[Sequence[str], tf.Tensor]] = None,\n    weights: Optional[tf.Tensor] = None,\n    labels: Optional[Union[tf.Tensor, tf.SparseTensor]] = None,\n    use_adjusted_mutual_info: bool = False,\n    min_diff_from_avg: Optional[int] = None,\n    coverage_top_k: Optional[int] = None,\n    coverage_frequency_threshold: Optional[int] = None,\n    key_fn: Optional[Callable[[Any], Any]] = None,\n    fingerprint_shuffle: Optional[bool] = False,\n    file_format: common_types.VocabularyFileFormatType = DEFAULT_VOCABULARY_FILE_FORMAT,\n    name: Optional[str] = None,\n) -&gt; common_types.TemporaryAnalyzerOutputType:\n    r\"\"\"Computes the unique values of `x` over the whole dataset.\n\n    Computes The unique values taken by `x`, which can be a `Tensor`,\n    `SparseTensor`, or `RaggedTensor` of any size.  The unique values will be\n    aggregated over all dimensions of `x` and all instances.\n\n    In case `file_format` is 'text' and one of the tokens contains the '\\n' or\n    '\\r' characters or is empty it will be discarded.\n\n    If an integer `Tensor` is provided, its semantic type should be categorical\n    not a continuous/numeric, since computing a vocabulary over a continuous\n    feature is not appropriate.\n\n    The unique values are sorted by decreasing frequency and then reverse\n    lexicographical order (e.g. [('a', 5), ('c', 3), ('b', 3)]). This is true even\n    if `x` is numerical dtype (e.g. [('3', 5), ('2', 3), ('111', 3)]).\n\n    For large datasets it is highly recommended to either set frequency_threshold\n    or top_k to control the size of the output, and also the run time of this\n    operation.\n\n    When labels are provided, we filter the vocabulary based on the relationship\n    between the token's presence in a record and the label for that record, using\n    (possibly adjusted) Mutual Information. Note: If labels are provided, the x\n    input must be a unique set of per record, as the semantics of the mutual\n    information calculation depend on a multi-hot representation of the input.\n    Having unique input tokens per row is advisable but not required for a\n    frequency-based vocabulary.\n\n    WARNING: The following is experimental and is still being actively worked on.\n\n    Supply `key_fn` if you would like to generate a vocabulary with coverage over\n    specific keys.\n\n    A \"coverage vocabulary\" is the union of two vocabulary \"arms\". The \"standard\n    arm\" of the vocabulary is equivalent to the one generated by the same function\n    call with no coverage arguments. Adding coverage only appends additional\n    entries to the end of the standard vocabulary.\n\n    The \"coverage arm\" of the vocabulary is determined by taking the\n    `coverage_top_k` most frequent unique terms per key. A term's key is obtained\n    by applying `key_fn` to the term. Use `coverage_frequency_threshold` to lower\n    bound the frequency of entries in the coverage arm of the vocabulary.\n\n    Note this is currently implemented for the case where the key is contained\n    within each vocabulary entry (b/117796748).\n\n    Args:\n    ----\n      x: A categorical/discrete input `Tensor`, `SparseTensor`, or `RaggedTensor`\n        with dtype tf.string or tf.int[8|16|32|64]. The inputs should generally be\n        unique per row (i.e. a bag of words/ngrams representation).\n      top_k: Limit the generated vocabulary to the first `top_k` elements. If set\n        to None, the full vocabulary is generated.\n      frequency_threshold: Limit the generated vocabulary only to elements whose\n        absolute frequency is &gt;= to the supplied threshold. If set to None, the\n        full vocabulary is generated.  Absolute frequency means the number of\n        occurrences of the element in the dataset, as opposed to the proportion of\n        instances that contain that element.\n      vocab_filename: The file name for the vocabulary file. If None, a file name\n        will be chosen based on the current scope. If not None, should be unique\n        within a given preprocessing function. NOTE To make your pipelines\n        resilient to implementation details please set `vocab_filename` when you\n        are using the vocab_filename on a downstream component.\n      store_frequency: If True, frequency of the words is stored in the vocabulary\n        file. In the case labels are provided, the mutual information is stored in\n        the file instead. Each line in the file will be of the form 'frequency\n        word'. NOTE: if this is True then the computed vocabulary cannot be used\n        with `tft.apply_vocabulary` directly, since frequencies are added to the\n        beginning of each row of the vocabulary, which the mapper will not ignore.\n      reserved_tokens: (Optional) A list of tokens that should appear in the\n        vocabulary regardless of their appearance in the input. These tokens would\n        maintain their order, and have a reserved spot at the beginning of the\n        vocabulary. Note: this field has no affect on cache.\n      weights: (Optional) Weights `Tensor` for the vocabulary. It must have the\n        same shape as x.\n      labels: (Optional) Labels dense `Tensor` for the vocabulary. If provided,\n        the vocabulary is calculated based on mutual information with the label,\n        rather than frequency. The labels must have the same batch dimension as x.\n        If x is sparse, labels should be a 1D tensor reflecting row-wise labels.\n        If x is dense, labels can either be a 1D tensor of row-wise labels, or a\n        dense tensor of the identical shape as x (i.e. element-wise labels).\n        Labels should be a discrete integerized tensor (If the label is numeric,\n        it should first be bucketized; If the label is a string, an integer\n        vocabulary should first be applied). Note: `CompositeTensor` labels are\n        not yet supported (b/134931826). WARNING: When labels are provided, the\n        frequency_threshold argument functions as a mutual information threshold,\n        which is a float. TODO(b/116308354): Fix confusing naming.\n      use_adjusted_mutual_info: If true, and labels are provided, calculate\n        vocabulary using adjusted rather than raw mutual information.\n      min_diff_from_avg: MI (or AMI) of a feature x label will be adjusted to zero\n        whenever the difference between count and the expected (average) count is\n        lower than min_diff_from_average. This can be thought of as a regularizing\n        parameter that pushes small MI/AMI values to zero. If None, a default\n        parameter will be selected based on the size of the dataset (see\n        calculate_recommended_min_diff_from_avg).\n      coverage_top_k: (Optional), (Experimental) The minimum number of elements\n        per key to be included in the vocabulary.\n      coverage_frequency_threshold: (Optional), (Experimental) Limit the coverage\n        arm of the vocabulary only to elements whose absolute frequency is &gt;= this\n        threshold for a given key.\n      key_fn: (Optional), (Experimental) A fn that takes in a single entry of `x`\n        and returns the corresponding key for coverage calculation. If this is\n        `None`, no coverage arm is added to the vocabulary.\n      fingerprint_shuffle: (Optional), (Experimental) Whether to sort the\n        vocabularies by fingerprint instead of counts. This is useful for load\n        balancing on the training parameter servers. Shuffle only happens while\n        writing the files, so all the filters above (top_k, frequency_threshold,\n        etc) will still take effect.\n      file_format: (Optional) A str. The format of the resulting vocabulary file.\n        Accepted formats are: 'tfrecord_gzip', 'text'. 'tfrecord_gzip' requires\n        tensorflow&gt;=2.4. The default value is 'text'.\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      The path name for the vocabulary file containing the unique values of `x`.\n\n    Raises:\n    ------\n      ValueError: If `top_k` or `frequency_threshold` is negative.\n        If `coverage_top_k` or `coverage_frequency_threshold` is negative.\n        If either `coverage_top_k` or `coverage_frequency_threshold` is specified\n          and `key_fn` is not.\n        If `key_fn` is specified and neither `coverage_top_k`, nor\n    \"\"\"\n    top_k, frequency_threshold = _get_top_k_and_frequency_threshold(\n        top_k, frequency_threshold\n    )\n\n    if (coverage_top_k or coverage_frequency_threshold) and not key_fn:\n        raise ValueError(\n            \"You must specify `key_fn` if you specify `coverage_top_k\"\n            \" or `coverage_frequency_threshold` in `vocabulary`.\"\n        )\n\n    if key_fn and not (coverage_top_k or coverage_frequency_threshold):\n        raise ValueError(\n            \"You must specify `coverage_top_k`  or \"\n            \"`coverage_frequency_threshold` if you specify `key_fn` in\"\n            \" `vocabulary`.\"\n        )\n\n    if file_format not in ALLOWED_VOCABULARY_FILE_FORMATS:\n        raise ValueError(\n            '\"{}\" is not an accepted file_format. It should be one of: {}'.format(\n                file_format, ALLOWED_VOCABULARY_FILE_FORMATS\n            )\n        )\n\n    coverage_top_k, coverage_frequency_threshold = _get_top_k_and_frequency_threshold(\n        coverage_top_k, coverage_frequency_threshold\n    )\n\n    if x.dtype != tf.string and not x.dtype.is_integer:\n        raise ValueError(\"expected tf.string or integer but got %r\" % x.dtype)\n\n    if labels is not None and not labels.dtype.is_integer:\n        raise ValueError(\"expected integer labels but got %r\" % labels.dtype)\n\n    if (\n        frequency_threshold is None\n        and labels is None\n        and key_fn is None\n        and not fingerprint_shuffle\n        and top_k is not None\n        and top_k &lt;= LARGE_VOCAB_TOP_K\n    ):\n        logging.info(\n            \"If the number of unique tokens is smaller than the provided \"\n            \"top_k or approximation error is acceptable, consider using \"\n            \"tft.experimental.approximate_vocabulary for a potentially \"\n            \"more efficient implementation.\"\n        )\n\n    with tf.compat.v1.name_scope(name, \"vocabulary\"):\n        vocabulary_key = vocab_filename\n        vocab_filename = _get_vocab_filename(vocab_filename, store_frequency)\n        informativeness_threshold = float(\"-inf\")\n        coverage_informativeness_threshold = float(\"-inf\")\n        if labels is not None:\n            if weights is not None:\n                vocab_ordering_type = _VocabOrderingType.WEIGHTED_MUTUAL_INFORMATION\n            else:\n                vocab_ordering_type = _VocabOrderingType.MUTUAL_INFORMATION\n            # Correct for the overloaded `frequency_threshold` API.\n            if frequency_threshold is not None:\n                informativeness_threshold = frequency_threshold\n            frequency_threshold = 0.0\n            if coverage_frequency_threshold is not None:\n                coverage_informativeness_threshold = coverage_frequency_threshold\n            coverage_frequency_threshold = 0.0\n        elif weights is not None:\n            vocab_ordering_type = _VocabOrderingType.WEIGHTED_FREQUENCY\n        else:\n            vocab_ordering_type = _VocabOrderingType.FREQUENCY\n        analyzer_inputs = _get_vocabulary_analyzer_inputs(\n            vocab_ordering_type=vocab_ordering_type,\n            x=x,\n            file_format=file_format,\n            labels=labels,\n            weights=weights,\n        )\n        return _vocabulary_analyzer_nodes(\n            analyzer_inputs=analyzer_inputs,\n            input_dtype=x.dtype.name,\n            vocab_ordering_type=vocab_ordering_type,\n            vocab_filename=vocab_filename,\n            top_k=top_k,\n            frequency_threshold=frequency_threshold or 0,\n            informativeness_threshold=informativeness_threshold,\n            use_adjusted_mutual_info=use_adjusted_mutual_info,\n            min_diff_from_avg=min_diff_from_avg,\n            fingerprint_shuffle=fingerprint_shuffle,\n            store_frequency=store_frequency,\n            key_fn=key_fn,\n            coverage_top_k=coverage_top_k,\n            coverage_frequency_threshold=coverage_frequency_threshold or 0,\n            coverage_informativeness_threshold=coverage_informativeness_threshold,\n            file_format=file_format,\n            vocabulary_key=vocabulary_key,\n            reserved_tokens=reserved_tokens,\n        )\n</code></pre>"},{"location":"api_docs/python/tft/#tensorflow_transform.word_count","title":"word_count","text":"<pre><code>word_count(\n    tokens: Union[SparseTensor, RaggedTensor],\n    name: Optional[str] = None,\n) -&gt; Tensor\n</code></pre> <p>Find the token count of each document/row.</p> <p><code>tokens</code> is either a <code>RaggedTensor</code> or <code>SparseTensor</code>, representing tokenized strings. This function simply returns size of each row, so the dtype is not constrained to string.</p>"},{"location":"api_docs/python/tft/#tensorflow_transform.word_count--example","title":"Example:","text":"<p>sparse = tf.SparseTensor(indices=[[0, 0], [0, 1], [2, 2]], ...                          values=['a', 'b', 'c'], dense_shape=(4, 4)) tft.word_count(sparse) </p> <p>tokens: either     (1) a <code>SparseTensor</code>, or     (2) a <code>RaggedTensor</code> with ragged rank of 1, non-ragged rank of 1     of dtype <code>tf.string</code> containing tokens to be counted   name: (Optional) A name for this operation.</p> <p>A one-dimensional <code>Tensor</code> the token counts of each row.</p> <p>ValueError: if tokens is neither sparse nor ragged</p> Source code in <code>tensorflow_transform/mappers.py</code> <pre><code>@common.log_api_use(common.MAPPER_COLLECTION)\ndef word_count(\n    tokens: Union[tf.SparseTensor, tf.RaggedTensor], name: Optional[str] = None\n) -&gt; tf.Tensor:\n    # pyformat: disable\n    \"\"\"Find the token count of each document/row.\n\n    `tokens` is either a `RaggedTensor` or `SparseTensor`, representing tokenized\n    strings. This function simply returns size of each row, so the dtype is not\n    constrained to string.\n\n    Example:\n    -------\n    &gt;&gt;&gt; sparse = tf.SparseTensor(indices=[[0, 0], [0, 1], [2, 2]],\n    ...                          values=['a', 'b', 'c'], dense_shape=(4, 4))\n    &gt;&gt;&gt; tft.word_count(sparse)\n    &lt;tf.Tensor: shape=(4,), dtype=int64, numpy=array([2, 0, 1, 0])&gt;\n\n    Args:\n    ----\n      tokens: either\n        (1) a `SparseTensor`, or\n        (2) a `RaggedTensor` with ragged rank of 1, non-ragged rank of 1\n        of dtype `tf.string` containing tokens to be counted\n      name: (Optional) A name for this operation.\n\n    Returns:\n    -------\n      A one-dimensional `Tensor` the token counts of each row.\n\n    Raises:\n    ------\n      ValueError: if tokens is neither sparse nor ragged\n    \"\"\"\n    # pyformat: enable\n    with tf.compat.v1.name_scope(name, \"word_count\"):\n        if isinstance(tokens, tf.RaggedTensor):\n            return tokens.row_lengths()\n        elif isinstance(tokens, tf.SparseTensor):\n            result = tf.sparse.reduce_sum(\n                tf.SparseTensor(\n                    indices=tokens.indices,\n                    values=tf.ones_like(tokens.values, dtype=tf.int64),\n                    dense_shape=tokens.dense_shape,\n                ),\n                axis=list(range(1, tokens.get_shape().ndims)),\n            )\n            result.set_shape([tokens.shape[0]])\n            return result\n        else:\n            raise ValueError(\"Invalid token tensor\")\n</code></pre>"}]}